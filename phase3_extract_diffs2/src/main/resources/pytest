('testing', 'test_setuponly.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -2,6 +2,7 @@

 import pytest
 from _pytest.config import ExitCode
+from _pytest.pytester import Pytester


 @pytest.fixture(params=["--setup-only", "--setup-plan", "--setup-show"], scope="module")
@@ -9,8 +10,10 @@
     return request.param


-def test_show_only_active_fixtures(testdir, mode, dummy_yaml_custom_test):
-    testdir.makepyfile(
+def test_show_only_active_fixtures(
+    pytester: Pytester, mode, dummy_yaml_custom_test
+) -> None:
+    pytester.makepyfile(
         '''
         import pytest
         @pytest.fixture
@@ -24,7 +27,7 @@
     '''
     )

-    result = testdir.runpytest(mode)
+    result = pytester.runpytest(mode)
     assert result.ret == 0

     result.stdout.fnmatch_lines(
@@ -33,8 +36,8 @@
     result.stdout.no_fnmatch_line("*_arg0*")


-def test_show_different_scopes(testdir, mode):
-    p = testdir.makepyfile(
+def test_show_different_scopes(pytester: Pytester, mode) -> None:
+    p = pytester.makepyfile(
         '''
         import pytest
         @pytest.fixture
@@ -48,7 +51,7 @@
     '''
     )

-    result = testdir.runpytest(mode, p)
+    result = pytester.runpytest(mode, p)
     assert result.ret == 0

     result.stdout.fnmatch_lines(
@@ -62,8 +65,8 @@
     )


-def test_show_nested_fixtures(testdir, mode):
-    testdir.makeconftest(
+def test_show_nested_fixtures(pytester: Pytester, mode) -> None:
+    pytester.makeconftest(
         '''
         import pytest
         @pytest.fixture(scope='session')
@@ -71,7 +74,7 @@
             """session scoped fixture"""
         '''
     )
-    p = testdir.makepyfile(
+    p = pytester.makepyfile(
         '''
         import pytest
         @pytest.fixture(scope='function')
@@ -82,7 +85,7 @@
     '''
     )

-    result = testdir.runpytest(mode, p)
+    result = pytester.runpytest(mode, p)
     assert result.ret == 0

     result.stdout.fnmatch_lines(
@@ -96,8 +99,8 @@
     )


-def test_show_fixtures_with_autouse(testdir, mode):
-    p = testdir.makepyfile(
+def test_show_fixtures_with_autouse(pytester: Pytester, mode) -> None:
+    p = pytester.makepyfile(
         '''
         import pytest
         @pytest.fixture
@@ -111,7 +114,7 @@
     '''
     )

-    result = testdir.runpytest(mode, p)
+    result = pytester.runpytest(mode, p)
     assert result.ret == 0

     result.stdout.fnmatch_lines(
@@ -123,8 +126,8 @@
     )


-def test_show_fixtures_with_parameters(testdir, mode):
-    testdir.makeconftest(
+def test_show_fixtures_with_parameters(pytester: Pytester, mode) -> None:
+    pytester.makeconftest(
         '''
         import pytest
         @pytest.fixture(scope='session', params=['foo', 'bar'])
@@ -132,7 +135,7 @@
             """session scoped fixture"""
         '''
     )
-    p = testdir.makepyfile(
+    p = pytester.makepyfile(
         '''
         import pytest
         @pytest.fixture(scope='function')
@@ -143,7 +146,7 @@
     '''
     )

-    result = testdir.runpytest(mode, p)
+    result = pytester.runpytest(mode, p)
     assert result.ret == 0

     result.stdout.fnmatch_lines(
@@ -156,8 +159,8 @@
     )


-def test_show_fixtures_with_parameter_ids(testdir, mode):
-    testdir.makeconftest(
+def test_show_fixtures_with_parameter_ids(pytester: Pytester, mode) -> None:
+    pytester.makeconftest(
         '''
         import pytest
         @pytest.fixture(
@@ -166,7 +169,7 @@
             """session scoped fixture"""
         '''
     )
-    p = testdir.makepyfile(
+    p = pytester.makepyfile(
         '''
         import pytest
         @pytest.fixture(scope='function')
@@ -177,7 +180,7 @@
     '''
     )

-    result = testdir.runpytest(mode, p)
+    result = pytester.runpytest(mode, p)
     assert result.ret == 0

     result.stdout.fnmatch_lines(
@@ -185,8 +188,8 @@
     )


-def test_show_fixtures_with_parameter_ids_function(testdir, mode):
-    p = testdir.makepyfile(
+def test_show_fixtures_with_parameter_ids_function(pytester: Pytester, mode) -> None:
+    p = pytester.makepyfile(
         """
         import pytest
         @pytest.fixture(params=['foo', 'bar'], ids=lambda p: p.upper())
@@ -197,7 +200,7 @@
     """
     )

-    result = testdir.runpytest(mode, p)
+    result = pytester.runpytest(mode, p)
     assert result.ret == 0

     result.stdout.fnmatch_lines(
@@ -205,8 +208,8 @@
     )


-def test_dynamic_fixture_request(testdir):
-    p = testdir.makepyfile(
+def test_dynamic_fixture_request(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
         """
         import pytest
         @pytest.fixture()
@@ -220,7 +223,7 @@
     """
     )

-    result = testdir.runpytest("--setup-only", p)
+    result = pytester.runpytest("--setup-only", p)
     assert result.ret == 0

     result.stdout.fnmatch_lines(
@@ -231,8 +234,8 @@
     )


-def test_capturing(testdir):
-    p = testdir.makepyfile(
+def test_capturing(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
         """
         import pytest, sys
         @pytest.fixture()
@@ -247,15 +250,15 @@
     """
     )

-    result = testdir.runpytest("--setup-only", p)
+    result = pytester.runpytest("--setup-only", p)
     result.stdout.fnmatch_lines(
         ["this should be captured", "this should also be captured"]
     )


-def test_show_fixtures_and_execute_test(testdir):
+def test_show_fixtures_and_execute_test(pytester: Pytester) -> None:
     """Verify that setups are shown and tests are executed."""
-    p = testdir.makepyfile(
+    p = pytester.makepyfile(
         """
         import pytest
         @pytest.fixture
@@ -266,7 +269,7 @@
     """
     )

-    result = testdir.runpytest("--setup-show", p)
+    result = pytester.runpytest("--setup-show", p)
     assert result.ret == 1

     result.stdout.fnmatch_lines(
@@ -274,8 +277,8 @@
     )


-def test_setup_show_with_KeyboardInterrupt_in_test(testdir):
-    p = testdir.makepyfile(
+def test_setup_show_with_KeyboardInterrupt_in_test(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
         """
         import pytest
         @pytest.fixture
@@ -285,7 +288,7 @@
             raise KeyboardInterrupt()
     """
     )
-    result = testdir.runpytest("--setup-show", p, no_reraise_ctrlc=True)
+    result = pytester.runpytest("--setup-show", p, no_reraise_ctrlc=True)
     result.stdout.fnmatch_lines(
         [
             "*SETUP    F arg*",
@@ -298,9 +301,9 @@
     assert result.ret == ExitCode.INTERRUPTED


-def test_show_fixture_action_with_bytes(testdir):
+def test_show_fixture_action_with_bytes(pytester: Pytester) -> None:
     # Issue 7126, BytesWarning when using --setup-show with bytes parameter
-    test_file = testdir.makepyfile(
+    test_file = pytester.makepyfile(
         """
         import pytest

@@ -309,7 +312,7 @@
             pass
         """
     )
-    result = testdir.run(
+    result = pytester.run(
         sys.executable, "-bb", "-m", "pytest", "--setup-show", str(test_file)
     )
     assert result.ret == 0
('testing', 'test_assertrewrite.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -2,6 +2,7 @@
 import errno
 import glob
 import importlib
+import marshal
 import os
 import py_compile
 import stat
@@ -9,27 +10,31 @@
 import textwrap
 import zipfile
 from functools import partial
+from pathlib import Path
+from typing import cast
 from typing import Dict
+from typing import Generator
 from typing import List
 from typing import Mapping
 from typing import Optional
 from typing import Set
-
-import py
+from unittest import mock

 import _pytest._code
 import pytest
+from _pytest._io.saferepr import DEFAULT_REPR_MAX_SIZE
 from _pytest.assertion import util
 from _pytest.assertion.rewrite import _get_assertion_exprs
+from _pytest.assertion.rewrite import _get_maxsize_for_saferepr
 from _pytest.assertion.rewrite import AssertionRewritingHook
 from _pytest.assertion.rewrite import get_cache_dir
 from _pytest.assertion.rewrite import PYC_TAIL
 from _pytest.assertion.rewrite import PYTEST_TAG
 from _pytest.assertion.rewrite import rewrite_asserts
+from _pytest.config import Config
 from _pytest.config import ExitCode
 from _pytest.pathlib import make_numbered_dir
-from _pytest.pathlib import Path
-from _pytest.pytester import Testdir
+from _pytest.pytester import Pytester


 def rewrite(src: str) -> ast.Module:
@@ -42,10 +47,10 @@
     f, extra_ns: Optional[Mapping[str, object]] = None, *, must_pass: bool = False
 ) -> Optional[str]:
     """Rewrite the assertions in f, run it, and get the failure message."""
-    src = "\n".join(_pytest._code.Code(f).source().lines)
+    src = "\n".join(_pytest._code.Code.from_function(f).source().lines)
     mod = rewrite(src)
     code = compile(mod, "<test>", "exec")
-    ns = {}  # type: Dict[str, object]
+    ns: Dict[str, object] = {}
     if extra_ns is not None:
         ns.update(extra_ns)
     exec(code, ns)
@@ -66,7 +71,7 @@


 class TestAssertionRewrite:
-    def test_place_initial_imports(self):
+    def test_place_initial_imports(self) -> None:
         s = """'Doc string'\nother = stuff"""
         m = rewrite(s)
         assert isinstance(m.body[0], ast.Expr)
@@ -108,6 +113,28 @@
             assert imp.col_offset == 0
         assert isinstance(m.body[3], ast.Expr)

+    def test_location_is_set(self) -> None:
+        s = textwrap.dedent(
+            """
+
+        assert False, (
+
+            "Ouch"
+          )
+
+        """
+        )
+        m = rewrite(s)
+        for node in m.body:
+            if isinstance(node, ast.Import):
+                continue
+            for n in [node, *ast.iter_child_nodes(node)]:
+                assert n.lineno == 3
+                assert n.col_offset == 0
+                if sys.version_info >= (3, 8):
+                    assert n.end_lineno == 6
+                    assert n.end_col_offset == 3
+
     def test_dont_rewrite(self) -> None:
         s = """'PYTEST_DONT_REWRITE'\nassert 14"""
         m = rewrite(s)
@@ -115,19 +142,19 @@
         assert isinstance(m.body[1], ast.Assert)
         assert m.body[1].msg is None

-    def test_dont_rewrite_plugin(self, testdir):
+    def test_dont_rewrite_plugin(self, pytester: Pytester) -> None:
         contents = {
             "conftest.py": "pytest_plugins = 'plugin'; import plugin",
             "plugin.py": "'PYTEST_DONT_REWRITE'",
             "test_foo.py": "def test_foo(): pass",
         }
-        testdir.makepyfile(**contents)
-        result = testdir.runpytest_subprocess()
+        pytester.makepyfile(**contents)
+        result = pytester.runpytest_subprocess()
         assert "warning" not in "".join(result.outlines)

-    def test_rewrites_plugin_as_a_package(self, testdir):
-        pkgdir = testdir.mkpydir("plugin")
-        pkgdir.join("__init__.py").write(
+    def test_rewrites_plugin_as_a_package(self, pytester: Pytester) -> None:
+        pkgdir = pytester.mkpydir("plugin")
+        pkgdir.joinpath("__init__.py").write_text(
             "import pytest\n"
             "@pytest.fixture\n"
             "def special_asserter():\n"
@@ -135,26 +162,27 @@
             "        assert x == y\n"
             "    return special_assert\n"
         )
-        testdir.makeconftest('pytest_plugins = ["plugin"]')
-        testdir.makepyfile("def test(special_asserter): special_asserter(1, 2)\n")
-        result = testdir.runpytest()
+        pytester.makeconftest('pytest_plugins = ["plugin"]')
+        pytester.makepyfile("def test(special_asserter): special_asserter(1, 2)\n")
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*assert 1 == 2*"])

-    def test_honors_pep_235(self, testdir, monkeypatch):
+    def test_honors_pep_235(self, pytester: Pytester, monkeypatch) -> None:
         # note: couldn't make it fail on macos with a single `sys.path` entry
         # note: these modules are named `test_*` to trigger rewriting
-        testdir.tmpdir.join("test_y.py").write("x = 1")
-        xdir = testdir.tmpdir.join("x").ensure_dir()
-        xdir.join("test_Y").ensure_dir().join("__init__.py").write("x = 2")
-        testdir.makepyfile(
+        pytester.makepyfile(test_y="x = 1")
+        xdir = pytester.mkdir("x")
+        pytester.mkpydir(str(xdir.joinpath("test_Y")))
+        xdir.joinpath("test_Y").joinpath("__init__.py").write_text("x = 2")
+        pytester.makepyfile(
             "import test_y\n"
             "import test_Y\n"
             "def test():\n"
             "    assert test_y.x == 1\n"
             "    assert test_Y.x == 2\n"
         )
-        monkeypatch.syspath_prepend(xdir)
-        testdir.runpytest().assert_outcomes(passed=1)
+        monkeypatch.syspath_prepend(str(xdir))
+        pytester.runpytest().assert_outcomes(passed=1)

     def test_name(self, request) -> None:
         def f1() -> None:
@@ -176,16 +204,8 @@
         def f4() -> None:
             assert sys == 42  # type: ignore[comparison-overlap]

-        verbose = request.config.getoption("verbose")
         msg = getmsg(f4, {"sys": sys})
-        if verbose > 0:
-            assert msg == (
-                "assert <module 'sys' (built-in)> == 42\n"
-                "  +<module 'sys' (built-in)>\n"
-                "  -42"
-            )
-        else:
-            assert msg == "assert sys == 42"
+        assert msg == "assert sys == 42"

         def f5() -> None:
             assert cls == 42  # type: ignore[name-defined]  # noqa: F821
@@ -196,20 +216,7 @@
         msg = getmsg(f5, {"cls": X})
         assert msg is not None
         lines = msg.splitlines()
-        if verbose > 1:
-            assert lines == [
-                "assert {!r} == 42".format(X),
-                "  +{!r}".format(X),
-                "  -42",
-            ]
-        elif verbose > 0:
-            assert lines == [
-                "assert <class 'test_...e.<locals>.X'> == 42",
-                "  +{!r}".format(X),
-                "  -42",
-            ]
-        else:
-            assert lines == ["assert cls == 42"]
+        assert lines == ["assert cls == 42"]

     def test_assertrepr_compare_same_width(self, request) -> None:
         """Should use same width/truncation with same initial width."""
@@ -251,87 +258,84 @@
         msg = getmsg(f, {"cls": Y})
         assert msg is not None
         lines = msg.splitlines()
-        if request.config.getoption("verbose") > 0:
-            assert lines == ["assert 3 == 2", "  +3", "  -2"]
-        else:
-            assert lines == [
-                "assert 3 == 2",
-                " +  where 3 = Y.foo",
-                " +    where Y = cls()",
-            ]
-
-    def test_assert_already_has_message(self):
+        assert lines == [
+            "assert 3 == 2",
+            " +  where 3 = Y.foo",
+            " +    where Y = cls()",
+        ]
+
+    def test_assert_already_has_message(self) -> None:
         def f():
             assert False, "something bad!"

         assert getmsg(f) == "AssertionError: something bad!\nassert False"

-    def test_assertion_message(self, testdir):
-        testdir.makepyfile(
+    def test_assertion_message(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             def test_foo():
                 assert 1 == 2, "The failure message"
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret == 1
         result.stdout.fnmatch_lines(
             ["*AssertionError*The failure message*", "*assert 1 == 2*"]
         )

-    def test_assertion_message_multiline(self, testdir):
-        testdir.makepyfile(
+    def test_assertion_message_multiline(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             def test_foo():
                 assert 1 == 2, "A multiline\\nfailure message"
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret == 1
         result.stdout.fnmatch_lines(
             ["*AssertionError*A multiline*", "*failure message*", "*assert 1 == 2*"]
         )

-    def test_assertion_message_tuple(self, testdir):
-        testdir.makepyfile(
+    def test_assertion_message_tuple(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             def test_foo():
                 assert 1 == 2, (1, 2)
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret == 1
         result.stdout.fnmatch_lines(
             ["*AssertionError*%s*" % repr((1, 2)), "*assert 1 == 2*"]
         )

-    def test_assertion_message_expr(self, testdir):
-        testdir.makepyfile(
+    def test_assertion_message_expr(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             def test_foo():
                 assert 1 == 2, 1 + 2
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret == 1
         result.stdout.fnmatch_lines(["*AssertionError*3*", "*assert 1 == 2*"])

-    def test_assertion_message_escape(self, testdir):
-        testdir.makepyfile(
+    def test_assertion_message_escape(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             def test_foo():
                 assert 1 == 2, 'To be escaped: %'
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret == 1
         result.stdout.fnmatch_lines(
             ["*AssertionError: To be escaped: %", "*assert 1 == 2"]
         )

-    def test_assertion_messages_bytes(self, testdir):
-        testdir.makepyfile("def test_bytes_assertion():\n    assert False, b'ohai!'\n")
-        result = testdir.runpytest()
+    def test_assertion_messages_bytes(self, pytester: Pytester) -> None:
+        pytester.makepyfile("def test_bytes_assertion():\n    assert False, b'ohai!'\n")
+        result = pytester.runpytest()
         assert result.ret == 1
         result.stdout.fnmatch_lines(["*AssertionError: b'ohai!'", "*assert False"])

@@ -381,7 +385,7 @@
         )

         def f7() -> None:
-            assert False or x()  # type: ignore[unreachable]
+            assert False or x()

         assert (
             getmsg(f7, {"x": x})
@@ -471,12 +475,12 @@
         assert getmsg(f1) == "assert ((3 % 2) and False)"

         def f2() -> None:
-            assert False or 4 % 2  # type: ignore[unreachable]
+            assert False or 4 % 2

         assert getmsg(f2) == "assert (False or (4 % 2))"

-    def test_at_operator_issue1290(self, testdir):
-        testdir.makepyfile(
+    def test_at_operator_issue1290(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             class Matrix(object):
                 def __init__(self, num):
@@ -487,11 +491,11 @@
             def test_multmat_operator():
                 assert Matrix(2) @ Matrix(3) == 6"""
         )
-        testdir.runpytest().assert_outcomes(passed=1)
-
-    def test_starred_with_side_effect(self, testdir):
+        pytester.runpytest().assert_outcomes(passed=1)
+
+    def test_starred_with_side_effect(self, pytester: Pytester) -> None:
         """See #4412"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """\
             def test():
                 f = lambda x: x
@@ -499,7 +503,7 @@
                 assert 2 * next(x) == f(*[next(x)])
             """
         )
-        testdir.runpytest().assert_outcomes(passed=1)
+        pytester.runpytest().assert_outcomes(passed=1)

     def test_call(self) -> None:
         def g(a=42, *args, **kwargs) -> bool:
@@ -629,16 +633,13 @@

         getmsg(f5, must_pass=True)

-    def test_len(self, request):
+    def test_len(self, request) -> None:
         def f():
             values = list(range(10))
             assert len(values) == 11

         msg = getmsg(f)
-        if request.config.getoption("verbose") > 0:
-            assert msg == "assert 10 == 11\n  +10\n  -11"
-        else:
-            assert msg == "assert 10 == 11\n +  where 10 = len([0, 1, 2, 3, 4, 5, ...])"
+        assert msg == "assert 10 == 11\n +  where 10 = len([0, 1, 2, 3, 4, 5, ...])"

     def test_custom_reprcompare(self, monkeypatch) -> None:
         def my_reprcompare1(op, left, right) -> str:
@@ -652,7 +653,7 @@
         assert getmsg(f1) == "assert 42"

         def my_reprcompare2(op, left, right) -> str:
-            return "{} {} {}".format(left, op, right)
+            return f"{left} {op} {right}"

         monkeypatch.setattr(util, "_reprcompare", my_reprcompare2)

@@ -704,10 +705,7 @@
         msg = getmsg(f)
         assert msg is not None
         lines = util._format_lines([msg])
-        if request.config.getoption("verbose") > 0:
-            assert lines == ["assert 0 == 1\n  +0\n  -1"]
-        else:
-            assert lines == ["assert 0 == 1\n +  where 1 = \\n{ \\n~ \\n}.a"]
+        assert lines == ["assert 0 == 1\n +  where 1 = \\n{ \\n~ \\n}.a"]

     def test_custom_repr_non_ascii(self) -> None:
         def f() -> None:
@@ -727,31 +725,31 @@


 class TestRewriteOnImport:
-    def test_pycache_is_a_file(self, testdir):
-        testdir.tmpdir.join("__pycache__").write("Hello")
-        testdir.makepyfile(
+    def test_pycache_is_a_file(self, pytester: Pytester) -> None:
+        pytester.path.joinpath("__pycache__").write_text("Hello")
+        pytester.makepyfile(
             """
             def test_rewritten():
                 assert "@py_builtins" in globals()"""
         )
-        assert testdir.runpytest().ret == 0
-
-    def test_pycache_is_readonly(self, testdir):
-        cache = testdir.tmpdir.mkdir("__pycache__")
-        old_mode = cache.stat().mode
+        assert pytester.runpytest().ret == 0
+
+    def test_pycache_is_readonly(self, pytester: Pytester) -> None:
+        cache = pytester.mkdir("__pycache__")
+        old_mode = cache.stat().st_mode
         cache.chmod(old_mode ^ stat.S_IWRITE)
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_rewritten():
                 assert "@py_builtins" in globals()"""
         )
         try:
-            assert testdir.runpytest().ret == 0
+            assert pytester.runpytest().ret == 0
         finally:
             cache.chmod(old_mode)

-    def test_zipfile(self, testdir):
-        z = testdir.tmpdir.join("myzip.zip")
+    def test_zipfile(self, pytester: Pytester) -> None:
+        z = pytester.path.joinpath("myzip.zip")
         z_fn = str(z)
         f = zipfile.ZipFile(z_fn, "w")
         try:
@@ -760,33 +758,63 @@
         finally:
             f.close()
         z.chmod(256)
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import sys
             sys.path.append(%r)
             import test_gum.test_lizard"""
             % (z_fn,)
         )
-        assert testdir.runpytest().ret == ExitCode.NO_TESTS_COLLECTED
-
-    def test_readonly(self, testdir):
-        sub = testdir.mkdir("testing")
-        sub.join("test_readonly.py").write(
+        assert pytester.runpytest().ret == ExitCode.NO_TESTS_COLLECTED
+
+    @pytest.mark.skipif(
+        sys.version_info < (3, 9),
+        reason="importlib.resources.files was introduced in 3.9",
+    )
+    def test_load_resource_via_files_with_rewrite(self, pytester: Pytester) -> None:
+        example = pytester.path.joinpath("demo") / "example"
+        init = pytester.path.joinpath("demo") / "__init__.py"
+        pytester.makepyfile(
+            **{
+                "demo/__init__.py": """
+                from importlib.resources import files
+
+                def load():
+                    return files(__name__)
+                """,
+                "test_load": f"""
+                pytest_plugins = ["demo"]
+
+                def test_load():
+                    from demo import load
+                    found = {{str(i) for i in load().iterdir() if i.name != "__pycache__"}}
+                    assert found == {{{str(example)!r}, {str(init)!r}}}
+                """,
+            }
+        )
+        example.mkdir()
+
+        assert pytester.runpytest("-vv").ret == ExitCode.OK
+
+    def test_readonly(self, pytester: Pytester) -> None:
+        sub = pytester.mkdir("testing")
+        sub.joinpath("test_readonly.py").write_bytes(
             b"""
 def test_rewritten():
     assert "@py_builtins" in globals()
             """,
-            "wb",
-        )
-        old_mode = sub.stat().mode
+        )
+        old_mode = sub.stat().st_mode
         sub.chmod(320)
         try:
-            assert testdir.runpytest().ret == 0
+            assert pytester.runpytest().ret == 0
         finally:
             sub.chmod(old_mode)

-    def test_dont_write_bytecode(self, testdir, monkeypatch):
-        testdir.makepyfile(
+    def test_dont_write_bytecode(self, pytester: Pytester, monkeypatch) -> None:
+        monkeypatch.delenv("PYTHONPYCACHEPREFIX", raising=False)
+
+        pytester.makepyfile(
             """
             import os
             def test_no_bytecode():
@@ -795,17 +823,20 @@
                 assert not os.path.exists(os.path.dirname(__cached__))"""
         )
         monkeypatch.setenv("PYTHONDONTWRITEBYTECODE", "1")
-        assert testdir.runpytest_subprocess().ret == 0
-
-    def test_orphaned_pyc_file(self, testdir):
-        testdir.makepyfile(
+        assert pytester.runpytest_subprocess().ret == 0
+
+    def test_orphaned_pyc_file(self, pytester: Pytester, monkeypatch) -> None:
+        monkeypatch.delenv("PYTHONPYCACHEPREFIX", raising=False)
+        monkeypatch.setattr(sys, "pycache_prefix", None, raising=False)
+
+        pytester.makepyfile(
             """
             import orphan
             def test_it():
                 assert orphan.value == 17
             """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             orphan="""
             value = 17
             """
@@ -821,100 +852,105 @@
             assert len(pycs) == 1
             os.rename(pycs[0], "orphan.pyc")

-        assert testdir.runpytest().ret == 0
-
-    def test_cached_pyc_includes_pytest_version(self, testdir, monkeypatch):
+        assert pytester.runpytest().ret == 0
+
+    def test_cached_pyc_includes_pytest_version(
+        self, pytester: Pytester, monkeypatch
+    ) -> None:
         """Avoid stale caches (#1671)"""
         monkeypatch.delenv("PYTHONDONTWRITEBYTECODE", raising=False)
-        testdir.makepyfile(
+        monkeypatch.delenv("PYTHONPYCACHEPREFIX", raising=False)
+        pytester.makepyfile(
             test_foo="""
             def test_foo():
                 assert True
             """
         )
-        result = testdir.runpytest_subprocess()
+        result = pytester.runpytest_subprocess()
         assert result.ret == 0
-        found_names = glob.glob(
-            "__pycache__/*-pytest-{}.pyc".format(pytest.__version__)
-        )
+        found_names = glob.glob(f"__pycache__/*-pytest-{pytest.__version__}.pyc")
         assert found_names, "pyc with expected tag not found in names: {}".format(
             glob.glob("__pycache__/*.pyc")
         )

     @pytest.mark.skipif('"__pypy__" in sys.modules')
-    def test_pyc_vs_pyo(self, testdir, monkeypatch):
-        testdir.makepyfile(
+    def test_pyc_vs_pyo(self, pytester: Pytester, monkeypatch) -> None:
+        pytester.makepyfile(
             """
             import pytest
             def test_optimized():
                 "hello"
                 assert test_optimized.__doc__ is None"""
         )
-        p = make_numbered_dir(root=Path(testdir.tmpdir), prefix="runpytest-")
+        p = make_numbered_dir(root=Path(pytester.path), prefix="runpytest-")
         tmp = "--basetemp=%s" % p
         monkeypatch.setenv("PYTHONOPTIMIZE", "2")
         monkeypatch.delenv("PYTHONDONTWRITEBYTECODE", raising=False)
-        assert testdir.runpytest_subprocess(tmp).ret == 0
+        monkeypatch.delenv("PYTHONPYCACHEPREFIX", raising=False)
+        assert pytester.runpytest_subprocess(tmp).ret == 0
         tagged = "test_pyc_vs_pyo." + PYTEST_TAG
         assert tagged + ".pyo" in os.listdir("__pycache__")
         monkeypatch.undo()
         monkeypatch.delenv("PYTHONDONTWRITEBYTECODE", raising=False)
-        assert testdir.runpytest_subprocess(tmp).ret == 1
+        monkeypatch.delenv("PYTHONPYCACHEPREFIX", raising=False)
+        assert pytester.runpytest_subprocess(tmp).ret == 1
         assert tagged + ".pyc" in os.listdir("__pycache__")

-    def test_package(self, testdir):
-        pkg = testdir.tmpdir.join("pkg")
+    def test_package(self, pytester: Pytester) -> None:
+        pkg = pytester.path.joinpath("pkg")
         pkg.mkdir()
-        pkg.join("__init__.py").ensure()
-        pkg.join("test_blah.py").write(
+        pkg.joinpath("__init__.py")
+        pkg.joinpath("test_blah.py").write_text(
             """
 def test_rewritten():
     assert "@py_builtins" in globals()"""
         )
-        assert testdir.runpytest().ret == 0
-
-    def test_translate_newlines(self, testdir):
+        assert pytester.runpytest().ret == 0
+
+    def test_translate_newlines(self, pytester: Pytester) -> None:
         content = "def test_rewritten():\r\n assert '@py_builtins' in globals()"
         b = content.encode("utf-8")
-        testdir.tmpdir.join("test_newlines.py").write(b, "wb")
-        assert testdir.runpytest().ret == 0
-
-    def test_package_without__init__py(self, testdir):
-        pkg = testdir.mkdir("a_package_without_init_py")
-        pkg.join("module.py").ensure()
-        testdir.makepyfile("import a_package_without_init_py.module")
-        assert testdir.runpytest().ret == ExitCode.NO_TESTS_COLLECTED
-
-    def test_rewrite_warning(self, testdir):
-        testdir.makeconftest(
+        pytester.path.joinpath("test_newlines.py").write_bytes(b)
+        assert pytester.runpytest().ret == 0
+
+    def test_package_without__init__py(self, pytester: Pytester) -> None:
+        pkg = pytester.mkdir("a_package_without_init_py")
+        pkg.joinpath("module.py").touch()
+        pytester.makepyfile("import a_package_without_init_py.module")
+        assert pytester.runpytest().ret == ExitCode.NO_TESTS_COLLECTED
+
+    def test_rewrite_warning(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest
             pytest.register_assert_rewrite("_pytest")
         """
         )
         # needs to be a subprocess because pytester explicitly disables this warning
-        result = testdir.runpytest_subprocess()
+        result = pytester.runpytest_subprocess()
         result.stdout.fnmatch_lines(["*Module already imported*: _pytest"])

-    def test_rewrite_module_imported_from_conftest(self, testdir):
-        testdir.makeconftest(
+    def test_rewrite_module_imported_from_conftest(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import test_rewrite_module_imported
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             test_rewrite_module_imported="""
             def test_rewritten():
                 assert "@py_builtins" in globals()
         """
         )
-        assert testdir.runpytest_subprocess().ret == 0
-
-    def test_remember_rewritten_modules(self, pytestconfig, testdir, monkeypatch):
+        assert pytester.runpytest_subprocess().ret == 0
+
+    def test_remember_rewritten_modules(
+        self, pytestconfig, pytester: Pytester, monkeypatch
+    ) -> None:
         """`AssertionRewriteHook` should remember rewritten modules so it
         doesn't give false positives (#2005)."""
-        monkeypatch.syspath_prepend(testdir.tmpdir)
-        testdir.makepyfile(test_remember_rewritten_modules="")
+        monkeypatch.syspath_prepend(pytester.path)
+        pytester.makepyfile(test_remember_rewritten_modules="")
         warnings = []
         hook = AssertionRewritingHook(pytestconfig)
         monkeypatch.setattr(
@@ -928,8 +964,8 @@
         hook.mark_rewrite("test_remember_rewritten_modules")
         assert warnings == []

-    def test_rewrite_warning_using_pytest_plugins(self, testdir):
-        testdir.makepyfile(
+    def test_rewrite_warning_using_pytest_plugins(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             **{
                 "conftest.py": "pytest_plugins = ['core', 'gui', 'sci']",
                 "core.py": "",
@@ -938,14 +974,16 @@
                 "test_rewrite_warning_pytest_plugins.py": "def test(): pass",
             }
         )
-        testdir.chdir()
-        result = testdir.runpytest_subprocess()
+        pytester.chdir()
+        result = pytester.runpytest_subprocess()
         result.stdout.fnmatch_lines(["*= 1 passed in *=*"])
         result.stdout.no_fnmatch_line("*pytest-warning summary*")

-    def test_rewrite_warning_using_pytest_plugins_env_var(self, testdir, monkeypatch):
+    def test_rewrite_warning_using_pytest_plugins_env_var(
+        self, pytester: Pytester, monkeypatch
+    ) -> None:
         monkeypatch.setenv("PYTEST_PLUGINS", "plugin")
-        testdir.makepyfile(
+        pytester.makepyfile(
             **{
                 "plugin.py": "",
                 "test_rewrite_warning_using_pytest_plugins_env_var.py": """
@@ -956,29 +994,30 @@
             """,
             }
         )
-        testdir.chdir()
-        result = testdir.runpytest_subprocess()
+        pytester.chdir()
+        result = pytester.runpytest_subprocess()
         result.stdout.fnmatch_lines(["*= 1 passed in *=*"])
         result.stdout.no_fnmatch_line("*pytest-warning summary*")


 class TestAssertionRewriteHookDetails:
-    def test_sys_meta_path_munged(self, testdir):
-        testdir.makepyfile(
+    def test_sys_meta_path_munged(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             def test_meta_path():
                 import sys; sys.meta_path = []"""
         )
-        assert testdir.runpytest().ret == 0
-
-    def test_write_pyc(self, testdir: Testdir, tmpdir, monkeypatch) -> None:
+        assert pytester.runpytest().ret == 0
+
+    def test_write_pyc(self, pytester: Pytester, tmp_path, monkeypatch) -> None:
         from _pytest.assertion.rewrite import _write_pyc
         from _pytest.assertion import AssertionState

-        config = testdir.parseconfig()
+        config = pytester.parseconfig()
         state = AssertionState(config, "rewrite")
-        source_path = str(tmpdir.ensure("source.py"))
-        pycpath = tmpdir.join("pyc").strpath
+        tmp_path.joinpath("source.py").touch()
+        source_path = str(tmp_path)
+        pycpath = tmp_path.joinpath("pyc")
         co = compile("1", "f.py", "single")
         assert _write_pyc(state, co, os.stat(source_path), pycpath)

@@ -990,7 +1029,7 @@
                 e = OSError()
                 e.errno = 10
                 raise e
-                yield  # type:ignore[unreachable]
+                yield

             monkeypatch.setattr(
                 _pytest.assertion.rewrite, "atomic_write", atomic_write_failed
@@ -1004,7 +1043,7 @@

         assert not _write_pyc(state, co, os.stat(source_path), pycpath)

-    def test_resources_provider_for_loader(self, testdir):
+    def test_resources_provider_for_loader(self, pytester: Pytester) -> None:
         """
         Attempts to load resources from a package should succeed normally,
         even when the AssertionRewriteHook is used to load the modules.
@@ -1013,7 +1052,7 @@
         """
         pytest.importorskip("pkg_resources")

-        testdir.mkpydir("testpkg")
+        pytester.mkpydir("testpkg")
         contents = {
             "testpkg/test_pkg": """
                 import pkg_resources
@@ -1028,10 +1067,10 @@
                     assert res == 'Load me please.'
                 """
         }
-        testdir.makepyfile(**contents)
-        testdir.maketxtfile(**{"testpkg/resource": "Load me please."})
-
-        result = testdir.runpytest_subprocess()
+        pytester.makepyfile(**contents)
+        pytester.maketxtfile(**{"testpkg/resource": "Load me please."})
+
+        result = pytester.runpytest_subprocess()
         result.assert_outcomes(passed=1)

     def test_read_pyc(self, tmp_path: Path) -> None:
@@ -1050,21 +1089,88 @@
         py_compile.compile(str(source), str(pyc))

         contents = pyc.read_bytes()
-        strip_bytes = 20  # header is around 8 bytes, strip a little more
+        strip_bytes = 20  # header is around 16 bytes, strip a little more
         assert len(contents) > strip_bytes
         pyc.write_bytes(contents[:strip_bytes])

         assert _read_pyc(source, pyc) is None  # no error

-    def test_reload_is_same_and_reloads(self, testdir: Testdir) -> None:
+    def test_read_pyc_success(self, tmp_path: Path, pytester: Pytester) -> None:
+        """
+        Ensure that the _rewrite_test() -> _write_pyc() produces a pyc file
+        that can be properly read with _read_pyc()
+        """
+        from _pytest.assertion import AssertionState
+        from _pytest.assertion.rewrite import _read_pyc
+        from _pytest.assertion.rewrite import _rewrite_test
+        from _pytest.assertion.rewrite import _write_pyc
+
+        config = pytester.parseconfig()
+        state = AssertionState(config, "rewrite")
+
+        fn = tmp_path / "source.py"
+        pyc = Path(str(fn) + "c")
+
+        fn.write_text("def test(): assert True")
+
+        source_stat, co = _rewrite_test(fn, config)
+        _write_pyc(state, co, source_stat, pyc)
+        assert _read_pyc(fn, pyc, state.trace) is not None
+
+    def test_read_pyc_more_invalid(self, tmp_path: Path) -> None:
+        from _pytest.assertion.rewrite import _read_pyc
+
+        source = tmp_path / "source.py"
+        pyc = tmp_path / "source.pyc"
+
+        source_bytes = b"def test(): pass\n"
+        source.write_bytes(source_bytes)
+
+        magic = importlib.util.MAGIC_NUMBER
+
+        flags = b"\x00\x00\x00\x00"
+
+        mtime = b"\x58\x3c\xb0\x5f"
+        mtime_int = int.from_bytes(mtime, "little")
+        os.utime(source, (mtime_int, mtime_int))
+
+        size = len(source_bytes).to_bytes(4, "little")
+
+        code = marshal.dumps(compile(source_bytes, str(source), "exec"))
+
+        # Good header.
+        pyc.write_bytes(magic + flags + mtime + size + code)
+        assert _read_pyc(source, pyc, print) is not None
+
+        # Too short.
+        pyc.write_bytes(magic + flags + mtime)
+        assert _read_pyc(source, pyc, print) is None
+
+        # Bad magic.
+        pyc.write_bytes(b"\x12\x34\x56\x78" + flags + mtime + size + code)
+        assert _read_pyc(source, pyc, print) is None
+
+        # Unsupported flags.
+        pyc.write_bytes(magic + b"\x00\xff\x00\x00" + mtime + size + code)
+        assert _read_pyc(source, pyc, print) is None
+
+        # Bad mtime.
+        pyc.write_bytes(magic + flags + b"\x58\x3d\xb0\x5f" + size + code)
+        assert _read_pyc(source, pyc, print) is None
+
+        # Bad size.
+        pyc.write_bytes(magic + flags + mtime + b"\x99\x00\x00\x00" + code)
+        assert _read_pyc(source, pyc, print) is None
+
+    def test_reload_is_same_and_reloads(self, pytester: Pytester) -> None:
         """Reloading a (collected) module after change picks up the change."""
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
             python_files = *.py
             """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             file="""
             def reloaded():
                 return False
@@ -1085,13 +1191,13 @@
                 assert file.reloaded()
             """,
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["* 1 passed*"])

-    def test_get_data_support(self, testdir):
+    def test_get_data_support(self, pytester: Pytester) -> None:
         """Implement optional PEP302 api (#808)."""
-        path = testdir.mkpydir("foo")
-        path.join("test_foo.py").write(
+        path = pytester.mkpydir("foo")
+        path.joinpath("test_foo.py").write_text(
             textwrap.dedent(
                 """\
                 class Test(object):
@@ -1102,13 +1208,13 @@
                 """
             )
         )
-        path.join("data.txt").write("Hey")
-        result = testdir.runpytest()
+        path.joinpath("data.txt").write_text("Hey")
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*1 passed*"])


-def test_issue731(testdir):
-    testdir.makepyfile(
+def test_issue731(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
     class LongReprWithBraces(object):
         def __repr__(self):
@@ -1122,45 +1228,45 @@
         assert obj.some_method()
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.no_fnmatch_line("*unbalanced braces*")


 class TestIssue925:
-    def test_simple_case(self, testdir):
-        testdir.makepyfile(
+    def test_simple_case(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
         def test_ternary_display():
             assert (False == False) == False
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*E*assert (False == False) == False"])

-    def test_long_case(self, testdir):
-        testdir.makepyfile(
+    def test_long_case(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
         def test_ternary_display():
              assert False == (False == True) == True
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*E*assert (False == True) == True"])

-    def test_many_brackets(self, testdir):
-        testdir.makepyfile(
+    def test_many_brackets(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             def test_ternary_display():
                  assert True == ((False == True) == True)
             """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*E*assert True == ((False == True) == True)"])


 class TestIssue2121:
-    def test_rewrite_python_files_contain_subdirs(self, testdir):
-        testdir.makepyfile(
+    def test_rewrite_python_files_contain_subdirs(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             **{
                 "tests/file.py": """
                 def test_simple_failure():
@@ -1168,21 +1274,21 @@
                 """
             }
         )
-        testdir.makeini(
+        pytester.makeini(
             """
                 [pytest]
                 python_files = tests/**.py
             """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*E*assert (1 + 1) == 3"])


 @pytest.mark.skipif(
-    sys.maxsize <= (2 ** 31 - 1), reason="Causes OverflowError on 32bit systems"
+    sys.maxsize <= (2**31 - 1), reason="Causes OverflowError on 32bit systems"
 )
 @pytest.mark.parametrize("offset", [-1, +1])
-def test_source_mtime_long_long(testdir, offset):
+def test_source_mtime_long_long(pytester: Pytester, offset) -> None:
     """Support modification dates after 2038 in rewritten files (#4903).

     pytest would crash with:
@@ -1190,7 +1296,7 @@
             fp.write(struct.pack("<ll", mtime, size))
         E   struct.error: argument out of range
     """
-    p = testdir.makepyfile(
+    p = pytester.makepyfile(
         """
         def test(): pass
     """
@@ -1198,21 +1304,23 @@
     # use unsigned long timestamp which overflows signed long,
     # which was the cause of the bug
     # +1 offset also tests masking of 0xFFFFFFFF
-    timestamp = 2 ** 32 + offset
+    timestamp = 2**32 + offset
     os.utime(str(p), (timestamp, timestamp))
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert result.ret == 0


-def test_rewrite_infinite_recursion(testdir, pytestconfig, monkeypatch) -> None:
+def test_rewrite_infinite_recursion(
+    pytester: Pytester, pytestconfig, monkeypatch
+) -> None:
     """Fix infinite recursion when writing pyc files: if an import happens to be triggered when writing the pyc
     file, this would cause another call to the hook, which would trigger another pyc writing, which could
     trigger another import, and so on. (#3506)"""
     from _pytest.assertion import rewrite as rewritemod

-    testdir.syspathinsert()
-    testdir.makepyfile(test_foo="def test_foo(): pass")
-    testdir.makepyfile(test_bar="def test_bar(): pass")
+    pytester.syspathinsert()
+    pytester.makepyfile(test_foo="def test_foo(): pass")
+    pytester.makepyfile(test_bar="def test_bar(): pass")

     original_write_pyc = rewritemod._write_pyc

@@ -1238,14 +1346,16 @@

 class TestEarlyRewriteBailout:
     @pytest.fixture
-    def hook(self, pytestconfig, monkeypatch, testdir) -> AssertionRewritingHook:
+    def hook(
+        self, pytestconfig, monkeypatch, pytester: Pytester
+    ) -> Generator[AssertionRewritingHook, None, None]:
         """Returns a patched AssertionRewritingHook instance so we can configure its initial paths and track
         if PathFinder.find_spec has been called.
         """
         import importlib.machinery

-        self.find_spec_calls = []  # type: List[str]
-        self.initial_paths = set()  # type: Set[py.path.local]
+        self.find_spec_calls: List[str] = []
+        self.initial_paths: Set[Path] = set()

         class StubSession:
             _initialpaths = self.initial_paths
@@ -1259,27 +1369,27 @@

         hook = AssertionRewritingHook(pytestconfig)
         # use default patterns, otherwise we inherit pytest's testing config
-        hook.fnpats[:] = ["test_*.py", "*_test.py"]
-        monkeypatch.setattr(hook, "_find_spec", spy_find_spec)
-        hook.set_session(StubSession())  # type: ignore[arg-type]
-        testdir.syspathinsert()
-        return hook
-
-    def test_basic(self, testdir, hook: AssertionRewritingHook) -> None:
+        with mock.patch.object(hook, "fnpats", ["test_*.py", "*_test.py"]):
+            monkeypatch.setattr(hook, "_find_spec", spy_find_spec)
+            hook.set_session(StubSession())  # type: ignore[arg-type]
+            pytester.syspathinsert()
+            yield hook
+
+    def test_basic(self, pytester: Pytester, hook: AssertionRewritingHook) -> None:
         """
         Ensure we avoid calling PathFinder.find_spec when we know for sure a certain
         module will not be rewritten to optimize assertion rewriting (#3918).
         """
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest
             @pytest.fixture
             def fix(): return 1
         """
         )
-        testdir.makepyfile(test_foo="def test_foo(): pass")
-        testdir.makepyfile(bar="def bar(): pass")
-        foobar_path = testdir.makepyfile(foobar="def foobar(): pass")
+        pytester.makepyfile(test_foo="def test_foo(): pass")
+        pytester.makepyfile(bar="def bar(): pass")
+        foobar_path = pytester.makepyfile(foobar="def foobar(): pass")
         self.initial_paths.add(foobar_path)

         # conftest files should always be rewritten
@@ -1299,12 +1409,12 @@
         assert self.find_spec_calls == ["conftest", "test_foo", "foobar"]

     def test_pattern_contains_subdirectories(
-        self, testdir, hook: AssertionRewritingHook
+        self, pytester: Pytester, hook: AssertionRewritingHook
     ) -> None:
         """If one of the python_files patterns contain subdirectories ("tests/**.py") we can't bailout early
         because we need to match with the full path, which can only be found by calling PathFinder.find_spec
         """
-        p = testdir.makepyfile(
+        pytester.makepyfile(
             **{
                 "tests/file.py": """\
                     def test_simple_failure():
@@ -1312,31 +1422,32 @@
                 """
             }
         )
-        testdir.syspathinsert(p.dirpath())
-        hook.fnpats[:] = ["tests/**.py"]
-        assert hook.find_spec("file") is not None
-        assert self.find_spec_calls == ["file"]
+        pytester.syspathinsert("tests")
+        with mock.patch.object(hook, "fnpats", ["tests/**.py"]):
+            assert hook.find_spec("file") is not None
+            assert self.find_spec_calls == ["file"]

     @pytest.mark.skipif(
         sys.platform.startswith("win32"), reason="cannot remove cwd on Windows"
     )
-    def test_cwd_changed(self, testdir, monkeypatch):
+    @pytest.mark.skipif(
+        sys.platform.startswith("sunos5"), reason="cannot remove cwd on Solaris"
+    )
+    def test_cwd_changed(self, pytester: Pytester, monkeypatch) -> None:
         # Setup conditions for py's fspath trying to import pathlib on py34
         # always (previously triggered via xdist only).
         # Ref: https://github.com/pytest-dev/py/pull/207
         monkeypatch.syspath_prepend("")
         monkeypatch.delitem(sys.modules, "pathlib", raising=False)

-        testdir.makepyfile(
+        pytester.makepyfile(
             **{
                 "test_setup_nonexisting_cwd.py": """\
                     import os
-                    import shutil
                     import tempfile

-                    d = tempfile.mkdtemp()
-                    os.chdir(d)
-                    shutil.rmtree(d)
+                    with tempfile.TemporaryDirectory() as d:
+                        os.chdir(d)
                 """,
                 "test_test.py": """\
                     def test():
@@ -1344,30 +1455,30 @@
                 """,
             }
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["* 1 passed in *"])


 class TestAssertionPass:
-    def test_option_default(self, testdir):
-        config = testdir.parseconfig()
+    def test_option_default(self, pytester: Pytester) -> None:
+        config = pytester.parseconfig()
         assert config.getini("enable_assertion_pass_hook") is False

     @pytest.fixture
-    def flag_on(self, testdir):
-        testdir.makeini("[pytest]\nenable_assertion_pass_hook = True\n")
+    def flag_on(self, pytester: Pytester):
+        pytester.makeini("[pytest]\nenable_assertion_pass_hook = True\n")

     @pytest.fixture
-    def hook_on(self, testdir):
-        testdir.makeconftest(
+    def hook_on(self, pytester: Pytester):
+        pytester.makeconftest(
             """\
             def pytest_assertion_pass(item, lineno, orig, expl):
                 raise Exception("Assertion Passed: {} {} at line {}".format(orig, expl, lineno))
             """
         )

-    def test_hook_call(self, testdir, flag_on, hook_on):
-        testdir.makepyfile(
+    def test_hook_call(self, pytester: Pytester, flag_on, hook_on) -> None:
+        pytester.makepyfile(
             """\
             def test_simple():
                 a=1
@@ -1382,23 +1493,25 @@
                 assert False, "assert with message"
             """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             "*Assertion Passed: a+b == c+d (1 + 2) == (3 + 0) at line 7*"
         )

-    def test_hook_call_with_parens(self, testdir, flag_on, hook_on):
-        testdir.makepyfile(
+    def test_hook_call_with_parens(self, pytester: Pytester, flag_on, hook_on) -> None:
+        pytester.makepyfile(
             """\
             def f(): return 1
             def test():
                 assert f()
             """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines("*Assertion Passed: f() 1")

-    def test_hook_not_called_without_hookimpl(self, testdir, monkeypatch, flag_on):
+    def test_hook_not_called_without_hookimpl(
+        self, pytester: Pytester, monkeypatch, flag_on
+    ) -> None:
         """Assertion pass should not be called (and hence formatting should
         not occur) if there is no hook declared for pytest_assertion_pass"""

@@ -1409,7 +1522,7 @@
             _pytest.assertion.rewrite, "_call_assertion_pass", raise_on_assertionpass
         )

-        testdir.makepyfile(
+        pytester.makepyfile(
             """\
             def test_simple():
                 a=1
@@ -1420,10 +1533,12 @@
                 assert a+b == c+d
             """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.assert_outcomes(passed=1)

-    def test_hook_not_called_without_cmd_option(self, testdir, monkeypatch):
+    def test_hook_not_called_without_cmd_option(
+        self, pytester: Pytester, monkeypatch
+    ) -> None:
         """Assertion pass should not be called (and hence formatting should
         not occur) if there is no hook declared for pytest_assertion_pass"""

@@ -1434,14 +1549,14 @@
             _pytest.assertion.rewrite, "_call_assertion_pass", raise_on_assertionpass
         )

-        testdir.makeconftest(
+        pytester.makeconftest(
             """\
             def pytest_assertion_pass(item, lineno, orig, expl):
                 raise Exception("Assertion Passed: {} {} at line {}".format(orig, expl, lineno))
             """
         )

-        testdir.makepyfile(
+        pytester.makepyfile(
             """\
             def test_simple():
                 a=1
@@ -1452,7 +1567,7 @@
                 assert a+b == c+d
             """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.assert_outcomes(passed=1)


@@ -1539,7 +1654,7 @@
         # fmt: on
     ),
 )
-def test_get_assertion_exprs(src, expected):
+def test_get_assertion_exprs(src, expected) -> None:
     assert _get_assertion_exprs(src) == expected


@@ -1557,7 +1672,7 @@

     # monkeypatch to simulate all error situations
     def fake_mkdir(p, exist_ok=False, *, exc):
-        assert isinstance(p, str)
+        assert isinstance(p, Path)
         raise exc

     monkeypatch.setattr(os, "makedirs", partial(fake_mkdir, exc=FileNotFoundError()))
@@ -1593,24 +1708,31 @@
             (None, "/home/projects/src/foo.py", "/home/projects/src/__pycache__"),
         ],
     )
-    def test_get_cache_dir(self, monkeypatch, prefix, source, expected):
-        if prefix:
-            if sys.version_info < (3, 8):
-                pytest.skip("pycache_prefix not available in py<38")
-            monkeypatch.setattr(sys, "pycache_prefix", prefix)  # type:ignore
+    def test_get_cache_dir(self, monkeypatch, prefix, source, expected) -> None:
+        monkeypatch.delenv("PYTHONPYCACHEPREFIX", raising=False)
+
+        if prefix is not None and sys.version_info < (3, 8):
+            pytest.skip("pycache_prefix not available in py<38")
+        monkeypatch.setattr(sys, "pycache_prefix", prefix, raising=False)

         assert get_cache_dir(Path(source)) == Path(expected)

     @pytest.mark.skipif(
         sys.version_info < (3, 8), reason="pycache_prefix not available in py<38"
     )
-    def test_sys_pycache_prefix_integration(self, tmp_path, monkeypatch, testdir):
+    @pytest.mark.skipif(
+        sys.version_info[:2] == (3, 9) and sys.platform.startswith("win"),
+        reason="#9298",
+    )
+    def test_sys_pycache_prefix_integration(
+        self, tmp_path, monkeypatch, pytester: Pytester
+    ) -> None:
         """Integration test for sys.pycache_prefix (#4730)."""
         pycache_prefix = tmp_path / "my/pycs"
         monkeypatch.setattr(sys, "pycache_prefix", str(pycache_prefix))
         monkeypatch.setattr(sys, "dont_write_bytecode", False)

-        testdir.makepyfile(
+        pytester.makepyfile(
             **{
                 "src/test_foo.py": """
                 import bar
@@ -1620,11 +1742,11 @@
                 "src/bar/__init__.py": "",
             }
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret == 0

-        test_foo = Path(testdir.tmpdir) / "src/test_foo.py"
-        bar_init = Path(testdir.tmpdir) / "src/bar/__init__.py"
+        test_foo = pytester.path.joinpath("src/test_foo.py")
+        bar_init = pytester.path.joinpath("src/bar/__init__.py")
         assert test_foo.is_file()
         assert bar_init.is_file()

@@ -1637,3 +1759,52 @@
             cache_tag=sys.implementation.cache_tag
         )
         assert bar_init_pyc.is_file()
+
+
+class TestReprSizeVerbosity:
+    """
+    Check that verbosity also controls the string length threshold to shorten it using
+    ellipsis.
+    """
+
+    @pytest.mark.parametrize(
+        "verbose, expected_size",
+        [
+            (0, DEFAULT_REPR_MAX_SIZE),
+            (1, DEFAULT_REPR_MAX_SIZE * 10),
+            (2, None),
+            (3, None),
+        ],
+    )
+    def test_get_maxsize_for_saferepr(self, verbose: int, expected_size) -> None:
+        class FakeConfig:
+            def getoption(self, name: str) -> int:
+                assert name == "verbose"
+                return verbose
+
+        config = FakeConfig()
+        assert _get_maxsize_for_saferepr(cast(Config, config)) == expected_size
+
+    def create_test_file(self, pytester: Pytester, size: int) -> None:
+        pytester.makepyfile(
+            f"""
+            def test_very_long_string():
+                text = "x" * {size}
+                assert "hello world" in text
+            """
+        )
+
+    def test_default_verbosity(self, pytester: Pytester) -> None:
+        self.create_test_file(pytester, DEFAULT_REPR_MAX_SIZE)
+        result = pytester.runpytest()
+        result.stdout.fnmatch_lines(["*xxx...xxx*"])
+
+    def test_increased_verbosity(self, pytester: Pytester) -> None:
+        self.create_test_file(pytester, DEFAULT_REPR_MAX_SIZE)
+        result = pytester.runpytest("-v")
+        result.stdout.no_fnmatch_line("*xxx...xxx*")
+
+    def test_max_increased_verbosity(self, pytester: Pytester) -> None:
+        self.create_test_file(pytester, DEFAULT_REPR_MAX_SIZE * 10)
+        result = pytester.runpytest("-vv")
+        result.stdout.no_fnmatch_line("*xxx...xxx*")
('testing', 'conftest.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -3,8 +3,8 @@
 from typing import List

 import pytest
-from _pytest.pytester import RunResult
-from _pytest.pytester import Testdir
+from _pytest.monkeypatch import MonkeyPatch
+from _pytest.pytester import Pytester

 if sys.gettrace():

@@ -42,7 +42,7 @@
             # (https://github.com/pytest-dev/pytest/issues/5070)
             neutral_items.append(item)
         else:
-            if "testdir" in fixtures:
+            if "pytester" in fixtures:
                 co_names = item.function.__code__.co_names
                 if spawn_names.intersection(co_names):
                     item.add_marker(pytest.mark.uses_pexpect)
@@ -104,36 +104,36 @@


 @pytest.fixture
-def dummy_yaml_custom_test(testdir):
+def dummy_yaml_custom_test(pytester: Pytester):
     """Writes a conftest file that collects and executes a dummy yaml test.

     Taken from the docs, but stripped down to the bare minimum, useful for
     tests which needs custom items collected.
     """
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         import pytest

-        def pytest_collect_file(parent, path):
-            if path.ext == ".yaml" and path.basename.startswith("test"):
-                return YamlFile.from_parent(fspath=path, parent=parent)
+        def pytest_collect_file(parent, file_path):
+            if file_path.suffix == ".yaml" and file_path.name.startswith("test"):
+                return YamlFile.from_parent(path=file_path, parent=parent)

         class YamlFile(pytest.File):
             def collect(self):
-                yield YamlItem.from_parent(name=self.fspath.basename, parent=self)
+                yield YamlItem.from_parent(name=self.path.name, parent=self)

         class YamlItem(pytest.Item):
             def runtest(self):
                 pass
     """
     )
-    testdir.makefile(".yaml", test1="")
-
-
-@pytest.fixture
-def testdir(testdir: Testdir) -> Testdir:
-    testdir.monkeypatch.setenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", "1")
-    return testdir
+    pytester.makefile(".yaml", test1="")
+
+
+@pytest.fixture
+def pytester(pytester: Pytester, monkeypatch: MonkeyPatch) -> Pytester:
+    monkeypatch.setenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", "1")
+    return pytester


 @pytest.fixture(scope="session")
@@ -175,32 +175,11 @@
             """Replace color names for use with LineMatcher.re_match_lines"""
             return [line.format(**cls.RE_COLORS) for line in lines]

-        @classmethod
-        def requires_ordered_markup(cls, result: RunResult):
-            """Should be called if a test expects markup to appear in the output
-            in the order they were passed, for example:
-
-                tw.write(line, bold=True, red=True)
-
-            In Python 3.5 there's no guarantee that the generated markup will appear
-            in the order called, so we do some limited color testing and skip the rest of
-            the test.
-            """
-            if sys.version_info < (3, 6):
-                # terminal writer.write accepts keyword arguments, so
-                # py36+ is required so the markup appears in the expected order
-                output = result.stdout.str()
-                assert "test session starts" in output
-                assert "\x1b[1m" in output
-                pytest.skip(
-                    "doing limited testing because lacking ordered markup on py35"
-                )
-
     return ColorMapping


 @pytest.fixture
-def mock_timing(monkeypatch):
+def mock_timing(monkeypatch: MonkeyPatch):
     """Mocks _pytest.timing with a known object that can be used to control timing in tests
     deterministically.

('testing', 'test_warnings.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,4 +1,5 @@
 import os
+import sys
 import warnings
 from typing import List
 from typing import Optional
@@ -6,18 +7,18 @@

 import pytest
 from _pytest.fixtures import FixtureRequest
-from _pytest.pytester import Testdir
+from _pytest.pytester import Pytester

 WARNINGS_SUMMARY_HEADER = "warnings summary"


 @pytest.fixture
-def pyfile_with_warnings(testdir: Testdir, request: FixtureRequest) -> str:
+def pyfile_with_warnings(pytester: Pytester, request: FixtureRequest) -> str:
     """Create a test file which calls a function in a module which generates warnings."""
-    testdir.syspathinsert()
+    pytester.syspathinsert()
     test_name = request.function.__name__
     module_name = test_name.lstrip("test_") + "_module"
-    test_file = testdir.makepyfile(
+    test_file = pytester.makepyfile(
         """
         import {module_name}
         def test_func():
@@ -38,10 +39,10 @@
     return str(test_file)


-@pytest.mark.filterwarnings("default")
-def test_normal_flow(testdir, pyfile_with_warnings):
+@pytest.mark.filterwarnings("default::UserWarning", "default::RuntimeWarning")
+def test_normal_flow(pytester: Pytester, pyfile_with_warnings) -> None:
     """Check that the warnings section is displayed."""
-    result = testdir.runpytest(pyfile_with_warnings)
+    result = pytester.runpytest(pyfile_with_warnings)
     result.stdout.fnmatch_lines(
         [
             "*== %s ==*" % WARNINGS_SUMMARY_HEADER,
@@ -55,9 +56,9 @@
     )


-@pytest.mark.filterwarnings("always")
-def test_setup_teardown_warnings(testdir):
-    testdir.makepyfile(
+@pytest.mark.filterwarnings("always::UserWarning")
+def test_setup_teardown_warnings(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import warnings
         import pytest
@@ -72,7 +73,7 @@
             pass
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         [
             "*== %s ==*" % WARNINGS_SUMMARY_HEADER,
@@ -86,10 +87,10 @@


 @pytest.mark.parametrize("method", ["cmdline", "ini"])
-def test_as_errors(testdir, pyfile_with_warnings, method):
+def test_as_errors(pytester: Pytester, pyfile_with_warnings, method) -> None:
     args = ("-W", "error") if method == "cmdline" else ()
     if method == "ini":
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
             filterwarnings=error
@@ -97,7 +98,7 @@
         )
     # Use a subprocess, since changing logging level affects other threads
     # (xdist).
-    result = testdir.runpytest_subprocess(*args, pyfile_with_warnings)
+    result = pytester.runpytest_subprocess(*args, pyfile_with_warnings)
     result.stdout.fnmatch_lines(
         [
             "E       UserWarning: user warning",
@@ -108,24 +109,24 @@


 @pytest.mark.parametrize("method", ["cmdline", "ini"])
-def test_ignore(testdir, pyfile_with_warnings, method):
+def test_ignore(pytester: Pytester, pyfile_with_warnings, method) -> None:
     args = ("-W", "ignore") if method == "cmdline" else ()
     if method == "ini":
-        testdir.makeini(
+        pytester.makeini(
             """
         [pytest]
         filterwarnings= ignore
         """
         )

-    result = testdir.runpytest(*args, pyfile_with_warnings)
+    result = pytester.runpytest(*args, pyfile_with_warnings)
     result.stdout.fnmatch_lines(["* 1 passed in *"])
     assert WARNINGS_SUMMARY_HEADER not in result.stdout.str()


-@pytest.mark.filterwarnings("always")
-def test_unicode(testdir):
-    testdir.makepyfile(
+@pytest.mark.filterwarnings("always::UserWarning")
+def test_unicode(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import warnings
         import pytest
@@ -140,7 +141,7 @@
             pass
         """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         [
             "*== %s ==*" % WARNINGS_SUMMARY_HEADER,
@@ -150,9 +151,9 @@
     )


-def test_works_with_filterwarnings(testdir):
+def test_works_with_filterwarnings(pytester: Pytester) -> None:
     """Ensure our warnings capture does not mess with pre-installed filters (#2430)."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import warnings

@@ -170,22 +171,22 @@
                     assert True
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*== 1 passed in *"])


 @pytest.mark.parametrize("default_config", ["ini", "cmdline"])
-def test_filterwarnings_mark(testdir, default_config):
+def test_filterwarnings_mark(pytester: Pytester, default_config) -> None:
     """Test ``filterwarnings`` mark works and takes precedence over command
     line and ini options."""
     if default_config == "ini":
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
-            filterwarnings = always
-        """
-        )
-    testdir.makepyfile(
+            filterwarnings = always::RuntimeWarning
+        """
+        )
+    pytester.makepyfile(
         """
         import warnings
         import pytest
@@ -202,13 +203,15 @@
             warnings.warn(RuntimeWarning())
     """
     )
-    result = testdir.runpytest("-W always" if default_config == "cmdline" else "")
+    result = pytester.runpytest(
+        "-W always::RuntimeWarning" if default_config == "cmdline" else ""
+    )
     result.stdout.fnmatch_lines(["*= 1 failed, 2 passed, 1 warning in *"])


-def test_non_string_warning_argument(testdir):
+def test_non_string_warning_argument(pytester: Pytester) -> None:
     """Non-str argument passed to warning breaks pytest (#2956)"""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """\
         import warnings
         import pytest
@@ -217,13 +220,13 @@
             warnings.warn(UserWarning(1, 'foo'))
         """
     )
-    result = testdir.runpytest("-W", "always")
+    result = pytester.runpytest("-W", "always::UserWarning")
     result.stdout.fnmatch_lines(["*= 1 passed, 1 warning in *"])


-def test_filterwarnings_mark_registration(testdir):
+def test_filterwarnings_mark_registration(pytester: Pytester) -> None:
     """Ensure filterwarnings mark is registered"""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest

@@ -232,19 +235,19 @@
             pass
     """
     )
-    result = testdir.runpytest("--strict-markers")
+    result = pytester.runpytest("--strict-markers")
     assert result.ret == 0


-@pytest.mark.filterwarnings("always")
-def test_warning_captured_hook(testdir):
-    testdir.makeconftest(
+@pytest.mark.filterwarnings("always::UserWarning")
+def test_warning_recorded_hook(pytester: Pytester) -> None:
+    pytester.makeconftest(
         """
         def pytest_configure(config):
             config.issue_config_time_warning(UserWarning("config warning"), stacklevel=2)
     """
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest, warnings

@@ -268,15 +271,15 @@
         def pytest_warning_recorded(self, warning_message, when, nodeid, location):
             collected.append((str(warning_message.message), when, nodeid, location))

-    result = testdir.runpytest(plugins=[WarningCollector()])
+    result = pytester.runpytest(plugins=[WarningCollector()])
     result.stdout.fnmatch_lines(["*1 passed*"])

     expected = [
         ("config warning", "config", ""),
         ("collect warning", "collect", ""),
-        ("setup warning", "runtest", "test_warning_captured_hook.py::test_func"),
-        ("call warning", "runtest", "test_warning_captured_hook.py::test_func"),
-        ("teardown warning", "runtest", "test_warning_captured_hook.py::test_func"),
+        ("setup warning", "runtest", "test_warning_recorded_hook.py::test_func"),
+        ("call warning", "runtest", "test_warning_recorded_hook.py::test_func"),
+        ("teardown warning", "runtest", "test_warning_recorded_hook.py::test_func"),
     ]
     for index in range(len(expected)):
         collected_result = collected[index]
@@ -287,7 +290,7 @@
         assert collected_result[2] == expected_result[2], str(collected)

         # NOTE: collected_result[3] is location, which differs based on the platform you are on
-        #       thus, the best we can do here is assert the types of the paremeters match what we expect
+        #       thus, the best we can do here is assert the types of the parameters match what we expect
         #       and not try and preload it in the expected array
         if collected_result[3] is not None:
             assert type(collected_result[3][0]) is str, str(collected)
@@ -297,10 +300,10 @@
             assert collected_result[3] is None, str(collected)


-@pytest.mark.filterwarnings("always")
-def test_collection_warnings(testdir):
+@pytest.mark.filterwarnings("always::UserWarning")
+def test_collection_warnings(pytester: Pytester) -> None:
     """Check that we also capture warnings issued during test collection (#3251)."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import warnings

@@ -310,7 +313,7 @@
             pass
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         [
             "*== %s ==*" % WARNINGS_SUMMARY_HEADER,
@@ -321,10 +324,10 @@
     )


-@pytest.mark.filterwarnings("always")
-def test_mark_regex_escape(testdir):
+@pytest.mark.filterwarnings("always::UserWarning")
+def test_mark_regex_escape(pytester: Pytester) -> None:
     """@pytest.mark.filterwarnings should not try to escape regex characters (#3936)"""
-    testdir.makepyfile(
+    pytester.makepyfile(
         r"""
         import pytest, warnings

@@ -333,15 +336,17 @@
             warnings.warn(UserWarning("some (warning)"))
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert WARNINGS_SUMMARY_HEADER not in result.stdout.str()


-@pytest.mark.filterwarnings("default")
+@pytest.mark.filterwarnings("default::pytest.PytestWarning")
 @pytest.mark.parametrize("ignore_pytest_warnings", ["no", "ini", "cmdline"])
-def test_hide_pytest_internal_warnings(testdir, ignore_pytest_warnings):
+def test_hide_pytest_internal_warnings(
+    pytester: Pytester, ignore_pytest_warnings
+) -> None:
     """Make sure we can ignore internal pytest warnings using a warnings filter."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         import warnings
@@ -353,7 +358,7 @@
     """
     )
     if ignore_pytest_warnings == "ini":
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
             filterwarnings = ignore::pytest.PytestWarning
@@ -364,7 +369,7 @@
         if ignore_pytest_warnings == "cmdline"
         else []
     )
-    result = testdir.runpytest(*args)
+    result = pytester.runpytest(*args)
     if ignore_pytest_warnings != "no":
         assert WARNINGS_SUMMARY_HEADER not in result.stdout.str()
     else:
@@ -378,15 +383,17 @@


 @pytest.mark.parametrize("ignore_on_cmdline", [True, False])
-def test_option_precedence_cmdline_over_ini(testdir, ignore_on_cmdline):
+def test_option_precedence_cmdline_over_ini(
+    pytester: Pytester, ignore_on_cmdline
+) -> None:
     """Filters defined in the command-line should take precedence over filters in ini files (#3946)."""
-    testdir.makeini(
+    pytester.makeini(
         """
         [pytest]
-        filterwarnings = error
-    """
-    )
-    testdir.makepyfile(
+        filterwarnings = error::UserWarning
+    """
+    )
+    pytester.makepyfile(
         """
         import warnings
         def test():
@@ -394,22 +401,22 @@
     """
     )
     args = ["-W", "ignore"] if ignore_on_cmdline else []
-    result = testdir.runpytest(*args)
+    result = pytester.runpytest(*args)
     if ignore_on_cmdline:
         result.stdout.fnmatch_lines(["* 1 passed in*"])
     else:
         result.stdout.fnmatch_lines(["* 1 failed in*"])


-def test_option_precedence_mark(testdir):
+def test_option_precedence_mark(pytester: Pytester) -> None:
     """Filters defined by marks should always take precedence (#3946)."""
-    testdir.makeini(
+    pytester.makeini(
         """
         [pytest]
         filterwarnings = ignore
     """
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest, warnings
         @pytest.mark.filterwarnings('error')
@@ -417,7 +424,7 @@
             warnings.warn(UserWarning('hello'))
     """
     )
-    result = testdir.runpytest("-W", "ignore")
+    result = pytester.runpytest("-W", "ignore")
     result.stdout.fnmatch_lines(["* 1 failed in*"])


@@ -427,8 +434,8 @@
     from pytest's own test suite
     """

-    def create_file(self, testdir, mark=""):
-        testdir.makepyfile(
+    def create_file(self, pytester: Pytester, mark="") -> None:
+        pytester.makepyfile(
             """
             import pytest, warnings

@@ -443,18 +450,18 @@
         )

     @pytest.mark.parametrize("customize_filters", [True, False])
-    def test_shown_by_default(self, testdir, customize_filters):
+    def test_shown_by_default(self, pytester: Pytester, customize_filters) -> None:
         """Show deprecation warnings by default, even if user has customized the warnings filters (#4013)."""
-        self.create_file(testdir)
+        self.create_file(pytester)
         if customize_filters:
-            testdir.makeini(
+            pytester.makeini(
                 """
                 [pytest]
                 filterwarnings =
                     once::UserWarning
             """
             )
-        result = testdir.runpytest_subprocess()
+        result = pytester.runpytest_subprocess()
         result.stdout.fnmatch_lines(
             [
                 "*== %s ==*" % WARNINGS_SUMMARY_HEADER,
@@ -464,9 +471,9 @@
             ]
         )

-    def test_hidden_by_ini(self, testdir):
-        self.create_file(testdir)
-        testdir.makeini(
+    def test_hidden_by_ini(self, pytester: Pytester) -> None:
+        self.create_file(pytester)
+        pytester.makeini(
             """
             [pytest]
             filterwarnings =
@@ -474,18 +481,18 @@
                 ignore::PendingDeprecationWarning
         """
         )
-        result = testdir.runpytest_subprocess()
+        result = pytester.runpytest_subprocess()
         assert WARNINGS_SUMMARY_HEADER not in result.stdout.str()

-    def test_hidden_by_mark(self, testdir):
+    def test_hidden_by_mark(self, pytester: Pytester) -> None:
         """Should hide the deprecation warning from the function, but the warning during collection should
         be displayed normally.
         """
         self.create_file(
-            testdir,
+            pytester,
             mark='@pytest.mark.filterwarnings("ignore::PendingDeprecationWarning")',
         )
-        result = testdir.runpytest_subprocess()
+        result = pytester.runpytest_subprocess()
         result.stdout.fnmatch_lines(
             [
                 "*== %s ==*" % WARNINGS_SUMMARY_HEADER,
@@ -494,9 +501,9 @@
             ]
         )

-    def test_hidden_by_cmdline(self, testdir):
-        self.create_file(testdir)
-        result = testdir.runpytest_subprocess(
+    def test_hidden_by_cmdline(self, pytester: Pytester) -> None:
+        self.create_file(pytester)
+        result = pytester.runpytest_subprocess(
             "-W",
             "ignore::DeprecationWarning",
             "-W",
@@ -504,45 +511,43 @@
         )
         assert WARNINGS_SUMMARY_HEADER not in result.stdout.str()

-    def test_hidden_by_system(self, testdir, monkeypatch):
-        self.create_file(testdir)
+    def test_hidden_by_system(self, pytester: Pytester, monkeypatch) -> None:
+        self.create_file(pytester)
         monkeypatch.setenv("PYTHONWARNINGS", "once::UserWarning")
-        result = testdir.runpytest_subprocess()
+        result = pytester.runpytest_subprocess()
         assert WARNINGS_SUMMARY_HEADER not in result.stdout.str()


+@pytest.mark.skip("not relevant until pytest 8.0")
 @pytest.mark.parametrize("change_default", [None, "ini", "cmdline"])
-@pytest.mark.skip(
-    reason="This test should be enabled again before pytest 7.0 is released"
-)
-def test_deprecation_warning_as_error(testdir, change_default):
-    """This ensures that PytestDeprecationWarnings raised by pytest are turned into errors.
+def test_removed_in_x_warning_as_error(pytester: Pytester, change_default) -> None:
+    """This ensures that PytestRemovedInXWarnings raised by pytest are turned into errors.

     This test should be enabled as part of each major release, and skipped again afterwards
     to ensure our deprecations are turning into warnings as expected.
     """
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import warnings, pytest
         def test():
-            warnings.warn(pytest.PytestDeprecationWarning("some warning"))
+            warnings.warn(pytest.PytestRemovedIn8Warning("some warning"))
     """
     )
     if change_default == "ini":
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
             filterwarnings =
-                ignore::pytest.PytestDeprecationWarning
+                ignore::pytest.PytestRemovedIn8Warning
         """
         )

     args = (
-        ("-Wignore::pytest.PytestDeprecationWarning",)
+        ("-Wignore::pytest.PytestRemovedIn8Warning",)
         if change_default == "cmdline"
         else ()
     )
-    result = testdir.runpytest(*args)
+    result = pytester.runpytest(*args)
     if change_default is None:
         result.stdout.fnmatch_lines(["* 1 failed in *"])
     else:
@@ -552,23 +557,23 @@

 class TestAssertionWarnings:
     @staticmethod
-    def assert_result_warns(result, msg):
+    def assert_result_warns(result, msg) -> None:
         result.stdout.fnmatch_lines(["*PytestAssertRewriteWarning: %s*" % msg])

-    def test_tuple_warning(self, testdir):
-        testdir.makepyfile(
+    def test_tuple_warning(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """\
             def test_foo():
                 assert (1,2)
             """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         self.assert_result_warns(
             result, "assertion is always true, perhaps remove parentheses?"
         )


-def test_warnings_checker_twice():
+def test_warnings_checker_twice() -> None:
     """Issue #4617"""
     expectation = pytest.warns(UserWarning)
     with expectation:
@@ -577,11 +582,10 @@
         warnings.warn("Message B", UserWarning)


-@pytest.mark.filterwarnings("ignore::pytest.PytestExperimentalApiWarning")
-@pytest.mark.filterwarnings("always")
-def test_group_warnings_by_message(testdir):
-    testdir.copy_example("warnings/test_group_warnings_by_message.py")
-    result = testdir.runpytest()
+@pytest.mark.filterwarnings("always::UserWarning")
+def test_group_warnings_by_message(pytester: Pytester) -> None:
+    pytester.copy_example("warnings/test_group_warnings_by_message.py")
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         [
             "*== %s ==*" % WARNINGS_SUMMARY_HEADER,
@@ -609,12 +613,11 @@
     )


-@pytest.mark.filterwarnings("ignore::pytest.PytestExperimentalApiWarning")
-@pytest.mark.filterwarnings("always")
-def test_group_warnings_by_message_summary(testdir):
-    testdir.copy_example("warnings/test_group_warnings_by_message_summary")
-    testdir.syspathinsert()
-    result = testdir.runpytest()
+@pytest.mark.filterwarnings("always::UserWarning")
+def test_group_warnings_by_message_summary(pytester: Pytester) -> None:
+    pytester.copy_example("warnings/test_group_warnings_by_message_summary")
+    pytester.syspathinsert()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         [
             "*== %s ==*" % WARNINGS_SUMMARY_HEADER,
@@ -634,9 +637,9 @@
     )


-def test_pytest_configure_warning(testdir, recwarn):
+def test_pytest_configure_warning(pytester: Pytester, recwarn) -> None:
     """Issue 5115."""
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         def pytest_configure():
             import warnings
@@ -645,7 +648,7 @@
         """
     )

-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert result.ret == 5
     assert "INTERNALERROR" not in result.stderr.str()
     warning = recwarn.pop()
@@ -654,26 +657,26 @@

 class TestStackLevel:
     @pytest.fixture
-    def capwarn(self, testdir):
+    def capwarn(self, pytester: Pytester):
         class CapturedWarnings:
-            captured = (
-                []
-            )  # type: List[Tuple[warnings.WarningMessage, Optional[Tuple[str, int, str]]]]
+            captured: List[
+                Tuple[warnings.WarningMessage, Optional[Tuple[str, int, str]]]
+            ] = []

             @classmethod
             def pytest_warning_recorded(cls, warning_message, when, nodeid, location):
                 cls.captured.append((warning_message, location))

-        testdir.plugins = [CapturedWarnings()]
+        pytester.plugins = [CapturedWarnings()]

         return CapturedWarnings

-    def test_issue4445_rewrite(self, testdir, capwarn):
+    def test_issue4445_rewrite(self, pytester: Pytester, capwarn) -> None:
         """#4445: Make sure the warning points to a reasonable location
         See origin of _issue_warning_captured at: _pytest.assertion.rewrite.py:241
         """
-        testdir.makepyfile(some_mod="")
-        conftest = testdir.makeconftest(
+        pytester.makepyfile(some_mod="")
+        conftest = pytester.makeconftest(
             """
                 import some_mod
                 import pytest
@@ -681,7 +684,7 @@
                 pytest.register_assert_rewrite("some_mod")
             """
         )
-        testdir.parseconfig()
+        pytester.parseconfig()

         # with stacklevel=5 the warning originates from register_assert_rewrite
         # function in the created conftest.py
@@ -694,51 +697,51 @@
         assert func == "<module>"  # the above conftest.py
         assert lineno == 4

-    def test_issue4445_preparse(self, testdir, capwarn):
+    def test_issue4445_preparse(self, pytester: Pytester, capwarn) -> None:
         """#4445: Make sure the warning points to a reasonable location
         See origin of _issue_warning_captured at: _pytest.config.__init__.py:910
         """
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import nothing
             """
         )
-        testdir.parseconfig("--help")
+        pytester.parseconfig("--help")

         # with stacklevel=2 the warning should originate from config._preparse and is
-        # thrown by an errorneous conftest.py
+        # thrown by an erroneous conftest.py
         assert len(capwarn.captured) == 1
         warning, location = capwarn.captured.pop()
         file, _, func = location

         assert "could not load initial conftests" in str(warning.message)
-        assert "config{sep}__init__.py".format(sep=os.sep) in file
+        assert f"config{os.sep}__init__.py" in file
         assert func == "_preparse"

     @pytest.mark.filterwarnings("default")
-    def test_conftest_warning_captured(self, testdir: Testdir) -> None:
+    def test_conftest_warning_captured(self, pytester: Pytester) -> None:
         """Warnings raised during importing of conftest.py files is captured (#2891)."""
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import warnings
             warnings.warn(UserWarning("my custom warning"))
             """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             ["conftest.py:2", "*UserWarning: my custom warning*"]
         )

-    def test_issue4445_import_plugin(self, testdir, capwarn):
+    def test_issue4445_import_plugin(self, pytester: Pytester, capwarn) -> None:
         """#4445: Make sure the warning points to a reasonable location"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             some_plugin="""
             import pytest
             pytest.skip("thing", allow_module_level=True)
             """
         )
-        testdir.syspathinsert()
-        testdir.parseconfig("-p", "some_plugin")
+        pytester.syspathinsert()
+        pytester.parseconfig("-p", "some_plugin")

         # with stacklevel=2 the warning should originate from
         # config.PytestPluginManager.import_plugin is thrown by a skipped plugin
@@ -748,14 +751,14 @@
         file, _, func = location

         assert "skipped plugin 'some_plugin': thing" in str(warning.message)
-        assert "config{sep}__init__.py".format(sep=os.sep) in file
+        assert f"config{os.sep}__init__.py" in file
         assert func == "_warn_about_skipped_plugins"

-    def test_issue4445_issue5928_mark_generator(self, testdir):
+    def test_issue4445_issue5928_mark_generator(self, pytester: Pytester) -> None:
         """#4445 and #5928: Make sure the warning from an unknown mark points to
         the test file where this mark is used.
         """
-        testfile = testdir.makepyfile(
+        testfile = pytester.makepyfile(
             """
             import pytest

@@ -764,11 +767,65 @@
                 pass
             """
         )
-        result = testdir.runpytest_subprocess()
+        result = pytester.runpytest_subprocess()
         # with stacklevel=2 the warning should originate from the above created test file
         result.stdout.fnmatch_lines_random(
             [
-                "*{testfile}:3*".format(testfile=str(testfile)),
+                f"*{testfile}:3*",
                 "*Unknown pytest.mark.unknown*",
             ]
         )
+
+
+def test_resource_warning(pytester: Pytester, monkeypatch: pytest.MonkeyPatch) -> None:
+    # Some platforms (notably PyPy) don't have tracemalloc.
+    # We choose to explicitly not skip this in case tracemalloc is not
+    # available, using `importorskip("tracemalloc")` for example,
+    # because we want to ensure the same code path does not break in those platforms.
+    try:
+        import tracemalloc  # noqa
+
+        has_tracemalloc = True
+    except ImportError:
+        has_tracemalloc = False
+
+    # Explicitly disable PYTHONTRACEMALLOC in case pytest's test suite is running
+    # with it enabled.
+    monkeypatch.delenv("PYTHONTRACEMALLOC", raising=False)
+
+    pytester.makepyfile(
+        """
+        def open_file(p):
+            f = p.open("r")
+            assert p.read_text() == "hello"
+
+        def test_resource_warning(tmp_path):
+            p = tmp_path.joinpath("foo.txt")
+            p.write_text("hello")
+            open_file(p)
+        """
+    )
+    result = pytester.run(sys.executable, "-Xdev", "-m", "pytest")
+    expected_extra = (
+        [
+            "*ResourceWarning* unclosed file*",
+            "*Enable tracemalloc to get traceback where the object was allocated*",
+            "*See https* for more info.",
+        ]
+        if has_tracemalloc
+        else []
+    )
+    result.stdout.fnmatch_lines([*expected_extra, "*1 passed*"])
+
+    monkeypatch.setenv("PYTHONTRACEMALLOC", "20")
+
+    result = pytester.run(sys.executable, "-Xdev", "-m", "pytest")
+    expected_extra = (
+        [
+            "*ResourceWarning* unclosed file*",
+            "*Object allocated at*",
+        ]
+        if has_tracemalloc
+        else []
+    )
+    result.stdout.fnmatch_lines([*expected_extra, "*1 passed*"])
('testing', 'test_mark.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,24 +1,26 @@
 import os
 import sys
+from typing import List
+from typing import Optional
 from unittest import mock

 import pytest
 from _pytest.config import ExitCode
-from _pytest.mark import MarkGenerator as Mark
+from _pytest.mark import MarkGenerator
 from _pytest.mark.structures import EMPTY_PARAMETERSET_OPTION
 from _pytest.nodes import Collector
 from _pytest.nodes import Node
+from _pytest.pytester import Pytester


 class TestMark:
     @pytest.mark.parametrize("attr", ["mark", "param"])
-    @pytest.mark.parametrize("modulename", ["py.test", "pytest"])
-    def test_pytest_exists_in_namespace_all(self, attr: str, modulename: str) -> None:
-        module = sys.modules[modulename]
+    def test_pytest_exists_in_namespace_all(self, attr: str) -> None:
+        module = sys.modules["pytest"]
         assert attr in module.__all__  # type: ignore

     def test_pytest_mark_notcallable(self) -> None:
-        mark = Mark()
+        mark = MarkGenerator(_ispytest=True)
         with pytest.raises(TypeError):
             mark()  # type: ignore[operator]

@@ -36,17 +38,17 @@
         assert pytest.mark.foo(SomeClass) is SomeClass
         assert pytest.mark.foo.with_args(SomeClass) is not SomeClass  # type: ignore[comparison-overlap]

-    def test_pytest_mark_name_starts_with_underscore(self):
-        mark = Mark()
+    def test_pytest_mark_name_starts_with_underscore(self) -> None:
+        mark = MarkGenerator(_ispytest=True)
         with pytest.raises(AttributeError):
             mark._some_name


-def test_marked_class_run_twice(testdir):
+def test_marked_class_run_twice(pytester: Pytester) -> None:
     """Test fails file is run twice that contains marked class.
     See issue#683.
     """
-    py_file = testdir.makepyfile(
+    py_file = pytester.makepyfile(
         """
     import pytest
     @pytest.mark.parametrize('abc', [1, 2, 3])
@@ -55,13 +57,13 @@
             assert abc in [1, 2, 3]
     """
     )
-    file_name = os.path.basename(py_file.strpath)
-    rec = testdir.inline_run(file_name, file_name)
+    file_name = os.path.basename(py_file)
+    rec = pytester.inline_run(file_name, file_name)
     rec.assertoutcome(passed=6)


-def test_ini_markers(testdir):
-    testdir.makeini(
+def test_ini_markers(pytester: Pytester) -> None:
+    pytester.makeini(
         """
         [pytest]
         markers =
@@ -69,7 +71,7 @@
             a2: this is a smoke marker
     """
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         def test_markers(pytestconfig):
             markers = pytestconfig.getini("markers")
@@ -79,12 +81,12 @@
             assert markers[1].startswith("a2:")
     """
     )
-    rec = testdir.inline_run()
+    rec = pytester.inline_run()
     rec.assertoutcome(passed=1)


-def test_markers_option(testdir):
-    testdir.makeini(
+def test_markers_option(pytester: Pytester) -> None:
+    pytester.makeini(
         """
         [pytest]
         markers =
@@ -93,21 +95,21 @@
             nodescription
     """
     )
-    result = testdir.runpytest("--markers")
+    result = pytester.runpytest("--markers")
     result.stdout.fnmatch_lines(
         ["*a1*this is a webtest*", "*a1some*another marker", "*nodescription*"]
     )


-def test_ini_markers_whitespace(testdir):
-    testdir.makeini(
+def test_ini_markers_whitespace(pytester: Pytester) -> None:
+    pytester.makeini(
         """
         [pytest]
         markers =
             a1 : this is a whitespace marker
     """
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest

@@ -116,33 +118,33 @@
             assert True
     """
     )
-    rec = testdir.inline_run("--strict-markers", "-m", "a1")
+    rec = pytester.inline_run("--strict-markers", "-m", "a1")
     rec.assertoutcome(passed=1)


-def test_marker_without_description(testdir):
-    testdir.makefile(
+def test_marker_without_description(pytester: Pytester) -> None:
+    pytester.makefile(
         ".cfg",
         setup="""
         [tool:pytest]
         markers=slow
     """,
     )
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         import pytest
         pytest.mark.xfail('FAIL')
     """
     )
-    ftdir = testdir.mkdir("ft1_dummy")
-    testdir.tmpdir.join("conftest.py").move(ftdir.join("conftest.py"))
-    rec = testdir.runpytest("--strict-markers")
+    ftdir = pytester.mkdir("ft1_dummy")
+    pytester.path.joinpath("conftest.py").replace(ftdir.joinpath("conftest.py"))
+    rec = pytester.runpytest("--strict-markers")
     rec.assert_outcomes()


-def test_markers_option_with_plugin_in_current_dir(testdir):
-    testdir.makeconftest('pytest_plugins = "flip_flop"')
-    testdir.makepyfile(
+def test_markers_option_with_plugin_in_current_dir(pytester: Pytester) -> None:
+    pytester.makeconftest('pytest_plugins = "flip_flop"')
+    pytester.makepyfile(
         flip_flop="""\
         def pytest_configure(config):
             config.addinivalue_line("markers", "flip:flop")
@@ -154,7 +156,7 @@
                 return
             metafunc.parametrize("x", (10, 20))"""
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """\
         import pytest
         @pytest.mark.flipper
@@ -162,12 +164,12 @@
             assert x"""
     )

-    result = testdir.runpytest("--markers")
+    result = pytester.runpytest("--markers")
     result.stdout.fnmatch_lines(["*flip*flop*"])


-def test_mark_on_pseudo_function(testdir):
-    testdir.makepyfile(
+def test_mark_on_pseudo_function(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import pytest

@@ -176,13 +178,15 @@
             pass
     """
     )
-    reprec = testdir.inline_run()
+    reprec = pytester.inline_run()
     reprec.assertoutcome(passed=1)


 @pytest.mark.parametrize("option_name", ["--strict-markers", "--strict"])
-def test_strict_prohibits_unregistered_markers(testdir, option_name):
-    testdir.makepyfile(
+def test_strict_prohibits_unregistered_markers(
+    pytester: Pytester, option_name: str
+) -> None:
+    pytester.makepyfile(
         """
         import pytest
         @pytest.mark.unregisteredmark
@@ -190,7 +194,7 @@
             pass
     """
     )
-    result = testdir.runpytest(option_name)
+    result = pytester.runpytest(option_name)
     assert result.ret != 0
     result.stdout.fnmatch_lines(
         ["'unregisteredmark' not found in `markers` configuration option"]
@@ -208,8 +212,10 @@
         ("xyz or xyz2", ["test_one", "test_two"]),
     ],
 )
-def test_mark_option(expr: str, expected_passed: str, testdir) -> None:
-    testdir.makepyfile(
+def test_mark_option(
+    expr: str, expected_passed: List[Optional[str]], pytester: Pytester
+) -> None:
+    pytester.makepyfile(
         """
         import pytest
         @pytest.mark.xyz
@@ -220,18 +226,20 @@
             pass
     """
     )
-    rec = testdir.inline_run("-m", expr)
+    rec = pytester.inline_run("-m", expr)
     passed, skipped, fail = rec.listoutcomes()
-    passed = [x.nodeid.split("::")[-1] for x in passed]
-    assert passed == expected_passed
+    passed_str = [x.nodeid.split("::")[-1] for x in passed]
+    assert passed_str == expected_passed


 @pytest.mark.parametrize(
     ("expr", "expected_passed"),
     [("interface", ["test_interface"]), ("not interface", ["test_nointer"])],
 )
-def test_mark_option_custom(expr: str, expected_passed: str, testdir) -> None:
-    testdir.makeconftest(
+def test_mark_option_custom(
+    expr: str, expected_passed: List[str], pytester: Pytester
+) -> None:
+    pytester.makeconftest(
         """
         import pytest
         def pytest_collection_modifyitems(items):
@@ -240,7 +248,7 @@
                     item.add_marker(pytest.mark.interface)
     """
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         def test_interface():
             pass
@@ -248,10 +256,10 @@
             pass
     """
     )
-    rec = testdir.inline_run("-m", expr)
+    rec = pytester.inline_run("-m", expr)
     passed, skipped, fail = rec.listoutcomes()
-    passed = [x.nodeid.split("::")[-1] for x in passed]
-    assert passed == expected_passed
+    passed_str = [x.nodeid.split("::")[-1] for x in passed]
+    assert passed_str == expected_passed


 @pytest.mark.parametrize(
@@ -266,8 +274,10 @@
         ("not (1 or 2)", ["test_interface", "test_nointer", "test_pass"]),
     ],
 )
-def test_keyword_option_custom(expr: str, expected_passed: str, testdir) -> None:
-    testdir.makepyfile(
+def test_keyword_option_custom(
+    expr: str, expected_passed: List[str], pytester: Pytester
+) -> None:
+    pytester.makepyfile(
         """
         def test_interface():
             pass
@@ -281,15 +291,15 @@
             pass
     """
     )
-    rec = testdir.inline_run("-k", expr)
+    rec = pytester.inline_run("-k", expr)
     passed, skipped, fail = rec.listoutcomes()
-    passed = [x.nodeid.split("::")[-1] for x in passed]
-    assert passed == expected_passed
-
-
-def test_keyword_option_considers_mark(testdir):
-    testdir.copy_example("marks/marks_considered_keywords")
-    rec = testdir.inline_run("-k", "foo")
+    passed_str = [x.nodeid.split("::")[-1] for x in passed]
+    assert passed_str == expected_passed
+
+
+def test_keyword_option_considers_mark(pytester: Pytester) -> None:
+    pytester.copy_example("marks/marks_considered_keywords")
+    rec = pytester.inline_run("-k", "foo")
     passed = rec.listoutcomes()[0]
     assert len(passed) == 1

@@ -302,8 +312,10 @@
         ("2-3", ["test_func[2-3]"]),
     ],
 )
-def test_keyword_option_parametrize(expr: str, expected_passed: str, testdir) -> None:
-    testdir.makepyfile(
+def test_keyword_option_parametrize(
+    expr: str, expected_passed: List[str], pytester: Pytester
+) -> None:
+    pytester.makepyfile(
         """
         import pytest
         @pytest.mark.parametrize("arg", [None, 1.3, "2-3"])
@@ -311,14 +323,14 @@
             pass
     """
     )
-    rec = testdir.inline_run("-k", expr)
+    rec = pytester.inline_run("-k", expr)
     passed, skipped, fail = rec.listoutcomes()
-    passed = [x.nodeid.split("::")[-1] for x in passed]
-    assert passed == expected_passed
-
-
-def test_parametrize_with_module(testdir):
-    testdir.makepyfile(
+    passed_str = [x.nodeid.split("::")[-1] for x in passed]
+    assert passed_str == expected_passed
+
+
+def test_parametrize_with_module(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import pytest
         @pytest.mark.parametrize("arg", [pytest,])
@@ -326,7 +338,7 @@
             pass
     """
     )
-    rec = testdir.inline_run()
+    rec = pytester.inline_run()
     passed, skipped, fail = rec.listoutcomes()
     expected_id = "test_func[" + pytest.__name__ + "]"
     assert passed[0].nodeid.split("::")[-1] == expected_id
@@ -343,8 +355,14 @@
             "foo or or",
             "at column 8: expected not OR left parenthesis OR identifier; got or",
         ),
-        ("(foo", "at column 5: expected right parenthesis; got end of input",),
-        ("foo bar", "at column 5: expected end of input; got identifier",),
+        (
+            "(foo",
+            "at column 5: expected right parenthesis; got end of input",
+        ),
+        (
+            "foo bar",
+            "at column 5: expected end of input; got identifier",
+        ),
         (
             "or or",
             "at column 1: expected not OR left parenthesis OR identifier; got or",
@@ -356,23 +374,23 @@
     ],
 )
 def test_keyword_option_wrong_arguments(
-    expr: str, expected_error: str, testdir, capsys
+    expr: str, expected_error: str, pytester: Pytester, capsys
 ) -> None:
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
             def test_func(arg):
                 pass
         """
     )
-    testdir.inline_run("-k", expr)
+    pytester.inline_run("-k", expr)
     err = capsys.readouterr().err
     assert expected_error in err


-def test_parametrized_collected_from_command_line(testdir):
+def test_parametrized_collected_from_command_line(pytester: Pytester) -> None:
     """Parametrized test not collected if test named specified in command
     line issue#649."""
-    py_file = testdir.makepyfile(
+    py_file = pytester.makepyfile(
         """
         import pytest
         @pytest.mark.parametrize("arg", [None, 1.3, "2-3"])
@@ -380,14 +398,14 @@
             pass
     """
     )
-    file_name = os.path.basename(py_file.strpath)
-    rec = testdir.inline_run(file_name + "::" + "test_func")
+    file_name = os.path.basename(py_file)
+    rec = pytester.inline_run(file_name + "::" + "test_func")
     rec.assertoutcome(passed=3)


-def test_parametrized_collect_with_wrong_args(testdir):
+def test_parametrized_collect_with_wrong_args(pytester: Pytester) -> None:
     """Test collect parametrized func with wrong number of args."""
-    py_file = testdir.makepyfile(
+    py_file = pytester.makepyfile(
         """
         import pytest

@@ -397,7 +415,7 @@
     """
     )

-    result = testdir.runpytest(py_file)
+    result = pytester.runpytest(py_file)
     result.stdout.fnmatch_lines(
         [
             'test_parametrized_collect_with_wrong_args.py::test_func: in "parametrize" the number of names (2):',
@@ -408,9 +426,9 @@
     )


-def test_parametrized_with_kwargs(testdir):
+def test_parametrized_with_kwargs(pytester: Pytester) -> None:
     """Test collect parametrized func with wrong number of args."""
-    py_file = testdir.makepyfile(
+    py_file = pytester.makepyfile(
         """
         import pytest

@@ -424,13 +442,13 @@
     """
     )

-    result = testdir.runpytest(py_file)
+    result = pytester.runpytest(py_file)
     assert result.ret == 0


-def test_parametrize_iterator(testdir):
+def test_parametrize_iterator(pytester: Pytester) -> None:
     """`parametrize` should work with generators (#5354)."""
-    py_file = testdir.makepyfile(
+    py_file = pytester.makepyfile(
         """\
         import pytest

@@ -444,16 +462,16 @@
             assert a >= 1
         """
     )
-    result = testdir.runpytest(py_file)
+    result = pytester.runpytest(py_file)
     assert result.ret == 0
     # should not skip any tests
     result.stdout.fnmatch_lines(["*3 passed*"])


 class TestFunctional:
-    def test_merging_markers_deep(self, testdir):
+    def test_merging_markers_deep(self, pytester: Pytester) -> None:
         # issue 199 - propagate markers into nested classes
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             """
             import pytest
             class TestA(object):
@@ -466,13 +484,15 @@
                         assert True
         """
         )
-        items, rec = testdir.inline_genitems(p)
+        items, rec = pytester.inline_genitems(p)
         for item in items:
             print(item, item.keywords)
             assert [x for x in item.iter_markers() if x.name == "a"]

-    def test_mark_decorator_subclass_does_not_propagate_to_base(self, testdir):
-        p = testdir.makepyfile(
+    def test_mark_decorator_subclass_does_not_propagate_to_base(
+        self, pytester: Pytester
+    ) -> None:
+        p = pytester.makepyfile(
             """
             import pytest

@@ -487,12 +507,12 @@
                 def test_bar(self): pass
         """
         )
-        items, rec = testdir.inline_genitems(p)
+        items, rec = pytester.inline_genitems(p)
         self.assert_markers(items, test_foo=("a", "b"), test_bar=("a",))

-    def test_mark_should_not_pass_to_siebling_class(self, testdir):
+    def test_mark_should_not_pass_to_siebling_class(self, pytester: Pytester) -> None:
         """#568"""
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             """
             import pytest

@@ -510,7 +530,7 @@

         """
         )
-        items, rec = testdir.inline_genitems(p)
+        items, rec = pytester.inline_genitems(p)
         base_item, sub_item, sub_item_other = items
         print(items, [x.nodeid for x in items])
         # new api segregates
@@ -518,8 +538,8 @@
         assert not list(sub_item_other.iter_markers(name="b"))
         assert list(sub_item.iter_markers(name="b"))

-    def test_mark_decorator_baseclasses_merged(self, testdir):
-        p = testdir.makepyfile(
+    def test_mark_decorator_baseclasses_merged(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             import pytest

@@ -538,11 +558,11 @@
                 def test_bar(self): pass
         """
         )
-        items, rec = testdir.inline_genitems(p)
+        items, rec = pytester.inline_genitems(p)
         self.assert_markers(items, test_foo=("a", "b", "c"), test_bar=("a", "b", "d"))

-    def test_mark_closest(self, testdir):
-        p = testdir.makepyfile(
+    def test_mark_closest(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             import pytest

@@ -557,14 +577,18 @@

         """
         )
-        items, rec = testdir.inline_genitems(p)
+        items, rec = pytester.inline_genitems(p)
         has_own, has_inherited = items
-        assert has_own.get_closest_marker("c").kwargs == {"location": "function"}
-        assert has_inherited.get_closest_marker("c").kwargs == {"location": "class"}
+        has_own_marker = has_own.get_closest_marker("c")
+        has_inherited_marker = has_inherited.get_closest_marker("c")
+        assert has_own_marker is not None
+        assert has_inherited_marker is not None
+        assert has_own_marker.kwargs == {"location": "function"}
+        assert has_inherited_marker.kwargs == {"location": "class"}
         assert has_own.get_closest_marker("missing") is None

-    def test_mark_with_wrong_marker(self, testdir):
-        reprec = testdir.inline_runsource(
+    def test_mark_with_wrong_marker(self, pytester: Pytester) -> None:
+        reprec = pytester.inline_runsource(
             """
                 import pytest
                 class pytestmark(object):
@@ -577,8 +601,8 @@
         assert len(values) == 1
         assert "TypeError" in str(values[0].longrepr)

-    def test_mark_dynamically_in_funcarg(self, testdir):
-        testdir.makeconftest(
+    def test_mark_dynamically_in_funcarg(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest
             @pytest.fixture
@@ -589,17 +613,17 @@
                 terminalreporter._tw.line("keyword: %s" % values[0].keywords)
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_func(arg):
                 pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["keyword: *hello*"])

-    def test_no_marker_match_on_unmarked_names(self, testdir):
-        p = testdir.makepyfile(
+    def test_no_marker_match_on_unmarked_names(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             import pytest
             @pytest.mark.shouldmatch
@@ -610,15 +634,15 @@
                 assert 1
         """
         )
-        reprec = testdir.inline_run("-m", "test_unmarked", p)
+        reprec = pytester.inline_run("-m", "test_unmarked", p)
         passed, skipped, failed = reprec.listoutcomes()
         assert len(passed) + len(skipped) + len(failed) == 0
         dlist = reprec.getcalls("pytest_deselected")
         deselected_tests = dlist[0].items
         assert len(deselected_tests) == 2

-    def test_keywords_at_node_level(self, testdir):
-        testdir.makepyfile(
+    def test_keywords_at_node_level(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture(scope="session", autouse=True)
@@ -636,11 +660,11 @@
                 pass
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)

-    def test_keyword_added_for_session(self, testdir):
-        testdir.makeconftest(
+    def test_keyword_added_for_session(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest
             def pytest_collection_modifyitems(session):
@@ -651,7 +675,7 @@
                         session.add_marker(10))
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_some(request):
                 assert "mark1" in request.keywords
@@ -664,14 +688,14 @@
                 assert marker.kwargs == {}
         """
         )
-        reprec = testdir.inline_run("-m", "mark1")
+        reprec = pytester.inline_run("-m", "mark1")
         reprec.assertoutcome(passed=1)

-    def assert_markers(self, items, **expected):
+    def assert_markers(self, items, **expected) -> None:
         """Assert that given items have expected marker names applied to them.
         expected should be a dict of (item name -> seq of expected marker names).

-        Note: this could be moved to ``testdir`` if proven to be useful
+        Note: this could be moved to ``pytester`` if proven to be useful
         to other modules.
         """
         items = {x.name: x for x in items}
@@ -680,9 +704,9 @@
             assert markers == set(expected_markers)

     @pytest.mark.filterwarnings("ignore")
-    def test_mark_from_parameters(self, testdir):
+    def test_mark_from_parameters(self, pytester: Pytester) -> None:
         """#1540"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -701,12 +725,12 @@
                 assert True
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(skipped=1)

-    def test_reevaluate_dynamic_expr(self, testdir):
+    def test_reevaluate_dynamic_expr(self, pytester: Pytester) -> None:
         """#7360"""
-        py_file1 = testdir.makepyfile(
+        py_file1 = pytester.makepyfile(
             test_reevaluate_dynamic_expr1="""
             import pytest

@@ -717,7 +741,7 @@
                 assert True
         """
         )
-        py_file2 = testdir.makepyfile(
+        py_file2 = pytester.makepyfile(
             test_reevaluate_dynamic_expr2="""
             import pytest

@@ -729,15 +753,15 @@
         """
         )

-        file_name1 = os.path.basename(py_file1.strpath)
-        file_name2 = os.path.basename(py_file2.strpath)
-        reprec = testdir.inline_run(file_name1, file_name2)
+        file_name1 = os.path.basename(py_file1)
+        file_name2 = os.path.basename(py_file2)
+        reprec = pytester.inline_run(file_name1, file_name2)
         reprec.assertoutcome(passed=1, skipped=1)


 class TestKeywordSelection:
-    def test_select_simple(self, testdir):
-        file_test = testdir.makepyfile(
+    def test_select_simple(self, pytester: Pytester) -> None:
+        file_test = pytester.makepyfile(
             """
             def test_one():
                 assert 0
@@ -748,7 +772,7 @@
         )

         def check(keyword, name):
-            reprec = testdir.inline_run("-s", "-k", keyword, file_test)
+            reprec = pytester.inline_run("-s", "-k", keyword, file_test)
             passed, skipped, failed = reprec.listoutcomes()
             assert len(failed) == 1
             assert failed[0].nodeid.split("::")[-1] == name
@@ -769,8 +793,8 @@
             "xxx and TestClass and test_2",
         ],
     )
-    def test_select_extra_keywords(self, testdir, keyword):
-        p = testdir.makepyfile(
+    def test_select_extra_keywords(self, pytester: Pytester, keyword) -> None:
+        p = pytester.makepyfile(
             test_select="""
             def test_1():
                 pass
@@ -779,7 +803,7 @@
                     pass
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             conftest="""
             import pytest
             @pytest.hookimpl(hookwrapper=True)
@@ -790,7 +814,7 @@
                     item.extra_keyword_matches.add("xxx")
         """
         )
-        reprec = testdir.inline_run(p.dirpath(), "-s", "-k", keyword)
+        reprec = pytester.inline_run(p.parent, "-s", "-k", keyword)
         print("keyword", repr(keyword))
         passed, skipped, failed = reprec.listoutcomes()
         assert len(passed) == 1
@@ -799,38 +823,21 @@
         assert len(dlist) == 1
         assert dlist[0].items[0].name == "test_1"

-    def test_select_starton(self, testdir):
-        threepass = testdir.makepyfile(
-            test_threepass="""
-            def test_one(): assert 1
-            def test_two(): assert 1
-            def test_three(): assert 1
-        """
-        )
-        reprec = testdir.inline_run("-k", "test_two:", threepass)
-        passed, skipped, failed = reprec.listoutcomes()
-        assert len(passed) == 2
-        assert not failed
-        dlist = reprec.getcalls("pytest_deselected")
-        assert len(dlist) == 1
-        item = dlist[0].items[0]
-        assert item.name == "test_one"
-
-    def test_keyword_extra(self, testdir):
-        p = testdir.makepyfile(
+    def test_keyword_extra(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
            def test_one():
                assert 0
            test_one.mykeyword = True
         """
         )
-        reprec = testdir.inline_run("-k", "mykeyword", p)
+        reprec = pytester.inline_run("-k", "mykeyword", p)
         passed, skipped, failed = reprec.countoutcomes()
         assert failed == 1

     @pytest.mark.xfail
-    def test_keyword_extra_dash(self, testdir):
-        p = testdir.makepyfile(
+    def test_keyword_extra_dash(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
            def test_one():
                assert 0
@@ -839,42 +846,43 @@
         )
         # with argparse the argument to an option cannot
         # start with '-'
-        reprec = testdir.inline_run("-k", "-mykeyword", p)
+        reprec = pytester.inline_run("-k", "-mykeyword", p)
         passed, skipped, failed = reprec.countoutcomes()
         assert passed + skipped + failed == 0

     @pytest.mark.parametrize(
-        "keyword", ["__", "+", ".."],
-    )
-    def test_no_magic_values(self, testdir, keyword: str) -> None:
+        "keyword",
+        ["__", "+", ".."],
+    )
+    def test_no_magic_values(self, pytester: Pytester, keyword: str) -> None:
         """Make sure the tests do not match on magic values,
         no double underscored values, like '__dict__' and '+'.
         """
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             """
             def test_one(): assert 1
         """
         )

-        reprec = testdir.inline_run("-k", keyword, p)
+        reprec = pytester.inline_run("-k", keyword, p)
         passed, skipped, failed = reprec.countoutcomes()
         dlist = reprec.getcalls("pytest_deselected")
         assert passed + skipped + failed == 0
         deselected_tests = dlist[0].items
         assert len(deselected_tests) == 1

-    def test_no_match_directories_outside_the_suite(self, testdir):
+    def test_no_match_directories_outside_the_suite(self, pytester: Pytester) -> None:
         """`-k` should not match against directories containing the test suite (#7040)."""
         test_contents = """
             def test_aaa(): pass
             def test_ddd(): pass
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             **{"ddd/tests/__init__.py": "", "ddd/tests/test_foo.py": test_contents}
         )

         def get_collected_names(*args):
-            _, rec = testdir.inline_genitems(*args)
+            _, rec = pytester.inline_genitems(*args)
             calls = rec.getcalls("pytest_collection_finish")
             assert len(calls) == 1
             return [x.name for x in calls[0].session.items]
@@ -883,7 +891,7 @@
         assert get_collected_names() == ["test_aaa", "test_ddd"]

         # do not collect anything based on names outside the collection tree
-        assert get_collected_names("-k", testdir.tmpdir.basename) == []
+        assert get_collected_names("-k", pytester._name) == []

         # "-k ddd" should only collect "test_ddd", but not
         # 'test_aaa' just because one of its parent directories is named "ddd";
@@ -902,7 +910,7 @@
             ("foo", pytest.mark.bar(), False),
         ],
     )
-    def test__eq__(self, lhs, rhs, expected):
+    def test__eq__(self, lhs, rhs, expected) -> None:
         assert (lhs == rhs) == expected

     def test_aliases(self) -> None:
@@ -913,9 +921,11 @@


 @pytest.mark.parametrize("mark", [None, "", "skip", "xfail"])
-def test_parameterset_for_parametrize_marks(testdir, mark):
+def test_parameterset_for_parametrize_marks(
+    pytester: Pytester, mark: Optional[str]
+) -> None:
     if mark is not None:
-        testdir.makeini(
+        pytester.makeini(
             """
         [pytest]
         {}={}
@@ -924,7 +934,7 @@
             )
         )

-    config = testdir.parseconfig()
+    config = pytester.parseconfig()
     from _pytest.mark import pytest_configure, get_empty_parameterset_mark

     pytest_configure(config)
@@ -938,8 +948,8 @@
         assert result_mark.kwargs.get("run") is False


-def test_parameterset_for_fail_at_collect(testdir):
-    testdir.makeini(
+def test_parameterset_for_fail_at_collect(pytester: Pytester) -> None:
+    pytester.makeini(
         """
     [pytest]
     {}=fail_at_collect
@@ -948,7 +958,7 @@
         )
     )

-    config = testdir.parseconfig()
+    config = pytester.parseconfig()
     from _pytest.mark import pytest_configure, get_empty_parameterset_mark

     pytest_configure(config)
@@ -959,7 +969,7 @@
     ):
         get_empty_parameterset_mark(config, ["a"], pytest_configure)

-    p1 = testdir.makepyfile(
+    p1 = pytester.makepyfile(
         """
         import pytest

@@ -968,7 +978,7 @@
             pass
         """
     )
-    result = testdir.runpytest(str(p1))
+    result = pytester.runpytest(str(p1))
     result.stdout.fnmatch_lines(
         [
             "collected 0 items / 1 error",
@@ -980,13 +990,13 @@
     assert result.ret == ExitCode.INTERRUPTED


-def test_parameterset_for_parametrize_bad_markname(testdir):
+def test_parameterset_for_parametrize_bad_markname(pytester: Pytester) -> None:
     with pytest.raises(pytest.UsageError):
-        test_parameterset_for_parametrize_marks(testdir, "bad")
-
-
-def test_mark_expressions_no_smear(testdir):
-    testdir.makepyfile(
+        test_parameterset_for_parametrize_marks(pytester, "bad")
+
+
+def test_mark_expressions_no_smear(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import pytest

@@ -1004,7 +1014,7 @@
     """
     )

-    reprec = testdir.inline_run("-m", "FOO")
+    reprec = pytester.inline_run("-m", "FOO")
     passed, skipped, failed = reprec.countoutcomes()
     dlist = reprec.getcalls("pytest_deselected")
     assert passed == 1
@@ -1014,17 +1024,18 @@

     # todo: fixed
     # keywords smear - expected behaviour
-    # reprec_keywords = testdir.inline_run("-k", "FOO")
+    # reprec_keywords = pytester.inline_run("-k", "FOO")
     # passed_k, skipped_k, failed_k = reprec_keywords.countoutcomes()
     # assert passed_k == 2
     # assert skipped_k == failed_k == 0


-def test_addmarker_order():
+def test_addmarker_order(pytester) -> None:
     session = mock.Mock()
     session.own_markers = []
     session.parent = None
     session.nodeid = ""
+    session.path = pytester.path
     node = Node.from_parent(session, name="Test")
     node.add_marker("foo")
     node.add_marker("bar")
@@ -1034,9 +1045,9 @@


 @pytest.mark.filterwarnings("ignore")
-def test_markers_from_parametrize(testdir):
+def test_markers_from_parametrize(pytester: Pytester) -> None:
     """#3605"""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest

@@ -1067,7 +1078,7 @@
     """
     )

-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.assert_outcomes(passed=4)


@@ -1079,13 +1090,13 @@


 @pytest.mark.parametrize("s", (None, "hello world"))
-def test_pytest_param_id_allows_none_or_string(s):
+def test_pytest_param_id_allows_none_or_string(s) -> None:
     assert pytest.param(id=s)


-@pytest.mark.parametrize("expr", ("NOT internal_err", "NOT (internal_err)", "bogus/"))
-def test_marker_expr_eval_failure_handling(testdir, expr):
-    foo = testdir.makepyfile(
+@pytest.mark.parametrize("expr", ("NOT internal_err", "NOT (internal_err)", "bogus="))
+def test_marker_expr_eval_failure_handling(pytester: Pytester, expr) -> None:
+    foo = pytester.makepyfile(
         """
         import pytest

@@ -1094,7 +1105,7 @@
             pass
         """
     )
-    expected = "ERROR: Wrong expression passed to '-m': {}: *".format(expr)
-    result = testdir.runpytest(foo, "-m", expr)
+    expected = f"ERROR: Wrong expression passed to '-m': {expr}: *"
+    result = pytester.runpytest(foo, "-m", expr)
     result.stderr.fnmatch_lines([expected])
     assert result.ret == ExitCode.USAGE_ERROR
('testing', 'test_faulthandler.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,48 +1,69 @@
+import io
 import sys

 import pytest
+from _pytest.pytester import Pytester


-def test_enabled(testdir):
+def test_enabled(pytester: Pytester) -> None:
     """Test single crashing test displays a traceback."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
     import faulthandler
     def test_crash():
         faulthandler._sigabrt()
     """
     )
-    result = testdir.runpytest_subprocess()
+    result = pytester.runpytest_subprocess()
     result.stderr.fnmatch_lines(["*Fatal Python error*"])
     assert result.ret != 0


-def test_crash_near_exit(testdir):
-    """Test that fault handler displays crashes that happen even after
-    pytest is exiting (for example, when the interpreter is shutting down)."""
-    testdir.makepyfile(
+def setup_crashing_test(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
-    import faulthandler
-    import atexit
-    def test_ok():
-        atexit.register(faulthandler._sigabrt)
+        import faulthandler
+        import atexit
+        def test_ok():
+            atexit.register(faulthandler._sigabrt)
+        """
+    )
+
+
+def test_crash_during_shutdown_captured(pytester: Pytester) -> None:
     """
-    )
-    result = testdir.runpytest_subprocess()
+    Re-enable faulthandler if pytest encountered it enabled during configure.
+    We should be able to then see crashes during interpreter shutdown.
+    """
+    setup_crashing_test(pytester)
+    args = (sys.executable, "-Xfaulthandler", "-mpytest")
+    result = pytester.run(*args)
     result.stderr.fnmatch_lines(["*Fatal Python error*"])
     assert result.ret != 0


-def test_disabled(testdir):
+def test_crash_during_shutdown_not_captured(pytester: Pytester) -> None:
+    """
+    Check that pytest leaves faulthandler disabled if it was not enabled during configure.
+    This prevents us from seeing crashes during interpreter shutdown (see #8260).
+    """
+    setup_crashing_test(pytester)
+    args = (sys.executable, "-mpytest")
+    result = pytester.run(*args)
+    result.stderr.no_fnmatch_line("*Fatal Python error*")
+    assert result.ret != 0
+
+
+def test_disabled(pytester: Pytester) -> None:
     """Test option to disable fault handler in the command line."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
     import faulthandler
     def test_disabled():
         assert not faulthandler.is_enabled()
     """
     )
-    result = testdir.runpytest_subprocess("-p", "no:faulthandler")
+    result = pytester.runpytest_subprocess("-p", "no:faulthandler")
     result.stdout.fnmatch_lines(["*1 passed*"])
     assert result.ret == 0

@@ -56,19 +77,19 @@
         False,
     ],
 )
-def test_timeout(testdir, enabled: bool) -> None:
+def test_timeout(pytester: Pytester, enabled: bool) -> None:
     """Test option to dump tracebacks after a certain timeout.

     If faulthandler is disabled, no traceback will be dumped.
     """
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
     import os, time
     def test_timeout():
         time.sleep(1 if "CI" in os.environ else 0.1)
     """
     )
-    testdir.makeini(
+    pytester.makeini(
         """
         [pytest]
         faulthandler_timeout = 0.01
@@ -76,7 +97,7 @@
     )
     args = ["-p", "no:faulthandler"] if not enabled else []

-    result = testdir.runpytest_subprocess(*args)
+    result = pytester.runpytest_subprocess(*args)
     tb_output = "most recent call first"
     if enabled:
         result.stderr.fnmatch_lines(["*%s*" % tb_output])
@@ -87,12 +108,12 @@


 @pytest.mark.parametrize("hook_name", ["pytest_enter_pdb", "pytest_exception_interact"])
-def test_cancel_timeout_on_hook(monkeypatch, hook_name):
+def test_cancel_timeout_on_hook(monkeypatch, hook_name) -> None:
     """Make sure that we are cancelling any scheduled traceback dumping due
     to timeout before entering pdb (pytest-dev/pytest-faulthandler#12) or any
     other interactive exception (pytest-dev/pytest-faulthandler#14)."""
     import faulthandler
-    from _pytest.faulthandler import FaultHandlerHooks
+    from _pytest import faulthandler as faulthandler_plugin

     called = []

@@ -102,35 +123,50 @@

     # call our hook explicitly, we can trust that pytest will call the hook
     # for us at the appropriate moment
-    hook_func = getattr(FaultHandlerHooks, hook_name)
-    hook_func(self=None)
+    hook_func = getattr(faulthandler_plugin, hook_name)
+    hook_func()
     assert called == [1]


-@pytest.mark.parametrize("faulthandler_timeout", [0, 2])
-def test_already_initialized(faulthandler_timeout, testdir):
-    """Test for faulthandler being initialized earlier than pytest (#6575)."""
-    testdir.makepyfile(
+def test_already_initialized_crash(pytester: Pytester) -> None:
+    """Even if faulthandler is already initialized, we still dump tracebacks on crashes (#8258)."""
+    pytester.makepyfile(
         """
         def test():
             import faulthandler
-            assert faulthandler.is_enabled()
+            faulthandler._sigabrt()
     """
     )
-    result = testdir.run(
+    result = pytester.run(
         sys.executable,
         "-X",
         "faulthandler",
         "-mpytest",
-        testdir.tmpdir,
-        "-o",
-        "faulthandler_timeout={}".format(faulthandler_timeout),
+        pytester.path,
     )
-    # ensure warning is emitted if faulthandler_timeout is configured
-    warning_line = "*faulthandler.py*faulthandler module enabled before*"
-    if faulthandler_timeout > 0:
-        result.stdout.fnmatch_lines(warning_line)
-    else:
-        result.stdout.no_fnmatch_line(warning_line)
-    result.stdout.fnmatch_lines("*1 passed*")
-    assert result.ret == 0
+    result.stderr.fnmatch_lines(["*Fatal Python error*"])
+    assert result.ret != 0
+
+
+def test_get_stderr_fileno_invalid_fd() -> None:
+    """Test for faulthandler being able to handle invalid file descriptors for stderr (#8249)."""
+    from _pytest.faulthandler import get_stderr_fileno
+
+    class StdErrWrapper(io.StringIO):
+        """
+        Mimic ``twisted.logger.LoggingFile`` to simulate returning an invalid file descriptor.
+
+        https://github.com/twisted/twisted/blob/twisted-20.3.0/src/twisted/logger/_io.py#L132-L139
+        """
+
+        def fileno(self):
+            return -1
+
+    wrapper = StdErrWrapper()
+
+    with pytest.MonkeyPatch.context() as mp:
+        mp.setattr("sys.stderr", wrapper)
+
+        # Even when the stderr wrapper signals an invalid file descriptor,
+        # ``_get_stderr_fileno()`` should return the real one.
+        assert get_stderr_fileno() == 2
('testing', 'test_recwarn.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -3,6 +3,7 @@
 from typing import Optional

 import pytest
+from _pytest.pytester import Pytester
 from _pytest.recwarn import WarningsRecorder


@@ -12,8 +13,8 @@
     assert warn.filename == __file__


-def test_recwarn_functional(testdir) -> None:
-    testdir.makepyfile(
+def test_recwarn_functional(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import warnings
         def test_method(recwarn):
@@ -22,13 +23,24 @@
             assert isinstance(warn.message, UserWarning)
     """
     )
-    reprec = testdir.inline_run()
+    reprec = pytester.inline_run()
     reprec.assertoutcome(passed=1)
+
+
+@pytest.mark.filterwarnings("")
+def test_recwarn_captures_deprecation_warning(recwarn: WarningsRecorder) -> None:
+    """
+    Check that recwarn can capture DeprecationWarning by default
+    without custom filterwarnings (see #8666).
+    """
+    warnings.warn(DeprecationWarning("some deprecation"))
+    assert len(recwarn) == 1
+    assert recwarn.pop(DeprecationWarning)


 class TestWarningsRecorderChecker:
     def test_recording(self) -> None:
-        rec = WarningsRecorder()
+        rec = WarningsRecorder(_ispytest=True)
         with rec:
             assert not rec.list
             warnings.warn_explicit("hello", UserWarning, "xyz", 13)
@@ -45,7 +57,7 @@

     def test_warn_stacklevel(self) -> None:
         """#4243"""
-        rec = WarningsRecorder()
+        rec = WarningsRecorder(_ispytest=True)
         with rec:
             warnings.warn("test", DeprecationWarning, 2)

@@ -53,21 +65,21 @@
         from _pytest.recwarn import WarningsChecker

         with pytest.raises(TypeError):
-            WarningsChecker(5)  # type: ignore
+            WarningsChecker(5, _ispytest=True)  # type: ignore[arg-type]
         with pytest.raises(TypeError):
-            WarningsChecker(("hi", RuntimeWarning))  # type: ignore
+            WarningsChecker(("hi", RuntimeWarning), _ispytest=True)  # type: ignore[arg-type]
         with pytest.raises(TypeError):
-            WarningsChecker([DeprecationWarning, RuntimeWarning])  # type: ignore
+            WarningsChecker([DeprecationWarning, RuntimeWarning], _ispytest=True)  # type: ignore[arg-type]

     def test_invalid_enter_exit(self) -> None:
         # wrap this test in WarningsRecorder to ensure warning state gets reset
-        with WarningsRecorder():
+        with WarningsRecorder(_ispytest=True):
             with pytest.raises(RuntimeError):
-                rec = WarningsRecorder()
+                rec = WarningsRecorder(_ispytest=True)
                 rec.__exit__(None, None, None)  # can't exit before entering

             with pytest.raises(RuntimeError):
-                rec = WarningsRecorder()
+                rec = WarningsRecorder(_ispytest=True)
                 with rec:
                     with rec:
                         pass  # can't enter twice
@@ -102,13 +114,13 @@
         # Type ignored because `onceregistry` and `filters` are not
         # documented API.
         onceregistry = warnings.onceregistry.copy()  # type: ignore
-        filters = warnings.filters[:]  # type: ignore
+        filters = warnings.filters[:]
         warn = warnings.warn
         warn_explicit = warnings.warn_explicit
         self.test_deprecated_call_raises()
         self.test_deprecated_call()
         assert onceregistry == warnings.onceregistry  # type: ignore
-        assert filters == warnings.filters  # type: ignore
+        assert filters == warnings.filters
         assert warn is warnings.warn
         assert warn_explicit is warnings.warn_explicit

@@ -251,7 +263,7 @@
             with pytest.warns(RuntimeWarning):
                 warnings.warn("user", UserWarning)
         excinfo.match(
-            r"DID NOT WARN. No warnings of type \(.+RuntimeWarning.+,\) was emitted. "
+            r"DID NOT WARN. No warnings of type \(.+RuntimeWarning.+,\) were emitted. "
             r"The list of emitted warnings is: \[UserWarning\('user',?\)\]."
         )

@@ -259,7 +271,7 @@
             with pytest.warns(UserWarning):
                 warnings.warn("runtime", RuntimeWarning)
         excinfo.match(
-            r"DID NOT WARN. No warnings of type \(.+UserWarning.+,\) was emitted. "
+            r"DID NOT WARN. No warnings of type \(.+UserWarning.+,\) were emitted. "
             r"The list of emitted warnings is: \[RuntimeWarning\('runtime',?\)\]."
         )

@@ -267,7 +279,7 @@
             with pytest.warns(UserWarning):
                 pass
         excinfo.match(
-            r"DID NOT WARN. No warnings of type \(.+UserWarning.+,\) was emitted. "
+            r"DID NOT WARN. No warnings of type \(.+UserWarning.+,\) were emitted. "
             r"The list of emitted warnings is: \[\]."
         )

@@ -278,7 +290,7 @@
                 warnings.warn("import", ImportWarning)

         message_template = (
-            "DID NOT WARN. No warnings of type {0} was emitted. "
+            "DID NOT WARN. No warnings of type {0} were emitted. "
             "The list of emitted warnings is: {1}."
         )
         excinfo.match(
@@ -297,13 +309,25 @@
         assert str(record[0].message) == "user"

     def test_record_only(self) -> None:
-        with pytest.warns(None) as record:
+        with pytest.warns() as record:
             warnings.warn("user", UserWarning)
             warnings.warn("runtime", RuntimeWarning)

         assert len(record) == 2
         assert str(record[0].message) == "user"
         assert str(record[1].message) == "runtime"
+
+    def test_record_only_none_deprecated_warn(self) -> None:
+        # This should become an error when WARNS_NONE_ARG is removed in Pytest 8.0
+        with warnings.catch_warnings():
+            warnings.simplefilter("ignore")
+            with pytest.warns(None) as record:  # type: ignore[call-overload]
+                warnings.warn("user", UserWarning)
+                warnings.warn("runtime", RuntimeWarning)
+
+            assert len(record) == 2
+            assert str(record[0].message) == "user"
+            assert str(record[1].message) == "runtime"

     def test_record_by_subclass(self) -> None:
         with pytest.warns(Warning) as record:
@@ -328,9 +352,9 @@
         assert str(record[0].message) == "user"
         assert str(record[1].message) == "runtime"

-    def test_double_test(self, testdir) -> None:
+    def test_double_test(self, pytester: Pytester) -> None:
         """If a test is run again, the warning should still be raised"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest
             import warnings
@@ -341,7 +365,7 @@
                     warnings.warn("runtime", RuntimeWarning)
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*2 passed in*"])

     def test_match_regex(self) -> None:
('testing', 'test_session.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,10 +1,12 @@
 import pytest
 from _pytest.config import ExitCode
+from _pytest.monkeypatch import MonkeyPatch
+from _pytest.pytester import Pytester


 class SessionTests:
-    def test_basic_testitem_events(self, testdir):
-        tfile = testdir.makepyfile(
+    def test_basic_testitem_events(self, pytester: Pytester) -> None:
+        tfile = pytester.makepyfile(
             """
             def test_one():
                 pass
@@ -17,7 +19,7 @@
                     pass
         """
         )
-        reprec = testdir.inline_run(tfile)
+        reprec = pytester.inline_run(tfile)
         passed, skipped, failed = reprec.listoutcomes()
         assert len(skipped) == 0
         assert len(passed) == 1
@@ -35,8 +37,8 @@
         # assert len(colreports) == 4
         # assert colreports[1].report.failed

-    def test_nested_import_error(self, testdir):
-        tfile = testdir.makepyfile(
+    def test_nested_import_error(self, pytester: Pytester) -> None:
+        tfile = pytester.makepyfile(
             """
             import import_fails
             def test_this():
@@ -47,14 +49,14 @@
             a = 1
         """,
         )
-        reprec = testdir.inline_run(tfile)
+        reprec = pytester.inline_run(tfile)
         values = reprec.getfailedcollections()
         assert len(values) == 1
         out = str(values[0].longrepr)
         assert out.find("does_not_work") != -1

-    def test_raises_output(self, testdir):
-        reprec = testdir.inline_runsource(
+    def test_raises_output(self, pytester: Pytester) -> None:
+        reprec = pytester.inline_runsource(
             """
             import pytest
             def test_raises_doesnt():
@@ -63,18 +65,18 @@
         )
         passed, skipped, failed = reprec.listoutcomes()
         assert len(failed) == 1
-        out = failed[0].longrepr.reprcrash.message
+        out = failed[0].longrepr.reprcrash.message  # type: ignore[union-attr]
         assert "DID NOT RAISE" in out

-    def test_syntax_error_module(self, testdir):
-        reprec = testdir.inline_runsource("this is really not python")
+    def test_syntax_error_module(self, pytester: Pytester) -> None:
+        reprec = pytester.inline_runsource("this is really not python")
         values = reprec.getfailedcollections()
         assert len(values) == 1
         out = str(values[0].longrepr)
         assert out.find("not python") != -1

-    def test_exit_first_problem(self, testdir):
-        reprec = testdir.inline_runsource(
+    def test_exit_first_problem(self, pytester: Pytester) -> None:
+        reprec = pytester.inline_runsource(
             """
             def test_one(): assert 0
             def test_two(): assert 0
@@ -85,8 +87,8 @@
         assert failed == 1
         assert passed == skipped == 0

-    def test_maxfail(self, testdir):
-        reprec = testdir.inline_runsource(
+    def test_maxfail(self, pytester: Pytester) -> None:
+        reprec = pytester.inline_runsource(
             """
             def test_one(): assert 0
             def test_two(): assert 0
@@ -98,8 +100,8 @@
         assert failed == 2
         assert passed == skipped == 0

-    def test_broken_repr(self, testdir):
-        p = testdir.makepyfile(
+    def test_broken_repr(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             import pytest

@@ -124,14 +126,14 @@

         """
         )
-        reprec = testdir.inline_run(p)
+        reprec = pytester.inline_run(p)
         passed, skipped, failed = reprec.listoutcomes()
         assert (len(passed), len(skipped), len(failed)) == (1, 0, 1)
-        out = failed[0].longrepr.reprcrash.message
+        out = failed[0].longrepr.reprcrash.message  # type: ignore[union-attr]
         assert out.find("<[reprexc() raised in repr()] BrokenRepr1") != -1

-    def test_broken_repr_with_showlocals_verbose(self, testdir):
-        p = testdir.makepyfile(
+    def test_broken_repr_with_showlocals_verbose(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             class ObjWithErrorInRepr:
                 def __repr__(self):
@@ -142,10 +144,10 @@
                 assert x == "value"
         """
         )
-        reprec = testdir.inline_run("--showlocals", "-vv", p)
+        reprec = pytester.inline_run("--showlocals", "-vv", p)
         passed, skipped, failed = reprec.listoutcomes()
         assert (len(passed), len(skipped), len(failed)) == (0, 0, 1)
-        entries = failed[0].longrepr.reprtraceback.reprentries
+        entries = failed[0].longrepr.reprtraceback.reprentries  # type: ignore[union-attr]
         assert len(entries) == 1
         repr_locals = entries[0].reprlocals
         assert repr_locals.lines
@@ -154,8 +156,8 @@
             "x          = <[NotImplementedError() raised in repr()] ObjWithErrorInRepr"
         )

-    def test_skip_file_by_conftest(self, testdir):
-        testdir.makepyfile(
+    def test_skip_file_by_conftest(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             conftest="""
             import pytest
             def pytest_collect_file():
@@ -166,7 +168,7 @@
         """,
         )
         try:
-            reprec = testdir.inline_run(testdir.tmpdir)
+            reprec = pytester.inline_run(pytester.path)
         except pytest.skip.Exception:  # pragma: no cover
             pytest.fail("wrong skipped caught")
         reports = reprec.getreports("pytest_collectreport")
@@ -175,8 +177,8 @@


 class TestNewSession(SessionTests):
-    def test_order_of_execution(self, testdir):
-        reprec = testdir.inline_runsource(
+    def test_order_of_execution(self, pytester: Pytester) -> None:
+        reprec = pytester.inline_runsource(
             """
             values = []
             def test_1():
@@ -201,8 +203,8 @@
         assert failed == skipped == 0
         assert passed == 7

-    def test_collect_only_with_various_situations(self, testdir):
-        p = testdir.makepyfile(
+    def test_collect_only_with_various_situations(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             test_one="""
                 def test_one():
                     raise ValueError()
@@ -217,7 +219,7 @@
             test_three="xxxdsadsadsadsa",
             __init__="",
         )
-        reprec = testdir.inline_run("--collect-only", p.dirpath())
+        reprec = pytester.inline_run("--collect-only", p.parent)

         itemstarted = reprec.getcalls("pytest_itemcollected")
         assert len(itemstarted) == 3
@@ -225,70 +227,70 @@
         started = reprec.getcalls("pytest_collectstart")
         finished = reprec.getreports("pytest_collectreport")
         assert len(started) == len(finished)
-        assert len(started) == 8
+        assert len(started) == 6
         colfail = [x for x in finished if x.failed]
         assert len(colfail) == 1

-    def test_minus_x_import_error(self, testdir):
-        testdir.makepyfile(__init__="")
-        testdir.makepyfile(test_one="xxxx", test_two="yyyy")
-        reprec = testdir.inline_run("-x", testdir.tmpdir)
+    def test_minus_x_import_error(self, pytester: Pytester) -> None:
+        pytester.makepyfile(__init__="")
+        pytester.makepyfile(test_one="xxxx", test_two="yyyy")
+        reprec = pytester.inline_run("-x", pytester.path)
         finished = reprec.getreports("pytest_collectreport")
         colfail = [x for x in finished if x.failed]
         assert len(colfail) == 1

-    def test_minus_x_overridden_by_maxfail(self, testdir):
-        testdir.makepyfile(__init__="")
-        testdir.makepyfile(test_one="xxxx", test_two="yyyy", test_third="zzz")
-        reprec = testdir.inline_run("-x", "--maxfail=2", testdir.tmpdir)
+    def test_minus_x_overridden_by_maxfail(self, pytester: Pytester) -> None:
+        pytester.makepyfile(__init__="")
+        pytester.makepyfile(test_one="xxxx", test_two="yyyy", test_third="zzz")
+        reprec = pytester.inline_run("-x", "--maxfail=2", pytester.path)
         finished = reprec.getreports("pytest_collectreport")
         colfail = [x for x in finished if x.failed]
         assert len(colfail) == 2


-def test_plugin_specify(testdir):
+def test_plugin_specify(pytester: Pytester) -> None:
     with pytest.raises(ImportError):
-        testdir.parseconfig("-p", "nqweotexistent")
+        pytester.parseconfig("-p", "nqweotexistent")
     # pytest.raises(ImportError,
     #    "config.do_configure(config)"
     # )


-def test_plugin_already_exists(testdir):
-    config = testdir.parseconfig("-p", "terminal")
+def test_plugin_already_exists(pytester: Pytester) -> None:
+    config = pytester.parseconfig("-p", "terminal")
     assert config.option.plugins == ["terminal"]
     config._do_configure()
     config._ensure_unconfigure()


-def test_exclude(testdir):
-    hellodir = testdir.mkdir("hello")
-    hellodir.join("test_hello.py").write("x y syntaxerror")
-    hello2dir = testdir.mkdir("hello2")
-    hello2dir.join("test_hello2.py").write("x y syntaxerror")
-    testdir.makepyfile(test_ok="def test_pass(): pass")
-    result = testdir.runpytest("--ignore=hello", "--ignore=hello2")
+def test_exclude(pytester: Pytester) -> None:
+    hellodir = pytester.mkdir("hello")
+    hellodir.joinpath("test_hello.py").write_text("x y syntaxerror")
+    hello2dir = pytester.mkdir("hello2")
+    hello2dir.joinpath("test_hello2.py").write_text("x y syntaxerror")
+    pytester.makepyfile(test_ok="def test_pass(): pass")
+    result = pytester.runpytest("--ignore=hello", "--ignore=hello2")
     assert result.ret == 0
     result.stdout.fnmatch_lines(["*1 passed*"])


-def test_exclude_glob(testdir):
-    hellodir = testdir.mkdir("hello")
-    hellodir.join("test_hello.py").write("x y syntaxerror")
-    hello2dir = testdir.mkdir("hello2")
-    hello2dir.join("test_hello2.py").write("x y syntaxerror")
-    hello3dir = testdir.mkdir("hallo3")
-    hello3dir.join("test_hello3.py").write("x y syntaxerror")
-    subdir = testdir.mkdir("sub")
-    subdir.join("test_hello4.py").write("x y syntaxerror")
-    testdir.makepyfile(test_ok="def test_pass(): pass")
-    result = testdir.runpytest("--ignore-glob=*h[ea]llo*")
+def test_exclude_glob(pytester: Pytester) -> None:
+    hellodir = pytester.mkdir("hello")
+    hellodir.joinpath("test_hello.py").write_text("x y syntaxerror")
+    hello2dir = pytester.mkdir("hello2")
+    hello2dir.joinpath("test_hello2.py").write_text("x y syntaxerror")
+    hello3dir = pytester.mkdir("hallo3")
+    hello3dir.joinpath("test_hello3.py").write_text("x y syntaxerror")
+    subdir = pytester.mkdir("sub")
+    subdir.joinpath("test_hello4.py").write_text("x y syntaxerror")
+    pytester.makepyfile(test_ok="def test_pass(): pass")
+    result = pytester.runpytest("--ignore-glob=*h[ea]llo*")
     assert result.ret == 0
     result.stdout.fnmatch_lines(["*1 passed*"])


-def test_deselect(testdir):
-    testdir.makepyfile(
+def test_deselect(pytester: Pytester) -> None:
+    pytester.makepyfile(
         test_a="""
         import pytest

@@ -303,7 +305,7 @@
             def test_c2(self): pass
     """
     )
-    result = testdir.runpytest(
+    result = pytester.runpytest(
         "-v",
         "--deselect=test_a.py::test_a2[1]",
         "--deselect=test_a.py::test_a2[2]",
@@ -315,8 +317,8 @@
         assert not line.startswith(("test_a.py::test_a2[1]", "test_a.py::test_a2[2]"))


-def test_sessionfinish_with_start(testdir):
-    testdir.makeconftest(
+def test_sessionfinish_with_start(pytester: Pytester) -> None:
+    pytester.makeconftest(
         """
         import os
         values = []
@@ -329,18 +331,68 @@

     """
     )
-    res = testdir.runpytest("--collect-only")
+    res = pytester.runpytest("--collect-only")
     assert res.ret == ExitCode.NO_TESTS_COLLECTED


+def test_collection_args_do_not_duplicate_modules(pytester: Pytester) -> None:
+    """Test that when multiple collection args are specified on the command line
+    for the same module, only a single Module collector is created.
+
+    Regression test for #723, #3358.
+    """
+    pytester.makepyfile(
+        **{
+            "d/test_it": """
+                def test_1(): pass
+                def test_2(): pass
+                """
+        }
+    )
+
+    result = pytester.runpytest(
+        "--collect-only",
+        "d/test_it.py::test_1",
+        "d/test_it.py::test_2",
+    )
+    result.stdout.fnmatch_lines(
+        [
+            "<Module d/test_it.py>",
+            "  <Function test_1>",
+            "  <Function test_2>",
+        ],
+        consecutive=True,
+    )
+
+    # Different, but related case.
+    result = pytester.runpytest(
+        "--collect-only",
+        "--keep-duplicates",
+        "d",
+        "d",
+    )
+    result.stdout.fnmatch_lines(
+        [
+            "<Module d/test_it.py>",
+            "  <Function test_1>",
+            "  <Function test_2>",
+            "  <Function test_1>",
+            "  <Function test_2>",
+        ],
+        consecutive=True,
+    )
+
+
 @pytest.mark.parametrize("path", ["root", "{relative}/root", "{environment}/root"])
-def test_rootdir_option_arg(testdir, monkeypatch, path):
-    monkeypatch.setenv("PY_ROOTDIR_PATH", str(testdir.tmpdir))
-    path = path.format(relative=str(testdir.tmpdir), environment="$PY_ROOTDIR_PATH")
-
-    rootdir = testdir.mkdir("root")
-    rootdir.mkdir("tests")
-    testdir.makepyfile(
+def test_rootdir_option_arg(
+    pytester: Pytester, monkeypatch: MonkeyPatch, path: str
+) -> None:
+    monkeypatch.setenv("PY_ROOTDIR_PATH", str(pytester.path))
+    path = path.format(relative=str(pytester.path), environment="$PY_ROOTDIR_PATH")
+
+    rootdir = pytester.path / "root" / "tests"
+    rootdir.mkdir(parents=True)
+    pytester.makepyfile(
         """
         import os
         def test_one():
@@ -348,18 +400,18 @@
     """
     )

-    result = testdir.runpytest("--rootdir={}".format(path))
+    result = pytester.runpytest(f"--rootdir={path}")
     result.stdout.fnmatch_lines(
         [
-            "*rootdir: {}/root".format(testdir.tmpdir),
+            f"*rootdir: {pytester.path}/root",
             "root/test_rootdir_option_arg.py *",
             "*1 passed*",
         ]
     )


-def test_rootdir_wrong_option_arg(testdir):
-    result = testdir.runpytest("--rootdir=wrong_dir")
+def test_rootdir_wrong_option_arg(pytester: Pytester) -> None:
+    result = pytester.runpytest("--rootdir=wrong_dir")
     result.stderr.fnmatch_lines(
         ["*Directory *wrong_dir* not found. Check your '--rootdir' option.*"]
     )
('testing', 'test_skipping.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,7 +1,8 @@
 import sys
+import textwrap

 import pytest
-from _pytest.pytester import Testdir
+from _pytest.pytester import Pytester
 from _pytest.runner import runtestprotocol
 from _pytest.skipping import evaluate_skip_marks
 from _pytest.skipping import evaluate_xfail_marks
@@ -9,13 +10,13 @@


 class TestEvaluation:
-    def test_no_marker(self, testdir):
-        item = testdir.getitem("def test_func(): pass")
+    def test_no_marker(self, pytester: Pytester) -> None:
+        item = pytester.getitem("def test_func(): pass")
         skipped = evaluate_skip_marks(item)
         assert not skipped

-    def test_marked_xfail_no_args(self, testdir):
-        item = testdir.getitem(
+    def test_marked_xfail_no_args(self, pytester: Pytester) -> None:
+        item = pytester.getitem(
             """
             import pytest
             @pytest.mark.xfail
@@ -28,8 +29,8 @@
         assert xfailed.reason == ""
         assert xfailed.run

-    def test_marked_skipif_no_args(self, testdir):
-        item = testdir.getitem(
+    def test_marked_skipif_no_args(self, pytester: Pytester) -> None:
+        item = pytester.getitem(
             """
             import pytest
             @pytest.mark.skipif
@@ -41,8 +42,8 @@
         assert skipped
         assert skipped.reason == ""

-    def test_marked_one_arg(self, testdir):
-        item = testdir.getitem(
+    def test_marked_one_arg(self, pytester: Pytester) -> None:
+        item = pytester.getitem(
             """
             import pytest
             @pytest.mark.skipif("hasattr(os, 'sep')")
@@ -54,8 +55,8 @@
         assert skipped
         assert skipped.reason == "condition: hasattr(os, 'sep')"

-    def test_marked_one_arg_with_reason(self, testdir):
-        item = testdir.getitem(
+    def test_marked_one_arg_with_reason(self, pytester: Pytester) -> None:
+        item = pytester.getitem(
             """
             import pytest
             @pytest.mark.skipif("hasattr(os, 'sep')", attr=2, reason="hello world")
@@ -67,13 +68,13 @@
         assert skipped
         assert skipped.reason == "hello world"

-    def test_marked_one_arg_twice(self, testdir):
+    def test_marked_one_arg_twice(self, pytester: Pytester) -> None:
         lines = [
             """@pytest.mark.skipif("not hasattr(os, 'murks')")""",
             """@pytest.mark.skipif(condition="hasattr(os, 'murks')")""",
         ]
         for i in range(0, 2):
-            item = testdir.getitem(
+            item = pytester.getitem(
                 """
                 import pytest
                 %s
@@ -87,8 +88,8 @@
             assert skipped
             assert skipped.reason == "condition: not hasattr(os, 'murks')"

-    def test_marked_one_arg_twice2(self, testdir):
-        item = testdir.getitem(
+    def test_marked_one_arg_twice2(self, pytester: Pytester) -> None:
+        item = pytester.getitem(
             """
             import pytest
             @pytest.mark.skipif("hasattr(os, 'murks')")
@@ -101,8 +102,10 @@
         assert skipped
         assert skipped.reason == "condition: not hasattr(os, 'murks')"

-    def test_marked_skipif_with_boolean_without_reason(self, testdir) -> None:
-        item = testdir.getitem(
+    def test_marked_skipif_with_boolean_without_reason(
+        self, pytester: Pytester
+    ) -> None:
+        item = pytester.getitem(
             """
             import pytest
             @pytest.mark.skipif(False)
@@ -118,8 +121,8 @@
             in excinfo.value.msg
         )

-    def test_marked_skipif_with_invalid_boolean(self, testdir) -> None:
-        item = testdir.getitem(
+    def test_marked_skipif_with_invalid_boolean(self, pytester: Pytester) -> None:
+        item = pytester.getitem(
             """
             import pytest

@@ -138,8 +141,8 @@
         assert "Error evaluating 'skipif' condition as a boolean" in excinfo.value.msg
         assert "INVALID" in excinfo.value.msg

-    def test_skipif_class(self, testdir):
-        (item,) = testdir.getitems(
+    def test_skipif_class(self, pytester: Pytester) -> None:
+        (item,) = pytester.getitems(
             """
             import pytest
             class TestClass(object):
@@ -148,16 +151,146 @@
                     pass
         """
         )
-        item.config._hackxyz = 3
+        item.config._hackxyz = 3  # type: ignore[attr-defined]
         skipped = evaluate_skip_marks(item)
         assert skipped
         assert skipped.reason == "condition: config._hackxyz"

+    def test_skipif_markeval_namespace(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
+            """
+            import pytest
+
+            def pytest_markeval_namespace():
+                return {"color": "green"}
+            """
+        )
+        p = pytester.makepyfile(
+            """
+            import pytest
+
+            @pytest.mark.skipif("color == 'green'")
+            def test_1():
+                assert True
+
+            @pytest.mark.skipif("color == 'red'")
+            def test_2():
+                assert True
+        """
+        )
+        res = pytester.runpytest(p)
+        assert res.ret == 0
+        res.stdout.fnmatch_lines(["*1 skipped*"])
+        res.stdout.fnmatch_lines(["*1 passed*"])
+
+    def test_skipif_markeval_namespace_multiple(self, pytester: Pytester) -> None:
+        """Keys defined by ``pytest_markeval_namespace()`` in nested plugins override top-level ones."""
+        root = pytester.mkdir("root")
+        root.joinpath("__init__.py").touch()
+        root.joinpath("conftest.py").write_text(
+            textwrap.dedent(
+                """\
+            import pytest
+
+            def pytest_markeval_namespace():
+                return {"arg": "root"}
+            """
+            )
+        )
+        root.joinpath("test_root.py").write_text(
+            textwrap.dedent(
+                """\
+            import pytest
+
+            @pytest.mark.skipif("arg == 'root'")
+            def test_root():
+                assert False
+            """
+            )
+        )
+        foo = root.joinpath("foo")
+        foo.mkdir()
+        foo.joinpath("__init__.py").touch()
+        foo.joinpath("conftest.py").write_text(
+            textwrap.dedent(
+                """\
+            import pytest
+
+            def pytest_markeval_namespace():
+                return {"arg": "foo"}
+            """
+            )
+        )
+        foo.joinpath("test_foo.py").write_text(
+            textwrap.dedent(
+                """\
+            import pytest
+
+            @pytest.mark.skipif("arg == 'foo'")
+            def test_foo():
+                assert False
+            """
+            )
+        )
+        bar = root.joinpath("bar")
+        bar.mkdir()
+        bar.joinpath("__init__.py").touch()
+        bar.joinpath("conftest.py").write_text(
+            textwrap.dedent(
+                """\
+            import pytest
+
+            def pytest_markeval_namespace():
+                return {"arg": "bar"}
+            """
+            )
+        )
+        bar.joinpath("test_bar.py").write_text(
+            textwrap.dedent(
+                """\
+            import pytest
+
+            @pytest.mark.skipif("arg == 'bar'")
+            def test_bar():
+                assert False
+            """
+            )
+        )
+
+        reprec = pytester.inline_run("-vs", "--capture=no")
+        reprec.assertoutcome(skipped=3)
+
+    def test_skipif_markeval_namespace_ValueError(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
+            """
+            import pytest
+
+            def pytest_markeval_namespace():
+                return True
+            """
+        )
+        p = pytester.makepyfile(
+            """
+            import pytest
+
+            @pytest.mark.skipif("color == 'green'")
+            def test_1():
+                assert True
+        """
+        )
+        res = pytester.runpytest(p)
+        assert res.ret == 1
+        res.stdout.fnmatch_lines(
+            [
+                "*ValueError: pytest_markeval_namespace() needs to return a dict, got True*"
+            ]
+        )
+

 class TestXFail:
     @pytest.mark.parametrize("strict", [True, False])
-    def test_xfail_simple(self, testdir, strict):
-        item = testdir.getitem(
+    def test_xfail_simple(self, pytester: Pytester, strict: bool) -> None:
+        item = pytester.getitem(
             """
             import pytest
             @pytest.mark.xfail(strict=%s)
@@ -172,8 +305,8 @@
         assert callreport.skipped
         assert callreport.wasxfail == ""

-    def test_xfail_xpassed(self, testdir):
-        item = testdir.getitem(
+    def test_xfail_xpassed(self, pytester: Pytester) -> None:
+        item = pytester.getitem(
             """
             import pytest
             @pytest.mark.xfail(reason="this is an xfail")
@@ -187,9 +320,9 @@
         assert callreport.passed
         assert callreport.wasxfail == "this is an xfail"

-    def test_xfail_using_platform(self, testdir):
+    def test_xfail_using_platform(self, pytester: Pytester) -> None:
         """Verify that platform can be used with xfail statements."""
-        item = testdir.getitem(
+        item = pytester.getitem(
             """
             import pytest
             @pytest.mark.xfail("platform.platform() == platform.platform()")
@@ -202,8 +335,8 @@
         callreport = reports[1]
         assert callreport.wasxfail

-    def test_xfail_xpassed_strict(self, testdir):
-        item = testdir.getitem(
+    def test_xfail_xpassed_strict(self, pytester: Pytester) -> None:
+        item = pytester.getitem(
             """
             import pytest
             @pytest.mark.xfail(strict=True, reason="nope")
@@ -218,8 +351,8 @@
         assert str(callreport.longrepr) == "[XPASS(strict)] nope"
         assert not hasattr(callreport, "wasxfail")

-    def test_xfail_run_anyway(self, testdir):
-        testdir.makepyfile(
+    def test_xfail_run_anyway(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.xfail
@@ -229,7 +362,7 @@
                 pytest.xfail("hello")
         """
         )
-        result = testdir.runpytest("--runxfail")
+        result = pytester.runpytest("--runxfail")
         result.stdout.fnmatch_lines(
             ["*def test_func():*", "*assert 0*", "*1 failed*1 pass*"]
         )
@@ -247,8 +380,10 @@
             ),
         ],
     )
-    def test_xfail_run_with_skip_mark(self, testdir, test_input, expected):
-        testdir.makepyfile(
+    def test_xfail_run_with_skip_mark(
+        self, pytester: Pytester, test_input, expected
+    ) -> None:
+        pytester.makepyfile(
             test_sample="""
             import pytest
             @pytest.mark.skip
@@ -256,11 +391,11 @@
                 assert 0
         """
         )
-        result = testdir.runpytest(*test_input)
+        result = pytester.runpytest(*test_input)
         result.stdout.fnmatch_lines(expected)

-    def test_xfail_evalfalse_but_fails(self, testdir):
-        item = testdir.getitem(
+    def test_xfail_evalfalse_but_fails(self, pytester: Pytester) -> None:
+        item = pytester.getitem(
             """
             import pytest
             @pytest.mark.xfail('False')
@@ -274,8 +409,8 @@
         assert not hasattr(callreport, "wasxfail")
         assert "xfail" in callreport.keywords

-    def test_xfail_not_report_default(self, testdir):
-        p = testdir.makepyfile(
+    def test_xfail_not_report_default(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             test_one="""
             import pytest
             @pytest.mark.xfail
@@ -283,13 +418,13 @@
                 assert 0
         """
         )
-        testdir.runpytest(p, "-v")
+        pytester.runpytest(p, "-v")
         # result.stdout.fnmatch_lines([
         #    "*HINT*use*-r*"
         # ])

-    def test_xfail_not_run_xfail_reporting(self, testdir):
-        p = testdir.makepyfile(
+    def test_xfail_not_run_xfail_reporting(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             test_one="""
             import pytest
             @pytest.mark.xfail(run=False, reason="noway")
@@ -303,7 +438,7 @@
                 assert 1
         """
         )
-        result = testdir.runpytest(p, "-rx")
+        result = pytester.runpytest(p, "-rx")
         result.stdout.fnmatch_lines(
             [
                 "*test_one*test_this*",
@@ -314,8 +449,8 @@
             ]
         )

-    def test_xfail_not_run_no_setup_run(self, testdir):
-        p = testdir.makepyfile(
+    def test_xfail_not_run_no_setup_run(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             test_one="""
             import pytest
             @pytest.mark.xfail(run=False, reason="hello")
@@ -325,13 +460,13 @@
                 raise ValueError(42)
         """
         )
-        result = testdir.runpytest(p, "-rx")
+        result = pytester.runpytest(p, "-rx")
         result.stdout.fnmatch_lines(
             ["*test_one*test_this*", "*NOTRUN*hello", "*1 xfailed*"]
         )

-    def test_xfail_xpass(self, testdir):
-        p = testdir.makepyfile(
+    def test_xfail_xpass(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             test_one="""
             import pytest
             @pytest.mark.xfail
@@ -339,27 +474,27 @@
                 assert 1
         """
         )
-        result = testdir.runpytest(p, "-rX")
+        result = pytester.runpytest(p, "-rX")
         result.stdout.fnmatch_lines(["*XPASS*test_that*", "*1 xpassed*"])
         assert result.ret == 0

-    def test_xfail_imperative(self, testdir):
-        p = testdir.makepyfile(
+    def test_xfail_imperative(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             import pytest
             def test_this():
                 pytest.xfail("hello")
         """
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.stdout.fnmatch_lines(["*1 xfailed*"])
-        result = testdir.runpytest(p, "-rx")
+        result = pytester.runpytest(p, "-rx")
         result.stdout.fnmatch_lines(["*XFAIL*test_this*", "*reason:*hello*"])
-        result = testdir.runpytest(p, "--runxfail")
+        result = pytester.runpytest(p, "--runxfail")
         result.stdout.fnmatch_lines(["*1 pass*"])

-    def test_xfail_imperative_in_setup_function(self, testdir):
-        p = testdir.makepyfile(
+    def test_xfail_imperative_in_setup_function(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             import pytest
             def setup_function(function):
@@ -369,11 +504,11 @@
                 assert 0
         """
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.stdout.fnmatch_lines(["*1 xfailed*"])
-        result = testdir.runpytest(p, "-rx")
+        result = pytester.runpytest(p, "-rx")
         result.stdout.fnmatch_lines(["*XFAIL*test_this*", "*reason:*hello*"])
-        result = testdir.runpytest(p, "--runxfail")
+        result = pytester.runpytest(p, "--runxfail")
         result.stdout.fnmatch_lines(
             """
             *def test_this*
@@ -381,8 +516,8 @@
         """
         )

-    def xtest_dynamic_xfail_set_during_setup(self, testdir):
-        p = testdir.makepyfile(
+    def xtest_dynamic_xfail_set_during_setup(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             import pytest
             def setup_function(function):
@@ -393,11 +528,11 @@
                 assert 1
         """
         )
-        result = testdir.runpytest(p, "-rxX")
+        result = pytester.runpytest(p, "-rxX")
         result.stdout.fnmatch_lines(["*XFAIL*test_this*", "*XPASS*test_that*"])

-    def test_dynamic_xfail_no_run(self, testdir):
-        p = testdir.makepyfile(
+    def test_dynamic_xfail_no_run(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             import pytest
             @pytest.fixture
@@ -407,11 +542,11 @@
                 assert 0
         """
         )
-        result = testdir.runpytest(p, "-rxX")
+        result = pytester.runpytest(p, "-rxX")
         result.stdout.fnmatch_lines(["*XFAIL*test_this*", "*NOTRUN*"])

-    def test_dynamic_xfail_set_during_funcarg_setup(self, testdir):
-        p = testdir.makepyfile(
+    def test_dynamic_xfail_set_during_funcarg_setup(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             import pytest
             @pytest.fixture
@@ -421,12 +556,12 @@
                 assert 0
         """
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.stdout.fnmatch_lines(["*1 xfailed*"])

-    def test_dynamic_xfail_set_during_runtest_failed(self, testdir: Testdir) -> None:
+    def test_dynamic_xfail_set_during_runtest_failed(self, pytester: Pytester) -> None:
         # Issue #7486.
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             """
             import pytest
             def test_this(request):
@@ -434,21 +569,21 @@
                 assert 0
         """
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.assert_outcomes(xfailed=1)

     def test_dynamic_xfail_set_during_runtest_passed_strict(
-        self, testdir: Testdir
+        self, pytester: Pytester
     ) -> None:
         # Issue #7486.
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             """
             import pytest
             def test_this(request):
                 request.node.add_marker(pytest.mark.xfail(reason="xfail", strict=True))
         """
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.assert_outcomes(failed=1)

     @pytest.mark.parametrize(
@@ -460,8 +595,10 @@
             ("(AttributeError, TypeError)", "IndexError", "*1 failed*"),
         ],
     )
-    def test_xfail_raises(self, expected, actual, matchline, testdir):
-        p = testdir.makepyfile(
+    def test_xfail_raises(
+        self, expected, actual, matchline, pytester: Pytester
+    ) -> None:
+        p = pytester.makepyfile(
             """
             import pytest
             @pytest.mark.xfail(raises=%s)
@@ -470,13 +607,13 @@
         """
             % (expected, actual)
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.stdout.fnmatch_lines([matchline])

-    def test_strict_sanity(self, testdir):
+    def test_strict_sanity(self, pytester: Pytester) -> None:
         """Sanity check for xfail(strict=True): a failing test should behave
         exactly like a normal xfail."""
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             """
             import pytest
             @pytest.mark.xfail(reason='unsupported feature', strict=True)
@@ -484,13 +621,13 @@
                 assert 0
         """
         )
-        result = testdir.runpytest(p, "-rxX")
+        result = pytester.runpytest(p, "-rxX")
         result.stdout.fnmatch_lines(["*XFAIL*", "*unsupported feature*"])
         assert result.ret == 0

     @pytest.mark.parametrize("strict", [True, False])
-    def test_strict_xfail(self, testdir, strict):
-        p = testdir.makepyfile(
+    def test_strict_xfail(self, pytester: Pytester, strict: bool) -> None:
+        p = pytester.makepyfile(
             """
             import pytest

@@ -500,7 +637,7 @@
         """
             % strict
         )
-        result = testdir.runpytest(p, "-rxX")
+        result = pytester.runpytest(p, "-rxX")
         if strict:
             result.stdout.fnmatch_lines(
                 ["*test_foo*", "*XPASS(strict)*unsupported feature*"]
@@ -513,11 +650,11 @@
                 ]
             )
         assert result.ret == (1 if strict else 0)
-        assert testdir.tmpdir.join("foo_executed").isfile()
+        assert pytester.path.joinpath("foo_executed").exists()

     @pytest.mark.parametrize("strict", [True, False])
-    def test_strict_xfail_condition(self, testdir, strict):
-        p = testdir.makepyfile(
+    def test_strict_xfail_condition(self, pytester: Pytester, strict: bool) -> None:
+        p = pytester.makepyfile(
             """
             import pytest

@@ -527,13 +664,13 @@
         """
             % strict
         )
-        result = testdir.runpytest(p, "-rxX")
+        result = pytester.runpytest(p, "-rxX")
         result.stdout.fnmatch_lines(["*1 passed*"])
         assert result.ret == 0

     @pytest.mark.parametrize("strict", [True, False])
-    def test_xfail_condition_keyword(self, testdir, strict):
-        p = testdir.makepyfile(
+    def test_xfail_condition_keyword(self, pytester: Pytester, strict: bool) -> None:
+        p = pytester.makepyfile(
             """
             import pytest

@@ -543,20 +680,22 @@
         """
             % strict
         )
-        result = testdir.runpytest(p, "-rxX")
+        result = pytester.runpytest(p, "-rxX")
         result.stdout.fnmatch_lines(["*1 passed*"])
         assert result.ret == 0

     @pytest.mark.parametrize("strict_val", ["true", "false"])
-    def test_strict_xfail_default_from_file(self, testdir, strict_val):
-        testdir.makeini(
+    def test_strict_xfail_default_from_file(
+        self, pytester: Pytester, strict_val
+    ) -> None:
+        pytester.makeini(
             """
             [pytest]
             xfail_strict = %s
         """
             % strict_val
         )
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             """
             import pytest
             @pytest.mark.xfail(reason='unsupported feature')
@@ -564,15 +703,42 @@
                 pass
         """
         )
-        result = testdir.runpytest(p, "-rxX")
+        result = pytester.runpytest(p, "-rxX")
         strict = strict_val == "true"
         result.stdout.fnmatch_lines(["*1 failed*" if strict else "*1 xpassed*"])
         assert result.ret == (1 if strict else 0)

+    def test_xfail_markeval_namespace(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
+            """
+            import pytest
+
+            def pytest_markeval_namespace():
+                return {"color": "green"}
+            """
+        )
+        p = pytester.makepyfile(
+            """
+            import pytest
+
+            @pytest.mark.xfail("color == 'green'")
+            def test_1():
+                assert False
+
+            @pytest.mark.xfail("color == 'red'")
+            def test_2():
+                assert False
+        """
+        )
+        res = pytester.runpytest(p)
+        assert res.ret == 1
+        res.stdout.fnmatch_lines(["*1 failed*"])
+        res.stdout.fnmatch_lines(["*1 xfailed*"])
+

 class TestXFailwithSetupTeardown:
-    def test_failing_setup_issue9(self, testdir):
-        testdir.makepyfile(
+    def test_failing_setup_issue9(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             def setup_function(func):
@@ -583,11 +749,11 @@
                 pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*1 xfail*"])

-    def test_failing_teardown_issue9(self, testdir):
-        testdir.makepyfile(
+    def test_failing_teardown_issue9(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             def teardown_function(func):
@@ -598,13 +764,13 @@
                 pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*1 xfail*"])


 class TestSkip:
-    def test_skip_class(self, testdir):
-        testdir.makepyfile(
+    def test_skip_class(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.skip
@@ -618,11 +784,11 @@
                 pass
         """
         )
-        rec = testdir.inline_run()
+        rec = pytester.inline_run()
         rec.assertoutcome(skipped=2, passed=1)

-    def test_skips_on_false_string(self, testdir):
-        testdir.makepyfile(
+    def test_skips_on_false_string(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.skip('False')
@@ -630,11 +796,11 @@
                 pass
         """
         )
-        rec = testdir.inline_run()
+        rec = pytester.inline_run()
         rec.assertoutcome(skipped=1)

-    def test_arg_as_reason(self, testdir):
-        testdir.makepyfile(
+    def test_arg_as_reason(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.skip('testing stuff')
@@ -642,11 +808,11 @@
                 pass
         """
         )
-        result = testdir.runpytest("-rs")
+        result = pytester.runpytest("-rs")
         result.stdout.fnmatch_lines(["*testing stuff*", "*1 skipped*"])

-    def test_skip_no_reason(self, testdir):
-        testdir.makepyfile(
+    def test_skip_no_reason(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.skip
@@ -654,11 +820,11 @@
                 pass
         """
         )
-        result = testdir.runpytest("-rs")
+        result = pytester.runpytest("-rs")
         result.stdout.fnmatch_lines(["*unconditional skip*", "*1 skipped*"])

-    def test_skip_with_reason(self, testdir):
-        testdir.makepyfile(
+    def test_skip_with_reason(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.skip(reason="for lolz")
@@ -666,11 +832,11 @@
                 pass
         """
         )
-        result = testdir.runpytest("-rs")
+        result = pytester.runpytest("-rs")
         result.stdout.fnmatch_lines(["*for lolz*", "*1 skipped*"])

-    def test_only_skips_marked_test(self, testdir):
-        testdir.makepyfile(
+    def test_only_skips_marked_test(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.skip
@@ -683,11 +849,11 @@
                 assert True
         """
         )
-        result = testdir.runpytest("-rs")
+        result = pytester.runpytest("-rs")
         result.stdout.fnmatch_lines(["*nothing in particular*", "*1 passed*2 skipped*"])

-    def test_strict_and_skip(self, testdir):
-        testdir.makepyfile(
+    def test_strict_and_skip(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.skip
@@ -695,13 +861,30 @@
                 pass
         """
         )
-        result = testdir.runpytest("-rs")
+        result = pytester.runpytest("-rs", "--strict-markers")
         result.stdout.fnmatch_lines(["*unconditional skip*", "*1 skipped*"])

+    def test_wrong_skip_usage(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
+            """
+            import pytest
+            @pytest.mark.skip(False, reason="I thought this was skipif")
+            def test_hello():
+                pass
+        """
+        )
+        result = pytester.runpytest()
+        result.stdout.fnmatch_lines(
+            [
+                "*TypeError: *__init__() got multiple values for argument 'reason'"
+                " - maybe you meant pytest.mark.skipif?"
+            ]
+        )
+

 class TestSkipif:
-    def test_skipif_conditional(self, testdir):
-        item = testdir.getitem(
+    def test_skipif_conditional(self, pytester: Pytester) -> None:
+        item = pytester.getitem(
             """
             import pytest
             @pytest.mark.skipif("hasattr(os, 'sep')")
@@ -715,8 +898,8 @@
     @pytest.mark.parametrize(
         "params", ["\"hasattr(sys, 'platform')\"", 'True, reason="invalid platform"']
     )
-    def test_skipif_reporting(self, testdir, params):
-        p = testdir.makepyfile(
+    def test_skipif_reporting(self, pytester: Pytester, params) -> None:
+        p = pytester.makepyfile(
             test_foo="""
             import pytest
             @pytest.mark.skipif(%(params)s)
@@ -725,12 +908,12 @@
         """
             % dict(params=params)
         )
-        result = testdir.runpytest(p, "-s", "-rs")
+        result = pytester.runpytest(p, "-s", "-rs")
         result.stdout.fnmatch_lines(["*SKIP*1*test_foo.py*platform*", "*1 skipped*"])
         assert result.ret == 0

-    def test_skipif_using_platform(self, testdir):
-        item = testdir.getitem(
+    def test_skipif_using_platform(self, pytester: Pytester) -> None:
+        item = pytester.getitem(
             """
             import pytest
             @pytest.mark.skipif("platform.platform() == platform.platform()")
@@ -744,8 +927,10 @@
         "marker, msg1, msg2",
         [("skipif", "SKIP", "skipped"), ("xfail", "XPASS", "xpassed")],
     )
-    def test_skipif_reporting_multiple(self, testdir, marker, msg1, msg2):
-        testdir.makepyfile(
+    def test_skipif_reporting_multiple(
+        self, pytester: Pytester, marker, msg1, msg2
+    ) -> None:
+        pytester.makepyfile(
             test_foo="""
             import pytest
             @pytest.mark.{marker}(False, reason='first_condition')
@@ -756,25 +941,22 @@
                 marker=marker
             )
         )
-        result = testdir.runpytest("-s", "-rsxX")
+        result = pytester.runpytest("-s", "-rsxX")
         result.stdout.fnmatch_lines(
-            [
-                "*{msg1}*test_foo.py*second_condition*".format(msg1=msg1),
-                "*1 {msg2}*".format(msg2=msg2),
-            ]
+            [f"*{msg1}*test_foo.py*second_condition*", f"*1 {msg2}*"]
         )
         assert result.ret == 0


-def test_skip_not_report_default(testdir):
-    p = testdir.makepyfile(
+def test_skip_not_report_default(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
         test_one="""
         import pytest
         def test_this():
             pytest.skip("hello")
     """
     )
-    result = testdir.runpytest(p, "-v")
+    result = pytester.runpytest(p, "-v")
     result.stdout.fnmatch_lines(
         [
             # "*HINT*use*-r*",
@@ -783,8 +965,8 @@
     )


-def test_skipif_class(testdir):
-    p = testdir.makepyfile(
+def test_skipif_class(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
         """
         import pytest

@@ -796,12 +978,12 @@
                 assert 0
     """
     )
-    result = testdir.runpytest(p)
+    result = pytester.runpytest(p)
     result.stdout.fnmatch_lines(["*2 skipped*"])


-def test_skipped_reasons_functional(testdir):
-    testdir.makepyfile(
+def test_skipped_reasons_functional(pytester: Pytester) -> None:
+    pytester.makepyfile(
         test_one="""
             import pytest
             from conftest import doskip
@@ -827,7 +1009,7 @@
                 pytest.skip('test')
         """,
     )
-    result = testdir.runpytest("-rs")
+    result = pytester.runpytest("-rs")
     result.stdout.fnmatch_lines_random(
         [
             "SKIPPED [[]2[]] conftest.py:4: test",
@@ -837,8 +1019,8 @@
     assert result.ret == 0


-def test_skipped_folding(testdir):
-    testdir.makepyfile(
+def test_skipped_folding(pytester: Pytester) -> None:
+    pytester.makepyfile(
         test_one="""
             import pytest
             pytestmark = pytest.mark.skip("Folding")
@@ -851,13 +1033,13 @@
                     pass
        """
     )
-    result = testdir.runpytest("-rs")
+    result = pytester.runpytest("-rs")
     result.stdout.fnmatch_lines(["*SKIP*2*test_one.py: Folding"])
     assert result.ret == 0


-def test_reportchars(testdir):
-    testdir.makepyfile(
+def test_reportchars(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import pytest
         def test_1():
@@ -872,14 +1054,14 @@
             pytest.skip("four")
     """
     )
-    result = testdir.runpytest("-rfxXs")
+    result = pytester.runpytest("-rfxXs")
     result.stdout.fnmatch_lines(
         ["FAIL*test_1*", "XFAIL*test_2*", "XPASS*test_3*", "SKIP*four*"]
     )


-def test_reportchars_error(testdir):
-    testdir.makepyfile(
+def test_reportchars_error(pytester: Pytester) -> None:
+    pytester.makepyfile(
         conftest="""
         def pytest_runtest_teardown():
             assert 0
@@ -889,12 +1071,12 @@
             pass
         """,
     )
-    result = testdir.runpytest("-rE")
+    result = pytester.runpytest("-rE")
     result.stdout.fnmatch_lines(["ERROR*test_foo*"])


-def test_reportchars_all(testdir):
-    testdir.makepyfile(
+def test_reportchars_all(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import pytest
         def test_1():
@@ -914,7 +1096,7 @@
             pass
     """
     )
-    result = testdir.runpytest("-ra")
+    result = pytester.runpytest("-ra")
     result.stdout.fnmatch_lines(
         [
             "SKIP*four*",
@@ -926,8 +1108,8 @@
     )


-def test_reportchars_all_error(testdir):
-    testdir.makepyfile(
+def test_reportchars_all_error(pytester: Pytester) -> None:
+    pytester.makepyfile(
         conftest="""
         def pytest_runtest_teardown():
             assert 0
@@ -937,12 +1119,12 @@
             pass
         """,
     )
-    result = testdir.runpytest("-ra")
+    result = pytester.runpytest("-ra")
     result.stdout.fnmatch_lines(["ERROR*test_foo*"])


-def test_errors_in_xfail_skip_expressions(testdir) -> None:
-    testdir.makepyfile(
+def test_errors_in_xfail_skip_expressions(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import pytest
         @pytest.mark.skipif("asd")
@@ -956,30 +1138,41 @@
             pass
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     markline = "                ^"
     pypy_version_info = getattr(sys, "pypy_version_info", None)
     if pypy_version_info is not None and pypy_version_info < (6,):
         markline = markline[5:]
     elif sys.version_info >= (3, 8) or hasattr(sys, "pypy_version_info"):
         markline = markline[4:]
-    result.stdout.fnmatch_lines(
-        [
+
+    if sys.version_info[:2] >= (3, 10):
+        expected = [
             "*ERROR*test_nameerror*",
-            "*evaluating*skipif*condition*",
             "*asd*",
-            "*ERROR*test_syntax*",
-            "*evaluating*xfail*condition*",
-            "    syntax error",
-            markline,
-            "SyntaxError: invalid syntax",
-            "*1 pass*2 errors*",
+            "",
+            "During handling of the above exception, another exception occurred:",
         ]
-    )
-
-
-def test_xfail_skipif_with_globals(testdir):
-    testdir.makepyfile(
+    else:
+        expected = [
+            "*ERROR*test_nameerror*",
+        ]
+
+    expected += [
+        "*evaluating*skipif*condition*",
+        "*asd*",
+        "*ERROR*test_syntax*",
+        "*evaluating*xfail*condition*",
+        "    syntax error",
+        markline,
+        "SyntaxError: invalid syntax",
+        "*1 pass*2 errors*",
+    ]
+    result.stdout.fnmatch_lines(expected)
+
+
+def test_xfail_skipif_with_globals(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import pytest
         x = 3
@@ -991,12 +1184,12 @@
             assert 0
     """
     )
-    result = testdir.runpytest("-rsx")
+    result = pytester.runpytest("-rsx")
     result.stdout.fnmatch_lines(["*SKIP*x == 3*", "*XFAIL*test_boolean*", "*x == 3*"])


-def test_default_markers(testdir):
-    result = testdir.runpytest("--markers")
+def test_default_markers(pytester: Pytester) -> None:
+    result = pytester.runpytest("--markers")
     result.stdout.fnmatch_lines(
         [
             "*skipif(condition, ..., [*], reason=...)*skip*",
@@ -1005,14 +1198,14 @@
     )


-def test_xfail_test_setup_exception(testdir):
-    testdir.makeconftest(
+def test_xfail_test_setup_exception(pytester: Pytester) -> None:
+    pytester.makeconftest(
         """
             def pytest_runtest_setup():
                 0 / 0
         """
     )
-    p = testdir.makepyfile(
+    p = pytester.makepyfile(
         """
             import pytest
             @pytest.mark.xfail
@@ -1020,14 +1213,14 @@
                 assert 0
         """
     )
-    result = testdir.runpytest(p)
+    result = pytester.runpytest(p)
     assert result.ret == 0
     assert "xfailed" in result.stdout.str()
     result.stdout.no_fnmatch_line("*xpassed*")


-def test_imperativeskip_on_xfail_test(testdir):
-    testdir.makepyfile(
+def test_imperativeskip_on_xfail_test(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import pytest
         @pytest.mark.xfail
@@ -1039,14 +1232,14 @@
             pass
     """
     )
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         import pytest
         def pytest_runtest_setup(item):
             pytest.skip("abc")
     """
     )
-    result = testdir.runpytest("-rsxX")
+    result = pytester.runpytest("-rsxX")
     result.stdout.fnmatch_lines_random(
         """
         *SKIP*abc*
@@ -1057,8 +1250,8 @@


 class TestBooleanCondition:
-    def test_skipif(self, testdir):
-        testdir.makepyfile(
+    def test_skipif(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.skipif(True, reason="True123")
@@ -1069,15 +1262,15 @@
                 pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             """
             *1 passed*1 skipped*
         """
         )

-    def test_skipif_noreason(self, testdir):
-        testdir.makepyfile(
+    def test_skipif_noreason(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.skipif(True)
@@ -1085,15 +1278,15 @@
                 pass
         """
         )
-        result = testdir.runpytest("-rs")
+        result = pytester.runpytest("-rs")
         result.stdout.fnmatch_lines(
             """
             *1 error*
         """
         )

-    def test_xfail(self, testdir):
-        testdir.makepyfile(
+    def test_xfail(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.xfail(True, reason="True123")
@@ -1101,7 +1294,7 @@
                 assert 0
         """
         )
-        result = testdir.runpytest("-rxs")
+        result = pytester.runpytest("-rxs")
         result.stdout.fnmatch_lines(
             """
             *XFAIL*
@@ -1111,9 +1304,9 @@
         )


-def test_xfail_item(testdir):
+def test_xfail_item(pytester: Pytester) -> None:
     # Ensure pytest.xfail works with non-Python Item
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         import pytest

@@ -1122,20 +1315,20 @@
             def runtest(self):
                 pytest.xfail("Expected Failure")

-        def pytest_collect_file(path, parent):
+        def pytest_collect_file(file_path, parent):
             return MyItem.from_parent(name="foo", parent=parent)
     """
     )
-    result = testdir.inline_run()
+    result = pytester.inline_run()
     passed, skipped, failed = result.listoutcomes()
     assert not failed
     xfailed = [r for r in skipped if hasattr(r, "wasxfail")]
     assert xfailed


-def test_module_level_skip_error(testdir):
+def test_module_level_skip_error(pytester: Pytester) -> None:
     """Verify that using pytest.skip at module level causes a collection error."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         pytest.skip("skip_module_level")
@@ -1144,15 +1337,15 @@
             assert True
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
-        ["*Using pytest.skip outside of a test is not allowed*"]
-    )
-
-
-def test_module_level_skip_with_allow_module_level(testdir):
+        ["*Using pytest.skip outside of a test will skip the entire module*"]
+    )
+
+
+def test_module_level_skip_with_allow_module_level(pytester: Pytester) -> None:
     """Verify that using pytest.skip(allow_module_level=True) is allowed."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         pytest.skip("skip_module_level", allow_module_level=True)
@@ -1161,13 +1354,13 @@
             assert 0
     """
     )
-    result = testdir.runpytest("-rxs")
+    result = pytester.runpytest("-rxs")
     result.stdout.fnmatch_lines(["*SKIP*skip_module_level"])


-def test_invalid_skip_keyword_parameter(testdir):
+def test_invalid_skip_keyword_parameter(pytester: Pytester) -> None:
     """Verify that using pytest.skip() with unknown parameter raises an error."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         pytest.skip("skip_module_level", unknown=1)
@@ -1176,13 +1369,13 @@
             assert 0
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*TypeError:*['unknown']*"])


-def test_mark_xfail_item(testdir):
+def test_mark_xfail_item(pytester: Pytester) -> None:
     # Ensure pytest.mark.xfail works with non-Python Item
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         import pytest

@@ -1196,27 +1389,27 @@
             def runtest(self):
                 assert False

-        def pytest_collect_file(path, parent):
+        def pytest_collect_file(file_path, parent):
             return MyItem.from_parent(name="foo", parent=parent)
     """
     )
-    result = testdir.inline_run()
+    result = pytester.inline_run()
     passed, skipped, failed = result.listoutcomes()
     assert not failed
     xfailed = [r for r in skipped if hasattr(r, "wasxfail")]
     assert xfailed


-def test_summary_list_after_errors(testdir):
+def test_summary_list_after_errors(pytester: Pytester) -> None:
     """Ensure the list of errors/fails/xfails/skips appears after tracebacks in terminal reporting."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         def test_fail():
             assert 0
     """
     )
-    result = testdir.runpytest("-ra")
+    result = pytester.runpytest("-ra")
     result.stdout.fnmatch_lines(
         [
             "=* FAILURES *=",
@@ -1226,7 +1419,7 @@
     )


-def test_importorskip():
+def test_importorskip() -> None:
     with pytest.raises(
         pytest.skip.Exception,
         match="^could not import 'doesnotexist': No module named .*",
@@ -1234,8 +1427,8 @@
         pytest.importorskip("doesnotexist")


-def test_relpath_rootdir(testdir):
-    testdir.makepyfile(
+def test_relpath_rootdir(pytester: Pytester) -> None:
+    pytester.makepyfile(
         **{
             "tests/test_1.py": """
         import pytest
@@ -1245,7 +1438,96 @@
             """,
         }
     )
-    result = testdir.runpytest("-rs", "tests/test_1.py", "--rootdir=tests")
+    result = pytester.runpytest("-rs", "tests/test_1.py", "--rootdir=tests")
     result.stdout.fnmatch_lines(
         ["SKIPPED [[]1[]] tests/test_1.py:2: unconditional skip"]
     )
+
+
+def test_skip_using_reason_works_ok(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
+        """
+        import pytest
+
+        def test_skipping_reason():
+            pytest.skip(reason="skippedreason")
+        """
+    )
+    result = pytester.runpytest(p)
+    result.stdout.no_fnmatch_line("*PytestDeprecationWarning*")
+    result.assert_outcomes(skipped=1)
+
+
+def test_fail_using_reason_works_ok(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
+        """
+        import pytest
+
+        def test_failing_reason():
+            pytest.fail(reason="failedreason")
+        """
+    )
+    result = pytester.runpytest(p)
+    result.stdout.no_fnmatch_line("*PytestDeprecationWarning*")
+    result.assert_outcomes(failed=1)
+
+
+def test_fail_fails_with_msg_and_reason(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
+        """
+        import pytest
+
+        def test_fail_both_arguments():
+            pytest.fail(reason="foo", msg="bar")
+        """
+    )
+    result = pytester.runpytest(p)
+    result.stdout.fnmatch_lines(
+        "*UsageError: Passing both ``reason`` and ``msg`` to pytest.fail(...) is not permitted.*"
+    )
+    result.assert_outcomes(failed=1)
+
+
+def test_skip_fails_with_msg_and_reason(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
+        """
+        import pytest
+
+        def test_skip_both_arguments():
+            pytest.skip(reason="foo", msg="bar")
+        """
+    )
+    result = pytester.runpytest(p)
+    result.stdout.fnmatch_lines(
+        "*UsageError: Passing both ``reason`` and ``msg`` to pytest.skip(...) is not permitted.*"
+    )
+    result.assert_outcomes(failed=1)
+
+
+def test_exit_with_msg_and_reason_fails(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
+        """
+        import pytest
+
+        def test_exit_both_arguments():
+            pytest.exit(reason="foo", msg="bar")
+        """
+    )
+    result = pytester.runpytest(p)
+    result.stdout.fnmatch_lines(
+        "*UsageError: cannot pass reason and msg to exit(), `msg` is deprecated, use `reason`.*"
+    )
+    result.assert_outcomes(failed=1)
+
+
+def test_exit_with_reason_works_ok(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
+        """
+        import pytest
+
+        def test_exit_reason_only():
+            pytest.exit(reason="foo")
+        """
+    )
+    result = pytester.runpytest(p)
+    result.stdout.fnmatch_lines("*_pytest.outcomes.Exit: foo*")
('testing', 'test_pastebin.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,19 +1,43 @@
+import email.message
+import io
 from typing import List
 from typing import Union

 import pytest
+from _pytest.monkeypatch import MonkeyPatch
+from _pytest.pytester import Pytester


 class TestPasteCapture:
     @pytest.fixture
     def pastebinlist(self, monkeypatch, request) -> List[Union[str, bytes]]:
-        pastebinlist = []  # type: List[Union[str, bytes]]
+        pastebinlist: List[Union[str, bytes]] = []
         plugin = request.config.pluginmanager.getplugin("pastebin")
         monkeypatch.setattr(plugin, "create_new_paste", pastebinlist.append)
         return pastebinlist

-    def test_failed(self, testdir, pastebinlist):
-        testpath = testdir.makepyfile(
+    def test_failed(self, pytester: Pytester, pastebinlist) -> None:
+        testpath = pytester.makepyfile(
+            """
+            import pytest
+            def test_pass() -> None:
+                pass
+            def test_fail():
+                assert 0
+            def test_skip():
+                pytest.skip("")
+        """
+        )
+        reprec = pytester.inline_run(testpath, "--pastebin=failed")
+        assert len(pastebinlist) == 1
+        s = pastebinlist[0]
+        assert s.find("def test_fail") != -1
+        assert reprec.countoutcomes() == [1, 1, 1]
+
+    def test_all(self, pytester: Pytester, pastebinlist) -> None:
+        from _pytest.pytester import LineMatcher
+
+        testpath = pytester.makepyfile(
             """
             import pytest
             def test_pass():
@@ -24,27 +48,7 @@
                 pytest.skip("")
         """
         )
-        reprec = testdir.inline_run(testpath, "--pastebin=failed")
-        assert len(pastebinlist) == 1
-        s = pastebinlist[0]
-        assert s.find("def test_fail") != -1
-        assert reprec.countoutcomes() == [1, 1, 1]
-
-    def test_all(self, testdir, pastebinlist):
-        from _pytest.pytester import LineMatcher
-
-        testpath = testdir.makepyfile(
-            """
-            import pytest
-            def test_pass():
-                pass
-            def test_fail():
-                assert 0
-            def test_skip():
-                pytest.skip("")
-        """
-        )
-        reprec = testdir.inline_run(testpath, "--pastebin=all", "-v")
+        reprec = pytester.inline_run(testpath, "--pastebin=all", "-v")
         assert reprec.countoutcomes() == [1, 1, 1]
         assert len(pastebinlist) == 1
         contents = pastebinlist[0].decode("utf-8")
@@ -58,17 +62,17 @@
             ]
         )

-    def test_non_ascii_paste_text(self, testdir, pastebinlist):
+    def test_non_ascii_paste_text(self, pytester: Pytester, pastebinlist) -> None:
         """Make sure that text which contains non-ascii characters is pasted
         correctly. See #1219.
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             test_unicode="""\
             def test():
                 assert '☺' == 1
             """
         )
-        result = testdir.runpytest("--pastebin=all")
+        result = pytester.runpytest("--pastebin=all")
         expected_msg = "*assert '☺' == 1*"
         result.stdout.fnmatch_lines(
             [
@@ -86,7 +90,7 @@
         return request.config.pluginmanager.getplugin("pastebin")

     @pytest.fixture
-    def mocked_urlopen_fail(self, monkeypatch):
+    def mocked_urlopen_fail(self, monkeypatch: MonkeyPatch):
         """Monkeypatch the actual urlopen call to emulate a HTTP Error 400."""
         calls = []

@@ -95,13 +99,15 @@

         def mocked(url, data):
             calls.append((url, data))
-            raise urllib.error.HTTPError(url, 400, "Bad request", None, None)
+            raise urllib.error.HTTPError(
+                url, 400, "Bad request", email.message.Message(), io.BytesIO()
+            )

         monkeypatch.setattr(urllib.request, "urlopen", mocked)
         return calls

     @pytest.fixture
-    def mocked_urlopen_invalid(self, monkeypatch):
+    def mocked_urlopen_invalid(self, monkeypatch: MonkeyPatch):
         """Monkeypatch the actual urlopen calls done by the internal plugin
         function that connects to bpaste service, but return a url in an
         unexpected format."""
@@ -123,7 +129,7 @@
         return calls

     @pytest.fixture
-    def mocked_urlopen(self, monkeypatch):
+    def mocked_urlopen(self, monkeypatch: MonkeyPatch):
         """Monkeypatch the actual urlopen calls done by the internal plugin
         function that connects to bpaste service."""
         calls = []
@@ -143,7 +149,7 @@
         monkeypatch.setattr(urllib.request, "urlopen", mocked)
         return calls

-    def test_pastebin_invalid_url(self, pastebin, mocked_urlopen_invalid):
+    def test_pastebin_invalid_url(self, pastebin, mocked_urlopen_invalid) -> None:
         result = pastebin.create_new_paste(b"full-paste-contents")
         assert (
             result
@@ -151,24 +157,24 @@
         )
         assert len(mocked_urlopen_invalid) == 1

-    def test_pastebin_http_error(self, pastebin, mocked_urlopen_fail):
+    def test_pastebin_http_error(self, pastebin, mocked_urlopen_fail) -> None:
         result = pastebin.create_new_paste(b"full-paste-contents")
         assert result == "bad response: HTTP Error 400: Bad request"
         assert len(mocked_urlopen_fail) == 1

-    def test_create_new_paste(self, pastebin, mocked_urlopen):
+    def test_create_new_paste(self, pastebin, mocked_urlopen) -> None:
         result = pastebin.create_new_paste(b"full-paste-contents")
-        assert result == "https://bpaste.net/show/3c0c6750bd"
+        assert result == "https://bpa.st/show/3c0c6750bd"
         assert len(mocked_urlopen) == 1
         url, data = mocked_urlopen[0]
         assert type(data) is bytes
         lexer = "text"
-        assert url == "https://bpaste.net"
+        assert url == "https://bpa.st"
         assert "lexer=%s" % lexer in data.decode()
         assert "code=full-paste-contents" in data.decode()
         assert "expiry=1week" in data.decode()

-    def test_create_new_paste_failure(self, pastebin, monkeypatch):
+    def test_create_new_paste_failure(self, pastebin, monkeypatch: MonkeyPatch) -> None:
         import io
         import urllib.request

('testing', 'test_conftest.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,188 +1,245 @@
+import argparse
 import os
 import textwrap
-
-import py
+from pathlib import Path
+from typing import cast
+from typing import Dict
+from typing import Generator
+from typing import List
+from typing import Optional

 import pytest
 from _pytest.config import ExitCode
 from _pytest.config import PytestPluginManager
-from _pytest.pathlib import Path
+from _pytest.monkeypatch import MonkeyPatch
 from _pytest.pathlib import symlink_or_skip
-
-
-def ConftestWithSetinitial(path):
+from _pytest.pytester import Pytester
+from _pytest.tmpdir import TempPathFactory
+
+
+def ConftestWithSetinitial(path) -> PytestPluginManager:
     conftest = PytestPluginManager()
     conftest_setinitial(conftest, [path])
     return conftest


-def conftest_setinitial(conftest, args, confcutdir=None):
+def conftest_setinitial(
+    conftest: PytestPluginManager, args, confcutdir: Optional["os.PathLike[str]"] = None
+) -> None:
     class Namespace:
-        def __init__(self):
+        def __init__(self) -> None:
             self.file_or_dir = args
-            self.confcutdir = str(confcutdir)
+            self.confcutdir = os.fspath(confcutdir) if confcutdir is not None else None
             self.noconftest = False
             self.pyargs = False
             self.importmode = "prepend"

-    conftest._set_initial_conftests(Namespace())
+    namespace = cast(argparse.Namespace, Namespace())
+    conftest._set_initial_conftests(namespace, rootpath=Path(args[0]))


 @pytest.mark.usefixtures("_sys_snapshot")
 class TestConftestValueAccessGlobal:
     @pytest.fixture(scope="module", params=["global", "inpackage"])
-    def basedir(self, request, tmpdir_factory):
-        tmpdir = tmpdir_factory.mktemp("basedir", numbered=True)
-        tmpdir.ensure("adir/conftest.py").write("a=1 ; Directory = 3")
-        tmpdir.ensure("adir/b/conftest.py").write("b=2 ; a = 1.5")
+    def basedir(
+        self, request, tmp_path_factory: TempPathFactory
+    ) -> Generator[Path, None, None]:
+        tmp_path = tmp_path_factory.mktemp("basedir", numbered=True)
+        tmp_path.joinpath("adir/b").mkdir(parents=True)
+        tmp_path.joinpath("adir/conftest.py").write_text("a=1 ; Directory = 3")
+        tmp_path.joinpath("adir/b/conftest.py").write_text("b=2 ; a = 1.5")
         if request.param == "inpackage":
-            tmpdir.ensure("adir/__init__.py")
-            tmpdir.ensure("adir/b/__init__.py")
-
-        yield tmpdir
-
-    def test_basic_init(self, basedir):
+            tmp_path.joinpath("adir/__init__.py").touch()
+            tmp_path.joinpath("adir/b/__init__.py").touch()
+
+        yield tmp_path
+
+    def test_basic_init(self, basedir: Path) -> None:
         conftest = PytestPluginManager()
-        p = basedir.join("adir")
-        assert conftest._rget_with_confmod("a", p, importmode="prepend")[1] == 1
-
-    def test_immediate_initialiation_and_incremental_are_the_same(self, basedir):
+        p = basedir / "adir"
+        assert (
+            conftest._rget_with_confmod("a", p, importmode="prepend", rootpath=basedir)[
+                1
+            ]
+            == 1
+        )
+
+    def test_immediate_initialiation_and_incremental_are_the_same(
+        self, basedir: Path
+    ) -> None:
         conftest = PytestPluginManager()
         assert not len(conftest._dirpath2confmods)
-        conftest._getconftestmodules(basedir, importmode="prepend")
+        conftest._getconftestmodules(
+            basedir, importmode="prepend", rootpath=Path(basedir)
+        )
         snap1 = len(conftest._dirpath2confmods)
         assert snap1 == 1
-        conftest._getconftestmodules(basedir.join("adir"), importmode="prepend")
+        conftest._getconftestmodules(
+            basedir / "adir", importmode="prepend", rootpath=basedir
+        )
         assert len(conftest._dirpath2confmods) == snap1 + 1
-        conftest._getconftestmodules(basedir.join("b"), importmode="prepend")
+        conftest._getconftestmodules(
+            basedir / "b", importmode="prepend", rootpath=basedir
+        )
         assert len(conftest._dirpath2confmods) == snap1 + 2

-    def test_value_access_not_existing(self, basedir):
+    def test_value_access_not_existing(self, basedir: Path) -> None:
         conftest = ConftestWithSetinitial(basedir)
         with pytest.raises(KeyError):
-            conftest._rget_with_confmod("a", basedir, importmode="prepend")
-
-    def test_value_access_by_path(self, basedir):
+            conftest._rget_with_confmod(
+                "a", basedir, importmode="prepend", rootpath=Path(basedir)
+            )
+
+    def test_value_access_by_path(self, basedir: Path) -> None:
         conftest = ConftestWithSetinitial(basedir)
-        adir = basedir.join("adir")
-        assert conftest._rget_with_confmod("a", adir, importmode="prepend")[1] == 1
+        adir = basedir / "adir"
         assert (
-            conftest._rget_with_confmod("a", adir.join("b"), importmode="prepend")[1]
+            conftest._rget_with_confmod(
+                "a", adir, importmode="prepend", rootpath=basedir
+            )[1]
+            == 1
+        )
+        assert (
+            conftest._rget_with_confmod(
+                "a", adir / "b", importmode="prepend", rootpath=basedir
+            )[1]
             == 1.5
         )

-    def test_value_access_with_confmod(self, basedir):
-        startdir = basedir.join("adir", "b")
-        startdir.ensure("xx", dir=True)
+    def test_value_access_with_confmod(self, basedir: Path) -> None:
+        startdir = basedir / "adir" / "b"
+        startdir.joinpath("xx").mkdir()
         conftest = ConftestWithSetinitial(startdir)
-        mod, value = conftest._rget_with_confmod("a", startdir, importmode="prepend")
+        mod, value = conftest._rget_with_confmod(
+            "a", startdir, importmode="prepend", rootpath=Path(basedir)
+        )
         assert value == 1.5
-        path = py.path.local(mod.__file__)
-        assert path.dirpath() == basedir.join("adir", "b")
-        assert path.purebasename.startswith("conftest")
-
-
-def test_conftest_in_nonpkg_with_init(tmpdir, _sys_snapshot):
-    tmpdir.ensure("adir-1.0/conftest.py").write("a=1 ; Directory = 3")
-    tmpdir.ensure("adir-1.0/b/conftest.py").write("b=2 ; a = 1.5")
-    tmpdir.ensure("adir-1.0/b/__init__.py")
-    tmpdir.ensure("adir-1.0/__init__.py")
-    ConftestWithSetinitial(tmpdir.join("adir-1.0", "b"))
-
-
-def test_doubledash_considered(testdir):
-    conf = testdir.mkdir("--option")
-    conf.ensure("conftest.py")
+        assert mod.__file__ is not None
+        path = Path(mod.__file__)
+        assert path.parent == basedir / "adir" / "b"
+        assert path.stem == "conftest"
+
+
+def test_conftest_in_nonpkg_with_init(tmp_path: Path, _sys_snapshot) -> None:
+    tmp_path.joinpath("adir-1.0/b").mkdir(parents=True)
+    tmp_path.joinpath("adir-1.0/conftest.py").write_text("a=1 ; Directory = 3")
+    tmp_path.joinpath("adir-1.0/b/conftest.py").write_text("b=2 ; a = 1.5")
+    tmp_path.joinpath("adir-1.0/b/__init__.py").touch()
+    tmp_path.joinpath("adir-1.0/__init__.py").touch()
+    ConftestWithSetinitial(tmp_path.joinpath("adir-1.0", "b"))
+
+
+def test_doubledash_considered(pytester: Pytester) -> None:
+    conf = pytester.mkdir("--option")
+    conf.joinpath("conftest.py").touch()
     conftest = PytestPluginManager()
-    conftest_setinitial(conftest, [conf.basename, conf.basename])
-    values = conftest._getconftestmodules(conf, importmode="prepend")
+    conftest_setinitial(conftest, [conf.name, conf.name])
+    values = conftest._getconftestmodules(
+        conf, importmode="prepend", rootpath=pytester.path
+    )
     assert len(values) == 1


-def test_issue151_load_all_conftests(testdir):
+def test_issue151_load_all_conftests(pytester: Pytester) -> None:
     names = "code proj src".split()
     for name in names:
-        p = testdir.mkdir(name)
-        p.ensure("conftest.py")
-
-    conftest = PytestPluginManager()
-    conftest_setinitial(conftest, names)
-    d = list(conftest._conftestpath2mod.values())
-    assert len(d) == len(names)
-
-
-def test_conftest_global_import(testdir):
-    testdir.makeconftest("x=3")
-    p = testdir.makepyfile(
+        p = pytester.mkdir(name)
+        p.joinpath("conftest.py").touch()
+
+    pm = PytestPluginManager()
+    conftest_setinitial(pm, names)
+    assert len(set(pm.get_plugins()) - {pm}) == len(names)
+
+
+def test_conftest_global_import(pytester: Pytester) -> None:
+    pytester.makeconftest("x=3")
+    p = pytester.makepyfile(
         """
-        import py, pytest
+        from pathlib import Path
+        import pytest
         from _pytest.config import PytestPluginManager
         conf = PytestPluginManager()
-        mod = conf._importconftest(py.path.local("conftest.py"), importmode="prepend")
+        mod = conf._importconftest(Path("conftest.py"), importmode="prepend", rootpath=Path.cwd())
         assert mod.x == 3
         import conftest
         assert conftest is mod, (conftest, mod)
-        subconf = py.path.local().ensure("sub", "conftest.py")
-        subconf.write("y=4")
-        mod2 = conf._importconftest(subconf, importmode="prepend")
+        sub = Path("sub")
+        sub.mkdir()
+        subconf = sub / "conftest.py"
+        subconf.write_text("y=4")
+        mod2 = conf._importconftest(subconf, importmode="prepend", rootpath=Path.cwd())
         assert mod != mod2
         assert mod2.y == 4
         import conftest
         assert conftest is mod2, (conftest, mod)
     """
     )
-    res = testdir.runpython(p)
+    res = pytester.runpython(p)
     assert res.ret == 0


-def test_conftestcutdir(testdir):
-    conf = testdir.makeconftest("")
-    p = testdir.mkdir("x")
+def test_conftestcutdir(pytester: Pytester) -> None:
+    conf = pytester.makeconftest("")
+    p = pytester.mkdir("x")
     conftest = PytestPluginManager()
-    conftest_setinitial(conftest, [testdir.tmpdir], confcutdir=p)
-    values = conftest._getconftestmodules(p, importmode="prepend")
+    conftest_setinitial(conftest, [pytester.path], confcutdir=p)
+    values = conftest._getconftestmodules(
+        p, importmode="prepend", rootpath=pytester.path
+    )
     assert len(values) == 0
-    values = conftest._getconftestmodules(conf.dirpath(), importmode="prepend")
+    values = conftest._getconftestmodules(
+        conf.parent, importmode="prepend", rootpath=pytester.path
+    )
     assert len(values) == 0
-    assert conf not in conftest._conftestpath2mod
+    assert not conftest.has_plugin(str(conf))
     # but we can still import a conftest directly
-    conftest._importconftest(conf, importmode="prepend")
-    values = conftest._getconftestmodules(conf.dirpath(), importmode="prepend")
+    conftest._importconftest(conf, importmode="prepend", rootpath=pytester.path)
+    values = conftest._getconftestmodules(
+        conf.parent, importmode="prepend", rootpath=pytester.path
+    )
+    assert values[0].__file__ is not None
     assert values[0].__file__.startswith(str(conf))
     # and all sub paths get updated properly
-    values = conftest._getconftestmodules(p, importmode="prepend")
+    values = conftest._getconftestmodules(
+        p, importmode="prepend", rootpath=pytester.path
+    )
     assert len(values) == 1
+    assert values[0].__file__ is not None
     assert values[0].__file__.startswith(str(conf))


-def test_conftestcutdir_inplace_considered(testdir):
-    conf = testdir.makeconftest("")
+def test_conftestcutdir_inplace_considered(pytester: Pytester) -> None:
+    conf = pytester.makeconftest("")
     conftest = PytestPluginManager()
-    conftest_setinitial(conftest, [conf.dirpath()], confcutdir=conf.dirpath())
-    values = conftest._getconftestmodules(conf.dirpath(), importmode="prepend")
+    conftest_setinitial(conftest, [conf.parent], confcutdir=conf.parent)
+    values = conftest._getconftestmodules(
+        conf.parent, importmode="prepend", rootpath=pytester.path
+    )
     assert len(values) == 1
+    assert values[0].__file__ is not None
     assert values[0].__file__.startswith(str(conf))


 @pytest.mark.parametrize("name", "test tests whatever .dotdir".split())
-def test_setinitial_conftest_subdirs(testdir, name):
-    sub = testdir.mkdir(name)
-    subconftest = sub.ensure("conftest.py")
-    conftest = PytestPluginManager()
-    conftest_setinitial(conftest, [sub.dirpath()], confcutdir=testdir.tmpdir)
-    key = Path(str(subconftest)).resolve()
+def test_setinitial_conftest_subdirs(pytester: Pytester, name: str) -> None:
+    sub = pytester.mkdir(name)
+    subconftest = sub.joinpath("conftest.py")
+    subconftest.touch()
+    pm = PytestPluginManager()
+    conftest_setinitial(pm, [sub.parent], confcutdir=pytester.path)
+    key = subconftest.resolve()
     if name not in ("whatever", ".dotdir"):
-        assert key in conftest._conftestpath2mod
-        assert len(conftest._conftestpath2mod) == 1
+        assert pm.has_plugin(str(key))
+        assert len(set(pm.get_plugins()) - {pm}) == 1
     else:
-        assert key not in conftest._conftestpath2mod
-        assert len(conftest._conftestpath2mod) == 0
-
-
-def test_conftest_confcutdir(testdir):
-    testdir.makeconftest("assert 0")
-    x = testdir.mkdir("x")
-    x.join("conftest.py").write(
+        assert not pm.has_plugin(str(key))
+        assert len(set(pm.get_plugins()) - {pm}) == 0
+
+
+def test_conftest_confcutdir(pytester: Pytester) -> None:
+    pytester.makeconftest("assert 0")
+    x = pytester.mkdir("x")
+    x.joinpath("conftest.py").write_text(
         textwrap.dedent(
             """\
             def pytest_addoption(parser):
@@ -190,12 +247,40 @@
             """
         )
     )
-    result = testdir.runpytest("-h", "--confcutdir=%s" % x, x)
+    result = pytester.runpytest("-h", "--confcutdir=%s" % x, x)
     result.stdout.fnmatch_lines(["*--xyz*"])
     result.stdout.no_fnmatch_line("*warning: could not load initial*")


-def test_conftest_symlink(testdir):
+def test_installed_conftest_is_picked_up(pytester: Pytester, tmp_path: Path) -> None:
+    """When using `--pyargs` to run tests in an installed packages (located e.g.
+    in a site-packages in the PYTHONPATH), conftest files in there are picked
+    up.
+
+    Regression test for #9767.
+    """
+    # pytester dir - the source tree.
+    # tmp_path - the simulated site-packages dir (not in source tree).
+
+    pytester.syspathinsert(tmp_path)
+    pytester.makepyprojecttoml("[tool.pytest.ini_options]")
+    tmp_path.joinpath("foo").mkdir()
+    tmp_path.joinpath("foo", "__init__.py").touch()
+    tmp_path.joinpath("foo", "conftest.py").write_text(
+        textwrap.dedent(
+            """\
+            import pytest
+            @pytest.fixture
+            def fix(): return None
+            """
+        )
+    )
+    tmp_path.joinpath("foo", "test_it.py").write_text("def test_it(fix): pass")
+    result = pytester.runpytest("--pyargs", "foo")
+    assert result.ret == 0
+
+
+def test_conftest_symlink(pytester: Pytester) -> None:
     """`conftest.py` discovery follows normal path resolution and does not resolve symlinks."""
     # Structure:
     # /real
@@ -208,11 +293,12 @@
     # /symlinktests -> /real/app/tests (running at symlinktests should fail)
     # /symlink -> /real (running at /symlink should work)

-    real = testdir.tmpdir.mkdir("real")
-    realtests = real.mkdir("app").mkdir("tests")
-    symlink_or_skip(realtests, testdir.tmpdir.join("symlinktests"))
-    symlink_or_skip(real, testdir.tmpdir.join("symlink"))
-    testdir.makepyfile(
+    real = pytester.mkdir("real")
+    realtests = real.joinpath("app/tests")
+    realtests.mkdir(parents=True)
+    symlink_or_skip(realtests, pytester.path.joinpath("symlinktests"))
+    symlink_or_skip(real, pytester.path.joinpath("symlink"))
+    pytester.makepyfile(
         **{
             "real/app/tests/test_foo.py": "def test1(fixture): pass",
             "real/conftest.py": textwrap.dedent(
@@ -230,19 +316,19 @@
     )

     # Should fail because conftest cannot be found from the link structure.
-    result = testdir.runpytest("-vs", "symlinktests")
+    result = pytester.runpytest("-vs", "symlinktests")
     result.stdout.fnmatch_lines(["*fixture 'fixture' not found*"])
     assert result.ret == ExitCode.TESTS_FAILED

     # Should not cause "ValueError: Plugin already registered" (#4174).
-    result = testdir.runpytest("-vs", "symlink")
+    result = pytester.runpytest("-vs", "symlink")
     assert result.ret == ExitCode.OK


-def test_conftest_symlink_files(testdir):
+def test_conftest_symlink_files(pytester: Pytester) -> None:
     """Symlinked conftest.py are found when pytest is executed in a directory with symlinked
     files."""
-    real = testdir.tmpdir.mkdir("real")
+    real = pytester.mkdir("real")
     source = {
         "app/test_foo.py": "def test1(fixture): pass",
         "app/__init__.py": "",
@@ -258,16 +344,16 @@
             """
         ),
     }
-    testdir.makepyfile(**{"real/%s" % k: v for k, v in source.items()})
+    pytester.makepyfile(**{"real/%s" % k: v for k, v in source.items()})

     # Create a build directory that contains symlinks to actual files
     # but doesn't symlink actual directories.
-    build = testdir.tmpdir.mkdir("build")
-    build.mkdir("app")
+    build = pytester.mkdir("build")
+    build.joinpath("app").mkdir()
     for f in source:
-        symlink_or_skip(real.join(f), build.join(f))
-    build.chdir()
-    result = testdir.runpytest("-vs", "app/test_foo.py")
+        symlink_or_skip(real.joinpath(f), build.joinpath(f))
+    os.chdir(build)
+    result = pytester.runpytest("-vs", "app/test_foo.py")
     result.stdout.fnmatch_lines(["*conftest_loaded*", "PASSED"])
     assert result.ret == ExitCode.OK

@@ -276,39 +362,39 @@
     os.path.normcase("x") != os.path.normcase("X"),
     reason="only relevant for case insensitive file systems",
 )
-def test_conftest_badcase(testdir):
+def test_conftest_badcase(pytester: Pytester) -> None:
     """Check conftest.py loading when directory casing is wrong (#5792)."""
-    testdir.tmpdir.mkdir("JenkinsRoot").mkdir("test")
+    pytester.path.joinpath("JenkinsRoot/test").mkdir(parents=True)
     source = {"setup.py": "", "test/__init__.py": "", "test/conftest.py": ""}
-    testdir.makepyfile(**{"JenkinsRoot/%s" % k: v for k, v in source.items()})
-
-    testdir.tmpdir.join("jenkinsroot/test").chdir()
-    result = testdir.runpytest()
+    pytester.makepyfile(**{"JenkinsRoot/%s" % k: v for k, v in source.items()})
+
+    os.chdir(pytester.path.joinpath("jenkinsroot/test"))
+    result = pytester.runpytest()
     assert result.ret == ExitCode.NO_TESTS_COLLECTED


-def test_conftest_uppercase(testdir):
+def test_conftest_uppercase(pytester: Pytester) -> None:
     """Check conftest.py whose qualified name contains uppercase characters (#5819)"""
     source = {"__init__.py": "", "Foo/conftest.py": "", "Foo/__init__.py": ""}
-    testdir.makepyfile(**source)
-
-    testdir.tmpdir.chdir()
-    result = testdir.runpytest()
+    pytester.makepyfile(**source)
+
+    os.chdir(pytester.path)
+    result = pytester.runpytest()
     assert result.ret == ExitCode.NO_TESTS_COLLECTED


-def test_no_conftest(testdir):
-    testdir.makeconftest("assert 0")
-    result = testdir.runpytest("--noconftest")
+def test_no_conftest(pytester: Pytester) -> None:
+    pytester.makeconftest("assert 0")
+    result = pytester.runpytest("--noconftest")
     assert result.ret == ExitCode.NO_TESTS_COLLECTED

-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert result.ret == ExitCode.USAGE_ERROR


-def test_conftest_existing_junitxml(testdir):
-    x = testdir.mkdir("tests")
-    x.join("conftest.py").write(
+def test_conftest_existing_junitxml(pytester: Pytester) -> None:
+    x = pytester.mkdir("tests")
+    x.joinpath("conftest.py").write_text(
         textwrap.dedent(
             """\
             def pytest_addoption(parser):
@@ -316,33 +402,37 @@
             """
         )
     )
-    testdir.makefile(ext=".xml", junit="")  # Writes junit.xml
-    result = testdir.runpytest("-h", "--junitxml", "junit.xml")
+    pytester.makefile(ext=".xml", junit="")  # Writes junit.xml
+    result = pytester.runpytest("-h", "--junitxml", "junit.xml")
     result.stdout.fnmatch_lines(["*--xyz*"])


-def test_conftest_import_order(testdir, monkeypatch):
-    ct1 = testdir.makeconftest("")
-    sub = testdir.mkdir("sub")
-    ct2 = sub.join("conftest.py")
-    ct2.write("")
-
-    def impct(p, importmode):
+def test_conftest_import_order(pytester: Pytester, monkeypatch: MonkeyPatch) -> None:
+    ct1 = pytester.makeconftest("")
+    sub = pytester.mkdir("sub")
+    ct2 = sub / "conftest.py"
+    ct2.write_text("")
+
+    def impct(p, importmode, root):
         return p

     conftest = PytestPluginManager()
-    conftest._confcutdir = testdir.tmpdir
+    conftest._confcutdir = pytester.path
     monkeypatch.setattr(conftest, "_importconftest", impct)
-    assert conftest._getconftestmodules(sub, importmode="prepend") == [ct1, ct2]
-
-
-def test_fixture_dependency(testdir):
-    ct1 = testdir.makeconftest("")
-    ct1 = testdir.makepyfile("__init__.py")
-    ct1.write("")
-    sub = testdir.mkdir("sub")
-    sub.join("__init__.py").write("")
-    sub.join("conftest.py").write(
+    mods = cast(
+        List[Path],
+        conftest._getconftestmodules(sub, importmode="prepend", rootpath=pytester.path),
+    )
+    expected = [ct1, ct2]
+    assert mods == expected
+
+
+def test_fixture_dependency(pytester: Pytester) -> None:
+    pytester.makeconftest("")
+    pytester.path.joinpath("__init__.py").touch()
+    sub = pytester.mkdir("sub")
+    sub.joinpath("__init__.py").touch()
+    sub.joinpath("conftest.py").write_text(
         textwrap.dedent(
             """\
             import pytest
@@ -361,9 +451,10 @@
             """
         )
     )
-    subsub = sub.mkdir("subsub")
-    subsub.join("__init__.py").write("")
-    subsub.join("test_bar.py").write(
+    subsub = sub.joinpath("subsub")
+    subsub.mkdir()
+    subsub.joinpath("__init__.py").touch()
+    subsub.joinpath("test_bar.py").write_text(
         textwrap.dedent(
             """\
             import pytest
@@ -377,13 +468,13 @@
             """
         )
     )
-    result = testdir.runpytest("sub")
+    result = pytester.runpytest("sub")
     result.stdout.fnmatch_lines(["*1 passed*"])


-def test_conftest_found_with_double_dash(testdir):
-    sub = testdir.mkdir("sub")
-    sub.join("conftest.py").write(
+def test_conftest_found_with_double_dash(pytester: Pytester) -> None:
+    sub = pytester.mkdir("sub")
+    sub.joinpath("conftest.py").write_text(
         textwrap.dedent(
             """\
             def pytest_addoption(parser):
@@ -391,9 +482,9 @@
             """
         )
     )
-    p = sub.join("test_hello.py")
-    p.write("def test_hello(): pass")
-    result = testdir.runpytest(str(p) + "::test_hello", "-h")
+    p = sub.joinpath("test_hello.py")
+    p.write_text("def test_hello(): pass")
+    result = pytester.runpytest(str(p) + "::test_hello", "-h")
     result.stdout.fnmatch_lines(
         """
         *--hello-world*
@@ -402,13 +493,13 @@


 class TestConftestVisibility:
-    def _setup_tree(self, testdir):  # for issue616
+    def _setup_tree(self, pytester: Pytester) -> Dict[str, Path]:  # for issue616
         # example mostly taken from:
         # https://mail.python.org/pipermail/pytest-dev/2014-September/002617.html
-        runner = testdir.mkdir("empty")
-        package = testdir.mkdir("package")
-
-        package.join("conftest.py").write(
+        runner = pytester.mkdir("empty")
+        package = pytester.mkdir("package")
+
+        package.joinpath("conftest.py").write_text(
             textwrap.dedent(
                 """\
                 import pytest
@@ -418,7 +509,7 @@
                 """
             )
         )
-        package.join("test_pkgroot.py").write(
+        package.joinpath("test_pkgroot.py").write_text(
             textwrap.dedent(
                 """\
                 def test_pkgroot(fxtr):
@@ -427,9 +518,10 @@
             )
         )

-        swc = package.mkdir("swc")
-        swc.join("__init__.py").ensure()
-        swc.join("conftest.py").write(
+        swc = package.joinpath("swc")
+        swc.mkdir()
+        swc.joinpath("__init__.py").touch()
+        swc.joinpath("conftest.py").write_text(
             textwrap.dedent(
                 """\
                 import pytest
@@ -439,7 +531,7 @@
                 """
             )
         )
-        swc.join("test_with_conftest.py").write(
+        swc.joinpath("test_with_conftest.py").write_text(
             textwrap.dedent(
                 """\
                 def test_with_conftest(fxtr):
@@ -448,9 +540,10 @@
             )
         )

-        snc = package.mkdir("snc")
-        snc.join("__init__.py").ensure()
-        snc.join("test_no_conftest.py").write(
+        snc = package.joinpath("snc")
+        snc.mkdir()
+        snc.joinpath("__init__.py").touch()
+        snc.joinpath("test_no_conftest.py").write_text(
             textwrap.dedent(
                 """\
                 def test_no_conftest(fxtr):
@@ -460,9 +553,8 @@
             )
         )
         print("created directory structure:")
-        tmppath = Path(str(testdir.tmpdir))
-        for x in tmppath.rglob(""):
-            print("   " + str(x.relative_to(tmppath)))
+        for x in pytester.path.rglob(""):
+            print("   " + str(x.relative_to(pytester.path)))

         return {"runner": runner, "package": package, "swc": swc, "snc": snc}

@@ -494,29 +586,32 @@
         ],
     )
     def test_parsefactories_relative_node_ids(
-        self, testdir, chdir, testarg, expect_ntests_passed
-    ):
+        self, pytester: Pytester, chdir: str, testarg: str, expect_ntests_passed: int
+    ) -> None:
         """#616"""
-        dirs = self._setup_tree(testdir)
-        print("pytest run in cwd: %s" % (dirs[chdir].relto(testdir.tmpdir)))
-        print("pytestarg        : %s" % (testarg))
-        print("expected pass    : %s" % (expect_ntests_passed))
-        with dirs[chdir].as_cwd():
-            reprec = testdir.inline_run(testarg, "-q", "--traceconfig")
-            reprec.assertoutcome(passed=expect_ntests_passed)
+        dirs = self._setup_tree(pytester)
+        print("pytest run in cwd: %s" % (dirs[chdir].relative_to(pytester.path)))
+        print("pytestarg        : %s" % testarg)
+        print("expected pass    : %s" % expect_ntests_passed)
+        os.chdir(dirs[chdir])
+        reprec = pytester.inline_run(testarg, "-q", "--traceconfig")
+        reprec.assertoutcome(passed=expect_ntests_passed)


 @pytest.mark.parametrize(
     "confcutdir,passed,error", [(".", 2, 0), ("src", 1, 1), (None, 1, 1)]
 )
-def test_search_conftest_up_to_inifile(testdir, confcutdir, passed, error):
+def test_search_conftest_up_to_inifile(
+    pytester: Pytester, confcutdir: str, passed: int, error: int
+) -> None:
     """Test that conftest files are detected only up to an ini file, unless
     an explicit --confcutdir option is given.
     """
-    root = testdir.tmpdir
-    src = root.join("src").ensure(dir=1)
-    src.join("pytest.ini").write("[pytest]")
-    src.join("conftest.py").write(
+    root = pytester.path
+    src = root.joinpath("src")
+    src.mkdir()
+    src.joinpath("pytest.ini").write_text("[pytest]")
+    src.joinpath("conftest.py").write_text(
         textwrap.dedent(
             """\
             import pytest
@@ -525,7 +620,7 @@
             """
         )
     )
-    src.join("test_foo.py").write(
+    src.joinpath("test_foo.py").write_text(
         textwrap.dedent(
             """\
             def test_1(fix1):
@@ -535,7 +630,7 @@
             """
         )
     )
-    root.join("conftest.py").write(
+    root.joinpath("conftest.py").write_text(
         textwrap.dedent(
             """\
             import pytest
@@ -547,8 +642,8 @@

     args = [str(src)]
     if confcutdir:
-        args = ["--confcutdir=%s" % root.join(confcutdir)]
-    result = testdir.runpytest(*args)
+        args = ["--confcutdir=%s" % root.joinpath(confcutdir)]
+    result = pytester.runpytest(*args)
     match = ""
     if passed:
         match += "*%d passed*" % passed
@@ -557,8 +652,8 @@
     result.stdout.fnmatch_lines(match)


-def test_issue1073_conftest_special_objects(testdir):
-    testdir.makeconftest(
+def test_issue1073_conftest_special_objects(pytester: Pytester) -> None:
+    pytester.makeconftest(
         """\
         class DontTouchMe(object):
             def __getattr__(self, x):
@@ -567,59 +662,59 @@
         x = DontTouchMe()
         """
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """\
         def test_some():
             pass
         """
     )
-    res = testdir.runpytest()
+    res = pytester.runpytest()
     assert res.ret == 0


-def test_conftest_exception_handling(testdir):
-    testdir.makeconftest(
+def test_conftest_exception_handling(pytester: Pytester) -> None:
+    pytester.makeconftest(
         """\
         raise ValueError()
         """
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """\
         def test_some():
             pass
         """
     )
-    res = testdir.runpytest()
+    res = pytester.runpytest()
     assert res.ret == 4
     assert "raise ValueError()" in [line.strip() for line in res.errlines]


-def test_hook_proxy(testdir):
+def test_hook_proxy(pytester: Pytester) -> None:
     """Session's gethookproxy() would cache conftests incorrectly (#2016).
     It was decided to remove the cache altogether.
     """
-    testdir.makepyfile(
+    pytester.makepyfile(
         **{
             "root/demo-0/test_foo1.py": "def test1(): pass",
             "root/demo-a/test_foo2.py": "def test1(): pass",
             "root/demo-a/conftest.py": """\
-            def pytest_ignore_collect(path, config):
+            def pytest_ignore_collect(collection_path, config):
                 return True
             """,
             "root/demo-b/test_foo3.py": "def test1(): pass",
             "root/demo-c/test_foo4.py": "def test1(): pass",
         }
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         ["*test_foo1.py*", "*test_foo3.py*", "*test_foo4.py*", "*3 passed*"]
     )


-def test_required_option_help(testdir):
-    testdir.makeconftest("assert 0")
-    x = testdir.mkdir("x")
-    x.join("conftest.py").write(
+def test_required_option_help(pytester: Pytester) -> None:
+    pytester.makeconftest("assert 0")
+    x = pytester.mkdir("x")
+    x.joinpath("conftest.py").write_text(
         textwrap.dedent(
             """\
             def pytest_addoption(parser):
@@ -627,6 +722,6 @@
             """
         )
     )
-    result = testdir.runpytest("-h", x)
+    result = pytester.runpytest("-h", x)
     result.stdout.no_fnmatch_line("*argument --xyz is required*")
     assert "general:" in result.stdout.str()
('testing', 'test_nodes.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,26 +1,39 @@
-import py
+import re
+import warnings
+from pathlib import Path
+from typing import cast
+from typing import List
+from typing import Type

 import pytest
 from _pytest import nodes
-from _pytest.pytester import Testdir
+from _pytest.compat import legacy_path
+from _pytest.outcomes import OutcomeException
+from _pytest.pytester import Pytester
+from _pytest.warning_types import PytestWarning


 @pytest.mark.parametrize(
-    "baseid, nodeid, expected",
+    ("nodeid", "expected"),
     (
-        ("", "", True),
-        ("", "foo", True),
-        ("", "foo/bar", True),
-        ("", "foo/bar::TestBaz", True),
-        ("foo", "food", False),
-        ("foo/bar::TestBaz", "foo/bar", False),
-        ("foo/bar::TestBaz", "foo/bar::TestBop", False),
-        ("foo/bar", "foo/bar::TestBop", True),
+        ("", [""]),
+        ("a", ["", "a"]),
+        ("aa/b", ["", "aa", "aa/b"]),
+        ("a/b/c", ["", "a", "a/b", "a/b/c"]),
+        ("a/bbb/c::D", ["", "a", "a/bbb", "a/bbb/c", "a/bbb/c::D"]),
+        ("a/b/c::D::eee", ["", "a", "a/b", "a/b/c", "a/b/c::D", "a/b/c::D::eee"]),
+        ("::xx", ["", "::xx"]),
+        # / only considered until first ::
+        ("a/b/c::D/d::e", ["", "a", "a/b", "a/b/c", "a/b/c::D/d", "a/b/c::D/d::e"]),
+        # : alone is not a separator.
+        ("a/b::D:e:f::g", ["", "a", "a/b", "a/b::D:e:f", "a/b::D:e:f::g"]),
+        # / not considered if a part of a test name
+        ("a/b::c/d::e[/test]", ["", "a", "a/b", "a/b::c/d", "a/b::c/d::e[/test]"]),
     ),
 )
-def test_ischildnode(baseid: str, nodeid: str, expected: bool) -> None:
-    result = nodes.ischildnode(baseid, nodeid)
-    assert result is expected
+def test_iterparentnodeids(nodeid: str, expected: List[str]) -> None:
+    result = list(nodes.iterparentnodeids(nodeid))
+    assert result == expected


 def test_node_from_parent_disallowed_arguments() -> None:
@@ -30,43 +43,109 @@
         nodes.Node.from_parent(None, config=None)  # type: ignore[arg-type]


-def test_std_warn_not_pytestwarning(testdir: Testdir) -> None:
-    items = testdir.getitems(
+def test_node_direct_construction_deprecated() -> None:
+    with pytest.raises(
+        OutcomeException,
+        match=(
+            "Direct construction of _pytest.nodes.Node has been deprecated, please "
+            "use _pytest.nodes.Node.from_parent.\nSee "
+            "https://docs.pytest.org/en/stable/deprecations.html#node-construction-changed-to-node-from-parent"
+            " for more details."
+        ),
+    ):
+        nodes.Node(None, session=None)  # type: ignore[arg-type]
+
+
+def test_subclassing_both_item_and_collector_deprecated(
+    request, tmp_path: Path
+) -> None:
+    """
+    Verifies we warn on diamond inheritance as well as correctly managing legacy
+    inheritance constructors with missing args as found in plugins.
+    """
+
+    # We do not expect any warnings messages to issued during class definition.
+    with warnings.catch_warnings():
+        warnings.simplefilter("error")
+
+        class SoWrong(nodes.Item, nodes.File):
+            def __init__(self, fspath, parent):
+                """Legacy ctor with legacy call # don't wana see"""
+                super().__init__(fspath, parent)
+
+    with pytest.warns(PytestWarning) as rec:
+        SoWrong.from_parent(
+            request.session, fspath=legacy_path(tmp_path / "broken.txt")
+        )
+    messages = [str(x.message) for x in rec]
+    assert any(
+        re.search(".*SoWrong.* not using a cooperative constructor.*", x)
+        for x in messages
+    )
+    assert any(
+        re.search("(?m)SoWrong .* should not be a collector", x) for x in messages
+    )
+
+
+@pytest.mark.parametrize(
+    "warn_type, msg", [(DeprecationWarning, "deprecated"), (PytestWarning, "pytest")]
+)
+def test_node_warn_is_no_longer_only_pytest_warnings(
+    pytester: Pytester, warn_type: Type[Warning], msg: str
+) -> None:
+    items = pytester.getitems(
         """
         def test():
             pass
     """
     )
-    with pytest.raises(ValueError, match=".*instance of PytestWarning.*"):
-        items[0].warn(UserWarning("some warning"))  # type: ignore[arg-type]
+    with pytest.warns(warn_type, match=msg):
+        items[0].warn(warn_type(msg))
+
+
+def test_node_warning_enforces_warning_types(pytester: Pytester) -> None:
+    items = pytester.getitems(
+        """
+        def test():
+            pass
+    """
+    )
+    with pytest.raises(
+        ValueError, match="warning must be an instance of Warning or subclass"
+    ):
+        items[0].warn(Exception("ok"))  # type: ignore[arg-type]


 def test__check_initialpaths_for_relpath() -> None:
     """Ensure that it handles dirs, and does not always use dirname."""
-    cwd = py.path.local()
+    cwd = Path.cwd()

     class FakeSession1:
-        _initialpaths = [cwd]
+        _initialpaths = frozenset({cwd})

-    assert nodes._check_initialpaths_for_relpath(FakeSession1, cwd) == ""
+    session = cast(pytest.Session, FakeSession1)

-    sub = cwd.join("file")
+    assert nodes._check_initialpaths_for_relpath(session, cwd) == ""
+
+    sub = cwd / "file"

     class FakeSession2:
-        _initialpaths = [cwd]
+        _initialpaths = frozenset({cwd})

-    assert nodes._check_initialpaths_for_relpath(FakeSession2, sub) == "file"
+    session = cast(pytest.Session, FakeSession2)

-    outside = py.path.local("/outside")
-    assert nodes._check_initialpaths_for_relpath(FakeSession2, outside) is None
+    assert nodes._check_initialpaths_for_relpath(session, sub) == "file"
+
+    outside = Path("/outside-this-does-not-exist")
+    assert nodes._check_initialpaths_for_relpath(session, outside) is None


-def test_failure_with_changed_cwd(testdir):
+def test_failure_with_changed_cwd(pytester: Pytester) -> None:
     """
     Test failure lines should use absolute paths if cwd has changed since
     invocation, so the path is correct (#6428).
     """
-    p = testdir.makepyfile(
+    p = pytester.makepyfile(
         """
         import os
         import pytest
@@ -84,5 +163,5 @@
             assert False
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines([str(p) + ":*: AssertionError", "*1 failed in *"])
('testing', 'test_unittest.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -4,10 +4,12 @@

 import pytest
 from _pytest.config import ExitCode
-
-
-def test_simple_unittest(testdir):
-    testpath = testdir.makepyfile(
+from _pytest.monkeypatch import MonkeyPatch
+from _pytest.pytester import Pytester
+
+
+def test_simple_unittest(pytester: Pytester) -> None:
+    testpath = pytester.makepyfile(
         """
         import unittest
         class MyTestCase(unittest.TestCase):
@@ -17,13 +19,13 @@
                 self.assertEqual('foo', 'bar')
     """
     )
-    reprec = testdir.inline_run(testpath)
+    reprec = pytester.inline_run(testpath)
     assert reprec.matchreport("testpassing").passed
     assert reprec.matchreport("test_failing").failed


-def test_runTest_method(testdir):
-    testdir.makepyfile(
+def test_runTest_method(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import unittest
         class MyTestCaseWithRunTest(unittest.TestCase):
@@ -36,7 +38,7 @@
                 pass
         """
     )
-    result = testdir.runpytest("-v")
+    result = pytester.runpytest("-v")
     result.stdout.fnmatch_lines(
         """
         *MyTestCaseWithRunTest::runTest*
@@ -46,8 +48,8 @@
     )


-def test_isclasscheck_issue53(testdir):
-    testpath = testdir.makepyfile(
+def test_isclasscheck_issue53(pytester: Pytester) -> None:
+    testpath = pytester.makepyfile(
         """
         import unittest
         class _E(object):
@@ -56,12 +58,12 @@
         E = _E()
     """
     )
-    result = testdir.runpytest(testpath)
+    result = pytester.runpytest(testpath)
     assert result.ret == ExitCode.NO_TESTS_COLLECTED


-def test_setup(testdir):
-    testpath = testdir.makepyfile(
+def test_setup(pytester: Pytester) -> None:
+    testpath = pytester.makepyfile(
         """
         import unittest
         class MyTestCase(unittest.TestCase):
@@ -77,14 +79,14 @@

     """
     )
-    reprec = testdir.inline_run("-s", testpath)
+    reprec = pytester.inline_run("-s", testpath)
     assert reprec.matchreport("test_both", when="call").passed
     rep = reprec.matchreport("test_both", when="teardown")
     assert rep.failed and "42" in str(rep.longrepr)


-def test_setUpModule(testdir):
-    testpath = testdir.makepyfile(
+def test_setUpModule(pytester: Pytester) -> None:
+    testpath = pytester.makepyfile(
         """
         values = []

@@ -101,12 +103,12 @@
             assert values == [1]
         """
     )
-    result = testdir.runpytest(testpath)
+    result = pytester.runpytest(testpath)
     result.stdout.fnmatch_lines(["*2 passed*"])


-def test_setUpModule_failing_no_teardown(testdir):
-    testpath = testdir.makepyfile(
+def test_setUpModule_failing_no_teardown(pytester: Pytester) -> None:
+    testpath = pytester.makepyfile(
         """
         values = []

@@ -120,14 +122,14 @@
             pass
     """
     )
-    reprec = testdir.inline_run(testpath)
+    reprec = pytester.inline_run(testpath)
     reprec.assertoutcome(passed=0, failed=1)
     call = reprec.getcalls("pytest_runtest_setup")[0]
     assert not call.item.module.values


-def test_new_instances(testdir):
-    testpath = testdir.makepyfile(
+def test_new_instances(pytester: Pytester) -> None:
+    testpath = pytester.makepyfile(
         """
         import unittest
         class MyTestCase(unittest.TestCase):
@@ -137,13 +139,13 @@
                 assert not hasattr(self, 'x')
     """
     )
-    reprec = testdir.inline_run(testpath)
+    reprec = pytester.inline_run(testpath)
     reprec.assertoutcome(passed=2)


-def test_function_item_obj_is_instance(testdir):
+def test_function_item_obj_is_instance(pytester: Pytester) -> None:
     """item.obj should be a bound method on unittest.TestCase function items (#5390)."""
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         def pytest_runtest_makereport(item, call):
             if call.when == 'call':
@@ -151,7 +153,7 @@
                 assert isinstance(item.obj.__self__, class_)
     """
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import unittest

@@ -160,12 +162,12 @@
                 pass
     """
     )
-    result = testdir.runpytest_inprocess()
+    result = pytester.runpytest_inprocess()
     result.stdout.fnmatch_lines(["* 1 passed in*"])


-def test_teardown(testdir):
-    testpath = testdir.makepyfile(
+def test_teardown(pytester: Pytester) -> None:
+    testpath = pytester.makepyfile(
         """
         import unittest
         class MyTestCase(unittest.TestCase):
@@ -179,14 +181,14 @@
                 self.assertEqual(MyTestCase.values, [None])
     """
     )
-    reprec = testdir.inline_run(testpath)
+    reprec = pytester.inline_run(testpath)
     passed, skipped, failed = reprec.countoutcomes()
     assert failed == 0, failed
     assert passed == 2
     assert passed + skipped + failed == 2


-def test_teardown_issue1649(testdir):
+def test_teardown_issue1649(pytester: Pytester) -> None:
     """
     Are TestCase objects cleaned up? Often unittest TestCase objects set
     attributes that are large and expensive during setUp.
@@ -194,7 +196,7 @@
     The TestCase will not be cleaned up if the test fails, because it
     would then exist in the stackframe.
     """
-    testpath = testdir.makepyfile(
+    testpath = pytester.makepyfile(
         """
         import unittest
         class TestCaseObjectsShouldBeCleanedUp(unittest.TestCase):
@@ -205,14 +207,14 @@

     """
     )
-    testdir.inline_run("-s", testpath)
+    pytester.inline_run("-s", testpath)
     gc.collect()
     for obj in gc.get_objects():
         assert type(obj).__name__ != "TestCaseObjectsShouldBeCleanedUp"


-def test_unittest_skip_issue148(testdir):
-    testpath = testdir.makepyfile(
+def test_unittest_skip_issue148(pytester: Pytester) -> None:
+    testpath = pytester.makepyfile(
         """
         import unittest

@@ -228,12 +230,12 @@
                 xxx
     """
     )
-    reprec = testdir.inline_run(testpath)
+    reprec = pytester.inline_run(testpath)
     reprec.assertoutcome(skipped=1)


-def test_method_and_teardown_failing_reporting(testdir):
-    testdir.makepyfile(
+def test_method_and_teardown_failing_reporting(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import unittest
         class TC(unittest.TestCase):
@@ -243,7 +245,7 @@
                 assert False, "down2"
     """
     )
-    result = testdir.runpytest("-s")
+    result = pytester.runpytest("-s")
     assert result.ret == 1
     result.stdout.fnmatch_lines(
         [
@@ -256,8 +258,8 @@
     )


-def test_setup_failure_is_shown(testdir):
-    testdir.makepyfile(
+def test_setup_failure_is_shown(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import unittest
         import pytest
@@ -269,14 +271,14 @@
                 xyz
     """
     )
-    result = testdir.runpytest("-s")
+    result = pytester.runpytest("-s")
     assert result.ret == 1
     result.stdout.fnmatch_lines(["*setUp*", "*assert 0*down1*", "*1 failed*"])
     result.stdout.no_fnmatch_line("*never42*")


-def test_setup_setUpClass(testdir):
-    testpath = testdir.makepyfile(
+def test_setup_setUpClass(pytester: Pytester) -> None:
+    testpath = pytester.makepyfile(
         """
         import unittest
         import pytest
@@ -296,12 +298,36 @@
             assert MyTestCase.x == 0
     """
     )
-    reprec = testdir.inline_run(testpath)
+    reprec = pytester.inline_run(testpath)
     reprec.assertoutcome(passed=3)


-def test_setup_class(testdir):
-    testpath = testdir.makepyfile(
+def test_fixtures_setup_setUpClass_issue8394(pytester: Pytester) -> None:
+    pytester.makepyfile(
+        """
+        import unittest
+        class MyTestCase(unittest.TestCase):
+            @classmethod
+            def setUpClass(cls):
+                pass
+            def test_func1(self):
+                pass
+            @classmethod
+            def tearDownClass(cls):
+                pass
+    """
+    )
+    result = pytester.runpytest("--fixtures")
+    assert result.ret == 0
+    result.stdout.no_fnmatch_line("*no docstring available*")
+
+    result = pytester.runpytest("--fixtures", "-v")
+    assert result.ret == 0
+    result.stdout.fnmatch_lines(["*no docstring available*"])
+
+
+def test_setup_class(pytester: Pytester) -> None:
+    testpath = pytester.makepyfile(
         """
         import unittest
         import pytest
@@ -319,13 +345,13 @@
             assert MyTestCase.x == 0
     """
     )
-    reprec = testdir.inline_run(testpath)
+    reprec = pytester.inline_run(testpath)
     reprec.assertoutcome(passed=3)


 @pytest.mark.parametrize("type", ["Error", "Failure"])
-def test_testcase_adderrorandfailure_defers(testdir, type):
-    testdir.makepyfile(
+def test_testcase_adderrorandfailure_defers(pytester: Pytester, type: str) -> None:
+    pytester.makepyfile(
         """
         from unittest import TestCase
         import pytest
@@ -343,38 +369,46 @@
     """
         % (type, type)
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.no_fnmatch_line("*should not raise*")


 @pytest.mark.parametrize("type", ["Error", "Failure"])
-def test_testcase_custom_exception_info(testdir, type):
-    testdir.makepyfile(
-        """
+def test_testcase_custom_exception_info(pytester: Pytester, type: str) -> None:
+    pytester.makepyfile(
+        """
+        from typing import Generic, TypeVar
         from unittest import TestCase
-        import py, pytest
-        import _pytest._code
+        import pytest, _pytest._code
+
         class MyTestCase(TestCase):
             def run(self, result):
                 excinfo = pytest.raises(ZeroDivisionError, lambda: 0/0)
-                # we fake an incompatible exception info
-                from _pytest.monkeypatch import MonkeyPatch
-                mp = MonkeyPatch()
-                def t(*args):
-                    mp.undo()
-                    raise TypeError()
-                mp.setattr(_pytest._code, 'ExceptionInfo', t)
+                # We fake an incompatible exception info.
+                class FakeExceptionInfo(Generic[TypeVar("E")]):
+                    def __init__(self, *args, **kwargs):
+                        mp.undo()
+                        raise TypeError()
+                    @classmethod
+                    def from_current(cls):
+                        return cls()
+                    @classmethod
+                    def from_exc_info(cls, *args, **kwargs):
+                        return cls()
+                mp = pytest.MonkeyPatch()
+                mp.setattr(_pytest._code, 'ExceptionInfo', FakeExceptionInfo)
                 try:
                     excinfo = excinfo._excinfo
                     result.add%(type)s(self, excinfo)
                 finally:
                     mp.undo()
+
             def test_hello(self):
                 pass
     """
         % locals()
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         [
             "NOTE: Incompatible Exception Representation*",
@@ -384,8 +418,10 @@
     )


-def test_testcase_totally_incompatible_exception_info(testdir):
-    (item,) = testdir.getitems(
+def test_testcase_totally_incompatible_exception_info(pytester: Pytester) -> None:
+    import _pytest.unittest
+
+    (item,) = pytester.getitems(
         """
         from unittest import TestCase
         class MyTestCase(TestCase):
@@ -393,13 +429,15 @@
                 pass
     """
     )
-    item.addError(None, 42)
-    excinfo = item._excinfo.pop(0)
-    assert "ERROR: Unknown Incompatible" in str(excinfo.getrepr())
-
-
-def test_module_level_pytestmark(testdir):
-    testpath = testdir.makepyfile(
+    assert isinstance(item, _pytest.unittest.TestCaseFunction)
+    item.addError(None, 42)  # type: ignore[arg-type]
+    excinfo = item._excinfo
+    assert excinfo is not None
+    assert "ERROR: Unknown Incompatible" in str(excinfo.pop(0).getrepr())
+
+
+def test_module_level_pytestmark(pytester: Pytester) -> None:
+    testpath = pytester.makepyfile(
         """
         import unittest
         import pytest
@@ -409,7 +447,7 @@
                 assert 0
     """
     )
-    reprec = testdir.inline_run(testpath, "-s")
+    reprec = pytester.inline_run(testpath, "-s")
     reprec.assertoutcome(skipped=1)


@@ -420,8 +458,8 @@
         # https://twistedmatrix.com/trac/ticket/9227
         cls.ignore_unclosed_socket_warning = ("-W", "always")

-    def test_trial_testcase_runtest_not_collected(self, testdir):
-        testdir.makepyfile(
+    def test_trial_testcase_runtest_not_collected(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             from twisted.trial.unittest import TestCase

@@ -430,9 +468,9 @@
                     pass
         """
         )
-        reprec = testdir.inline_run(*self.ignore_unclosed_socket_warning)
+        reprec = pytester.inline_run(*self.ignore_unclosed_socket_warning)
         reprec.assertoutcome(passed=1)
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             from twisted.trial.unittest import TestCase

@@ -441,11 +479,11 @@
                     pass
         """
         )
-        reprec = testdir.inline_run(*self.ignore_unclosed_socket_warning)
+        reprec = pytester.inline_run(*self.ignore_unclosed_socket_warning)
         reprec.assertoutcome(passed=1)

-    def test_trial_exceptions_with_skips(self, testdir):
-        testdir.makepyfile(
+    def test_trial_exceptions_with_skips(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             from twisted.trial import unittest
             import pytest
@@ -479,7 +517,7 @@
                     pass
         """
         )
-        result = testdir.runpytest("-rxs", *self.ignore_unclosed_socket_warning)
+        result = pytester.runpytest("-rxs", *self.ignore_unclosed_socket_warning)
         result.stdout.fnmatch_lines_random(
             [
                 "*XFAIL*test_trial_todo*",
@@ -494,8 +532,8 @@
         )
         assert result.ret == 1

-    def test_trial_error(self, testdir):
-        testdir.makepyfile(
+    def test_trial_error(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             from twisted.trial.unittest import TestCase
             from twisted.internet.defer import Deferred
@@ -532,9 +570,7 @@
                 # will crash both at test time and at teardown
         """
         )
-        # Ignore DeprecationWarning (for `cmp`) from attrs through twisted,
-        # for stable test results.
-        result = testdir.runpytest(
+        result = pytester.runpytest(
             "-vv", "-oconsole_output_style=classic", "-W", "ignore::DeprecationWarning"
         )
         result.stdout.fnmatch_lines(
@@ -560,8 +596,8 @@
             ]
         )

-    def test_trial_pdb(self, testdir):
-        p = testdir.makepyfile(
+    def test_trial_pdb(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             from twisted.trial import unittest
             import pytest
@@ -570,12 +606,12 @@
                     assert 0, "hellopdb"
         """
         )
-        child = testdir.spawn_pytest(p)
+        child = pytester.spawn_pytest(str(p))
         child.expect("hellopdb")
         child.sendeof()

-    def test_trial_testcase_skip_property(self, testdir):
-        testpath = testdir.makepyfile(
+    def test_trial_testcase_skip_property(self, pytester: Pytester) -> None:
+        testpath = pytester.makepyfile(
             """
             from twisted.trial import unittest
             class MyTestCase(unittest.TestCase):
@@ -584,11 +620,11 @@
                     pass
             """
         )
-        reprec = testdir.inline_run(testpath, "-s")
+        reprec = pytester.inline_run(testpath, "-s")
         reprec.assertoutcome(skipped=1)

-    def test_trial_testfunction_skip_property(self, testdir):
-        testpath = testdir.makepyfile(
+    def test_trial_testfunction_skip_property(self, pytester: Pytester) -> None:
+        testpath = pytester.makepyfile(
             """
             from twisted.trial import unittest
             class MyTestCase(unittest.TestCase):
@@ -597,11 +633,11 @@
                 test_func.skip = 'dont run'
             """
         )
-        reprec = testdir.inline_run(testpath, "-s")
+        reprec = pytester.inline_run(testpath, "-s")
         reprec.assertoutcome(skipped=1)

-    def test_trial_testcase_todo_property(self, testdir):
-        testpath = testdir.makepyfile(
+    def test_trial_testcase_todo_property(self, pytester: Pytester) -> None:
+        testpath = pytester.makepyfile(
             """
             from twisted.trial import unittest
             class MyTestCase(unittest.TestCase):
@@ -610,11 +646,11 @@
                     assert 0
             """
         )
-        reprec = testdir.inline_run(testpath, "-s")
+        reprec = pytester.inline_run(testpath, "-s")
         reprec.assertoutcome(skipped=1)

-    def test_trial_testfunction_todo_property(self, testdir):
-        testpath = testdir.makepyfile(
+    def test_trial_testfunction_todo_property(self, pytester: Pytester) -> None:
+        testpath = pytester.makepyfile(
             """
             from twisted.trial import unittest
             class MyTestCase(unittest.TestCase):
@@ -623,15 +659,15 @@
                 test_func.todo = 'dont run'
             """
         )
-        reprec = testdir.inline_run(
+        reprec = pytester.inline_run(
             testpath, "-s", *self.ignore_unclosed_socket_warning
         )
         reprec.assertoutcome(skipped=1)


-def test_djangolike_testcase(testdir):
+def test_djangolike_testcase(pytester: Pytester) -> None:
     # contributed from Morten Breekevold
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         from unittest import TestCase, main

@@ -674,7 +710,7 @@
                 print("_post_teardown()")
     """
     )
-    result = testdir.runpytest("-s")
+    result = pytester.runpytest("-s")
     assert result.ret == 0
     result.stdout.fnmatch_lines(
         [
@@ -687,8 +723,8 @@
     )


-def test_unittest_not_shown_in_traceback(testdir):
-    testdir.makepyfile(
+def test_unittest_not_shown_in_traceback(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import unittest
         class t(unittest.TestCase):
@@ -697,12 +733,12 @@
                 self.assertEqual(x, 4)
     """
     )
-    res = testdir.runpytest()
+    res = pytester.runpytest()
     res.stdout.no_fnmatch_line("*failUnlessEqual*")


-def test_unorderable_types(testdir):
-    testdir.makepyfile(
+def test_unorderable_types(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import unittest
         class TestJoinEmpty(unittest.TestCase):
@@ -716,13 +752,13 @@
         TestFoo = make_test()
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.no_fnmatch_line("*TypeError*")
     assert result.ret == ExitCode.NO_TESTS_COLLECTED


-def test_unittest_typerror_traceback(testdir):
-    testdir.makepyfile(
+def test_unittest_typerror_traceback(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import unittest
         class TestJoinEmpty(unittest.TestCase):
@@ -730,14 +766,16 @@
                 pass
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert "TypeError" in result.stdout.str()
     assert result.ret == 1


 @pytest.mark.parametrize("runner", ["pytest", "unittest"])
-def test_unittest_expected_failure_for_failing_test_is_xfail(testdir, runner):
-    script = testdir.makepyfile(
+def test_unittest_expected_failure_for_failing_test_is_xfail(
+    pytester: Pytester, runner
+) -> None:
+    script = pytester.makepyfile(
         """
         import unittest
         class MyTestCase(unittest.TestCase):
@@ -749,19 +787,22 @@
     """
     )
     if runner == "pytest":
-        result = testdir.runpytest("-rxX")
+        result = pytester.runpytest("-rxX")
         result.stdout.fnmatch_lines(
             ["*XFAIL*MyTestCase*test_failing_test_is_xfail*", "*1 xfailed*"]
         )
     else:
-        result = testdir.runpython(script)
+        result = pytester.runpython(script)
         result.stderr.fnmatch_lines(["*1 test in*", "*OK*(expected failures=1)*"])
     assert result.ret == 0


 @pytest.mark.parametrize("runner", ["pytest", "unittest"])
-def test_unittest_expected_failure_for_passing_test_is_fail(testdir, runner):
-    script = testdir.makepyfile(
+def test_unittest_expected_failure_for_passing_test_is_fail(
+    pytester: Pytester,
+    runner: str,
+) -> None:
+    script = pytester.makepyfile(
         """
         import unittest
         class MyTestCase(unittest.TestCase):
@@ -774,31 +815,33 @@
     )

     if runner == "pytest":
-        result = testdir.runpytest("-rxX")
+        result = pytester.runpytest("-rxX")
         result.stdout.fnmatch_lines(
-            ["*MyTestCase*test_passing_test_is_fail*", "*1 failed*"]
+            [
+                "*MyTestCase*test_passing_test_is_fail*",
+                "Unexpected success",
+                "*1 failed*",
+            ]
         )
     else:
-        result = testdir.runpython(script)
+        result = pytester.runpython(script)
         result.stderr.fnmatch_lines(["*1 test in*", "*(unexpected successes=1)*"])

     assert result.ret == 1


-@pytest.mark.parametrize(
-    "fix_type, stmt", [("fixture", "return"), ("yield_fixture", "yield")]
-)
-def test_unittest_setup_interaction(testdir, fix_type, stmt):
-    testdir.makepyfile(
+@pytest.mark.parametrize("stmt", ["return", "yield"])
+def test_unittest_setup_interaction(pytester: Pytester, stmt: str) -> None:
+    pytester.makepyfile(
         """
         import unittest
         import pytest
         class MyTestCase(unittest.TestCase):
-            @pytest.{fix_type}(scope="class", autouse=True)
+            @pytest.fixture(scope="class", autouse=True)
             def perclass(self, request):
                 request.cls.hello = "world"
                 {stmt}
-            @pytest.{fix_type}(scope="function", autouse=True)
+            @pytest.fixture(scope="function", autouse=True)
             def perfunction(self, request):
                 request.instance.funcname = request.function.__name__
                 {stmt}
@@ -813,15 +856,15 @@
             def test_classattr(self):
                 assert self.__class__.hello == "world"
     """.format(
-            fix_type=fix_type, stmt=stmt
-        )
-    )
-    result = testdir.runpytest()
+            stmt=stmt
+        )
+    )
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*3 passed*"])


-def test_non_unittest_no_setupclass_support(testdir):
-    testpath = testdir.makepyfile(
+def test_non_unittest_no_setupclass_support(pytester: Pytester) -> None:
+    testpath = pytester.makepyfile(
         """
         class TestFoo(object):
             x = 0
@@ -842,12 +885,12 @@

     """
     )
-    reprec = testdir.inline_run(testpath)
+    reprec = pytester.inline_run(testpath)
     reprec.assertoutcome(passed=2)


-def test_no_teardown_if_setupclass_failed(testdir):
-    testpath = testdir.makepyfile(
+def test_no_teardown_if_setupclass_failed(pytester: Pytester) -> None:
+    testpath = pytester.makepyfile(
         """
         import unittest

@@ -870,13 +913,13 @@
             assert MyTestCase.x == 1
     """
     )
-    reprec = testdir.inline_run(testpath)
+    reprec = pytester.inline_run(testpath)
     reprec.assertoutcome(passed=1, failed=1)


-def test_cleanup_functions(testdir):
+def test_cleanup_functions(pytester: Pytester) -> None:
     """Ensure functions added with addCleanup are always called after each test ends (#6947)"""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import unittest

@@ -895,7 +938,7 @@
                 assert cleanups == ["test_func_1", "test_func_2"]
     """
     )
-    result = testdir.runpytest("-v")
+    result = pytester.runpytest("-v")
     result.stdout.fnmatch_lines(
         [
             "*::test_func_1 PASSED *",
@@ -905,8 +948,8 @@
     )


-def test_issue333_result_clearing(testdir):
-    testdir.makeconftest(
+def test_issue333_result_clearing(pytester: Pytester) -> None:
+    pytester.makeconftest(
         """
         import pytest
         @pytest.hookimpl(hookwrapper=True)
@@ -915,7 +958,7 @@
             assert 0
     """
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import unittest
         class TestIt(unittest.TestCase):
@@ -924,12 +967,12 @@
     """
     )

-    reprec = testdir.inline_run()
+    reprec = pytester.inline_run()
     reprec.assertoutcome(failed=1)


-def test_unittest_raise_skip_issue748(testdir):
-    testdir.makepyfile(
+def test_unittest_raise_skip_issue748(pytester: Pytester) -> None:
+    pytester.makepyfile(
         test_foo="""
         import unittest

@@ -938,7 +981,7 @@
                 raise unittest.SkipTest('skipping due to reasons')
     """
     )
-    result = testdir.runpytest("-v", "-rs")
+    result = pytester.runpytest("-v", "-rs")
     result.stdout.fnmatch_lines(
         """
         *SKIP*[1]*test_foo.py*skipping due to reasons*
@@ -947,8 +990,8 @@
     )


-def test_unittest_skip_issue1169(testdir):
-    testdir.makepyfile(
+def test_unittest_skip_issue1169(pytester: Pytester) -> None:
+    pytester.makepyfile(
         test_foo="""
         import unittest

@@ -958,7 +1001,7 @@
                  self.fail()
         """
     )
-    result = testdir.runpytest("-v", "-rs")
+    result = pytester.runpytest("-v", "-rs")
     result.stdout.fnmatch_lines(
         """
         *SKIP*[1]*skipping due to reasons*
@@ -967,8 +1010,8 @@
     )


-def test_class_method_containing_test_issue1558(testdir):
-    testdir.makepyfile(
+def test_class_method_containing_test_issue1558(pytester: Pytester) -> None:
+    pytester.makepyfile(
         test_foo="""
         import unittest

@@ -980,16 +1023,16 @@
             test_should_not_run.__test__ = False
     """
     )
-    reprec = testdir.inline_run()
+    reprec = pytester.inline_run()
     reprec.assertoutcome(passed=1)


 @pytest.mark.parametrize("base", ["builtins.object", "unittest.TestCase"])
-def test_usefixtures_marker_on_unittest(base, testdir):
+def test_usefixtures_marker_on_unittest(base, pytester: Pytester) -> None:
     """#3498"""
     module = base.rsplit(".", 1)[0]
     pytest.importorskip(module)
-    testdir.makepyfile(
+    pytester.makepyfile(
         conftest="""
         import pytest

@@ -1018,7 +1061,7 @@
         """
     )

-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         import {module}
@@ -1043,16 +1086,16 @@
         )
     )

-    result = testdir.runpytest("-s")
+    result = pytester.runpytest("-s")
     result.assert_outcomes(passed=2)


-def test_testcase_handles_init_exceptions(testdir):
+def test_testcase_handles_init_exceptions(pytester: Pytester) -> None:
     """
     Regression test to make sure exceptions in the __init__ method are bubbled up correctly.
     See https://github.com/pytest-dev/pytest/issues/3788
     """
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         from unittest import TestCase
         import pytest
@@ -1063,14 +1106,14 @@
                 pass
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert "should raise this exception" in result.stdout.str()
     result.stdout.no_fnmatch_line("*ERROR at teardown of MyTestCase.test_hello*")


-def test_error_message_with_parametrized_fixtures(testdir):
-    testdir.copy_example("unittest/test_parametrized_fixture_error_message.py")
-    result = testdir.runpytest()
+def test_error_message_with_parametrized_fixtures(pytester: Pytester) -> None:
+    pytester.copy_example("unittest/test_parametrized_fixture_error_message.py")
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         [
             "*test_two does not support fixtures*",
@@ -1088,15 +1131,17 @@
         ("test_setup_skip_module.py", "1 error"),
     ],
 )
-def test_setup_inheritance_skipping(testdir, test_name, expected_outcome):
+def test_setup_inheritance_skipping(
+    pytester: Pytester, test_name, expected_outcome
+) -> None:
     """Issue #4700"""
-    testdir.copy_example("unittest/{}".format(test_name))
-    result = testdir.runpytest()
-    result.stdout.fnmatch_lines(["* {} in *".format(expected_outcome)])
-
-
-def test_BdbQuit(testdir):
-    testdir.makepyfile(
+    pytester.copy_example(f"unittest/{test_name}")
+    result = pytester.runpytest()
+    result.stdout.fnmatch_lines([f"* {expected_outcome} in *"])
+
+
+def test_BdbQuit(pytester: Pytester) -> None:
+    pytester.makepyfile(
         test_foo="""
         import unittest

@@ -1109,12 +1154,12 @@
                 pass
     """
     )
-    reprec = testdir.inline_run()
+    reprec = pytester.inline_run()
     reprec.assertoutcome(failed=1, passed=1)


-def test_exit_outcome(testdir):
-    testdir.makepyfile(
+def test_exit_outcome(pytester: Pytester) -> None:
+    pytester.makepyfile(
         test_foo="""
         import pytest
         import unittest
@@ -1127,11 +1172,11 @@
                 pass
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*Exit: pytest_exit called*", "*= no tests ran in *"])


-def test_trace(testdir, monkeypatch):
+def test_trace(pytester: Pytester, monkeypatch: MonkeyPatch) -> None:
     calls = []

     def check_call(*args, **kwargs):
@@ -1146,7 +1191,7 @@

     monkeypatch.setattr("_pytest.debugging.pytestPDB._init_pdb", check_call)

-    p1 = testdir.makepyfile(
+    p1 = pytester.makepyfile(
         """
         import unittest

@@ -1155,23 +1200,23 @@
                 self.assertEqual('foo', 'foo')
     """
     )
-    result = testdir.runpytest("--trace", str(p1))
+    result = pytester.runpytest("--trace", str(p1))
     assert len(calls) == 2
     assert result.ret == 0


-def test_pdb_teardown_called(testdir, monkeypatch) -> None:
+def test_pdb_teardown_called(pytester: Pytester, monkeypatch: MonkeyPatch) -> None:
     """Ensure tearDown() is always called when --pdb is given in the command-line.

     We delay the normal tearDown() calls when --pdb is given, so this ensures we are calling
     tearDown() eventually to avoid memory leaks when using --pdb.
     """
-    teardowns = []  # type: List[str]
+    teardowns: List[str] = []
     monkeypatch.setattr(
         pytest, "test_pdb_teardown_called_teardowns", teardowns, raising=False
     )

-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import unittest
         import pytest
@@ -1187,7 +1232,7 @@
                 pass
     """
     )
-    result = testdir.runpytest_inprocess("--pdb")
+    result = pytester.runpytest_inprocess("--pdb")
     result.stdout.fnmatch_lines("* 2 passed in *")
     assert teardowns == [
         "test_pdb_teardown_called.MyTestCase.test_1",
@@ -1196,12 +1241,14 @@


 @pytest.mark.parametrize("mark", ["@unittest.skip", "@pytest.mark.skip"])
-def test_pdb_teardown_skipped(testdir, monkeypatch, mark: str) -> None:
+def test_pdb_teardown_skipped(
+    pytester: Pytester, monkeypatch: MonkeyPatch, mark: str
+) -> None:
     """With --pdb, setUp and tearDown should not be called for skipped tests."""
-    tracked = []  # type: List[str]
+    tracked: List[str] = []
     monkeypatch.setattr(pytest, "test_pdb_teardown_skipped", tracked, raising=False)

-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import unittest
         import pytest
@@ -1222,29 +1269,29 @@
             mark=mark
         )
     )
-    result = testdir.runpytest_inprocess("--pdb")
+    result = pytester.runpytest_inprocess("--pdb")
     result.stdout.fnmatch_lines("* 1 skipped in *")
     assert tracked == []


-def test_async_support(testdir):
+def test_async_support(pytester: Pytester) -> None:
     pytest.importorskip("unittest.async_case")

-    testdir.copy_example("unittest/test_unittest_asyncio.py")
-    reprec = testdir.inline_run()
+    pytester.copy_example("unittest/test_unittest_asyncio.py")
+    reprec = pytester.inline_run()
     reprec.assertoutcome(failed=1, passed=2)


-def test_asynctest_support(testdir):
+def test_asynctest_support(pytester: Pytester) -> None:
     """Check asynctest support (#7110)"""
     pytest.importorskip("asynctest")

-    testdir.copy_example("unittest/test_unittest_asynctest.py")
-    reprec = testdir.inline_run()
+    pytester.copy_example("unittest/test_unittest_asynctest.py")
+    reprec = pytester.inline_run()
     reprec.assertoutcome(failed=1, passed=2)


-def test_plain_unittest_does_not_support_async(testdir):
+def test_plain_unittest_does_not_support_async(pytester: Pytester) -> None:
     """Async functions in plain unittest.TestCase subclasses are not supported without plugins.

     This test exists here to avoid introducing this support by accident, leading users
@@ -1252,8 +1299,8 @@

     See https://github.com/pytest-dev/pytest-asyncio/issues/180 for more context.
     """
-    testdir.copy_example("unittest/test_unittest_plain_async.py")
-    result = testdir.runpytest_subprocess()
+    pytester.copy_example("unittest/test_unittest_plain_async.py")
+    result = pytester.runpytest_subprocess()
     if hasattr(sys, "pypy_version_info"):
         # in PyPy we can't reliable get the warning about the coroutine not being awaited,
         # because it depends on the coroutine being garbage collected; given that
@@ -1265,3 +1312,216 @@
             "*1 passed*",
         ]
     result.stdout.fnmatch_lines(expected_lines)
+
+
+@pytest.mark.skipif(
+    sys.version_info < (3, 8), reason="Feature introduced in Python 3.8"
+)
+def test_do_class_cleanups_on_success(pytester: Pytester) -> None:
+    testpath = pytester.makepyfile(
+        """
+        import unittest
+        class MyTestCase(unittest.TestCase):
+            values = []
+            @classmethod
+            def setUpClass(cls):
+                def cleanup():
+                    cls.values.append(1)
+                cls.addClassCleanup(cleanup)
+            def test_one(self):
+                pass
+            def test_two(self):
+                pass
+        def test_cleanup_called_exactly_once():
+            assert MyTestCase.values == [1]
+    """
+    )
+    reprec = pytester.inline_run(testpath)
+    passed, skipped, failed = reprec.countoutcomes()
+    assert failed == 0
+    assert passed == 3
+
+
+@pytest.mark.skipif(
+    sys.version_info < (3, 8), reason="Feature introduced in Python 3.8"
+)
+def test_do_class_cleanups_on_setupclass_failure(pytester: Pytester) -> None:
+    testpath = pytester.makepyfile(
+        """
+        import unittest
+        class MyTestCase(unittest.TestCase):
+            values = []
+            @classmethod
+            def setUpClass(cls):
+                def cleanup():
+                    cls.values.append(1)
+                cls.addClassCleanup(cleanup)
+                assert False
+            def test_one(self):
+                pass
+        def test_cleanup_called_exactly_once():
+            assert MyTestCase.values == [1]
+    """
+    )
+    reprec = pytester.inline_run(testpath)
+    passed, skipped, failed = reprec.countoutcomes()
+    assert failed == 1
+    assert passed == 1
+
+
+@pytest.mark.skipif(
+    sys.version_info < (3, 8), reason="Feature introduced in Python 3.8"
+)
+def test_do_class_cleanups_on_teardownclass_failure(pytester: Pytester) -> None:
+    testpath = pytester.makepyfile(
+        """
+        import unittest
+        class MyTestCase(unittest.TestCase):
+            values = []
+            @classmethod
+            def setUpClass(cls):
+                def cleanup():
+                    cls.values.append(1)
+                cls.addClassCleanup(cleanup)
+            @classmethod
+            def tearDownClass(cls):
+                assert False
+            def test_one(self):
+                pass
+            def test_two(self):
+                pass
+        def test_cleanup_called_exactly_once():
+            assert MyTestCase.values == [1]
+    """
+    )
+    reprec = pytester.inline_run(testpath)
+    passed, skipped, failed = reprec.countoutcomes()
+    assert passed == 3
+
+
+def test_do_cleanups_on_success(pytester: Pytester) -> None:
+    testpath = pytester.makepyfile(
+        """
+        import unittest
+        class MyTestCase(unittest.TestCase):
+            values = []
+            def setUp(self):
+                def cleanup():
+                    self.values.append(1)
+                self.addCleanup(cleanup)
+            def test_one(self):
+                pass
+            def test_two(self):
+                pass
+        def test_cleanup_called_the_right_number_of_times():
+            assert MyTestCase.values == [1, 1]
+    """
+    )
+    reprec = pytester.inline_run(testpath)
+    passed, skipped, failed = reprec.countoutcomes()
+    assert failed == 0
+    assert passed == 3
+
+
+def test_do_cleanups_on_setup_failure(pytester: Pytester) -> None:
+    testpath = pytester.makepyfile(
+        """
+        import unittest
+        class MyTestCase(unittest.TestCase):
+            values = []
+            def setUp(self):
+                def cleanup():
+                    self.values.append(1)
+                self.addCleanup(cleanup)
+                assert False
+            def test_one(self):
+                pass
+            def test_two(self):
+                pass
+        def test_cleanup_called_the_right_number_of_times():
+            assert MyTestCase.values == [1, 1]
+    """
+    )
+    reprec = pytester.inline_run(testpath)
+    passed, skipped, failed = reprec.countoutcomes()
+    assert failed == 2
+    assert passed == 1
+
+
+def test_do_cleanups_on_teardown_failure(pytester: Pytester) -> None:
+    testpath = pytester.makepyfile(
+        """
+        import unittest
+        class MyTestCase(unittest.TestCase):
+            values = []
+            def setUp(self):
+                def cleanup():
+                    self.values.append(1)
+                self.addCleanup(cleanup)
+            def tearDown(self):
+                assert False
+            def test_one(self):
+                pass
+            def test_two(self):
+                pass
+        def test_cleanup_called_the_right_number_of_times():
+            assert MyTestCase.values == [1, 1]
+    """
+    )
+    reprec = pytester.inline_run(testpath)
+    passed, skipped, failed = reprec.countoutcomes()
+    assert failed == 2
+    assert passed == 1
+
+
+def test_traceback_pruning(pytester: Pytester) -> None:
+    """Regression test for #9610 - doesn't crash during traceback pruning."""
+    pytester.makepyfile(
+        """
+        import unittest
+
+        class MyTestCase(unittest.TestCase):
+            def __init__(self, test_method):
+                unittest.TestCase.__init__(self, test_method)
+
+        class TestIt(MyTestCase):
+            @classmethod
+            def tearDownClass(cls) -> None:
+                assert False
+
+            def test_it(self):
+                pass
+        """
+    )
+    reprec = pytester.inline_run()
+    passed, skipped, failed = reprec.countoutcomes()
+    assert passed == 1
+    assert failed == 1
+    assert reprec.ret == 1
+
+
+def test_raising_unittest_skiptest_during_collection(
+    pytester: Pytester,
+) -> None:
+    pytester.makepyfile(
+        """
+        import unittest
+
+        class TestIt(unittest.TestCase):
+            def test_it(self): pass
+            def test_it2(self): pass
+
+        raise unittest.SkipTest()
+
+        class TestIt2(unittest.TestCase):
+            def test_it(self): pass
+            def test_it2(self): pass
+        """
+    )
+    reprec = pytester.inline_run()
+    passed, skipped, failed = reprec.countoutcomes()
+    assert passed == 0
+    # Unittest reports one fake test for a skipped module.
+    assert skipped == 1
+    assert failed == 0
+    assert reprec.ret == ExitCode.NO_TESTS_COLLECTED
('testing', 'test_setupplan.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,6 +1,11 @@
-def test_show_fixtures_and_test(testdir, dummy_yaml_custom_test):
+from _pytest.pytester import Pytester
+
+
+def test_show_fixtures_and_test(
+    pytester: Pytester, dummy_yaml_custom_test: None
+) -> None:
     """Verify that fixtures are not executed."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         @pytest.fixture
@@ -11,7 +16,7 @@
     """
     )

-    result = testdir.runpytest("--setup-plan")
+    result = pytester.runpytest("--setup-plan")
     assert result.ret == 0

     result.stdout.fnmatch_lines(
@@ -19,7 +24,9 @@
     )


-def test_show_multi_test_fixture_setup_and_teardown_correctly_simple(testdir):
+def test_show_multi_test_fixture_setup_and_teardown_correctly_simple(
+    pytester: Pytester,
+) -> None:
     """Verify that when a fixture lives for longer than a single test, --setup-plan
     correctly displays the SETUP/TEARDOWN indicators the right number of times.

@@ -31,7 +38,7 @@
     correct fixture lifetimes. It was purely a display bug for --setup-plan, and
     did not affect the related --setup-show or --setup-only.)
     """
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         @pytest.fixture(scope = 'class')
@@ -45,7 +52,7 @@
     """
     )

-    result = testdir.runpytest("--setup-plan")
+    result = pytester.runpytest("--setup-plan")
     assert result.ret == 0

     setup_fragment = "SETUP    C fix"
@@ -66,9 +73,11 @@
     assert teardown_count == 1


-def test_show_multi_test_fixture_setup_and_teardown_same_as_setup_show(testdir):
+def test_show_multi_test_fixture_setup_and_teardown_same_as_setup_show(
+    pytester: Pytester,
+) -> None:
     """Verify that SETUP/TEARDOWN messages match what comes out of --setup-show."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         @pytest.fixture(scope = 'session')
@@ -93,8 +102,8 @@
     """
     )

-    plan_result = testdir.runpytest("--setup-plan")
-    show_result = testdir.runpytest("--setup-show")
+    plan_result = pytester.runpytest("--setup-plan")
+    show_result = pytester.runpytest("--setup-show")

     # the number and text of these lines should be identical
     plan_lines = [
('testing', 'test_collection.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,41 +1,55 @@
 import os
 import pprint
+import shutil
 import sys
 import textwrap
+from pathlib import Path
+from typing import List

 import pytest
 from _pytest.config import ExitCode
+from _pytest.fixtures import FixtureRequest
 from _pytest.main import _in_venv
 from _pytest.main import Session
-from _pytest.pathlib import Path
+from _pytest.monkeypatch import MonkeyPatch
+from _pytest.nodes import Item
 from _pytest.pathlib import symlink_or_skip
-from _pytest.pytester import Testdir
+from _pytest.pytester import HookRecorder
+from _pytest.pytester import Pytester
+
+
+def ensure_file(file_path: Path) -> Path:
+    """Ensure that file exists"""
+    file_path.parent.mkdir(parents=True, exist_ok=True)
+    file_path.touch(exist_ok=True)
+    return file_path


 class TestCollector:
-    def test_collect_versus_item(self):
-        from pytest import Collector, Item
+    def test_collect_versus_item(self) -> None:
+        from pytest import Collector
+        from pytest import Item

         assert not issubclass(Collector, Item)
         assert not issubclass(Item, Collector)

-    def test_check_equality(self, testdir: Testdir) -> None:
-        modcol = testdir.getmodulecol(
+    def test_check_equality(self, pytester: Pytester) -> None:
+        modcol = pytester.getmodulecol(
             """
             def test_pass(): pass
             def test_fail(): assert 0
         """
         )
-        fn1 = testdir.collect_by_name(modcol, "test_pass")
+        fn1 = pytester.collect_by_name(modcol, "test_pass")
         assert isinstance(fn1, pytest.Function)
-        fn2 = testdir.collect_by_name(modcol, "test_pass")
+        fn2 = pytester.collect_by_name(modcol, "test_pass")
         assert isinstance(fn2, pytest.Function)

         assert fn1 == fn2
         assert fn1 != modcol
         assert hash(fn1) == hash(fn2)

-        fn3 = testdir.collect_by_name(modcol, "test_fail")
+        fn3 = pytester.collect_by_name(modcol, "test_fail")
         assert isinstance(fn3, pytest.Function)
         assert not (fn1 == fn3)
         assert fn1 != fn3
@@ -48,50 +62,59 @@
             assert [1, 2, 3] != fn  # type: ignore[comparison-overlap]
             assert modcol != fn

-        assert testdir.collect_by_name(modcol, "doesnotexist") is None
-
-    def test_getparent(self, testdir):
-        modcol = testdir.getmodulecol(
+        assert pytester.collect_by_name(modcol, "doesnotexist") is None
+
+    def test_getparent_and_accessors(self, pytester: Pytester) -> None:
+        modcol = pytester.getmodulecol(
             """
             class TestClass:
                  def test_foo(self):
                      pass
         """
         )
-        cls = testdir.collect_by_name(modcol, "TestClass")
-        fn = testdir.collect_by_name(testdir.collect_by_name(cls, "()"), "test_foo")
-
-        parent = fn.getparent(pytest.Module)
-        assert parent is modcol
-
-        parent = fn.getparent(pytest.Function)
-        assert parent is fn
-
-        parent = fn.getparent(pytest.Class)
-        assert parent is cls
-
-    def test_getcustomfile_roundtrip(self, testdir):
-        hello = testdir.makefile(".xxx", hello="world")
-        testdir.makepyfile(
+        cls = pytester.collect_by_name(modcol, "TestClass")
+        assert isinstance(cls, pytest.Class)
+        fn = pytester.collect_by_name(cls, "test_foo")
+        assert isinstance(fn, pytest.Function)
+
+        assert fn.getparent(pytest.Module) is modcol
+        assert modcol.module is not None
+        assert modcol.cls is None
+        assert modcol.instance is None
+
+        assert fn.getparent(pytest.Class) is cls
+        assert cls.module is not None
+        assert cls.cls is not None
+        assert cls.instance is None
+
+        assert fn.getparent(pytest.Function) is fn
+        assert fn.module is not None
+        assert fn.cls is not None
+        assert fn.instance is not None
+        assert fn.function is not None
+
+    def test_getcustomfile_roundtrip(self, pytester: Pytester) -> None:
+        hello = pytester.makefile(".xxx", hello="world")
+        pytester.makepyfile(
             conftest="""
             import pytest
             class CustomFile(pytest.File):
                 pass
-            def pytest_collect_file(path, parent):
-                if path.ext == ".xxx":
-                    return CustomFile.from_parent(fspath=path, parent=parent)
-        """
-        )
-        node = testdir.getpathnode(hello)
+            def pytest_collect_file(file_path, parent):
+                if file_path.suffix == ".xxx":
+                    return CustomFile.from_parent(path=file_path, parent=parent)
+        """
+        )
+        node = pytester.getpathnode(hello)
         assert isinstance(node, pytest.File)
         assert node.name == "hello.xxx"
         nodes = node.session.perform_collect([node.nodeid], genitems=False)
         assert len(nodes) == 1
         assert isinstance(nodes[0], pytest.File)

-    def test_can_skip_class_with_test_attr(self, testdir):
+    def test_can_skip_class_with_test_attr(self, pytester: Pytester) -> None:
         """Assure test class is skipped when using `__test__=False` (See #2007)."""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             class TestFoo(object):
                 __test__ = False
@@ -101,25 +124,25 @@
                     assert True
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["collected 0 items", "*no tests ran in*"])


 class TestCollectFS:
-    def test_ignored_certain_directories(self, testdir):
-        tmpdir = testdir.tmpdir
-        tmpdir.ensure("build", "test_notfound.py")
-        tmpdir.ensure("dist", "test_notfound.py")
-        tmpdir.ensure("_darcs", "test_notfound.py")
-        tmpdir.ensure("CVS", "test_notfound.py")
-        tmpdir.ensure("{arch}", "test_notfound.py")
-        tmpdir.ensure(".whatever", "test_notfound.py")
-        tmpdir.ensure(".bzr", "test_notfound.py")
-        tmpdir.ensure("normal", "test_found.py")
-        for x in Path(str(tmpdir)).rglob("test_*.py"):
+    def test_ignored_certain_directories(self, pytester: Pytester) -> None:
+        tmp_path = pytester.path
+        ensure_file(tmp_path / "build" / "test_notfound.py")
+        ensure_file(tmp_path / "dist" / "test_notfound.py")
+        ensure_file(tmp_path / "_darcs" / "test_notfound.py")
+        ensure_file(tmp_path / "CVS" / "test_notfound.py")
+        ensure_file(tmp_path / "{arch}" / "test_notfound.py")
+        ensure_file(tmp_path / ".whatever" / "test_notfound.py")
+        ensure_file(tmp_path / ".bzr" / "test_notfound.py")
+        ensure_file(tmp_path / "normal" / "test_found.py")
+        for x in tmp_path.rglob("test_*.py"):
             x.write_text("def test_hello(): pass", "utf-8")

-        result = testdir.runpytest("--collect-only")
+        result = pytester.runpytest("--collect-only")
         s = result.stdout.str()
         assert "test_notfound" not in s
         assert "test_found" in s
@@ -135,20 +158,20 @@
             "Activate.ps1",
         ),
     )
-    def test_ignored_virtualenvs(self, testdir, fname):
+    def test_ignored_virtualenvs(self, pytester: Pytester, fname: str) -> None:
         bindir = "Scripts" if sys.platform.startswith("win") else "bin"
-        testdir.tmpdir.ensure("virtual", bindir, fname)
-        testfile = testdir.tmpdir.ensure("virtual", "test_invenv.py")
-        testfile.write("def test_hello(): pass")
+        ensure_file(pytester.path / "virtual" / bindir / fname)
+        testfile = ensure_file(pytester.path / "virtual" / "test_invenv.py")
+        testfile.write_text("def test_hello(): pass")

         # by default, ignore tests inside a virtualenv
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.no_fnmatch_line("*test_invenv*")
         # allow test collection if user insists
-        result = testdir.runpytest("--collect-in-virtualenv")
+        result = pytester.runpytest("--collect-in-virtualenv")
         assert "test_invenv" in result.stdout.str()
         # allow test collection if user directly passes in the directory
-        result = testdir.runpytest("virtual")
+        result = pytester.runpytest("virtual")
         assert "test_invenv" in result.stdout.str()

     @pytest.mark.parametrize(
@@ -162,16 +185,18 @@
             "Activate.ps1",
         ),
     )
-    def test_ignored_virtualenvs_norecursedirs_precedence(self, testdir, fname):
+    def test_ignored_virtualenvs_norecursedirs_precedence(
+        self, pytester: Pytester, fname: str
+    ) -> None:
         bindir = "Scripts" if sys.platform.startswith("win") else "bin"
         # norecursedirs takes priority
-        testdir.tmpdir.ensure(".virtual", bindir, fname)
-        testfile = testdir.tmpdir.ensure(".virtual", "test_invenv.py")
-        testfile.write("def test_hello(): pass")
-        result = testdir.runpytest("--collect-in-virtualenv")
+        ensure_file(pytester.path / ".virtual" / bindir / fname)
+        testfile = ensure_file(pytester.path / ".virtual" / "test_invenv.py")
+        testfile.write_text("def test_hello(): pass")
+        result = pytester.runpytest("--collect-in-virtualenv")
         result.stdout.no_fnmatch_line("*test_invenv*")
         # ...unless the virtualenv is explicitly given on the CLI
-        result = testdir.runpytest("--collect-in-virtualenv", ".virtual")
+        result = pytester.runpytest("--collect-in-virtualenv", ".virtual")
         assert "test_invenv" in result.stdout.str()

     @pytest.mark.parametrize(
@@ -185,114 +210,118 @@
             "Activate.ps1",
         ),
     )
-    def test__in_venv(self, testdir, fname):
+    def test__in_venv(self, pytester: Pytester, fname: str) -> None:
         """Directly test the virtual env detection function"""
         bindir = "Scripts" if sys.platform.startswith("win") else "bin"
         # no bin/activate, not a virtualenv
-        base_path = testdir.tmpdir.mkdir("venv")
+        base_path = pytester.mkdir("venv")
         assert _in_venv(base_path) is False
         # with bin/activate, totally a virtualenv
-        base_path.ensure(bindir, fname)
+        bin_path = base_path.joinpath(bindir)
+        bin_path.mkdir()
+        bin_path.joinpath(fname).touch()
         assert _in_venv(base_path) is True

-    def test_custom_norecursedirs(self, testdir):
-        testdir.makeini(
+    def test_custom_norecursedirs(self, pytester: Pytester) -> None:
+        pytester.makeini(
             """
             [pytest]
             norecursedirs = mydir xyz*
         """
         )
-        tmpdir = testdir.tmpdir
-        tmpdir.ensure("mydir", "test_hello.py").write("def test_1(): pass")
-        tmpdir.ensure("xyz123", "test_2.py").write("def test_2(): 0/0")
-        tmpdir.ensure("xy", "test_ok.py").write("def test_3(): pass")
-        rec = testdir.inline_run()
+        tmp_path = pytester.path
+        ensure_file(tmp_path / "mydir" / "test_hello.py").write_text(
+            "def test_1(): pass"
+        )
+        ensure_file(tmp_path / "xyz123" / "test_2.py").write_text("def test_2(): 0/0")
+        ensure_file(tmp_path / "xy" / "test_ok.py").write_text("def test_3(): pass")
+        rec = pytester.inline_run()
         rec.assertoutcome(passed=1)
-        rec = testdir.inline_run("xyz123/test_2.py")
+        rec = pytester.inline_run("xyz123/test_2.py")
         rec.assertoutcome(failed=1)

-    def test_testpaths_ini(self, testdir, monkeypatch):
-        testdir.makeini(
+    def test_testpaths_ini(self, pytester: Pytester, monkeypatch: MonkeyPatch) -> None:
+        pytester.makeini(
             """
             [pytest]
             testpaths = gui uts
         """
         )
-        tmpdir = testdir.tmpdir
-        tmpdir.ensure("env", "test_1.py").write("def test_env(): pass")
-        tmpdir.ensure("gui", "test_2.py").write("def test_gui(): pass")
-        tmpdir.ensure("uts", "test_3.py").write("def test_uts(): pass")
+        tmp_path = pytester.path
+        ensure_file(tmp_path / "env" / "test_1.py").write_text("def test_env(): pass")
+        ensure_file(tmp_path / "gui" / "test_2.py").write_text("def test_gui(): pass")
+        ensure_file(tmp_path / "uts" / "test_3.py").write_text("def test_uts(): pass")

         # executing from rootdir only tests from `testpaths` directories
         # are collected
-        items, reprec = testdir.inline_genitems("-v")
+        items, reprec = pytester.inline_genitems("-v")
         assert [x.name for x in items] == ["test_gui", "test_uts"]

         # check that explicitly passing directories in the command-line
         # collects the tests
         for dirname in ("env", "gui", "uts"):
-            items, reprec = testdir.inline_genitems(tmpdir.join(dirname))
+            items, reprec = pytester.inline_genitems(tmp_path.joinpath(dirname))
             assert [x.name for x in items] == ["test_%s" % dirname]

         # changing cwd to each subdirectory and running pytest without
         # arguments collects the tests in that directory normally
         for dirname in ("env", "gui", "uts"):
-            monkeypatch.chdir(testdir.tmpdir.join(dirname))
-            items, reprec = testdir.inline_genitems()
+            monkeypatch.chdir(pytester.path.joinpath(dirname))
+            items, reprec = pytester.inline_genitems()
             assert [x.name for x in items] == ["test_%s" % dirname]


 class TestCollectPluginHookRelay:
-    def test_pytest_collect_file(self, testdir):
+    def test_pytest_collect_file(self, pytester: Pytester) -> None:
         wascalled = []

         class Plugin:
-            def pytest_collect_file(self, path):
-                if not path.basename.startswith("."):
+            def pytest_collect_file(self, file_path: Path) -> None:
+                if not file_path.name.startswith("."):
                     # Ignore hidden files, e.g. .testmondata.
-                    wascalled.append(path)
-
-        testdir.makefile(".abc", "xyz")
-        pytest.main([testdir.tmpdir], plugins=[Plugin()])
+                    wascalled.append(file_path)
+
+        pytester.makefile(".abc", "xyz")
+        pytest.main(pytester.path, plugins=[Plugin()])
         assert len(wascalled) == 1
-        assert wascalled[0].ext == ".abc"
+        assert wascalled[0].suffix == ".abc"


 class TestPrunetraceback:
-    def test_custom_repr_failure(self, testdir):
-        p = testdir.makepyfile(
+    def test_custom_repr_failure(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             import not_exists
         """
         )
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest
-            def pytest_collect_file(path, parent):
-                return MyFile.from_parent(fspath=path, parent=parent)
+            def pytest_collect_file(file_path, parent):
+                return MyFile.from_parent(path=file_path, parent=parent)
             class MyError(Exception):
                 pass
             class MyFile(pytest.File):
                 def collect(self):
                     raise MyError()
                 def repr_failure(self, excinfo):
-                    if excinfo.errisinstance(MyError):
+                    if isinstance(excinfo.value, MyError):
                         return "hello world"
                     return pytest.File.repr_failure(self, excinfo)
         """
         )

-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.stdout.fnmatch_lines(["*ERROR collecting*", "*hello world*"])

     @pytest.mark.xfail(reason="other mechanism for adding to reporting needed")
-    def test_collect_report_postprocessing(self, testdir):
-        p = testdir.makepyfile(
+    def test_collect_report_postprocessing(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             import not_exists
         """
         )
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest
             @pytest.hookimpl(hookwrapper=True)
@@ -303,65 +332,74 @@
                 outcome.force_result(rep)
         """
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.stdout.fnmatch_lines(["*ERROR collecting*", "*header1*"])


 class TestCustomConftests:
-    def test_ignore_collect_path(self, testdir):
-        testdir.makeconftest(
-            """
-            def pytest_ignore_collect(path, config):
-                return path.basename.startswith("x") or \
-                       path.basename == "test_one.py"
-        """
-        )
-        sub = testdir.mkdir("xy123")
-        sub.ensure("test_hello.py").write("syntax error")
-        sub.join("conftest.py").write("syntax error")
-        testdir.makepyfile("def test_hello(): pass")
-        testdir.makepyfile(test_one="syntax error")
-        result = testdir.runpytest("--fulltrace")
+    def test_ignore_collect_path(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
+            """
+            def pytest_ignore_collect(collection_path, config):
+                return collection_path.name.startswith("x") or collection_path.name == "test_one.py"
+        """
+        )
+        sub = pytester.mkdir("xy123")
+        ensure_file(sub / "test_hello.py").write_text("syntax error")
+        sub.joinpath("conftest.py").write_text("syntax error")
+        pytester.makepyfile("def test_hello(): pass")
+        pytester.makepyfile(test_one="syntax error")
+        result = pytester.runpytest("--fulltrace")
         assert result.ret == 0
         result.stdout.fnmatch_lines(["*1 passed*"])

-    def test_ignore_collect_not_called_on_argument(self, testdir):
-        testdir.makeconftest(
-            """
-            def pytest_ignore_collect(path, config):
+    def test_ignore_collect_not_called_on_argument(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
+            """
+            def pytest_ignore_collect(collection_path, config):
                 return True
         """
         )
-        p = testdir.makepyfile("def test_hello(): pass")
-        result = testdir.runpytest(p)
+        p = pytester.makepyfile("def test_hello(): pass")
+        result = pytester.runpytest(p)
         assert result.ret == 0
         result.stdout.fnmatch_lines(["*1 passed*"])
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret == ExitCode.NO_TESTS_COLLECTED
         result.stdout.fnmatch_lines(["*collected 0 items*"])

-    def test_collectignore_exclude_on_option(self, testdir):
-        testdir.makeconftest(
-            """
-            collect_ignore = ['hello', 'test_world.py']
+    def test_collectignore_exclude_on_option(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
+            """
+            from pathlib import Path
+
+            class MyPathLike:
+                def __init__(self, path):
+                    self.path = path
+                def __fspath__(self):
+                    return "path"
+
+            collect_ignore = [MyPathLike('hello'), 'test_world.py', Path('bye')]
+
             def pytest_addoption(parser):
                 parser.addoption("--XX", action="store_true", default=False)
+
             def pytest_configure(config):
                 if config.getvalue("XX"):
                     collect_ignore[:] = []
         """
         )
-        testdir.mkdir("hello")
-        testdir.makepyfile(test_world="def test_hello(): pass")
-        result = testdir.runpytest()
+        pytester.mkdir("hello")
+        pytester.makepyfile(test_world="def test_hello(): pass")
+        result = pytester.runpytest()
         assert result.ret == ExitCode.NO_TESTS_COLLECTED
         result.stdout.no_fnmatch_line("*passed*")
-        result = testdir.runpytest("--XX")
+        result = pytester.runpytest("--XX")
         assert result.ret == 0
         assert "passed" in result.stdout.str()

-    def test_collectignoreglob_exclude_on_option(self, testdir):
-        testdir.makeconftest(
+    def test_collectignoreglob_exclude_on_option(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             collect_ignore_glob = ['*w*l[dt]*']
             def pytest_addoption(parser):
@@ -371,80 +409,80 @@
                     collect_ignore_glob[:] = []
         """
         )
-        testdir.makepyfile(test_world="def test_hello(): pass")
-        testdir.makepyfile(test_welt="def test_hallo(): pass")
-        result = testdir.runpytest()
+        pytester.makepyfile(test_world="def test_hello(): pass")
+        pytester.makepyfile(test_welt="def test_hallo(): pass")
+        result = pytester.runpytest()
         assert result.ret == ExitCode.NO_TESTS_COLLECTED
         result.stdout.fnmatch_lines(["*collected 0 items*"])
-        result = testdir.runpytest("--XX")
+        result = pytester.runpytest("--XX")
         assert result.ret == 0
         result.stdout.fnmatch_lines(["*2 passed*"])

-    def test_pytest_fs_collect_hooks_are_seen(self, testdir):
-        testdir.makeconftest(
+    def test_pytest_fs_collect_hooks_are_seen(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest
             class MyModule(pytest.Module):
                 pass
-            def pytest_collect_file(path, parent):
-                if path.ext == ".py":
-                    return MyModule.from_parent(fspath=path, parent=parent)
-        """
-        )
-        testdir.mkdir("sub")
-        testdir.makepyfile("def test_x(): pass")
-        result = testdir.runpytest("--co")
+            def pytest_collect_file(file_path, parent):
+                if file_path.suffix == ".py":
+                    return MyModule.from_parent(path=file_path, parent=parent)
+        """
+        )
+        pytester.mkdir("sub")
+        pytester.makepyfile("def test_x(): pass")
+        result = pytester.runpytest("--co")
         result.stdout.fnmatch_lines(["*MyModule*", "*test_x*"])

-    def test_pytest_collect_file_from_sister_dir(self, testdir):
-        sub1 = testdir.mkpydir("sub1")
-        sub2 = testdir.mkpydir("sub2")
-        conf1 = testdir.makeconftest(
+    def test_pytest_collect_file_from_sister_dir(self, pytester: Pytester) -> None:
+        sub1 = pytester.mkpydir("sub1")
+        sub2 = pytester.mkpydir("sub2")
+        conf1 = pytester.makeconftest(
             """
             import pytest
             class MyModule1(pytest.Module):
                 pass
-            def pytest_collect_file(path, parent):
-                if path.ext == ".py":
-                    return MyModule1.from_parent(fspath=path, parent=parent)
-        """
-        )
-        conf1.move(sub1.join(conf1.basename))
-        conf2 = testdir.makeconftest(
+            def pytest_collect_file(file_path, parent):
+                if file_path.suffix == ".py":
+                    return MyModule1.from_parent(path=file_path, parent=parent)
+        """
+        )
+        conf1.replace(sub1.joinpath(conf1.name))
+        conf2 = pytester.makeconftest(
             """
             import pytest
             class MyModule2(pytest.Module):
                 pass
-            def pytest_collect_file(path, parent):
-                if path.ext == ".py":
-                    return MyModule2.from_parent(fspath=path, parent=parent)
-        """
-        )
-        conf2.move(sub2.join(conf2.basename))
-        p = testdir.makepyfile("def test_x(): pass")
-        p.copy(sub1.join(p.basename))
-        p.copy(sub2.join(p.basename))
-        result = testdir.runpytest("--co")
+            def pytest_collect_file(file_path, parent):
+                if file_path.suffix == ".py":
+                    return MyModule2.from_parent(path=file_path, parent=parent)
+        """
+        )
+        conf2.replace(sub2.joinpath(conf2.name))
+        p = pytester.makepyfile("def test_x(): pass")
+        shutil.copy(p, sub1.joinpath(p.name))
+        shutil.copy(p, sub2.joinpath(p.name))
+        result = pytester.runpytest("--co")
         result.stdout.fnmatch_lines(["*MyModule1*", "*MyModule2*", "*test_x*"])


 class TestSession:
-    def test_collect_topdir(self, testdir):
-        p = testdir.makepyfile("def test_func(): pass")
-        id = "::".join([p.basename, "test_func"])
+    def test_collect_topdir(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile("def test_func(): pass")
+        id = "::".join([p.name, "test_func"])
         # XXX migrate to collectonly? (see below)
-        config = testdir.parseconfig(id)
-        topdir = testdir.tmpdir
+        config = pytester.parseconfig(id)
+        topdir = pytester.path
         rcol = Session.from_config(config)
-        assert topdir == rcol.fspath
+        assert topdir == rcol.path
         # rootid = rcol.nodeid
         # root2 = rcol.perform_collect([rcol.nodeid], genitems=False)[0]
         # assert root2 == rcol, rootid
         colitems = rcol.perform_collect([rcol.nodeid], genitems=False)
         assert len(colitems) == 1
-        assert colitems[0].fspath == p
-
-    def get_reported_items(self, hookrec):
+        assert colitems[0].path == p
+
+    def get_reported_items(self, hookrec: HookRecorder) -> List[Item]:
         """Return pytest.Item instances reported by the pytest_collectreport hook"""
         calls = hookrec.getcalls("pytest_collectreport")
         return [
@@ -454,22 +492,22 @@
             if isinstance(x, pytest.Item)
         ]

-    def test_collect_protocol_single_function(self, testdir):
-        p = testdir.makepyfile("def test_func(): pass")
-        id = "::".join([p.basename, "test_func"])
-        items, hookrec = testdir.inline_genitems(id)
+    def test_collect_protocol_single_function(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile("def test_func(): pass")
+        id = "::".join([p.name, "test_func"])
+        items, hookrec = pytester.inline_genitems(id)
         (item,) = items
         assert item.name == "test_func"
         newid = item.nodeid
         assert newid == id
         pprint.pprint(hookrec.calls)
-        topdir = testdir.tmpdir  # noqa
+        topdir = pytester.path  # noqa
         hookrec.assert_contains(
             [
-                ("pytest_collectstart", "collector.fspath == topdir"),
-                ("pytest_make_collect_report", "collector.fspath == topdir"),
-                ("pytest_collectstart", "collector.fspath == p"),
-                ("pytest_make_collect_report", "collector.fspath == p"),
+                ("pytest_collectstart", "collector.path == topdir"),
+                ("pytest_make_collect_report", "collector.path == topdir"),
+                ("pytest_collectstart", "collector.path == p"),
+                ("pytest_make_collect_report", "collector.path == p"),
                 ("pytest_pycollect_makeitem", "name == 'test_func'"),
                 ("pytest_collectreport", "report.result[0].name == 'test_func'"),
             ]
@@ -477,17 +515,17 @@
         # ensure we are reporting the collection of the single test item (#2464)
         assert [x.name for x in self.get_reported_items(hookrec)] == ["test_func"]

-    def test_collect_protocol_method(self, testdir):
-        p = testdir.makepyfile(
+    def test_collect_protocol_method(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             class TestClass(object):
                 def test_method(self):
                     pass
         """
         )
-        normid = p.basename + "::TestClass::test_method"
-        for id in [p.basename, p.basename + "::TestClass", normid]:
-            items, hookrec = testdir.inline_genitems(id)
+        normid = p.name + "::TestClass::test_method"
+        for id in [p.name, p.name + "::TestClass", normid]:
+            items, hookrec = pytester.inline_genitems(id)
             assert len(items) == 1
             assert items[0].name == "test_method"
             newid = items[0].nodeid
@@ -495,9 +533,9 @@
             # ensure we are reporting the collection of the single test item (#2464)
             assert [x.name for x in self.get_reported_items(hookrec)] == ["test_method"]

-    def test_collect_custom_nodes_multi_id(self, testdir):
-        p = testdir.makepyfile("def test_func(): pass")
-        testdir.makeconftest(
+    def test_collect_custom_nodes_multi_id(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile("def test_func(): pass")
+        pytester.makeconftest(
             """
             import pytest
             class SpecialItem(pytest.Item):
@@ -506,93 +544,93 @@
             class SpecialFile(pytest.File):
                 def collect(self):
                     return [SpecialItem.from_parent(name="check", parent=self)]
-            def pytest_collect_file(path, parent):
-                if path.basename == %r:
-                    return SpecialFile.from_parent(fspath=path, parent=parent)
-        """
-            % p.basename
-        )
-        id = p.basename
-
-        items, hookrec = testdir.inline_genitems(id)
+            def pytest_collect_file(file_path, parent):
+                if file_path.name == %r:
+                    return SpecialFile.from_parent(path=file_path, parent=parent)
+        """
+            % p.name
+        )
+        id = p.name
+
+        items, hookrec = pytester.inline_genitems(id)
         pprint.pprint(hookrec.calls)
         assert len(items) == 2
         hookrec.assert_contains(
             [
-                ("pytest_collectstart", "collector.fspath == collector.session.fspath"),
+                ("pytest_collectstart", "collector.path == collector.session.path"),
                 (
                     "pytest_collectstart",
                     "collector.__class__.__name__ == 'SpecialFile'",
                 ),
                 ("pytest_collectstart", "collector.__class__.__name__ == 'Module'"),
                 ("pytest_pycollect_makeitem", "name == 'test_func'"),
-                ("pytest_collectreport", "report.nodeid.startswith(p.basename)"),
+                ("pytest_collectreport", "report.nodeid.startswith(p.name)"),
             ]
         )
         assert len(self.get_reported_items(hookrec)) == 2

-    def test_collect_subdir_event_ordering(self, testdir):
-        p = testdir.makepyfile("def test_func(): pass")
-        aaa = testdir.mkpydir("aaa")
-        test_aaa = aaa.join("test_aaa.py")
-        p.move(test_aaa)
-
-        items, hookrec = testdir.inline_genitems()
+    def test_collect_subdir_event_ordering(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile("def test_func(): pass")
+        aaa = pytester.mkpydir("aaa")
+        test_aaa = aaa.joinpath("test_aaa.py")
+        p.replace(test_aaa)
+
+        items, hookrec = pytester.inline_genitems()
         assert len(items) == 1
         pprint.pprint(hookrec.calls)
         hookrec.assert_contains(
             [
-                ("pytest_collectstart", "collector.fspath == test_aaa"),
+                ("pytest_collectstart", "collector.path == test_aaa"),
                 ("pytest_pycollect_makeitem", "name == 'test_func'"),
                 ("pytest_collectreport", "report.nodeid.startswith('aaa/test_aaa.py')"),
             ]
         )

-    def test_collect_two_commandline_args(self, testdir):
-        p = testdir.makepyfile("def test_func(): pass")
-        aaa = testdir.mkpydir("aaa")
-        bbb = testdir.mkpydir("bbb")
-        test_aaa = aaa.join("test_aaa.py")
-        p.copy(test_aaa)
-        test_bbb = bbb.join("test_bbb.py")
-        p.move(test_bbb)
+    def test_collect_two_commandline_args(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile("def test_func(): pass")
+        aaa = pytester.mkpydir("aaa")
+        bbb = pytester.mkpydir("bbb")
+        test_aaa = aaa.joinpath("test_aaa.py")
+        shutil.copy(p, test_aaa)
+        test_bbb = bbb.joinpath("test_bbb.py")
+        p.replace(test_bbb)

         id = "."

-        items, hookrec = testdir.inline_genitems(id)
+        items, hookrec = pytester.inline_genitems(id)
         assert len(items) == 2
         pprint.pprint(hookrec.calls)
         hookrec.assert_contains(
             [
-                ("pytest_collectstart", "collector.fspath == test_aaa"),
+                ("pytest_collectstart", "collector.path == test_aaa"),
                 ("pytest_pycollect_makeitem", "name == 'test_func'"),
                 ("pytest_collectreport", "report.nodeid == 'aaa/test_aaa.py'"),
-                ("pytest_collectstart", "collector.fspath == test_bbb"),
+                ("pytest_collectstart", "collector.path == test_bbb"),
                 ("pytest_pycollect_makeitem", "name == 'test_func'"),
                 ("pytest_collectreport", "report.nodeid == 'bbb/test_bbb.py'"),
             ]
         )

-    def test_serialization_byid(self, testdir):
-        testdir.makepyfile("def test_func(): pass")
-        items, hookrec = testdir.inline_genitems()
+    def test_serialization_byid(self, pytester: Pytester) -> None:
+        pytester.makepyfile("def test_func(): pass")
+        items, hookrec = pytester.inline_genitems()
         assert len(items) == 1
         (item,) = items
-        items2, hookrec = testdir.inline_genitems(item.nodeid)
+        items2, hookrec = pytester.inline_genitems(item.nodeid)
         (item2,) = items2
         assert item2.name == item.name
-        assert item2.fspath == item.fspath
-
-    def test_find_byid_without_instance_parents(self, testdir):
-        p = testdir.makepyfile(
+        assert item2.path == item.path
+
+    def test_find_byid_without_instance_parents(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             class TestClass(object):
                 def test_method(self):
                     pass
         """
         )
-        arg = p.basename + "::TestClass::test_method"
-        items, hookrec = testdir.inline_genitems(arg)
+        arg = p.name + "::TestClass::test_method"
+        items, hookrec = pytester.inline_genitems(arg)
         assert len(items) == 1
         (item,) = items
         assert item.nodeid.endswith("TestClass::test_method")
@@ -601,43 +639,45 @@


 class Test_getinitialnodes:
-    def test_global_file(self, testdir, tmpdir) -> None:
-        x = tmpdir.ensure("x.py")
-        with tmpdir.as_cwd():
-            config = testdir.parseconfigure(x)
-        col = testdir.getnode(config, x)
+    def test_global_file(self, pytester: Pytester) -> None:
+        tmp_path = pytester.path
+        x = ensure_file(tmp_path / "x.py")
+        config = pytester.parseconfigure(x)
+        col = pytester.getnode(config, x)
         assert isinstance(col, pytest.Module)
         assert col.name == "x.py"
         assert col.parent is not None
         assert col.parent.parent is None
-        for col in col.listchain():
-            assert col.config is config
-
-    def test_pkgfile(self, testdir):
+        for parent in col.listchain():
+            assert parent.config is config
+
+    def test_pkgfile(self, pytester: Pytester, monkeypatch: MonkeyPatch) -> None:
         """Verify nesting when a module is within a package.
         The parent chain should match: Module<x.py> -> Package<subdir> -> Session.
             Session's parent should always be None.
         """
-        tmpdir = testdir.tmpdir
-        subdir = tmpdir.join("subdir")
-        x = subdir.ensure("x.py")
-        subdir.ensure("__init__.py")
-        with subdir.as_cwd():
-            config = testdir.parseconfigure(x)
-        col = testdir.getnode(config, x)
+        tmp_path = pytester.path
+        subdir = tmp_path.joinpath("subdir")
+        x = ensure_file(subdir / "x.py")
+        ensure_file(subdir / "__init__.py")
+        with monkeypatch.context() as mp:
+            mp.chdir(subdir)
+            config = pytester.parseconfigure(x)
+        col = pytester.getnode(config, x)
+        assert col is not None
         assert col.name == "x.py"
         assert isinstance(col, pytest.Module)
         assert isinstance(col.parent, pytest.Package)
         assert isinstance(col.parent.parent, pytest.Session)
         # session is batman (has no parents)
         assert col.parent.parent.parent is None
-        for col in col.listchain():
-            assert col.config is config
+        for parent in col.listchain():
+            assert parent.config is config


 class Test_genitems:
-    def test_check_collect_hashes(self, testdir):
-        p = testdir.makepyfile(
+    def test_check_collect_hashes(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             def test_1():
                 pass
@@ -646,8 +686,8 @@
                 pass
         """
         )
-        p.copy(p.dirpath(p.purebasename + "2" + ".py"))
-        items, reprec = testdir.inline_genitems(p.dirpath())
+        shutil.copy(p, p.parent / (p.stem + "2" + ".py"))
+        items, reprec = pytester.inline_genitems(p.parent)
         assert len(items) == 4
         for numi, i in enumerate(items):
             for numj, j in enumerate(items):
@@ -655,8 +695,8 @@
                     assert hash(i) != hash(j)
                     assert i != j

-    def test_example_items1(self, testdir):
-        p = testdir.makepyfile(
+    def test_example_items1(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             import pytest

@@ -673,7 +713,7 @@
                     pass
         """
         )
-        items, reprec = testdir.inline_genitems(p)
+        items, reprec = pytester.inline_genitems(p)
         assert len(items) == 4
         assert items[0].name == "testone"
         assert items[1].name == "testmethod_one"
@@ -681,27 +721,27 @@
         assert items[3].name == "testmethod_two[.[]"

         # let's also test getmodpath here
-        assert items[0].getmodpath() == "testone"
-        assert items[1].getmodpath() == "TestX.testmethod_one"
-        assert items[2].getmodpath() == "TestY.testmethod_one"
+        assert items[0].getmodpath() == "testone"  # type: ignore[attr-defined]
+        assert items[1].getmodpath() == "TestX.testmethod_one"  # type: ignore[attr-defined]
+        assert items[2].getmodpath() == "TestY.testmethod_one"  # type: ignore[attr-defined]
         # PR #6202: Fix incorrect result of getmodpath method. (Resolves issue #6189)
-        assert items[3].getmodpath() == "TestY.testmethod_two[.[]"
-
-        s = items[0].getmodpath(stopatmodule=False)
+        assert items[3].getmodpath() == "TestY.testmethod_two[.[]"  # type: ignore[attr-defined]
+
+        s = items[0].getmodpath(stopatmodule=False)  # type: ignore[attr-defined]
         assert s.endswith("test_example_items1.testone")
         print(s)

-    def test_class_and_functions_discovery_using_glob(self, testdir):
+    def test_class_and_functions_discovery_using_glob(self, pytester: Pytester) -> None:
         """Test that Python_classes and Python_functions config options work
         as prefixes and glob-like patterns (#600)."""
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
             python_classes = *Suite Test
             python_functions = *_test test
         """
         )
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             """
             class MyTestSuite(object):
                 def x_test(self):
@@ -712,26 +752,26 @@
                     pass
         """
         )
-        items, reprec = testdir.inline_genitems(p)
-        ids = [x.getmodpath() for x in items]
+        items, reprec = pytester.inline_genitems(p)
+        ids = [x.getmodpath() for x in items]  # type: ignore[attr-defined]
         assert ids == ["MyTestSuite.x_test", "TestCase.test_y"]


-def test_matchnodes_two_collections_same_file(testdir):
-    testdir.makeconftest(
+def test_matchnodes_two_collections_same_file(pytester: Pytester) -> None:
+    pytester.makeconftest(
         """
         import pytest
         def pytest_configure(config):
             config.pluginmanager.register(Plugin2())

         class Plugin2(object):
-            def pytest_collect_file(self, path, parent):
-                if path.ext == ".abc":
-                    return MyFile2.from_parent(fspath=path, parent=parent)
-
-        def pytest_collect_file(path, parent):
-            if path.ext == ".abc":
-                return MyFile1.from_parent(fspath=path, parent=parent)
+            def pytest_collect_file(self, file_path, parent):
+                if file_path.suffix == ".abc":
+                    return MyFile2.from_parent(path=file_path, parent=parent)
+
+        def pytest_collect_file(file_path, parent):
+            if file_path.suffix == ".abc":
+                return MyFile1.from_parent(path=file_path, parent=parent)

         class MyFile1(pytest.File):
             def collect(self):
@@ -750,17 +790,17 @@
                 pass
     """
     )
-    p = testdir.makefile(".abc", "")
-    result = testdir.runpytest()
+    p = pytester.makefile(".abc", "")
+    result = pytester.runpytest()
     assert result.ret == 0
     result.stdout.fnmatch_lines(["*2 passed*"])
-    res = testdir.runpytest("%s::item2" % p.basename)
+    res = pytester.runpytest("%s::item2" % p.name)
     res.stdout.fnmatch_lines(["*1 passed*"])


-class TestNodekeywords:
-    def test_no_under(self, testdir):
-        modcol = testdir.getmodulecol(
+class TestNodeKeywords:
+    def test_no_under(self, pytester: Pytester) -> None:
+        modcol = pytester.getmodulecol(
             """
             def test_pass(): pass
             def test_fail(): assert 0
@@ -772,8 +812,8 @@
             assert not x.startswith("_")
         assert modcol.name in repr(modcol.keywords)

-    def test_issue345(self, testdir):
-        testdir.makepyfile(
+    def test_issue345(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             def test_should_not_be_selected():
                 assert False, 'I should not have been selected to run'
@@ -782,17 +822,19 @@
                 pass
         """
         )
-        reprec = testdir.inline_run("-k repr")
+        reprec = pytester.inline_run("-k repr")
         reprec.assertoutcome(passed=1, failed=0)

-    def test_keyword_matching_is_case_insensitive_by_default(self, testdir):
+    def test_keyword_matching_is_case_insensitive_by_default(
+        self, pytester: Pytester
+    ) -> None:
         """Check that selection via -k EXPRESSION is case-insensitive.

         Since markers are also added to the node keywords, they too can
         be matched without having to think about case sensitivity.

         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -819,8 +861,56 @@
         )
         num_matching_tests = 4
         for expression in ("specifictopic", "SPECIFICTOPIC", "SpecificTopic"):
-            reprec = testdir.inline_run("-k " + expression)
+            reprec = pytester.inline_run("-k " + expression)
             reprec.assertoutcome(passed=num_matching_tests, failed=0)
+
+    def test_duplicates_handled_correctly(self, pytester: Pytester) -> None:
+        item = pytester.getitem(
+            """
+            import pytest
+            pytestmark = pytest.mark.kw
+            class TestClass:
+                pytestmark = pytest.mark.kw
+                def test_method(self): pass
+                test_method.kw = 'method'
+        """,
+            "test_method",
+        )
+        assert item.parent is not None and item.parent.parent is not None
+        item.parent.parent.keywords["kw"] = "class"
+
+        assert item.keywords["kw"] == "method"
+        assert len(item.keywords) == len(set(item.keywords))
+
+    def test_unpacked_marks_added_to_keywords(self, pytester: Pytester) -> None:
+        item = pytester.getitem(
+            """
+            import pytest
+            pytestmark = pytest.mark.foo
+            class TestClass:
+                pytestmark = pytest.mark.bar
+                def test_method(self): pass
+                test_method.pytestmark = pytest.mark.baz
+        """,
+            "test_method",
+        )
+        assert isinstance(item, pytest.Function)
+        cls = item.getparent(pytest.Class)
+        assert cls is not None
+        mod = item.getparent(pytest.Module)
+        assert mod is not None
+
+        assert item.keywords["foo"] == pytest.mark.foo.mark
+        assert item.keywords["bar"] == pytest.mark.bar.mark
+        assert item.keywords["baz"] == pytest.mark.baz.mark
+
+        assert cls.keywords["foo"] == pytest.mark.foo.mark
+        assert cls.keywords["bar"] == pytest.mark.bar.mark
+        assert "baz" not in cls.keywords
+
+        assert mod.keywords["foo"] == pytest.mark.foo.mark
+        assert "bar" not in mod.keywords
+        assert "baz" not in mod.keywords


 COLLECTION_ERROR_PY_FILES = dict(
@@ -845,11 +935,11 @@
 )


-def test_exit_on_collection_error(testdir):
+def test_exit_on_collection_error(pytester: Pytester) -> None:
     """Verify that all collection errors are collected and no tests executed"""
-    testdir.makepyfile(**COLLECTION_ERROR_PY_FILES)
-
-    res = testdir.runpytest()
+    pytester.makepyfile(**COLLECTION_ERROR_PY_FILES)
+
+    res = pytester.runpytest()
     assert res.ret == 2

     res.stdout.fnmatch_lines(
@@ -863,14 +953,16 @@
     )


-def test_exit_on_collection_with_maxfail_smaller_than_n_errors(testdir):
+def test_exit_on_collection_with_maxfail_smaller_than_n_errors(
+    pytester: Pytester,
+) -> None:
     """
     Verify collection is aborted once maxfail errors are encountered ignoring
     further modules which would cause more collection errors.
     """
-    testdir.makepyfile(**COLLECTION_ERROR_PY_FILES)
-
-    res = testdir.runpytest("--maxfail=1")
+    pytester.makepyfile(**COLLECTION_ERROR_PY_FILES)
+
+    res = pytester.runpytest("--maxfail=1")
     assert res.ret == 1
     res.stdout.fnmatch_lines(
         [
@@ -884,14 +976,16 @@
     res.stdout.no_fnmatch_line("*test_03*")


-def test_exit_on_collection_with_maxfail_bigger_than_n_errors(testdir):
+def test_exit_on_collection_with_maxfail_bigger_than_n_errors(
+    pytester: Pytester,
+) -> None:
     """
     Verify the test run aborts due to collection errors even if maxfail count of
     errors was not reached.
     """
-    testdir.makepyfile(**COLLECTION_ERROR_PY_FILES)
-
-    res = testdir.runpytest("--maxfail=4")
+    pytester.makepyfile(**COLLECTION_ERROR_PY_FILES)
+
+    res = pytester.runpytest("--maxfail=4")
     assert res.ret == 2
     res.stdout.fnmatch_lines(
         [
@@ -906,14 +1000,14 @@
     )


-def test_continue_on_collection_errors(testdir):
+def test_continue_on_collection_errors(pytester: Pytester) -> None:
     """
     Verify tests are executed even when collection errors occur when the
     --continue-on-collection-errors flag is set
     """
-    testdir.makepyfile(**COLLECTION_ERROR_PY_FILES)
-
-    res = testdir.runpytest("--continue-on-collection-errors")
+    pytester.makepyfile(**COLLECTION_ERROR_PY_FILES)
+
+    res = pytester.runpytest("--continue-on-collection-errors")
     assert res.ret == 1

     res.stdout.fnmatch_lines(
@@ -921,7 +1015,7 @@
     )


-def test_continue_on_collection_errors_maxfail(testdir):
+def test_continue_on_collection_errors_maxfail(pytester: Pytester) -> None:
     """
     Verify tests are executed even when collection errors occur and that maxfail
     is honoured (including the collection error count).
@@ -929,18 +1023,18 @@
     test_4 is never executed because the test run is with --maxfail=3 which
     means it is interrupted after the 2 collection errors + 1 failure.
     """
-    testdir.makepyfile(**COLLECTION_ERROR_PY_FILES)
-
-    res = testdir.runpytest("--continue-on-collection-errors", "--maxfail=3")
+    pytester.makepyfile(**COLLECTION_ERROR_PY_FILES)
+
+    res = pytester.runpytest("--continue-on-collection-errors", "--maxfail=3")
     assert res.ret == 1

     res.stdout.fnmatch_lines(["collected 2 items / 2 errors", "*1 failed, 2 errors*"])


-def test_fixture_scope_sibling_conftests(testdir):
+def test_fixture_scope_sibling_conftests(pytester: Pytester) -> None:
     """Regression test case for https://github.com/pytest-dev/pytest/issues/2836"""
-    foo_path = testdir.mkdir("foo")
-    foo_path.join("conftest.py").write(
+    foo_path = pytester.mkdir("foo")
+    foo_path.joinpath("conftest.py").write_text(
         textwrap.dedent(
             """\
             import pytest
@@ -950,13 +1044,13 @@
             """
         )
     )
-    foo_path.join("test_foo.py").write("def test_foo(fix): assert fix == 1")
+    foo_path.joinpath("test_foo.py").write_text("def test_foo(fix): assert fix == 1")

     # Tests in `food/` should not see the conftest fixture from `foo/`
-    food_path = testdir.mkpydir("food")
-    food_path.join("test_food.py").write("def test_food(fix): assert fix == 1")
-
-    res = testdir.runpytest()
+    food_path = pytester.mkpydir("food")
+    food_path.joinpath("test_food.py").write_text("def test_food(fix): assert fix == 1")
+
+    res = pytester.runpytest()
     assert res.ret == 1

     res.stdout.fnmatch_lines(
@@ -968,10 +1062,10 @@
     )


-def test_collect_init_tests(testdir):
+def test_collect_init_tests(pytester: Pytester) -> None:
     """Check that we collect files from __init__.py files when they patch the 'python_files' (#3773)"""
-    p = testdir.copy_example("collect/collect_init_tests")
-    result = testdir.runpytest(p, "--collect-only")
+    p = pytester.copy_example("collect/collect_init_tests")
+    result = pytester.runpytest(p, "--collect-only")
     result.stdout.fnmatch_lines(
         [
             "collected 2 items",
@@ -982,7 +1076,7 @@
             "    <Function test_foo>",
         ]
     )
-    result = testdir.runpytest("./tests", "--collect-only")
+    result = pytester.runpytest("./tests", "--collect-only")
     result.stdout.fnmatch_lines(
         [
             "collected 2 items",
@@ -994,7 +1088,7 @@
         ]
     )
     # Ignores duplicates with "." and pkginit (#4310).
-    result = testdir.runpytest("./tests", ".", "--collect-only")
+    result = pytester.runpytest("./tests", ".", "--collect-only")
     result.stdout.fnmatch_lines(
         [
             "collected 2 items",
@@ -1006,7 +1100,7 @@
         ]
     )
     # Same as before, but different order.
-    result = testdir.runpytest(".", "tests", "--collect-only")
+    result = pytester.runpytest(".", "tests", "--collect-only")
     result.stdout.fnmatch_lines(
         [
             "collected 2 items",
@@ -1017,23 +1111,23 @@
             "    <Function test_foo>",
         ]
     )
-    result = testdir.runpytest("./tests/test_foo.py", "--collect-only")
+    result = pytester.runpytest("./tests/test_foo.py", "--collect-only")
     result.stdout.fnmatch_lines(
         ["<Package tests>", "  <Module test_foo.py>", "    <Function test_foo>"]
     )
     result.stdout.no_fnmatch_line("*test_init*")
-    result = testdir.runpytest("./tests/__init__.py", "--collect-only")
+    result = pytester.runpytest("./tests/__init__.py", "--collect-only")
     result.stdout.fnmatch_lines(
         ["<Package tests>", "  <Module __init__.py>", "    <Function test_init>"]
     )
     result.stdout.no_fnmatch_line("*test_foo*")


-def test_collect_invalid_signature_message(testdir):
+def test_collect_invalid_signature_message(pytester: Pytester) -> None:
     """Check that we issue a proper message when we can't determine the signature of a test
     function (#4026).
     """
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest

@@ -1043,17 +1137,17 @@
                 pass
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         ["Could not determine arguments of *.fix *: invalid method signature"]
     )


-def test_collect_handles_raising_on_dunder_class(testdir):
+def test_collect_handles_raising_on_dunder_class(pytester: Pytester) -> None:
     """Handle proxy classes like Django's LazySettings that might raise on
     ``isinstance`` (#4266).
     """
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         class ImproperlyConfigured(Exception):
             pass
@@ -1071,14 +1165,14 @@
             pass
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*1 passed in*"])
     assert result.ret == 0


-def test_collect_with_chdir_during_import(testdir):
-    subdir = testdir.tmpdir.mkdir("sub")
-    testdir.tmpdir.join("conftest.py").write(
+def test_collect_with_chdir_during_import(pytester: Pytester) -> None:
+    subdir = pytester.mkdir("sub")
+    pytester.path.joinpath("conftest.py").write_text(
         textwrap.dedent(
             """
             import os
@@ -1087,7 +1181,7 @@
             % (str(subdir),)
         )
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         def test_1():
             import os
@@ -1095,31 +1189,31 @@
         """
         % (str(subdir),)
     )
-    with testdir.tmpdir.as_cwd():
-        result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*1 passed in*"])
     assert result.ret == 0

     # Handles relative testpaths.
-    testdir.makeini(
+    pytester.makeini(
         """
         [pytest]
         testpaths = .
     """
     )
-    with testdir.tmpdir.as_cwd():
-        result = testdir.runpytest("--collect-only")
+    result = pytester.runpytest("--collect-only")
     result.stdout.fnmatch_lines(["collected 1 item"])


-def test_collect_pyargs_with_testpaths(testdir, monkeypatch):
-    testmod = testdir.mkdir("testmod")
+def test_collect_pyargs_with_testpaths(
+    pytester: Pytester, monkeypatch: MonkeyPatch
+) -> None:
+    testmod = pytester.mkdir("testmod")
     # NOTE: __init__.py is not collected since it does not match python_files.
-    testmod.ensure("__init__.py").write("def test_func(): pass")
-    testmod.ensure("test_file.py").write("def test_func(): pass")
-
-    root = testdir.mkdir("root")
-    root.ensure("pytest.ini").write(
+    testmod.joinpath("__init__.py").write_text("def test_func(): pass")
+    testmod.joinpath("test_file.py").write_text("def test_func(): pass")
+
+    root = pytester.mkdir("root")
+    root.joinpath("pytest.ini").write_text(
         textwrap.dedent(
             """
         [pytest]
@@ -1128,32 +1222,33 @@
     """
         )
     )
-    monkeypatch.setenv("PYTHONPATH", str(testdir.tmpdir), prepend=os.pathsep)
-    with root.as_cwd():
-        result = testdir.runpytest_subprocess()
+    monkeypatch.setenv("PYTHONPATH", str(pytester.path), prepend=os.pathsep)
+    with monkeypatch.context() as mp:
+        mp.chdir(root)
+        result = pytester.runpytest_subprocess()
     result.stdout.fnmatch_lines(["*1 passed in*"])


-def test_collect_symlink_file_arg(testdir):
+def test_collect_symlink_file_arg(pytester: Pytester) -> None:
     """Collect a direct symlink works even if it does not match python_files (#4325)."""
-    real = testdir.makepyfile(
+    real = pytester.makepyfile(
         real="""
         def test_nodeid(request):
             assert request.node.nodeid == "symlink.py::test_nodeid"
         """
     )
-    symlink = testdir.tmpdir.join("symlink.py")
+    symlink = pytester.path.joinpath("symlink.py")
     symlink_or_skip(real, symlink)
-    result = testdir.runpytest("-v", symlink)
+    result = pytester.runpytest("-v", symlink)
     result.stdout.fnmatch_lines(["symlink.py::test_nodeid PASSED*", "*1 passed in*"])
     assert result.ret == 0


-def test_collect_symlink_out_of_tree(testdir):
+def test_collect_symlink_out_of_tree(pytester: Pytester) -> None:
     """Test collection of symlink via out-of-tree rootdir."""
-    sub = testdir.tmpdir.join("sub")
-    real = sub.join("test_real.py")
-    real.write(
+    sub = pytester.mkdir("sub")
+    real = sub.joinpath("test_real.py")
+    real.write_text(
         textwrap.dedent(
             """
         def test_nodeid(request):
@@ -1161,14 +1256,13 @@
             assert request.node.nodeid == "test_real.py::test_nodeid"
         """
         ),
-        ensure=True,
-    )
-
-    out_of_tree = testdir.tmpdir.join("out_of_tree").ensure(dir=True)
-    symlink_to_sub = out_of_tree.join("symlink_to_sub")
+    )
+
+    out_of_tree = pytester.mkdir("out_of_tree")
+    symlink_to_sub = out_of_tree.joinpath("symlink_to_sub")
     symlink_or_skip(sub, symlink_to_sub)
-    sub.chdir()
-    result = testdir.runpytest("-vs", "--rootdir=%s" % sub, symlink_to_sub)
+    os.chdir(sub)
+    result = pytester.runpytest("-vs", "--rootdir=%s" % sub, symlink_to_sub)
     result.stdout.fnmatch_lines(
         [
             # Should not contain "sub/"!
@@ -1178,30 +1272,40 @@
     assert result.ret == 0


-def test_collectignore_via_conftest(testdir):
+def test_collect_symlink_dir(pytester: Pytester) -> None:
+    """A symlinked directory is collected."""
+    dir = pytester.mkdir("dir")
+    dir.joinpath("test_it.py").write_text("def test_it(): pass", "utf-8")
+    symlink_or_skip(pytester.path.joinpath("symlink_dir"), dir)
+    result = pytester.runpytest()
+    result.assert_outcomes(passed=2)
+
+
+def test_collectignore_via_conftest(pytester: Pytester) -> None:
     """collect_ignore in parent conftest skips importing child (issue #4592)."""
-    tests = testdir.mkpydir("tests")
-    tests.ensure("conftest.py").write("collect_ignore = ['ignore_me']")
-
-    ignore_me = tests.mkdir("ignore_me")
-    ignore_me.ensure("__init__.py")
-    ignore_me.ensure("conftest.py").write("assert 0, 'should_not_be_called'")
-
-    result = testdir.runpytest()
+    tests = pytester.mkpydir("tests")
+    tests.joinpath("conftest.py").write_text("collect_ignore = ['ignore_me']")
+
+    ignore_me = tests.joinpath("ignore_me")
+    ignore_me.mkdir()
+    ignore_me.joinpath("__init__.py").touch()
+    ignore_me.joinpath("conftest.py").write_text("assert 0, 'should_not_be_called'")
+
+    result = pytester.runpytest()
     assert result.ret == ExitCode.NO_TESTS_COLLECTED


-def test_collect_pkg_init_and_file_in_args(testdir):
-    subdir = testdir.mkdir("sub")
-    init = subdir.ensure("__init__.py")
-    init.write("def test_init(): pass")
-    p = subdir.ensure("test_file.py")
-    p.write("def test_file(): pass")
+def test_collect_pkg_init_and_file_in_args(pytester: Pytester) -> None:
+    subdir = pytester.mkdir("sub")
+    init = subdir.joinpath("__init__.py")
+    init.write_text("def test_init(): pass")
+    p = subdir.joinpath("test_file.py")
+    p.write_text("def test_file(): pass")

     # NOTE: without "-o python_files=*.py" this collects test_file.py twice.
     # This changed/broke with "Add package scoped fixtures #2283" (2b1410895)
     # initially (causing a RecursionError).
-    result = testdir.runpytest("-v", str(init), str(p))
+    result = pytester.runpytest("-v", str(init), str(p))
     result.stdout.fnmatch_lines(
         [
             "sub/test_file.py::test_file PASSED*",
@@ -1210,7 +1314,7 @@
         ]
     )

-    result = testdir.runpytest("-v", "-o", "python_files=*.py", str(init), str(p))
+    result = pytester.runpytest("-v", "-o", "python_files=*.py", str(init), str(p))
     result.stdout.fnmatch_lines(
         [
             "sub/__init__.py::test_init PASSED*",
@@ -1220,33 +1324,33 @@
     )


-def test_collect_pkg_init_only(testdir):
-    subdir = testdir.mkdir("sub")
-    init = subdir.ensure("__init__.py")
-    init.write("def test_init(): pass")
-
-    result = testdir.runpytest(str(init))
+def test_collect_pkg_init_only(pytester: Pytester) -> None:
+    subdir = pytester.mkdir("sub")
+    init = subdir.joinpath("__init__.py")
+    init.write_text("def test_init(): pass")
+
+    result = pytester.runpytest(str(init))
     result.stdout.fnmatch_lines(["*no tests ran in*"])

-    result = testdir.runpytest("-v", "-o", "python_files=*.py", str(init))
+    result = pytester.runpytest("-v", "-o", "python_files=*.py", str(init))
     result.stdout.fnmatch_lines(["sub/__init__.py::test_init PASSED*", "*1 passed in*"])


 @pytest.mark.parametrize("use_pkg", (True, False))
-def test_collect_sub_with_symlinks(use_pkg, testdir):
+def test_collect_sub_with_symlinks(use_pkg: bool, pytester: Pytester) -> None:
     """Collection works with symlinked files and broken symlinks"""
-    sub = testdir.mkdir("sub")
+    sub = pytester.mkdir("sub")
     if use_pkg:
-        sub.ensure("__init__.py")
-    sub.join("test_file.py").write("def test_file(): pass")
+        sub.joinpath("__init__.py").touch()
+    sub.joinpath("test_file.py").write_text("def test_file(): pass")

     # Create a broken symlink.
-    symlink_or_skip("test_doesnotexist.py", sub.join("test_broken.py"))
+    symlink_or_skip("test_doesnotexist.py", sub.joinpath("test_broken.py"))

     # Symlink that gets collected.
-    symlink_or_skip("test_file.py", sub.join("test_symlink.py"))
-
-    result = testdir.runpytest("-v", str(sub))
+    symlink_or_skip("test_file.py", sub.joinpath("test_symlink.py"))
+
+    result = pytester.runpytest("-v", str(sub))
     result.stdout.fnmatch_lines(
         [
             "sub/test_file.py::test_file PASSED*",
@@ -1256,9 +1360,9 @@
     )


-def test_collector_respects_tbstyle(testdir):
-    p1 = testdir.makepyfile("assert 0")
-    result = testdir.runpytest(p1, "--tb=native")
+def test_collector_respects_tbstyle(pytester: Pytester) -> None:
+    p1 = pytester.makepyfile("assert 0")
+    result = pytester.runpytest(p1, "--tb=native")
     assert result.ret == ExitCode.INTERRUPTED
     result.stdout.fnmatch_lines(
         [
@@ -1273,58 +1377,70 @@
     )


-def test_does_not_eagerly_collect_packages(testdir):
-    testdir.makepyfile("def test(): pass")
-    pydir = testdir.mkpydir("foopkg")
-    pydir.join("__init__.py").write("assert False")
-    result = testdir.runpytest()
+def test_does_not_eagerly_collect_packages(pytester: Pytester) -> None:
+    pytester.makepyfile("def test(): pass")
+    pydir = pytester.mkpydir("foopkg")
+    pydir.joinpath("__init__.py").write_text("assert False")
+    result = pytester.runpytest()
     assert result.ret == ExitCode.OK


-def test_does_not_put_src_on_path(testdir):
+def test_does_not_put_src_on_path(pytester: Pytester) -> None:
     # `src` is not on sys.path so it should not be importable
-    testdir.tmpdir.join("src/nope/__init__.py").ensure()
-    testdir.makepyfile(
+    ensure_file(pytester.path / "src/nope/__init__.py")
+    pytester.makepyfile(
         "import pytest\n"
         "def test():\n"
         "    with pytest.raises(ImportError):\n"
         "        import nope\n"
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert result.ret == ExitCode.OK


-def test_fscollector_from_parent(tmpdir, request):
+def test_fscollector_from_parent(pytester: Pytester, request: FixtureRequest) -> None:
     """Ensure File.from_parent can forward custom arguments to the constructor.

     Context: https://github.com/pytest-dev/pytest-cpp/pull/47
     """

     class MyCollector(pytest.File):
-        def __init__(self, fspath, parent, x):
-            super().__init__(fspath, parent)
+        def __init__(self, *k, x, **kw):
+            super().__init__(*k, **kw)
             self.x = x

+    collector = MyCollector.from_parent(
+        parent=request.session, path=pytester.path / "foo", x=10
+    )
+    assert collector.x == 10
+
+
+def test_class_from_parent(pytester: Pytester, request: FixtureRequest) -> None:
+    """Ensure Class.from_parent can forward custom arguments to the constructor."""
+
+    class MyCollector(pytest.Class):
+        def __init__(self, name, parent, x):
+            super().__init__(name, parent)
+            self.x = x
+
         @classmethod
-        def from_parent(cls, parent, *, fspath, x):
-            return super().from_parent(parent=parent, fspath=fspath, x=x)
-
-    collector = MyCollector.from_parent(
-        parent=request.session, fspath=tmpdir / "foo", x=10
-    )
+        def from_parent(cls, parent, *, name, x):
+            return super().from_parent(parent=parent, name=name, x=x)
+
+    collector = MyCollector.from_parent(parent=request.session, name="foo", x=10)
     assert collector.x == 10


 class TestImportModeImportlib:
-    def test_collect_duplicate_names(self, testdir):
+    def test_collect_duplicate_names(self, pytester: Pytester) -> None:
         """--import-mode=importlib can import modules with same names that are not in packages."""
-        testdir.makepyfile(
+        pytester.makepyfile(
             **{
                 "tests_a/test_foo.py": "def test_foo1(): pass",
                 "tests_b/test_foo.py": "def test_foo2(): pass",
             }
         )
-        result = testdir.runpytest("-v", "--import-mode=importlib")
+        result = pytester.runpytest("-v", "--import-mode=importlib")
         result.stdout.fnmatch_lines(
             [
                 "tests_a/test_foo.py::test_foo1 *",
@@ -1333,11 +1449,11 @@
             ]
         )

-    def test_conftest(self, testdir):
+    def test_conftest(self, pytester: Pytester) -> None:
         """Directory containing conftest modules are not put in sys.path as a side-effect of
         importing them."""
-        tests_dir = testdir.tmpdir.join("tests")
-        testdir.makepyfile(
+        tests_dir = pytester.path.joinpath("tests")
+        pytester.makepyfile(
             **{
                 "tests/conftest.py": "",
                 "tests/test_foo.py": """
@@ -1349,13 +1465,13 @@
                 ),
             }
         )
-        result = testdir.runpytest("-v", "--import-mode=importlib")
+        result = pytester.runpytest("-v", "--import-mode=importlib")
         result.stdout.fnmatch_lines(["* 1 passed in *"])

-    def setup_conftest_and_foo(self, testdir):
+    def setup_conftest_and_foo(self, pytester: Pytester) -> None:
         """Setup a tests folder to be used to test if modules in that folder can be imported
         due to side-effects of --import-mode or not."""
-        testdir.makepyfile(
+        pytester.makepyfile(
             **{
                 "tests/conftest.py": "",
                 "tests/foo.py": """
@@ -1369,41 +1485,81 @@
             }
         )

-    def test_modules_importable_as_side_effect(self, testdir):
+    def test_modules_importable_as_side_effect(self, pytester: Pytester) -> None:
         """In import-modes `prepend` and `append`, we are able to import modules from folders
         containing conftest.py files due to the side effect of changing sys.path."""
-        self.setup_conftest_and_foo(testdir)
-        result = testdir.runpytest("-v", "--import-mode=prepend")
+        self.setup_conftest_and_foo(pytester)
+        result = pytester.runpytest("-v", "--import-mode=prepend")
         result.stdout.fnmatch_lines(["* 1 passed in *"])

-    def test_modules_not_importable_as_side_effect(self, testdir):
+    def test_modules_not_importable_as_side_effect(self, pytester: Pytester) -> None:
         """In import-mode `importlib`, modules in folders containing conftest.py are not
         importable, as don't change sys.path or sys.modules as side effect of importing
         the conftest.py file.
         """
-        self.setup_conftest_and_foo(testdir)
-        result = testdir.runpytest("-v", "--import-mode=importlib")
-        exc_name = (
-            "ModuleNotFoundError" if sys.version_info[:2] > (3, 5) else "ImportError"
-        )
+        self.setup_conftest_and_foo(pytester)
+        result = pytester.runpytest("-v", "--import-mode=importlib")
         result.stdout.fnmatch_lines(
             [
-                "*{}: No module named 'foo'".format(exc_name),
-                "tests?test_foo.py:2: {}".format(exc_name),
+                "*ModuleNotFoundError: No module named 'foo'",
+                "tests?test_foo.py:2: ModuleNotFoundError",
                 "* 1 failed in *",
             ]
         )

-
-def test_does_not_crash_on_error_from_decorated_function(testdir: Testdir) -> None:
+    def test_using_python_path(self, pytester: Pytester) -> None:
+        """
+        Dummy modules created by insert_missing_modules should not get in
+        the way of modules that could be imported via python path (#9645).
+        """
+        pytester.makeini(
+            """
+            [pytest]
+            pythonpath = .
+            addopts = --import-mode importlib
+            """
+        )
+        pytester.makepyfile(
+            **{
+                "tests/__init__.py": "",
+                "tests/conftest.py": "",
+                "tests/subpath/__init__.py": "",
+                "tests/subpath/helper.py": "",
+                "tests/subpath/test_something.py": """
+                import tests.subpath.helper
+
+                def test_something():
+                    assert True
+                """,
+            }
+        )
+        result = pytester.runpytest()
+        result.stdout.fnmatch_lines("*1 passed in*")
+
+
+def test_does_not_crash_on_error_from_decorated_function(pytester: Pytester) -> None:
     """Regression test for an issue around bad exception formatting due to
     assertion rewriting mangling lineno's (#4984)."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         @pytest.fixture
         def a(): return 4
         """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     # Not INTERNAL_ERROR
     assert result.ret == ExitCode.INTERRUPTED
+
+
+def test_does_not_crash_on_recursive_symlink(pytester: Pytester) -> None:
+    """Regression test for an issue around recursive symlinks (#7951)."""
+    symlink_or_skip("recursive", pytester.path.joinpath("recursive"))
+    pytester.makepyfile(
+        """
+        def test_foo(): assert True
+        """
+    )
+    result = pytester.runpytest()
+
+    assert result.ret == ExitCode.OK
+    assert result.parseoutcomes() == {"passed": 1}
('testing', 'test_terminal.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -4,13 +4,14 @@
 import sys
 import textwrap
 from io import StringIO
+from pathlib import Path
+from types import SimpleNamespace
 from typing import cast
 from typing import Dict
 from typing import List
 from typing import Tuple

 import pluggy
-import py

 import _pytest.config
 import _pytest.terminal
@@ -19,12 +20,14 @@
 from _pytest.config import Config
 from _pytest.config import ExitCode
 from _pytest.monkeypatch import MonkeyPatch
-from _pytest.pathlib import Path
-from _pytest.pytester import Testdir
+from _pytest.pytester import Pytester
 from _pytest.reports import BaseReport
 from _pytest.reports import CollectReport
+from _pytest.reports import TestReport
 from _pytest.terminal import _folded_skips
+from _pytest.terminal import _format_trimmed
 from _pytest.terminal import _get_line_with_reprcrash_message
+from _pytest.terminal import _get_raw_skip_reason
 from _pytest.terminal import _plugin_nameversions
 from _pytest.terminal import getreportopt
 from _pytest.terminal import TerminalReporter
@@ -76,8 +79,8 @@


 class TestTerminal:
-    def test_pass_skip_fail(self, testdir, option):
-        testdir.makepyfile(
+    def test_pass_skip_fail(self, pytester: Pytester, option) -> None:
+        pytester.makepyfile(
             """
             import pytest
             def test_ok():
@@ -88,7 +91,7 @@
                 assert 0
         """
         )
-        result = testdir.runpytest(*option.args)
+        result = pytester.runpytest(*option.args)
         if option.verbosity > 0:
             result.stdout.fnmatch_lines(
                 [
@@ -105,16 +108,16 @@
             ["    def test_func():", ">       assert 0", "E       assert 0"]
         )

-    def test_internalerror(self, testdir, linecomp):
-        modcol = testdir.getmodulecol("def test_one(): pass")
+    def test_internalerror(self, pytester: Pytester, linecomp) -> None:
+        modcol = pytester.getmodulecol("def test_one(): pass")
         rep = TerminalReporter(modcol.config, file=linecomp.stringio)
         with pytest.raises(ValueError) as excinfo:
             raise ValueError("hello")
         rep.pytest_internalerror(excinfo.getrepr())
         linecomp.assert_contains_lines(["INTERNALERROR> *ValueError*hello*"])

-    def test_writeline(self, testdir, linecomp):
-        modcol = testdir.getmodulecol("def test_one(): pass")
+    def test_writeline(self, pytester: Pytester, linecomp) -> None:
+        modcol = pytester.getmodulecol("def test_one(): pass")
         rep = TerminalReporter(modcol.config, file=linecomp.stringio)
         rep.write_fspath_result(modcol.nodeid, ".")
         rep.write_line("hello world")
@@ -123,33 +126,37 @@
         assert lines[1].endswith(modcol.name + " .")
         assert lines[2] == "hello world"

-    def test_show_runtest_logstart(self, testdir, linecomp):
-        item = testdir.getitem("def test_func(): pass")
+    def test_show_runtest_logstart(self, pytester: Pytester, linecomp) -> None:
+        item = pytester.getitem("def test_func(): pass")
         tr = TerminalReporter(item.config, file=linecomp.stringio)
         item.config.pluginmanager.register(tr)
         location = item.reportinfo()
         tr.config.hook.pytest_runtest_logstart(
-            nodeid=item.nodeid, location=location, fspath=str(item.fspath)
+            nodeid=item.nodeid, location=location, fspath=str(item.path)
         )
         linecomp.assert_contains_lines(["*test_show_runtest_logstart.py*"])

-    def test_runtest_location_shown_before_test_starts(self, testdir):
-        testdir.makepyfile(
+    def test_runtest_location_shown_before_test_starts(
+        self, pytester: Pytester
+    ) -> None:
+        pytester.makepyfile(
             """
             def test_1():
                 import time
                 time.sleep(20)
         """
         )
-        child = testdir.spawn_pytest("")
+        child = pytester.spawn_pytest("")
         child.expect(".*test_runtest_location.*py")
         child.sendeof()
         child.kill(15)

-    def test_report_collect_after_half_a_second(self, testdir):
+    def test_report_collect_after_half_a_second(
+        self, pytester: Pytester, monkeypatch: MonkeyPatch
+    ) -> None:
         """Test for "collecting" being updated after 0.5s"""

-        testdir.makepyfile(
+        pytester.makepyfile(
             **{
                 "test1.py": """
                 import _pytest.terminal
@@ -163,9 +170,9 @@
             }
         )
         # Explicitly test colored output.
-        testdir.monkeypatch.setenv("PY_COLORS", "1")
-
-        child = testdir.spawn_pytest("-v test1.py test2.py")
+        monkeypatch.setenv("PY_COLORS", "1")
+
+        child = pytester.spawn_pytest("-v test1.py test2.py")
         child.expect(r"collecting \.\.\.")
         child.expect(r"collecting 1 item")
         child.expect(r"collecting 2 items")
@@ -173,8 +180,10 @@
         rest = child.read().decode("utf8")
         assert "= \x1b[32m\x1b[1m2 passed\x1b[0m\x1b[32m in" in rest

-    def test_itemreport_subclasses_show_subclassed_file(self, testdir):
-        testdir.makepyfile(
+    def test_itemreport_subclasses_show_subclassed_file(
+        self, pytester: Pytester
+    ) -> None:
+        pytester.makepyfile(
             **{
                 "tests/test_p1": """
             class BaseTests(object):
@@ -197,10 +206,10 @@
         """,
             }
         )
-        result = testdir.runpytest("tests/test_p2.py", "--rootdir=tests")
+        result = pytester.runpytest("tests/test_p2.py", "--rootdir=tests")
         result.stdout.fnmatch_lines(["tests/test_p2.py .*", "=* 1 passed in *"])

-        result = testdir.runpytest("-vv", "-rA", "tests/test_p2.py", "--rootdir=tests")
+        result = pytester.runpytest("-vv", "-rA", "tests/test_p2.py", "--rootdir=tests")
         result.stdout.fnmatch_lines(
             [
                 "tests/test_p2.py::TestMore::test_p1 <- test_p1.py PASSED *",
@@ -208,7 +217,7 @@
                 "PASSED tests/test_p2.py::TestMore::test_p1",
             ]
         )
-        result = testdir.runpytest("-vv", "-rA", "tests/test_p3.py", "--rootdir=tests")
+        result = pytester.runpytest("-vv", "-rA", "tests/test_p3.py", "--rootdir=tests")
         result.stdout.fnmatch_lines(
             [
                 "tests/test_p3.py::TestMore::test_p1 <- test_p1.py FAILED *",
@@ -224,9 +233,11 @@
             ]
         )

-    def test_itemreport_directclasses_not_shown_as_subclasses(self, testdir):
-        a = testdir.mkpydir("a123")
-        a.join("test_hello123.py").write(
+    def test_itemreport_directclasses_not_shown_as_subclasses(
+        self, pytester: Pytester
+    ) -> None:
+        a = pytester.mkpydir("a123")
+        a.joinpath("test_hello123.py").write_text(
             textwrap.dedent(
                 """\
                 class TestClass(object):
@@ -235,14 +246,14 @@
                 """
             )
         )
-        result = testdir.runpytest("-vv")
+        result = pytester.runpytest("-vv")
         assert result.ret == 0
         result.stdout.fnmatch_lines(["*a123/test_hello123.py*PASS*"])
         result.stdout.no_fnmatch_line("* <- *")

     @pytest.mark.parametrize("fulltrace", ("", "--fulltrace"))
-    def test_keyboard_interrupt(self, testdir, fulltrace):
-        testdir.makepyfile(
+    def test_keyboard_interrupt(self, pytester: Pytester, fulltrace) -> None:
+        pytester.makepyfile(
             """
             def test_foobar():
                 assert 0
@@ -253,7 +264,7 @@
         """
         )

-        result = testdir.runpytest(fulltrace, no_reraise_ctrlc=True)
+        result = pytester.runpytest(fulltrace, no_reraise_ctrlc=True)
         result.stdout.fnmatch_lines(
             [
                 "    def test_foobar():",
@@ -272,37 +283,37 @@
             )
         result.stdout.fnmatch_lines(["*KeyboardInterrupt*"])

-    def test_keyboard_in_sessionstart(self, testdir):
-        testdir.makeconftest(
+    def test_keyboard_in_sessionstart(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             def pytest_sessionstart():
                 raise KeyboardInterrupt
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_foobar():
                 pass
         """
         )

-        result = testdir.runpytest(no_reraise_ctrlc=True)
+        result = pytester.runpytest(no_reraise_ctrlc=True)
         assert result.ret == 2
         result.stdout.fnmatch_lines(["*KeyboardInterrupt*"])

-    def test_collect_single_item(self, testdir):
+    def test_collect_single_item(self, pytester: Pytester) -> None:
         """Use singular 'item' when reporting a single test item"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_foobar():
                 pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["collected 1 item"])

-    def test_rewrite(self, testdir, monkeypatch):
-        config = testdir.parseconfig()
+    def test_rewrite(self, pytester: Pytester, monkeypatch) -> None:
+        config = pytester.parseconfig()
         f = StringIO()
         monkeypatch.setattr(f, "isatty", lambda *args: True)
         tr = TerminalReporter(config, f)
@@ -312,57 +323,149 @@
         assert f.getvalue() == "hello" + "\r" + "hey" + (6 * " ")

     def test_report_teststatus_explicit_markup(
-        self, testdir: Testdir, color_mapping
+        self, monkeypatch: MonkeyPatch, pytester: Pytester, color_mapping
     ) -> None:
         """Test that TerminalReporter handles markup explicitly provided by
         a pytest_report_teststatus hook."""
-        testdir.monkeypatch.setenv("PY_COLORS", "1")
-        testdir.makeconftest(
+        monkeypatch.setenv("PY_COLORS", "1")
+        pytester.makeconftest(
             """
             def pytest_report_teststatus(report):
                 return 'foo', 'F', ('FOO', {'red': True})
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_foobar():
                 pass
         """
         )
-        result = testdir.runpytest("-v")
+        result = pytester.runpytest("-v")
         result.stdout.fnmatch_lines(
             color_mapping.format_for_fnmatch(["*{red}FOO{reset}*"])
         )

+    def test_verbose_skip_reason(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
+            """
+            import pytest
+
+            @pytest.mark.skip(reason="123")
+            def test_1():
+                pass
+
+            @pytest.mark.xfail(reason="456")
+            def test_2():
+                pass
+
+            @pytest.mark.xfail(reason="789")
+            def test_3():
+                assert False
+
+            @pytest.mark.xfail(reason="")
+            def test_4():
+                assert False
+
+            @pytest.mark.skip
+            def test_5():
+                pass
+
+            @pytest.mark.xfail
+            def test_6():
+                pass
+
+            def test_7():
+                pytest.skip()
+
+            def test_8():
+                pytest.skip("888 is great")
+
+            def test_9():
+                pytest.xfail()
+
+            def test_10():
+                pytest.xfail("It's 🕙 o'clock")
+
+            @pytest.mark.skip(
+                reason="cannot do foobar because baz is missing due to I don't know what"
+            )
+            def test_long_skip():
+                pass
+
+            @pytest.mark.xfail(
+                reason="cannot do foobar because baz is missing due to I don't know what"
+            )
+            def test_long_xfail():
+                print(1 / 0)
+        """
+        )
+
+        common_output = [
+            "test_verbose_skip_reason.py::test_1 SKIPPED (123) *",
+            "test_verbose_skip_reason.py::test_2 XPASS (456) *",
+            "test_verbose_skip_reason.py::test_3 XFAIL (789) *",
+            "test_verbose_skip_reason.py::test_4 XFAIL  *",
+            "test_verbose_skip_reason.py::test_5 SKIPPED (unconditional skip) *",
+            "test_verbose_skip_reason.py::test_6 XPASS  *",
+            "test_verbose_skip_reason.py::test_7 SKIPPED  *",
+            "test_verbose_skip_reason.py::test_8 SKIPPED (888 is great) *",
+            "test_verbose_skip_reason.py::test_9 XFAIL  *",
+            "test_verbose_skip_reason.py::test_10 XFAIL (It's 🕙 o'clock) *",
+        ]
+
+        result = pytester.runpytest("-v")
+        result.stdout.fnmatch_lines(
+            common_output
+            + [
+                "test_verbose_skip_reason.py::test_long_skip SKIPPED (cannot *...) *",
+                "test_verbose_skip_reason.py::test_long_xfail XFAIL (cannot *...) *",
+            ]
+        )
+
+        result = pytester.runpytest("-vv")
+        result.stdout.fnmatch_lines(
+            common_output
+            + [
+                (
+                    "test_verbose_skip_reason.py::test_long_skip SKIPPED"
+                    " (cannot do foobar because baz is missing due to I don't know what) *"
+                ),
+                (
+                    "test_verbose_skip_reason.py::test_long_xfail XFAIL"
+                    " (cannot do foobar because baz is missing due to I don't know what) *"
+                ),
+            ]
+        )
+

 class TestCollectonly:
-    def test_collectonly_basic(self, testdir):
-        testdir.makepyfile(
+    def test_collectonly_basic(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             def test_func():
                 pass
         """
         )
-        result = testdir.runpytest("--collect-only")
+        result = pytester.runpytest("--collect-only")
         result.stdout.fnmatch_lines(
             ["<Module test_collectonly_basic.py>", "  <Function test_func>"]
         )

-    def test_collectonly_skipped_module(self, testdir):
-        testdir.makepyfile(
+    def test_collectonly_skipped_module(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             pytest.skip("hello")
         """
         )
-        result = testdir.runpytest("--collect-only", "-rs")
+        result = pytester.runpytest("--collect-only", "-rs")
         result.stdout.fnmatch_lines(["*ERROR collecting*"])

     def test_collectonly_displays_test_description(
-        self, testdir: Testdir, dummy_yaml_custom_test
+        self, pytester: Pytester, dummy_yaml_custom_test
     ) -> None:
         """Used dummy_yaml_custom_test for an Item without ``obj``."""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_with_description():
                 '''  This test has a description.
@@ -371,7 +474,7 @@
                     more2.'''
             """
         )
-        result = testdir.runpytest("--collect-only", "--verbose")
+        result = pytester.runpytest("--collect-only", "--verbose")
         result.stdout.fnmatch_lines(
             [
                 "<YamlFile test1.yaml>",
@@ -386,24 +489,24 @@
             consecutive=True,
         )

-    def test_collectonly_failed_module(self, testdir):
-        testdir.makepyfile("""raise ValueError(0)""")
-        result = testdir.runpytest("--collect-only")
+    def test_collectonly_failed_module(self, pytester: Pytester) -> None:
+        pytester.makepyfile("""raise ValueError(0)""")
+        result = pytester.runpytest("--collect-only")
         result.stdout.fnmatch_lines(["*raise ValueError*", "*1 error*"])

-    def test_collectonly_fatal(self, testdir):
-        testdir.makeconftest(
+    def test_collectonly_fatal(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             def pytest_collectstart(collector):
                 assert 0, "urgs"
         """
         )
-        result = testdir.runpytest("--collect-only")
+        result = pytester.runpytest("--collect-only")
         result.stdout.fnmatch_lines(["*INTERNAL*args*"])
         assert result.ret == 3

-    def test_collectonly_simple(self, testdir):
-        p = testdir.makepyfile(
+    def test_collectonly_simple(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             def test_func1():
                 pass
@@ -412,7 +515,7 @@
                     pass
         """
         )
-        result = testdir.runpytest("--collect-only", p)
+        result = pytester.runpytest("--collect-only", p)
         # assert stderr.startswith("inserting into sys.path")
         assert result.ret == 0
         result.stdout.fnmatch_lines(
@@ -424,9 +527,9 @@
             ]
         )

-    def test_collectonly_error(self, testdir):
-        p = testdir.makepyfile("import Errlkjqweqwe")
-        result = testdir.runpytest("--collect-only", p)
+    def test_collectonly_error(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile("import Errlkjqweqwe")
+        result = pytester.runpytest("--collect-only", p)
         assert result.ret == 2
         result.stdout.fnmatch_lines(
             textwrap.dedent(
@@ -439,29 +542,71 @@
             ).strip()
         )

-    def test_collectonly_missing_path(self, testdir):
+    def test_collectonly_missing_path(self, pytester: Pytester) -> None:
         """Issue 115: failure in parseargs will cause session not to
         have the items attribute."""
-        result = testdir.runpytest("--collect-only", "uhm_missing_path")
+        result = pytester.runpytest("--collect-only", "uhm_missing_path")
         assert result.ret == 4
         result.stderr.fnmatch_lines(
             ["*ERROR: file or directory not found: uhm_missing_path"]
         )

-    def test_collectonly_quiet(self, testdir):
-        testdir.makepyfile("def test_foo(): pass")
-        result = testdir.runpytest("--collect-only", "-q")
+    def test_collectonly_quiet(self, pytester: Pytester) -> None:
+        pytester.makepyfile("def test_foo(): pass")
+        result = pytester.runpytest("--collect-only", "-q")
         result.stdout.fnmatch_lines(["*test_foo*"])

-    def test_collectonly_more_quiet(self, testdir):
-        testdir.makepyfile(test_fun="def test_foo(): pass")
-        result = testdir.runpytest("--collect-only", "-qq")
+    def test_collectonly_more_quiet(self, pytester: Pytester) -> None:
+        pytester.makepyfile(test_fun="def test_foo(): pass")
+        result = pytester.runpytest("--collect-only", "-qq")
         result.stdout.fnmatch_lines(["*test_fun.py: 1*"])

+    def test_collect_only_summary_status(self, pytester: Pytester) -> None:
+        """Custom status depending on test selection using -k or -m. #7701."""
+        pytester.makepyfile(
+            test_collect_foo="""
+            def test_foo(): pass
+            """,
+            test_collect_bar="""
+            def test_foobar(): pass
+            def test_bar(): pass
+            """,
+        )
+        result = pytester.runpytest("--collect-only")
+        result.stdout.fnmatch_lines("*== 3 tests collected in * ==*")
+
+        result = pytester.runpytest("--collect-only", "test_collect_foo.py")
+        result.stdout.fnmatch_lines("*== 1 test collected in * ==*")
+
+        result = pytester.runpytest("--collect-only", "-k", "foo")
+        result.stdout.fnmatch_lines("*== 2/3 tests collected (1 deselected) in * ==*")
+
+        result = pytester.runpytest("--collect-only", "-k", "test_bar")
+        result.stdout.fnmatch_lines("*== 1/3 tests collected (2 deselected) in * ==*")
+
+        result = pytester.runpytest("--collect-only", "-k", "invalid")
+        result.stdout.fnmatch_lines("*== no tests collected (3 deselected) in * ==*")
+
+        pytester.mkdir("no_tests_here")
+        result = pytester.runpytest("--collect-only", "no_tests_here")
+        result.stdout.fnmatch_lines("*== no tests collected in * ==*")
+
+        pytester.makepyfile(
+            test_contains_error="""
+            raise RuntimeError
+            """,
+        )
+        result = pytester.runpytest("--collect-only")
+        result.stdout.fnmatch_lines("*== 3 tests collected, 1 error in * ==*")
+        result = pytester.runpytest("--collect-only", "-k", "foo")
+        result.stdout.fnmatch_lines(
+            "*== 2/3 tests collected (1 deselected), 1 error in * ==*"
+        )
+

 class TestFixtureReporting:
-    def test_setup_fixture_error(self, testdir):
-        testdir.makepyfile(
+    def test_setup_fixture_error(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             def setup_function(function):
                 print("setup func")
@@ -470,7 +615,7 @@
                 pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             [
                 "*ERROR at setup of test_nada*",
@@ -482,8 +627,8 @@
         )
         assert result.ret != 0

-    def test_teardown_fixture_error(self, testdir):
-        testdir.makepyfile(
+    def test_teardown_fixture_error(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             def test_nada():
                 pass
@@ -492,7 +637,7 @@
                 assert 0
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             [
                 "*ERROR at teardown*",
@@ -504,8 +649,8 @@
             ]
         )

-    def test_teardown_fixture_error_and_test_failure(self, testdir):
-        testdir.makepyfile(
+    def test_teardown_fixture_error_and_test_failure(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             def test_fail():
                 assert 0, "failingfunc"
@@ -515,7 +660,7 @@
                 assert False
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             [
                 "*ERROR at teardown of test_fail*",
@@ -530,9 +675,9 @@
             ]
         )

-    def test_setup_teardown_output_and_test_failure(self, testdir):
+    def test_setup_teardown_output_and_test_failure(self, pytester: Pytester) -> None:
         """Test for issue #442."""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def setup_function(function):
                 print("setup func")
@@ -544,7 +689,7 @@
                 print("teardown func")
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             [
                 "*test_fail*",
@@ -560,8 +705,8 @@


 class TestTerminalFunctional:
-    def test_deselected(self, testdir):
-        testpath = testdir.makepyfile(
+    def test_deselected(self, pytester: Pytester) -> None:
+        testpath = pytester.makepyfile(
             """
                 def test_one():
                     pass
@@ -571,14 +716,14 @@
                     pass
            """
         )
-        result = testdir.runpytest("-k", "test_two:", testpath)
+        result = pytester.runpytest("-k", "test_t", testpath)
         result.stdout.fnmatch_lines(
             ["collected 3 items / 1 deselected / 2 selected", "*test_deselected.py ..*"]
         )
         assert result.ret == 0

-    def test_deselected_with_hookwrapper(self, testdir):
-        testpath = testdir.makeconftest(
+    def test_deselected_with_hookwrapper(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest

@@ -589,7 +734,7 @@
                 config.hook.pytest_deselected(items=[deselected])
             """
         )
-        testpath = testdir.makepyfile(
+        testpath = pytester.makepyfile(
             """
                 def test_one():
                     pass
@@ -599,7 +744,7 @@
                     pass
            """
         )
-        result = testdir.runpytest(testpath)
+        result = pytester.runpytest(testpath)
         result.stdout.fnmatch_lines(
             [
                 "collected 3 items / 1 deselected / 2 selected",
@@ -608,8 +753,10 @@
         )
         assert result.ret == 0

-    def test_show_deselected_items_using_markexpr_before_test_execution(self, testdir):
-        testdir.makepyfile(
+    def test_show_deselected_items_using_markexpr_before_test_execution(
+        self, pytester: Pytester
+    ) -> None:
+        pytester.makepyfile(
             test_show_deselected="""
             import pytest

@@ -625,7 +772,7 @@
                 pass
         """
         )
-        result = testdir.runpytest("-m", "not foo")
+        result = pytester.runpytest("-m", "not foo")
         result.stdout.fnmatch_lines(
             [
                 "collected 3 items / 1 deselected / 2 selected",
@@ -636,8 +783,35 @@
         result.stdout.no_fnmatch_line("*= 1 deselected =*")
         assert result.ret == 0

-    def test_no_skip_summary_if_failure(self, testdir):
-        testdir.makepyfile(
+    def test_selected_count_with_error(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
+            test_selected_count_3="""
+                def test_one():
+                    pass
+                def test_two():
+                    pass
+                def test_three():
+                    pass
+            """,
+            test_selected_count_error="""
+                5/0
+                def test_foo():
+                    pass
+                def test_bar():
+                    pass
+            """,
+        )
+        result = pytester.runpytest("-k", "test_t")
+        result.stdout.fnmatch_lines(
+            [
+                "collected 3 items / 1 error / 1 deselected / 2 selected",
+                "* ERROR collecting test_selected_count_error.py *",
+            ]
+        )
+        assert result.ret == ExitCode.INTERRUPTED
+
+    def test_no_skip_summary_if_failure(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             def test_ok():
@@ -648,12 +822,12 @@
                 pytest.skip("dontshow")
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.stdout.str().find("skip test summary") == -1
         assert result.ret == 1

-    def test_passes(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_passes(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             def test_passes():
                 pass
@@ -662,33 +836,35 @@
                     pass
         """
         )
-        old = p1.dirpath().chdir()
+        old = p1.parent
+        pytester.chdir()
         try:
-            result = testdir.runpytest()
+            result = pytester.runpytest()
         finally:
-            old.chdir()
+            os.chdir(old)
         result.stdout.fnmatch_lines(["test_passes.py ..*", "* 2 pass*"])
         assert result.ret == 0

-    def test_header_trailer_info(self, testdir, request):
-        testdir.monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD")
-        testdir.makepyfile(
+    def test_header_trailer_info(
+        self, monkeypatch: MonkeyPatch, pytester: Pytester, request
+    ) -> None:
+        monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD")
+        pytester.makepyfile(
             """
             def test_passes():
                 pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         verinfo = ".".join(map(str, sys.version_info[:3]))
         result.stdout.fnmatch_lines(
             [
                 "*===== test session starts ====*",
-                "platform %s -- Python %s*pytest-%s*py-%s*pluggy-%s"
+                "platform %s -- Python %s*pytest-%s**pluggy-%s"
                 % (
                     sys.platform,
                     verinfo,
                     pytest.__version__,
-                    py.__version__,
                     pluggy.__version__,
                 ),
                 "*test_header_trailer_info.py .*",
@@ -698,65 +874,66 @@
         if request.config.pluginmanager.list_plugin_distinfo():
             result.stdout.fnmatch_lines(["plugins: *"])

-    def test_no_header_trailer_info(self, testdir, request):
-        testdir.monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD")
-        testdir.makepyfile(
+    def test_no_header_trailer_info(
+        self, monkeypatch: MonkeyPatch, pytester: Pytester, request
+    ) -> None:
+        monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD")
+        pytester.makepyfile(
             """
             def test_passes():
                 pass
         """
         )
-        result = testdir.runpytest("--no-header")
+        result = pytester.runpytest("--no-header")
         verinfo = ".".join(map(str, sys.version_info[:3]))
         result.stdout.no_fnmatch_line(
-            "platform %s -- Python %s*pytest-%s*py-%s*pluggy-%s"
+            "platform %s -- Python %s*pytest-%s**pluggy-%s"
             % (
                 sys.platform,
                 verinfo,
                 pytest.__version__,
-                py.__version__,
                 pluggy.__version__,
             )
         )
         if request.config.pluginmanager.list_plugin_distinfo():
             result.stdout.no_fnmatch_line("plugins: *")

-    def test_header(self, testdir):
-        testdir.tmpdir.join("tests").ensure_dir()
-        testdir.tmpdir.join("gui").ensure_dir()
+    def test_header(self, pytester: Pytester) -> None:
+        pytester.path.joinpath("tests").mkdir()
+        pytester.path.joinpath("gui").mkdir()

         # no ini file
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["rootdir: *test_header0"])

         # with configfile
-        testdir.makeini("""[pytest]""")
-        result = testdir.runpytest()
+        pytester.makeini("""[pytest]""")
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["rootdir: *test_header0, configfile: tox.ini"])

         # with testpaths option, and not passing anything in the command-line
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
             testpaths = tests gui
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             ["rootdir: *test_header0, configfile: tox.ini, testpaths: tests, gui"]
         )

         # with testpaths option, passing directory in command-line: do not show testpaths then
-        result = testdir.runpytest("tests")
+        result = pytester.runpytest("tests")
         result.stdout.fnmatch_lines(["rootdir: *test_header0, configfile: tox.ini"])

     def test_header_absolute_testpath(
-        self, testdir: Testdir, monkeypatch: MonkeyPatch
+        self, pytester: Pytester, monkeypatch: MonkeyPatch
     ) -> None:
         """Regresstion test for #7814."""
-        tests = testdir.tmpdir.join("tests")
-        tests.ensure_dir()
-        testdir.makepyprojecttoml(
+        tests = pytester.path.joinpath("tests")
+        tests.mkdir()
+        pytester.makepyprojecttoml(
             """
             [tool.pytest.ini_options]
             testpaths = ['{}']
@@ -764,7 +941,7 @@
                 tests
             )
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             [
                 "rootdir: *absolute_testpath0, configfile: pyproject.toml, testpaths: {}".format(
@@ -773,38 +950,38 @@
             ]
         )

-    def test_no_header(self, testdir):
-        testdir.tmpdir.join("tests").ensure_dir()
-        testdir.tmpdir.join("gui").ensure_dir()
+    def test_no_header(self, pytester: Pytester) -> None:
+        pytester.path.joinpath("tests").mkdir()
+        pytester.path.joinpath("gui").mkdir()

         # with testpaths option, and not passing anything in the command-line
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
             testpaths = tests gui
         """
         )
-        result = testdir.runpytest("--no-header")
+        result = pytester.runpytest("--no-header")
         result.stdout.no_fnmatch_line(
             "rootdir: *test_header0, inifile: tox.ini, testpaths: tests, gui"
         )

         # with testpaths option, passing directory in command-line: do not show testpaths then
-        result = testdir.runpytest("tests", "--no-header")
+        result = pytester.runpytest("tests", "--no-header")
         result.stdout.no_fnmatch_line("rootdir: *test_header0, inifile: tox.ini")

-    def test_no_summary(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_no_summary(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             def test_no_summary():
                 assert false
         """
         )
-        result = testdir.runpytest(p1, "--no-summary")
+        result = pytester.runpytest(p1, "--no-summary")
         result.stdout.no_fnmatch_line("*= FAILURES =*")

-    def test_showlocals(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_showlocals(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             def test_showlocals():
                 x = 3
@@ -812,7 +989,7 @@
                 assert 0
         """
         )
-        result = testdir.runpytest(p1, "-l")
+        result = pytester.runpytest(p1, "-l")
         result.stdout.fnmatch_lines(
             [
                 # "_ _ * Locals *",
@@ -821,8 +998,8 @@
             ]
         )

-    def test_showlocals_short(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_showlocals_short(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             def test_showlocals_short():
                 x = 3
@@ -830,7 +1007,7 @@
                 assert 0
         """
         )
-        result = testdir.runpytest(p1, "-l", "--tb=short")
+        result = pytester.runpytest(p1, "-l", "--tb=short")
         result.stdout.fnmatch_lines(
             [
                 "test_showlocals_short.py:*",
@@ -842,8 +1019,8 @@
         )

     @pytest.fixture
-    def verbose_testfile(self, testdir):
-        return testdir.makepyfile(
+    def verbose_testfile(self, pytester: Pytester) -> Path:
+        return pytester.makepyfile(
             """
             import pytest
             def test_fail():
@@ -860,8 +1037,8 @@
         """
         )

-    def test_verbose_reporting(self, verbose_testfile, testdir):
-        result = testdir.runpytest(
+    def test_verbose_reporting(self, verbose_testfile, pytester: Pytester) -> None:
+        result = pytester.runpytest(
             verbose_testfile, "-v", "-Walways::pytest.PytestWarning"
         )
         result.stdout.fnmatch_lines(
@@ -874,12 +1051,18 @@
         )
         assert result.ret == 1

-    def test_verbose_reporting_xdist(self, verbose_testfile, testdir, pytestconfig):
+    def test_verbose_reporting_xdist(
+        self,
+        verbose_testfile,
+        monkeypatch: MonkeyPatch,
+        pytester: Pytester,
+        pytestconfig,
+    ) -> None:
         if not pytestconfig.pluginmanager.get_plugin("xdist"):
             pytest.skip("xdist plugin not installed")

-        testdir.monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD")
-        result = testdir.runpytest(
+        monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD")
+        result = pytester.runpytest(
             verbose_testfile, "-v", "-n 1", "-Walways::pytest.PytestWarning"
         )
         result.stdout.fnmatch_lines(
@@ -887,35 +1070,35 @@
         )
         assert result.ret == 1

-    def test_quiet_reporting(self, testdir):
-        p1 = testdir.makepyfile("def test_pass(): pass")
-        result = testdir.runpytest(p1, "-q")
+    def test_quiet_reporting(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile("def test_pass(): pass")
+        result = pytester.runpytest(p1, "-q")
         s = result.stdout.str()
         assert "test session starts" not in s
-        assert p1.basename not in s
+        assert p1.name not in s
         assert "===" not in s
         assert "passed" in s

-    def test_more_quiet_reporting(self, testdir):
-        p1 = testdir.makepyfile("def test_pass(): pass")
-        result = testdir.runpytest(p1, "-qq")
+    def test_more_quiet_reporting(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile("def test_pass(): pass")
+        result = pytester.runpytest(p1, "-qq")
         s = result.stdout.str()
         assert "test session starts" not in s
-        assert p1.basename not in s
+        assert p1.name not in s
         assert "===" not in s
         assert "passed" not in s

     @pytest.mark.parametrize(
         "params", [(), ("--collect-only",)], ids=["no-params", "collect-only"]
     )
-    def test_report_collectionfinish_hook(self, testdir, params):
-        testdir.makeconftest(
-            """
-            def pytest_report_collectionfinish(config, startdir, items):
-                return ['hello from hook: {0} items'.format(len(items))]
-        """
-        )
-        testdir.makepyfile(
+    def test_report_collectionfinish_hook(self, pytester: Pytester, params) -> None:
+        pytester.makeconftest(
+            """
+            def pytest_report_collectionfinish(config, start_path, items):
+                return [f'hello from hook: {len(items)} items']
+        """
+        )
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.parametrize('i', range(3))
@@ -923,25 +1106,25 @@
                 pass
         """
         )
-        result = testdir.runpytest(*params)
+        result = pytester.runpytest(*params)
         result.stdout.fnmatch_lines(["collected 3 items", "hello from hook: 3 items"])

-    def test_summary_f_alias(self, testdir):
+    def test_summary_f_alias(self, pytester: Pytester) -> None:
         """Test that 'f' and 'F' report chars are aliases and don't show up twice in the summary (#6334)"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test():
                 assert False
             """
         )
-        result = testdir.runpytest("-rfF")
+        result = pytester.runpytest("-rfF")
         expected = "FAILED test_summary_f_alias.py::test - assert False"
         result.stdout.fnmatch_lines([expected])
         assert result.stdout.lines.count(expected) == 1

-    def test_summary_s_alias(self, testdir):
+    def test_summary_s_alias(self, pytester: Pytester) -> None:
         """Test that 's' and 'S' report chars are aliases and don't show up twice in the summary"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -950,18 +1133,18 @@
                 pass
             """
         )
-        result = testdir.runpytest("-rsS")
+        result = pytester.runpytest("-rsS")
         expected = "SKIPPED [1] test_summary_s_alias.py:3: unconditional skip"
         result.stdout.fnmatch_lines([expected])
         assert result.stdout.lines.count(expected) == 1


-def test_fail_extra_reporting(testdir, monkeypatch):
+def test_fail_extra_reporting(pytester: Pytester, monkeypatch) -> None:
     monkeypatch.setenv("COLUMNS", "80")
-    testdir.makepyfile("def test_this(): assert 0, 'this_failed' * 100")
-    result = testdir.runpytest("-rN")
+    pytester.makepyfile("def test_this(): assert 0, 'this_failed' * 100")
+    result = pytester.runpytest("-rN")
     result.stdout.no_fnmatch_line("*short test summary*")
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         [
             "*test summary*",
@@ -970,28 +1153,28 @@
     )


-def test_fail_reporting_on_pass(testdir):
-    testdir.makepyfile("def test_this(): assert 1")
-    result = testdir.runpytest("-rf")
+def test_fail_reporting_on_pass(pytester: Pytester) -> None:
+    pytester.makepyfile("def test_this(): assert 1")
+    result = pytester.runpytest("-rf")
     result.stdout.no_fnmatch_line("*short test summary*")


-def test_pass_extra_reporting(testdir):
-    testdir.makepyfile("def test_this(): assert 1")
-    result = testdir.runpytest()
+def test_pass_extra_reporting(pytester: Pytester) -> None:
+    pytester.makepyfile("def test_this(): assert 1")
+    result = pytester.runpytest()
     result.stdout.no_fnmatch_line("*short test summary*")
-    result = testdir.runpytest("-rp")
+    result = pytester.runpytest("-rp")
     result.stdout.fnmatch_lines(["*test summary*", "PASS*test_pass_extra_reporting*"])


-def test_pass_reporting_on_fail(testdir):
-    testdir.makepyfile("def test_this(): assert 0")
-    result = testdir.runpytest("-rp")
+def test_pass_reporting_on_fail(pytester: Pytester) -> None:
+    pytester.makepyfile("def test_this(): assert 0")
+    result = pytester.runpytest("-rp")
     result.stdout.no_fnmatch_line("*short test summary*")


-def test_pass_output_reporting(testdir):
-    testdir.makepyfile(
+def test_pass_output_reporting(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         def setup_module():
             print("setup_module")
@@ -1006,12 +1189,12 @@
             pass
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     s = result.stdout.str()
     assert "test_pass_has_output" not in s
     assert "Four score and seven years ago..." not in s
     assert "test_pass_no_output" not in s
-    result = testdir.runpytest("-rPp")
+    result = pytester.runpytest("-rPp")
     result.stdout.fnmatch_lines(
         [
             "*= PASSES =*",
@@ -1030,8 +1213,8 @@
     )


-def test_color_yes(testdir, color_mapping):
-    p1 = testdir.makepyfile(
+def test_color_yes(pytester: Pytester, color_mapping) -> None:
+    p1 = pytester.makepyfile(
         """
         def fail():
             assert 0
@@ -1040,8 +1223,7 @@
             fail()
         """
     )
-    result = testdir.runpytest("--color=yes", str(p1))
-    color_mapping.requires_ordered_markup(result)
+    result = pytester.runpytest("--color=yes", str(p1))
     result.stdout.fnmatch_lines(
         color_mapping.format_for_fnmatch(
             [
@@ -1068,7 +1250,7 @@
             ]
         )
     )
-    result = testdir.runpytest("--color=yes", "--tb=short", str(p1))
+    result = pytester.runpytest("--color=yes", "--tb=short", str(p1))
     result.stdout.fnmatch_lines(
         color_mapping.format_for_fnmatch(
             [
@@ -1090,17 +1272,17 @@
     )


-def test_color_no(testdir):
-    testdir.makepyfile("def test_this(): assert 1")
-    result = testdir.runpytest("--color=no")
+def test_color_no(pytester: Pytester) -> None:
+    pytester.makepyfile("def test_this(): assert 1")
+    result = pytester.runpytest("--color=no")
     assert "test session starts" in result.stdout.str()
     result.stdout.no_fnmatch_line("*\x1b[1m*")


 @pytest.mark.parametrize("verbose", [True, False])
-def test_color_yes_collection_on_non_atty(testdir, verbose):
+def test_color_yes_collection_on_non_atty(pytester: Pytester, verbose) -> None:
     """#1397: Skip collect progress report when working on non-terminals."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         @pytest.mark.parametrize('i', range(10))
@@ -1111,7 +1293,7 @@
     args = ["--color=yes"]
     if verbose:
         args.append("-vv")
-    result = testdir.runpytest(*args)
+    result = pytester.runpytest(*args)
     assert "test session starts" in result.stdout.str()
     assert "\x1b[1m" in result.stdout.str()
     result.stdout.no_fnmatch_line("*collecting 10 items*")
@@ -1179,9 +1361,9 @@
     assert getreportopt(config) == "fE"


-def test_terminalreporter_reportopt_addopts(testdir):
-    testdir.makeini("[pytest]\naddopts=-rs")
-    testdir.makepyfile(
+def test_terminalreporter_reportopt_addopts(pytester: Pytester) -> None:
+    pytester.makeini("[pytest]\naddopts=-rs")
+    pytester.makepyfile(
         """
         import pytest

@@ -1194,12 +1376,12 @@
             assert not tr.hasopt('qwe')
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*1 passed*"])


-def test_tbstyle_short(testdir):
-    p = testdir.makepyfile(
+def test_tbstyle_short(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
         """
         import pytest

@@ -1211,19 +1393,19 @@
             assert x
     """
     )
-    result = testdir.runpytest("--tb=short")
+    result = pytester.runpytest("--tb=short")
     s = result.stdout.str()
     assert "arg = 42" not in s
     assert "x = 0" not in s
-    result.stdout.fnmatch_lines(["*%s:8*" % p.basename, "    assert x", "E   assert*"])
-    result = testdir.runpytest()
+    result.stdout.fnmatch_lines(["*%s:8*" % p.name, "    assert x", "E   assert*"])
+    result = pytester.runpytest()
     s = result.stdout.str()
     assert "x = 0" in s
     assert "assert x" in s


-def test_traceconfig(testdir):
-    result = testdir.runpytest("--traceconfig")
+def test_traceconfig(pytester: Pytester) -> None:
+    result = pytester.runpytest("--traceconfig")
     result.stdout.fnmatch_lines(["*active plugins*"])
     assert result.ret == ExitCode.NO_TESTS_COLLECTED

@@ -1232,15 +1414,15 @@
     """Test class which can be subclassed with a different option provider to
     run e.g. distributed tests."""

-    def test_collect_fail(self, testdir, option):
-        testdir.makepyfile("import xyz\n")
-        result = testdir.runpytest(*option.args)
+    def test_collect_fail(self, pytester: Pytester, option) -> None:
+        pytester.makepyfile("import xyz\n")
+        result = pytester.runpytest(*option.args)
         result.stdout.fnmatch_lines(
             ["ImportError while importing*", "*No module named *xyz*", "*1 error*"]
         )

-    def test_maxfailures(self, testdir, option):
-        testdir.makepyfile(
+    def test_maxfailures(self, pytester: Pytester, option) -> None:
+        pytester.makepyfile(
             """
             def test_1():
                 assert 0
@@ -1250,7 +1432,7 @@
                 assert 0
         """
         )
-        result = testdir.runpytest("--maxfail=2", *option.args)
+        result = pytester.runpytest("--maxfail=2", *option.args)
         result.stdout.fnmatch_lines(
             [
                 "*def test_1():*",
@@ -1260,15 +1442,15 @@
             ]
         )

-    def test_maxfailures_with_interrupted(self, testdir):
-        testdir.makepyfile(
+    def test_maxfailures_with_interrupted(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             def test(request):
                 request.session.shouldstop = "session_interrupted"
                 assert 0
         """
         )
-        result = testdir.runpytest("--maxfail=1", "-ra")
+        result = pytester.runpytest("--maxfail=1", "-ra")
         result.stdout.fnmatch_lines(
             [
                 "*= short test summary info =*",
@@ -1279,8 +1461,8 @@
             ]
         )

-    def test_tb_option(self, testdir, option):
-        testdir.makepyfile(
+    def test_tb_option(self, pytester: Pytester, option) -> None:
+        pytester.makepyfile(
             """
             import pytest
             def g():
@@ -1292,7 +1474,7 @@
         )
         for tbopt in ["long", "short", "no"]:
             print("testing --tb=%s..." % tbopt)
-            result = testdir.runpytest("-rN", "--tb=%s" % tbopt)
+            result = pytester.runpytest("-rN", "--tb=%s" % tbopt)
             s = result.stdout.str()
             if tbopt == "long":
                 assert "print(6*7)" in s
@@ -1306,8 +1488,8 @@
                 assert "--calling--" not in s
                 assert "IndexError" not in s

-    def test_tb_crashline(self, testdir, option):
-        p = testdir.makepyfile(
+    def test_tb_crashline(self, pytester: Pytester, option) -> None:
+        p = pytester.makepyfile(
             """
             import pytest
             def g():
@@ -1319,16 +1501,16 @@
                 assert 0, "hello"
         """
         )
-        result = testdir.runpytest("--tb=line")
-        bn = p.basename
+        result = pytester.runpytest("--tb=line")
+        bn = p.name
         result.stdout.fnmatch_lines(
             ["*%s:3: IndexError*" % bn, "*%s:8: AssertionError: hello*" % bn]
         )
         s = result.stdout.str()
         assert "def test_func2" not in s

-    def test_pytest_report_header(self, testdir, option):
-        testdir.makeconftest(
+    def test_pytest_report_header(self, pytester: Pytester, option) -> None:
+        pytester.makeconftest(
             """
             def pytest_sessionstart(session):
                 session.config._somevalue = 42
@@ -1336,17 +1518,17 @@
                 return "hello: %s" % config._somevalue
         """
         )
-        testdir.mkdir("a").join("conftest.py").write(
-            """
-def pytest_report_header(config, startdir):
-    return ["line1", str(startdir)]
+        pytester.mkdir("a").joinpath("conftest.py").write_text(
+            """
+def pytest_report_header(config, start_path):
+    return ["line1", str(start_path)]
 """
         )
-        result = testdir.runpytest("a")
-        result.stdout.fnmatch_lines(["*hello: 42*", "line1", str(testdir.tmpdir)])
-
-    def test_show_capture(self, testdir):
-        testdir.makepyfile(
+        result = pytester.runpytest("a")
+        result.stdout.fnmatch_lines(["*hello: 42*", "line1", str(pytester.path)])
+
+    def test_show_capture(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import sys
             import logging
@@ -1358,7 +1540,7 @@
         """
         )

-        result = testdir.runpytest("--tb=short")
+        result = pytester.runpytest("--tb=short")
         result.stdout.fnmatch_lines(
             [
                 "!This is stdout!",
@@ -1367,7 +1549,7 @@
             ]
         )

-        result = testdir.runpytest("--show-capture=all", "--tb=short")
+        result = pytester.runpytest("--show-capture=all", "--tb=short")
         result.stdout.fnmatch_lines(
             [
                 "!This is stdout!",
@@ -1376,29 +1558,29 @@
             ]
         )

-        stdout = testdir.runpytest("--show-capture=stdout", "--tb=short").stdout.str()
+        stdout = pytester.runpytest("--show-capture=stdout", "--tb=short").stdout.str()
         assert "!This is stderr!" not in stdout
         assert "!This is stdout!" in stdout
         assert "!This is a warning log msg!" not in stdout

-        stdout = testdir.runpytest("--show-capture=stderr", "--tb=short").stdout.str()
+        stdout = pytester.runpytest("--show-capture=stderr", "--tb=short").stdout.str()
         assert "!This is stdout!" not in stdout
         assert "!This is stderr!" in stdout
         assert "!This is a warning log msg!" not in stdout

-        stdout = testdir.runpytest("--show-capture=log", "--tb=short").stdout.str()
+        stdout = pytester.runpytest("--show-capture=log", "--tb=short").stdout.str()
         assert "!This is stdout!" not in stdout
         assert "!This is stderr!" not in stdout
         assert "!This is a warning log msg!" in stdout

-        stdout = testdir.runpytest("--show-capture=no", "--tb=short").stdout.str()
+        stdout = pytester.runpytest("--show-capture=no", "--tb=short").stdout.str()
         assert "!This is stdout!" not in stdout
         assert "!This is stderr!" not in stdout
         assert "!This is a warning log msg!" not in stdout

-    def test_show_capture_with_teardown_logs(self, testdir):
+    def test_show_capture_with_teardown_logs(self, pytester: Pytester) -> None:
         """Ensure that the capturing of teardown logs honor --show-capture setting"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import logging
             import sys
@@ -1416,30 +1598,30 @@
         """
         )

-        result = testdir.runpytest("--show-capture=stdout", "--tb=short").stdout.str()
+        result = pytester.runpytest("--show-capture=stdout", "--tb=short").stdout.str()
         assert "!stdout!" in result
         assert "!stderr!" not in result
         assert "!log!" not in result

-        result = testdir.runpytest("--show-capture=stderr", "--tb=short").stdout.str()
+        result = pytester.runpytest("--show-capture=stderr", "--tb=short").stdout.str()
         assert "!stdout!" not in result
         assert "!stderr!" in result
         assert "!log!" not in result

-        result = testdir.runpytest("--show-capture=log", "--tb=short").stdout.str()
+        result = pytester.runpytest("--show-capture=log", "--tb=short").stdout.str()
         assert "!stdout!" not in result
         assert "!stderr!" not in result
         assert "!log!" in result

-        result = testdir.runpytest("--show-capture=no", "--tb=short").stdout.str()
+        result = pytester.runpytest("--show-capture=no", "--tb=short").stdout.str()
         assert "!stdout!" not in result
         assert "!stderr!" not in result
         assert "!log!" not in result


 @pytest.mark.xfail("not hasattr(os, 'dup')")
-def test_fdopen_kept_alive_issue124(testdir):
-    testdir.makepyfile(
+def test_fdopen_kept_alive_issue124(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import os, sys
         k = []
@@ -1452,12 +1634,12 @@
             stdout.close()
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*2 passed*"])


-def test_tbstyle_native_setup_error(testdir):
-    testdir.makepyfile(
+def test_tbstyle_native_setup_error(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import pytest
         @pytest.fixture
@@ -1468,14 +1650,14 @@
             pass
     """
     )
-    result = testdir.runpytest("--tb=native")
+    result = pytester.runpytest("--tb=native")
     result.stdout.fnmatch_lines(
         ['*File *test_tbstyle_native_setup_error.py", line *, in setup_error_fixture*']
     )


-def test_terminal_summary(testdir):
-    testdir.makeconftest(
+def test_terminal_summary(pytester: Pytester) -> None:
+    pytester.makeconftest(
         """
         def pytest_terminal_summary(terminalreporter, exitstatus):
             w = terminalreporter
@@ -1484,7 +1666,7 @@
             w.line("exitstatus: {0}".format(exitstatus))
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         """
         *==== hello ====*
@@ -1494,19 +1676,19 @@
     )


-@pytest.mark.filterwarnings("default")
-def test_terminal_summary_warnings_are_displayed(testdir):
+@pytest.mark.filterwarnings("default::UserWarning")
+def test_terminal_summary_warnings_are_displayed(pytester: Pytester) -> None:
     """Test that warnings emitted during pytest_terminal_summary are displayed.
     (#1305).
     """
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         import warnings
         def pytest_terminal_summary(terminalreporter):
             warnings.warn(UserWarning('internal warning'))
     """
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         def test_failure():
             import warnings
@@ -1514,7 +1696,7 @@
             assert 0
     """
     )
-    result = testdir.runpytest("-ra")
+    result = pytester.runpytest("-ra")
     result.stdout.fnmatch_lines(
         [
             "*= warnings summary =*",
@@ -1531,9 +1713,9 @@
     assert stdout.count("=== warnings summary ") == 2


-@pytest.mark.filterwarnings("default")
-def test_terminal_summary_warnings_header_once(testdir):
-    testdir.makepyfile(
+@pytest.mark.filterwarnings("default::UserWarning")
+def test_terminal_summary_warnings_header_once(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         def test_failure():
             import warnings
@@ -1541,7 +1723,7 @@
             assert 0
     """
     )
-    result = testdir.runpytest("-ra")
+    result = pytester.runpytest("-ra")
     result.stdout.fnmatch_lines(
         [
             "*= warnings summary =*",
@@ -1557,8 +1739,8 @@


 @pytest.mark.filterwarnings("default")
-def test_terminal_no_summary_warnings_header_once(testdir):
-    testdir.makepyfile(
+def test_terminal_no_summary_warnings_header_once(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         def test_failure():
             import warnings
@@ -1566,7 +1748,7 @@
             assert 0
     """
     )
-    result = testdir.runpytest("--no-summary")
+    result = pytester.runpytest("--no-summary")
     result.stdout.no_fnmatch_line("*= warnings summary =*")
     result.stdout.no_fnmatch_line("*= short test summary info =*")

@@ -1726,9 +1908,9 @@
     tr._main_color = None

     print("Based on stats: %s" % stats_arg)
-    print('Expect summary: "{}"; with color "{}"'.format(exp_line, exp_color))
+    print(f'Expect summary: "{exp_line}"; with color "{exp_color}"')
     (line, color) = tr.build_summary_stats_line()
-    print('Actually got:   "{}"; with color "{}"'.format(line, color))
+    print(f'Actually got:   "{line}"; with color "{color}"')
     assert line == exp_line
     assert color == exp_color

@@ -1755,8 +1937,8 @@
     """Ensure classic output style works as expected (#3883)"""

     @pytest.fixture
-    def test_files(self, testdir):
-        testdir.makepyfile(
+    def test_files(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             **{
                 "test_one.py": "def test_one(): pass",
                 "test_two.py": "def test_two(): assert 0",
@@ -1768,39 +1950,39 @@
             }
         )

-    def test_normal_verbosity(self, testdir, test_files):
-        result = testdir.runpytest("-o", "console_output_style=classic")
+    def test_normal_verbosity(self, pytester: Pytester, test_files) -> None:
+        result = pytester.runpytest("-o", "console_output_style=classic")
         result.stdout.fnmatch_lines(
             [
                 "test_one.py .",
                 "test_two.py F",
-                "sub{}test_three.py .F.".format(os.sep),
+                f"sub{os.sep}test_three.py .F.",
                 "*2 failed, 3 passed in*",
             ]
         )

-    def test_verbose(self, testdir, test_files):
-        result = testdir.runpytest("-o", "console_output_style=classic", "-v")
+    def test_verbose(self, pytester: Pytester, test_files) -> None:
+        result = pytester.runpytest("-o", "console_output_style=classic", "-v")
         result.stdout.fnmatch_lines(
             [
                 "test_one.py::test_one PASSED",
                 "test_two.py::test_two FAILED",
-                "sub{}test_three.py::test_three_1 PASSED".format(os.sep),
-                "sub{}test_three.py::test_three_2 FAILED".format(os.sep),
-                "sub{}test_three.py::test_three_3 PASSED".format(os.sep),
+                f"sub{os.sep}test_three.py::test_three_1 PASSED",
+                f"sub{os.sep}test_three.py::test_three_2 FAILED",
+                f"sub{os.sep}test_three.py::test_three_3 PASSED",
                 "*2 failed, 3 passed in*",
             ]
         )

-    def test_quiet(self, testdir, test_files):
-        result = testdir.runpytest("-o", "console_output_style=classic", "-q")
+    def test_quiet(self, pytester: Pytester, test_files) -> None:
+        result = pytester.runpytest("-o", "console_output_style=classic", "-q")
         result.stdout.fnmatch_lines([".F.F.", "*2 failed, 3 passed in*"])


 class TestProgressOutputStyle:
     @pytest.fixture
-    def many_tests_files(self, testdir):
-        testdir.makepyfile(
+    def many_tests_files(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             test_bar="""
                 import pytest
                 @pytest.mark.parametrize('i', range(10))
@@ -1818,10 +2000,10 @@
             """,
         )

-    def test_zero_tests_collected(self, testdir):
+    def test_zero_tests_collected(self, pytester: Pytester) -> None:
         """Some plugins (testmon for example) might issue pytest_runtest_logreport without any tests being
         actually collected (#2971)."""
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
         def pytest_collection_modifyitems(items, config):
             from _pytest.runner import CollectReport
@@ -1832,12 +2014,12 @@
                 config.hook.pytest_runtest_logreport(report=rep)
         """
         )
-        output = testdir.runpytest()
+        output = pytester.runpytest()
         output.stdout.no_fnmatch_line("*ZeroDivisionError*")
         output.stdout.fnmatch_lines(["=* 2 passed in *="])

-    def test_normal(self, many_tests_files, testdir):
-        output = testdir.runpytest()
+    def test_normal(self, many_tests_files, pytester: Pytester) -> None:
+        output = pytester.runpytest()
         output.stdout.re_match_lines(
             [
                 r"test_bar.py \.{10} \s+ \[ 50%\]",
@@ -1846,9 +2028,11 @@
             ]
         )

-    def test_colored_progress(self, testdir, monkeypatch, color_mapping):
+    def test_colored_progress(
+        self, pytester: Pytester, monkeypatch, color_mapping
+    ) -> None:
         monkeypatch.setenv("PY_COLORS", "1")
-        testdir.makepyfile(
+        pytester.makepyfile(
             test_axfail="""
                 import pytest
                 @pytest.mark.xfail
@@ -1873,7 +2057,7 @@
                 def test_foobar(i): raise ValueError()
             """,
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.re_match_lines(
             color_mapping.format_for_rematch(
                 [
@@ -1886,7 +2070,7 @@
         )

         # Only xfail should have yellow progress indicator.
-        result = testdir.runpytest("test_axfail.py")
+        result = pytester.runpytest("test_axfail.py")
         result.stdout.re_match_lines(
             color_mapping.format_for_rematch(
                 [
@@ -1896,14 +2080,14 @@
             )
         )

-    def test_count(self, many_tests_files, testdir):
-        testdir.makeini(
+    def test_count(self, many_tests_files, pytester: Pytester) -> None:
+        pytester.makeini(
             """
             [pytest]
             console_output_style = count
         """
         )
-        output = testdir.runpytest()
+        output = pytester.runpytest()
         output.stdout.re_match_lines(
             [
                 r"test_bar.py \.{10} \s+ \[10/20\]",
@@ -1912,8 +2096,8 @@
             ]
         )

-    def test_verbose(self, many_tests_files, testdir):
-        output = testdir.runpytest("-v")
+    def test_verbose(self, many_tests_files, pytester: Pytester) -> None:
+        output = pytester.runpytest("-v")
         output.stdout.re_match_lines(
             [
                 r"test_bar.py::test_bar\[0\] PASSED \s+ \[  5%\]",
@@ -1922,14 +2106,14 @@
             ]
         )

-    def test_verbose_count(self, many_tests_files, testdir):
-        testdir.makeini(
+    def test_verbose_count(self, many_tests_files, pytester: Pytester) -> None:
+        pytester.makeini(
             """
             [pytest]
             console_output_style = count
         """
         )
-        output = testdir.runpytest("-v")
+        output = pytester.runpytest("-v")
         output.stdout.re_match_lines(
             [
                 r"test_bar.py::test_bar\[0\] PASSED \s+ \[ 1/20\]",
@@ -1938,28 +2122,34 @@
             ]
         )

-    def test_xdist_normal(self, many_tests_files, testdir, monkeypatch):
+    def test_xdist_normal(
+        self, many_tests_files, pytester: Pytester, monkeypatch
+    ) -> None:
         pytest.importorskip("xdist")
         monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", raising=False)
-        output = testdir.runpytest("-n2")
+        output = pytester.runpytest("-n2")
         output.stdout.re_match_lines([r"\.{20} \s+ \[100%\]"])

-    def test_xdist_normal_count(self, many_tests_files, testdir, monkeypatch):
+    def test_xdist_normal_count(
+        self, many_tests_files, pytester: Pytester, monkeypatch
+    ) -> None:
         pytest.importorskip("xdist")
         monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", raising=False)
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
             console_output_style = count
         """
         )
-        output = testdir.runpytest("-n2")
+        output = pytester.runpytest("-n2")
         output.stdout.re_match_lines([r"\.{20} \s+ \[20/20\]"])

-    def test_xdist_verbose(self, many_tests_files, testdir, monkeypatch):
+    def test_xdist_verbose(
+        self, many_tests_files, pytester: Pytester, monkeypatch
+    ) -> None:
         pytest.importorskip("xdist")
         monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", raising=False)
-        output = testdir.runpytest("-n2", "-v")
+        output = pytester.runpytest("-n2", "-v")
         output.stdout.re_match_lines_random(
             [
                 r"\[gw\d\] \[\s*\d+%\] PASSED test_bar.py::test_bar\[1\]",
@@ -1984,13 +2174,13 @@
             ]
         )

-    def test_capture_no(self, many_tests_files, testdir):
-        output = testdir.runpytest("-s")
+    def test_capture_no(self, many_tests_files, pytester: Pytester) -> None:
+        output = pytester.runpytest("-s")
         output.stdout.re_match_lines(
             [r"test_bar.py \.{10}", r"test_foo.py \.{5}", r"test_foobar.py \.{5}"]
         )

-        output = testdir.runpytest("--capture=no")
+        output = pytester.runpytest("--capture=no")
         output.stdout.no_fnmatch_line("*%]*")


@@ -1998,8 +2188,8 @@
     """Ensure we show the correct percentages for tests that fail during teardown (#3088)"""

     @pytest.fixture
-    def contest_with_teardown_fixture(self, testdir):
-        testdir.makeconftest(
+    def contest_with_teardown_fixture(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest

@@ -2011,8 +2201,8 @@
         )

     @pytest.fixture
-    def many_files(self, testdir, contest_with_teardown_fixture):
-        testdir.makepyfile(
+    def many_files(self, pytester: Pytester, contest_with_teardown_fixture) -> None:
+        pytester.makepyfile(
             test_bar="""
                 import pytest
                 @pytest.mark.parametrize('i', range(5))
@@ -2027,26 +2217,28 @@
             """,
         )

-    def test_teardown_simple(self, testdir, contest_with_teardown_fixture):
-        testdir.makepyfile(
+    def test_teardown_simple(
+        self, pytester: Pytester, contest_with_teardown_fixture
+    ) -> None:
+        pytester.makepyfile(
             """
             def test_foo(fail_teardown):
                 pass
         """
         )
-        output = testdir.runpytest()
+        output = pytester.runpytest()
         output.stdout.re_match_lines([r"test_teardown_simple.py \.E\s+\[100%\]"])

     def test_teardown_with_test_also_failing(
-        self, testdir, contest_with_teardown_fixture
-    ):
-        testdir.makepyfile(
+        self, pytester: Pytester, contest_with_teardown_fixture
+    ) -> None:
+        pytester.makepyfile(
             """
             def test_foo(fail_teardown):
                 assert 0
         """
         )
-        output = testdir.runpytest("-rfE")
+        output = pytester.runpytest("-rfE")
         output.stdout.re_match_lines(
             [
                 r"test_teardown_with_test_also_failing.py FE\s+\[100%\]",
@@ -2055,16 +2247,16 @@
             ]
         )

-    def test_teardown_many(self, testdir, many_files):
-        output = testdir.runpytest()
+    def test_teardown_many(self, pytester: Pytester, many_files) -> None:
+        output = pytester.runpytest()
         output.stdout.re_match_lines(
             [r"test_bar.py (\.E){5}\s+\[ 25%\]", r"test_foo.py (\.E){15}\s+\[100%\]"]
         )

     def test_teardown_many_verbose(
-        self, testdir: Testdir, many_files, color_mapping
+        self, pytester: Pytester, many_files, color_mapping
     ) -> None:
-        result = testdir.runpytest("-v")
+        result = pytester.runpytest("-v")
         result.stdout.fnmatch_lines(
             color_mapping.format_for_fnmatch(
                 [
@@ -2078,10 +2270,10 @@
             )
         )

-    def test_xdist_normal(self, many_files, testdir, monkeypatch):
+    def test_xdist_normal(self, many_files, pytester: Pytester, monkeypatch) -> None:
         pytest.importorskip("xdist")
         monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", raising=False)
-        output = testdir.runpytest("-n2")
+        output = pytester.runpytest("-n2")
         output.stdout.re_match_lines([r"[\.E]{40} \s+ \[100%\]"])


@@ -2096,19 +2288,19 @@

     ev1 = cast(CollectReport, X())
     ev1.when = "execute"
-    ev1.skipped = True
+    ev1.skipped = True  # type: ignore[misc]
     ev1.longrepr = longrepr

     ev2 = cast(CollectReport, X())
     ev2.when = "execute"
     ev2.longrepr = longrepr
-    ev2.skipped = True
+    ev2.skipped = True  # type: ignore[misc]

     # ev3 might be a collection report
     ev3 = cast(CollectReport, X())
     ev3.when = "collect"
     ev3.longrepr = longrepr
-    ev3.skipped = True
+    ev3.skipped = True  # type: ignore[misc]

     values = _folded_skips(Path.cwd(), [ev1, ev2, ev3])
     assert len(values) == 1
@@ -2119,7 +2311,7 @@
     assert reason == message


-def test_line_with_reprcrash(monkeypatch):
+def test_line_with_reprcrash(monkeypatch: MonkeyPatch) -> None:
     mocked_verbose_word = "FAILED"

     mocked_pos = "some::nodeid"
@@ -2147,7 +2339,7 @@
         actual = _get_line_with_reprcrash_message(config, rep(), width)  # type: ignore

         assert actual == expected
-        if actual != "{} {}".format(mocked_verbose_word, mocked_pos):
+        if actual != f"{mocked_verbose_word} {mocked_pos}":
             assert len(actual) <= width
             assert wcswidth(actual) <= width

@@ -2201,9 +2393,9 @@
     assert format_session_duration(seconds) == expected


-def test_collecterror(testdir):
-    p1 = testdir.makepyfile("raise SyntaxError()")
-    result = testdir.runpytest("-ra", str(p1))
+def test_collecterror(pytester: Pytester) -> None:
+    p1 = pytester.makepyfile("raise SyntaxError()")
+    result = pytester.runpytest("-ra", str(p1))
     result.stdout.fnmatch_lines(
         [
             "collected 0 items / 1 error",
@@ -2218,30 +2410,29 @@
     )


-def test_no_summary_collecterror(testdir):
-    p1 = testdir.makepyfile("raise SyntaxError()")
-    result = testdir.runpytest("-ra", "--no-summary", str(p1))
+def test_no_summary_collecterror(pytester: Pytester) -> None:
+    p1 = pytester.makepyfile("raise SyntaxError()")
+    result = pytester.runpytest("-ra", "--no-summary", str(p1))
     result.stdout.no_fnmatch_line("*= ERRORS =*")


-def test_via_exec(testdir: Testdir) -> None:
-    p1 = testdir.makepyfile("exec('def test_via_exec(): pass')")
-    result = testdir.runpytest(str(p1), "-vv")
+def test_via_exec(pytester: Pytester) -> None:
+    p1 = pytester.makepyfile("exec('def test_via_exec(): pass')")
+    result = pytester.runpytest(str(p1), "-vv")
     result.stdout.fnmatch_lines(
         ["test_via_exec.py::test_via_exec <- <string> PASSED*", "*= 1 passed in *"]
     )


 class TestCodeHighlight:
-    def test_code_highlight_simple(self, testdir: Testdir, color_mapping) -> None:
-        testdir.makepyfile(
+    def test_code_highlight_simple(self, pytester: Pytester, color_mapping) -> None:
+        pytester.makepyfile(
             """
             def test_foo():
                 assert 1 == 10
         """
         )
-        result = testdir.runpytest("--color=yes")
-        color_mapping.requires_ordered_markup(result)
+        result = pytester.runpytest("--color=yes")
         result.stdout.fnmatch_lines(
             color_mapping.format_for_fnmatch(
                 [
@@ -2252,16 +2443,17 @@
             )
         )

-    def test_code_highlight_continuation(self, testdir: Testdir, color_mapping) -> None:
-        testdir.makepyfile(
+    def test_code_highlight_continuation(
+        self, pytester: Pytester, color_mapping
+    ) -> None:
+        pytester.makepyfile(
             """
             def test_foo():
                 print('''
                 '''); assert 0
         """
         )
-        result = testdir.runpytest("--color=yes")
-        color_mapping.requires_ordered_markup(result)
+        result = pytester.runpytest("--color=yes")

         result.stdout.fnmatch_lines(
             color_mapping.format_for_fnmatch(
@@ -2273,3 +2465,81 @@
                 ]
             )
         )
+
+    def test_code_highlight_custom_theme(
+        self, pytester: Pytester, color_mapping, monkeypatch: MonkeyPatch
+    ) -> None:
+        pytester.makepyfile(
+            """
+            def test_foo():
+                assert 1 == 10
+        """
+        )
+        monkeypatch.setenv("PYTEST_THEME", "solarized-dark")
+        monkeypatch.setenv("PYTEST_THEME_MODE", "dark")
+        result = pytester.runpytest("--color=yes")
+        result.stdout.fnmatch_lines(
+            color_mapping.format_for_fnmatch(
+                [
+                    "    {kw}def{hl-reset} {function}test_foo{hl-reset}():",
+                    ">       {kw}assert{hl-reset} {number}1{hl-reset} == {number}10{hl-reset}",
+                    "{bold}{red}E       assert 1 == 10{reset}",
+                ]
+            )
+        )
+
+    def test_code_highlight_invalid_theme(
+        self, pytester: Pytester, color_mapping, monkeypatch: MonkeyPatch
+    ) -> None:
+        pytester.makepyfile(
+            """
+            def test_foo():
+                assert 1 == 10
+        """
+        )
+        monkeypatch.setenv("PYTEST_THEME", "invalid")
+        result = pytester.runpytest_subprocess("--color=yes")
+        result.stderr.fnmatch_lines(
+            "ERROR: PYTEST_THEME environment variable had an invalid value: 'invalid'. "
+            "Only valid pygment styles are allowed."
+        )
+
+    def test_code_highlight_invalid_theme_mode(
+        self, pytester: Pytester, color_mapping, monkeypatch: MonkeyPatch
+    ) -> None:
+        pytester.makepyfile(
+            """
+            def test_foo():
+                assert 1 == 10
+        """
+        )
+        monkeypatch.setenv("PYTEST_THEME_MODE", "invalid")
+        result = pytester.runpytest_subprocess("--color=yes")
+        result.stderr.fnmatch_lines(
+            "ERROR: PYTEST_THEME_MODE environment variable had an invalid value: 'invalid'. "
+            "The only allowed values are 'dark' and 'light'."
+        )
+
+
+def test_raw_skip_reason_skipped() -> None:
+    report = SimpleNamespace()
+    report.skipped = True
+    report.longrepr = ("xyz", 3, "Skipped: Just so")
+
+    reason = _get_raw_skip_reason(cast(TestReport, report))
+    assert reason == "Just so"
+
+
+def test_raw_skip_reason_xfail() -> None:
+    report = SimpleNamespace()
+    report.wasxfail = "reason: To everything there is a season"
+
+    reason = _get_raw_skip_reason(cast(TestReport, report))
+    assert reason == "To everything there is a season"
+
+
+def test_format_trimmed() -> None:
+    msg = "unconditional skip"
+
+    assert _format_trimmed(" ({}) ", msg, len(msg) + 4) == " (unconditional skip) "
+    assert _format_trimmed(" ({}) ", msg, len(msg) + 3) == " (unconditional ...) "
('testing', 'test_error_diffs.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -4,9 +4,8 @@
 See https://github.com/pytest-dev/pytest/issues/3333 for details.

 """
-import sys
-
 import pytest
+from _pytest.pytester import Pytester


 TESTCASES = [
@@ -209,74 +208,67 @@
         """,
         id='Test "not in" string',
     ),
+    pytest.param(
+        """
+        from dataclasses import dataclass
+
+        @dataclass
+        class A:
+            a: int
+            b: str
+
+        def test_this():
+            result =   A(1, 'spam')
+            expected = A(2, 'spam')
+            assert result == expected
+        """,
+        """
+        >       assert result == expected
+        E       AssertionError: assert A(a=1, b='spam') == A(a=2, b='spam')
+        E         Matching attributes:
+        E         ['b']
+        E         Differing attributes:
+        E         ['a']
+        E         Drill down into differing attribute a:
+        E           a: 1 != 2
+        """,
+        id="Compare data classes",
+    ),
+    pytest.param(
+        """
+        import attr
+
+        @attr.s(auto_attribs=True)
+        class A:
+            a: int
+            b: str
+
+        def test_this():
+            result =   A(1, 'spam')
+            expected = A(1, 'eggs')
+            assert result == expected
+        """,
+        """
+        >       assert result == expected
+        E       AssertionError: assert A(a=1, b='spam') == A(a=1, b='eggs')
+        E         Matching attributes:
+        E         ['a']
+        E         Differing attributes:
+        E         ['b']
+        E         Drill down into differing attribute b:
+        E           b: 'spam' != 'eggs'
+        E           - eggs
+        E           + spam
+        """,
+        id="Compare attrs classes",
+    ),
 ]
-if sys.version_info[:2] >= (3, 7):
-    TESTCASES.extend(
-        [
-            pytest.param(
-                """
-                from dataclasses import dataclass
-
-                @dataclass
-                class A:
-                    a: int
-                    b: str
-
-                def test_this():
-                    result =   A(1, 'spam')
-                    expected = A(2, 'spam')
-                    assert result == expected
-                """,
-                """
-                >       assert result == expected
-                E       AssertionError: assert A(a=1, b='spam') == A(a=2, b='spam')
-                E         Matching attributes:
-                E         ['b']
-                E         Differing attributes:
-                E         ['a']
-                E         Drill down into differing attribute a:
-                E           a: 1 != 2
-                E           +1
-                E           -2
-                """,
-                id="Compare data classes",
-            ),
-            pytest.param(
-                """
-                import attr
-
-                @attr.s(auto_attribs=True)
-                class A:
-                    a: int
-                    b: str
-
-                def test_this():
-                    result =   A(1, 'spam')
-                    expected = A(1, 'eggs')
-                    assert result == expected
-                """,
-                """
-                >       assert result == expected
-                E       AssertionError: assert A(a=1, b='spam') == A(a=1, b='eggs')
-                E         Matching attributes:
-                E         ['a']
-                E         Differing attributes:
-                E         ['b']
-                E         Drill down into differing attribute b:
-                E           b: 'spam' != 'eggs'
-                E           - eggs
-                E           + spam
-                """,
-                id="Compare attrs classes",
-            ),
-        ]
-    )


 @pytest.mark.parametrize("code, expected", TESTCASES)
-def test_error_diff(code, expected, testdir):
-    expected = [line.lstrip() for line in expected.splitlines()]
-    p = testdir.makepyfile(code)
-    result = testdir.runpytest(p, "-vv")
-    result.stdout.fnmatch_lines(expected)
+def test_error_diff(code: str, expected: str, pytester: Pytester) -> None:
+    expected_lines = [line.lstrip() for line in expected.splitlines()]
+    p = pytester.makepyfile(code)
+    result = pytester.runpytest(p, "-vv")
+    result.stdout.fnmatch_lines(expected_lines)
     assert result.ret == 1
('testing', 'test_reports.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,4 +1,3 @@
-import sys
 from typing import Sequence
 from typing import Union

@@ -6,25 +5,24 @@
 from _pytest._code.code import ExceptionChainRepr
 from _pytest._code.code import ExceptionRepr
 from _pytest.config import Config
-from _pytest.pathlib import Path
-from _pytest.pytester import Testdir
+from _pytest.pytester import Pytester
 from _pytest.reports import CollectReport
 from _pytest.reports import TestReport


 class TestReportSerialization:
-    def test_xdist_longrepr_to_str_issue_241(self, testdir: Testdir) -> None:
+    def test_xdist_longrepr_to_str_issue_241(self, pytester: Pytester) -> None:
         """Regarding issue pytest-xdist#241.

         This test came originally from test_remote.py in xdist (ca03269).
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_a(): assert False
             def test_b(): pass
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reports = reprec.getreports("pytest_runtest_logreport")
         assert len(reports) == 6
         test_a_call = reports[1]
@@ -36,12 +34,12 @@
         assert test_b_call.outcome == "passed"
         assert test_b_call._to_json()["longrepr"] is None

-    def test_xdist_report_longrepr_reprcrash_130(self, testdir: Testdir) -> None:
+    def test_xdist_report_longrepr_reprcrash_130(self, pytester: Pytester) -> None:
         """Regarding issue pytest-xdist#130

         This test came originally from test_remote.py in xdist (ca03269).
         """
-        reprec = testdir.inline_runsource(
+        reprec = pytester.inline_runsource(
             """
                     def test_fail():
                         assert False, 'Expected Message'
@@ -75,14 +73,14 @@
         # Missing section attribute PR171
         assert added_section in a.longrepr.sections

-    def test_reprentries_serialization_170(self, testdir: Testdir) -> None:
+    def test_reprentries_serialization_170(self, pytester: Pytester) -> None:
         """Regarding issue pytest-xdist#170

         This test came originally from test_remote.py in xdist (ca03269).
         """
         from _pytest._code.code import ReprEntry

-        reprec = testdir.inline_runsource(
+        reprec = pytester.inline_runsource(
             """
                             def test_repr_entry():
                                 x = 0
@@ -121,14 +119,14 @@
             assert rep_entry.reprlocals.lines == a_entry.reprlocals.lines
             assert rep_entry.style == a_entry.style

-    def test_reprentries_serialization_196(self, testdir: Testdir) -> None:
+    def test_reprentries_serialization_196(self, pytester: Pytester) -> None:
         """Regarding issue pytest-xdist#196

         This test came originally from test_remote.py in xdist (ca03269).
         """
         from _pytest._code.code import ReprEntryNative

-        reprec = testdir.inline_runsource(
+        reprec = pytester.inline_runsource(
             """
                             def test_repr_entry_native():
                                 x = 0
@@ -150,9 +148,9 @@
             assert isinstance(rep_entries[i], ReprEntryNative)
             assert rep_entries[i].lines == a_entries[i].lines

-    def test_itemreport_outcomes(self, testdir: Testdir) -> None:
+    def test_itemreport_outcomes(self, pytester: Pytester) -> None:
         # This test came originally from test_remote.py in xdist (ca03269).
-        reprec = testdir.inline_runsource(
+        reprec = pytester.inline_runsource(
             """
             import pytest
             def test_pass(): pass
@@ -184,9 +182,9 @@
             if rep.failed:
                 assert newrep.longreprtext == rep.longreprtext

-    def test_collectreport_passed(self, testdir: Testdir) -> None:
+    def test_collectreport_passed(self, pytester: Pytester) -> None:
         """This test came originally from test_remote.py in xdist (ca03269)."""
-        reprec = testdir.inline_runsource("def test_func(): pass")
+        reprec = pytester.inline_runsource("def test_func(): pass")
         reports = reprec.getreports("pytest_collectreport")
         for rep in reports:
             d = rep._to_json()
@@ -195,9 +193,9 @@
             assert newrep.failed == rep.failed
             assert newrep.skipped == rep.skipped

-    def test_collectreport_fail(self, testdir: Testdir) -> None:
+    def test_collectreport_fail(self, pytester: Pytester) -> None:
         """This test came originally from test_remote.py in xdist (ca03269)."""
-        reprec = testdir.inline_runsource("qwe abc")
+        reprec = pytester.inline_runsource("qwe abc")
         reports = reprec.getreports("pytest_collectreport")
         assert reports
         for rep in reports:
@@ -209,9 +207,9 @@
             if rep.failed:
                 assert newrep.longrepr == str(rep.longrepr)

-    def test_extended_report_deserialization(self, testdir: Testdir) -> None:
+    def test_extended_report_deserialization(self, pytester: Pytester) -> None:
         """This test came originally from test_remote.py in xdist (ca03269)."""
-        reprec = testdir.inline_runsource("qwe abc")
+        reprec = pytester.inline_runsource("qwe abc")
         reports = reprec.getreports("pytest_collectreport")
         assert reports
         for rep in reports:
@@ -225,33 +223,41 @@
             if rep.failed:
                 assert newrep.longrepr == str(rep.longrepr)

-    def test_paths_support(self, testdir: Testdir) -> None:
-        """Report attributes which are py.path or pathlib objects should become strings."""
-        testdir.makepyfile(
+    def test_paths_support(self, pytester: Pytester) -> None:
+        """Report attributes which are path-like should become strings."""
+        pytester.makepyfile(
             """
             def test_a():
                 assert False
         """
         )
-        reprec = testdir.inline_run()
+
+        class MyPathLike:
+            def __init__(self, path: str) -> None:
+                self.path = path
+
+            def __fspath__(self) -> str:
+                return self.path
+
+        reprec = pytester.inline_run()
         reports = reprec.getreports("pytest_runtest_logreport")
         assert len(reports) == 3
         test_a_call = reports[1]
-        test_a_call.path1 = testdir.tmpdir  # type: ignore[attr-defined]
-        test_a_call.path2 = Path(testdir.tmpdir)  # type: ignore[attr-defined]
+        test_a_call.path1 = MyPathLike(str(pytester.path))  # type: ignore[attr-defined]
+        test_a_call.path2 = pytester.path  # type: ignore[attr-defined]
         data = test_a_call._to_json()
-        assert data["path1"] == str(testdir.tmpdir)
-        assert data["path2"] == str(testdir.tmpdir)
-
-    def test_deserialization_failure(self, testdir: Testdir) -> None:
+        assert data["path1"] == str(pytester.path)
+        assert data["path2"] == str(pytester.path)
+
+    def test_deserialization_failure(self, pytester: Pytester) -> None:
         """Check handling of failure during deserialization of report types."""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_a():
                 assert False
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reports = reprec.getreports("pytest_runtest_logreport")
         assert len(reports) == 3
         test_a_call = reports[1]
@@ -266,9 +272,11 @@
             TestReport._from_json(data)

     @pytest.mark.parametrize("report_class", [TestReport, CollectReport])
-    def test_chained_exceptions(self, testdir: Testdir, tw_mock, report_class) -> None:
+    def test_chained_exceptions(
+        self, pytester: Pytester, tw_mock, report_class
+    ) -> None:
         """Check serialization/deserialization of report objects containing chained exceptions (#5786)"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def foo():
                 raise ValueError('value error')
@@ -284,11 +292,11 @@
             )
         )

-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         if report_class is TestReport:
-            reports = reprec.getreports(
-                "pytest_runtest_logreport"
-            )  # type: Union[Sequence[TestReport], Sequence[CollectReport]]
+            reports: Union[
+                Sequence[TestReport], Sequence[CollectReport]
+            ] = reprec.getreports("pytest_runtest_logreport")
             # we have 3 reports: setup/call/teardown
             assert len(reports) == 3
             # get the call report
@@ -339,54 +347,28 @@
         # elsewhere and we do check the contents of the longrepr object after loading it.
         loaded_report.longrepr.toterminal(tw_mock)

-    def test_chained_exceptions_no_reprcrash(self, testdir: Testdir, tw_mock) -> None:
+    def test_chained_exceptions_no_reprcrash(self, pytester: Pytester, tw_mock) -> None:
         """Regression test for tracebacks without a reprcrash (#5971)

         This happens notably on exceptions raised by multiprocess.pool: the exception transfer
         from subprocess to main process creates an artificial exception, which ExceptionInfo
         can't obtain the ReprFileLocation from.
         """
-        # somehow in Python 3.5 on Windows this test fails with:
-        #   File "c:\...\3.5.4\x64\Lib\multiprocessing\connection.py", line 302, in _recv_bytes
-        #     overlapped=True)
-        # OSError: [WinError 6] The handle is invalid
-        #
-        # so in this platform we opted to use a mock traceback which is identical to the
-        # one produced by the multiprocessing module
-        if sys.version_info[:2] <= (3, 5) and sys.platform.startswith("win"):
-            testdir.makepyfile(
-                """
-                # equivalent of multiprocessing.pool.RemoteTraceback
-                class RemoteTraceback(Exception):
-                    def __init__(self, tb):
-                        self.tb = tb
-                    def __str__(self):
-                        return self.tb
-                def test_a():
-                    try:
-                        raise ValueError('value error')
-                    except ValueError as e:
-                        # equivalent to how multiprocessing.pool.rebuild_exc does it
-                        e.__cause__ = RemoteTraceback('runtime error')
-                        raise e
-            """
-            )
-        else:
-            testdir.makepyfile(
-                """
-                from concurrent.futures import ProcessPoolExecutor
-
-                def func():
-                    raise ValueError('value error')
-
-                def test_a():
-                    with ProcessPoolExecutor() as p:
-                        p.submit(func).result()
-            """
-            )
-
-        testdir.syspathinsert()
-        reprec = testdir.inline_run()
+        pytester.makepyfile(
+            """
+            from concurrent.futures import ProcessPoolExecutor
+
+            def func():
+                raise ValueError('value error')
+
+            def test_a():
+                with ProcessPoolExecutor() as p:
+                    p.submit(func).result()
+        """
+        )
+
+        pytester.syspathinsert()
+        reprec = pytester.inline_run()

         reports = reprec.getreports("pytest_runtest_logreport")

@@ -423,12 +405,13 @@
         loaded_report.longrepr.toterminal(tw_mock)

     def test_report_prevent_ConftestImportFailure_hiding_exception(
-        self, testdir: Testdir
+        self, pytester: Pytester
     ) -> None:
-        sub_dir = testdir.tmpdir.join("ns").ensure_dir()
-        sub_dir.join("conftest").new(ext=".py").write("import unknown")
-
-        result = testdir.runpytest_subprocess(".")
+        sub_dir = pytester.path.joinpath("ns")
+        sub_dir.mkdir()
+        sub_dir.joinpath("conftest.py").write_text("import unknown")
+
+        result = pytester.runpytest_subprocess(".")
         result.stdout.fnmatch_lines(["E   *Error: No module named 'unknown'"])
         result.stdout.no_fnmatch_line("ERROR  - *ConftestImportFailure*")

@@ -436,14 +419,14 @@
 class TestHooks:
     """Test that the hooks are working correctly for plugins"""

-    def test_test_report(self, testdir: Testdir, pytestconfig: Config) -> None:
-        testdir.makepyfile(
+    def test_test_report(self, pytester: Pytester, pytestconfig: Config) -> None:
+        pytester.makepyfile(
             """
             def test_a(): assert False
             def test_b(): pass
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reports = reprec.getreports("pytest_runtest_logreport")
         assert len(reports) == 6
         for rep in reports:
@@ -458,14 +441,14 @@
             assert new_rep.when == rep.when
             assert new_rep.outcome == rep.outcome

-    def test_collect_report(self, testdir: Testdir, pytestconfig: Config) -> None:
-        testdir.makepyfile(
+    def test_collect_report(self, pytester: Pytester, pytestconfig: Config) -> None:
+        pytester.makepyfile(
             """
             def test_a(): assert False
             def test_b(): pass
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reports = reprec.getreports("pytest_collectreport")
         assert len(reports) == 2
         for rep in reports:
@@ -484,14 +467,14 @@
         "hook_name", ["pytest_runtest_logreport", "pytest_collectreport"]
     )
     def test_invalid_report_types(
-        self, testdir: Testdir, pytestconfig: Config, hook_name: str
+        self, pytester: Pytester, pytestconfig: Config, hook_name: str
     ) -> None:
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_a(): pass
             """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reports = reprec.getreports(hook_name)
         assert reports
         rep = reports[0]
('testing', 'test_pluginmanager.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,13 +1,18 @@
 import os
+import shutil
 import sys
 import types
 from typing import List

 import pytest
+from _pytest.config import Config
 from _pytest.config import ExitCode
 from _pytest.config import PytestPluginManager
 from _pytest.config.exceptions import UsageError
 from _pytest.main import Session
+from _pytest.monkeypatch import MonkeyPatch
+from _pytest.pathlib import import_path
+from _pytest.pytester import Pytester


 @pytest.fixture
@@ -16,14 +21,16 @@


 class TestPytestPluginInteractions:
-    def test_addhooks_conftestplugin(self, testdir, _config_for_test):
-        testdir.makepyfile(
+    def test_addhooks_conftestplugin(
+        self, pytester: Pytester, _config_for_test: Config
+    ) -> None:
+        pytester.makepyfile(
             newhooks="""
             def pytest_myhook(xyz):
                 "new hook"
         """
         )
-        conf = testdir.makeconftest(
+        conf = pytester.makeconftest(
             """
             import newhooks
             def pytest_addhooks(pluginmanager):
@@ -37,38 +44,42 @@
         pm.hook.pytest_addhooks.call_historic(
             kwargs=dict(pluginmanager=config.pluginmanager)
         )
-        config.pluginmanager._importconftest(conf, importmode="prepend")
+        config.pluginmanager._importconftest(
+            conf, importmode="prepend", rootpath=pytester.path
+        )
         # print(config.pluginmanager.get_plugins())
         res = config.hook.pytest_myhook(xyz=10)
         assert res == [11]

-    def test_addhooks_nohooks(self, testdir):
-        testdir.makeconftest(
+    def test_addhooks_nohooks(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import sys
             def pytest_addhooks(pluginmanager):
                 pluginmanager.add_hookspecs(sys)
         """
         )
-        res = testdir.runpytest()
+        res = pytester.runpytest()
         assert res.ret != 0
         res.stderr.fnmatch_lines(["*did not find*sys*"])

-    def test_do_option_postinitialize(self, testdir):
-        config = testdir.parseconfigure()
+    def test_do_option_postinitialize(self, pytester: Pytester) -> None:
+        config = pytester.parseconfigure()
         assert not hasattr(config.option, "test123")
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             """
             def pytest_addoption(parser):
                 parser.addoption('--test123', action="store_true",
                     default=True)
         """
         )
-        config.pluginmanager._importconftest(p, importmode="prepend")
+        config.pluginmanager._importconftest(
+            p, importmode="prepend", rootpath=pytester.path
+        )
         assert config.option.test123

-    def test_configure(self, testdir):
-        config = testdir.parseconfig()
+    def test_configure(self, pytester: Pytester) -> None:
+        config = pytester.parseconfig()
         values = []

         class A:
@@ -87,7 +98,7 @@
         config.pluginmanager.register(A())
         assert len(values) == 2

-    def test_hook_tracing(self, _config_for_test) -> None:
+    def test_hook_tracing(self, _config_for_test: Config) -> None:
         pytestpm = _config_for_test.pluginmanager  # fully initialized with plugins
         saveindent = []

@@ -100,7 +111,7 @@
                 saveindent.append(pytestpm.trace.root.indent)
                 raise ValueError()

-        values = []  # type: List[str]
+        values: List[str] = []
         pytestpm.trace.root.setwriter(values.append)
         undo = pytestpm.enable_tracing()
         try:
@@ -120,25 +131,29 @@
         finally:
             undo()

-    def test_hook_proxy(self, testdir):
+    def test_hook_proxy(self, pytester: Pytester) -> None:
         """Test the gethookproxy function(#2016)"""
-        config = testdir.parseconfig()
+        config = pytester.parseconfig()
         session = Session.from_config(config)
-        testdir.makepyfile(**{"tests/conftest.py": "", "tests/subdir/conftest.py": ""})
-
-        conftest1 = testdir.tmpdir.join("tests/conftest.py")
-        conftest2 = testdir.tmpdir.join("tests/subdir/conftest.py")
-
-        config.pluginmanager._importconftest(conftest1, importmode="prepend")
-        ihook_a = session.gethookproxy(testdir.tmpdir.join("tests"))
+        pytester.makepyfile(**{"tests/conftest.py": "", "tests/subdir/conftest.py": ""})
+
+        conftest1 = pytester.path.joinpath("tests/conftest.py")
+        conftest2 = pytester.path.joinpath("tests/subdir/conftest.py")
+
+        config.pluginmanager._importconftest(
+            conftest1, importmode="prepend", rootpath=pytester.path
+        )
+        ihook_a = session.gethookproxy(pytester.path / "tests")
         assert ihook_a is not None
-        config.pluginmanager._importconftest(conftest2, importmode="prepend")
-        ihook_b = session.gethookproxy(testdir.tmpdir.join("tests"))
+        config.pluginmanager._importconftest(
+            conftest2, importmode="prepend", rootpath=pytester.path
+        )
+        ihook_b = session.gethookproxy(pytester.path / "tests")
         assert ihook_a is not ihook_b

-    def test_hook_with_addoption(self, testdir):
+    def test_hook_with_addoption(self, pytester: Pytester) -> None:
         """Test that hooks can be used in a call to pytest_addoption"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             newhooks="""
             import pytest
             @pytest.hookspec(firstresult=True)
@@ -146,7 +161,7 @@
                 pass
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             myplugin="""
             import newhooks
             def pytest_addhooks(pluginmanager):
@@ -156,30 +171,32 @@
                 parser.addoption("--config", help="Config, defaults to %(default)s", default=default_value)
         """
         )
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             pytest_plugins=("myplugin",)
             def pytest_default_value():
                 return "default_value"
         """
         )
-        res = testdir.runpytest("--help")
+        res = pytester.runpytest("--help")
         res.stdout.fnmatch_lines(["*--config=CONFIG*default_value*"])


-def test_default_markers(testdir):
-    result = testdir.runpytest("--markers")
+def test_default_markers(pytester: Pytester) -> None:
+    result = pytester.runpytest("--markers")
     result.stdout.fnmatch_lines(["*tryfirst*first*", "*trylast*last*"])


-def test_importplugin_error_message(testdir, pytestpm):
+def test_importplugin_error_message(
+    pytester: Pytester, pytestpm: PytestPluginManager
+) -> None:
     """Don't hide import errors when importing plugins and provide
     an easy to debug message.

     See #375 and #1998.
     """
-    testdir.syspathinsert(testdir.tmpdir)
-    testdir.makepyfile(
+    pytester.syspathinsert(pytester.path)
+    pytester.makepyfile(
         qwe="""\
         def test_traceback():
             raise ImportError('Not possible to import: ☺')
@@ -196,7 +213,7 @@


 class TestPytestPluginManager:
-    def test_register_imported_modules(self):
+    def test_register_imported_modules(self) -> None:
         pm = PytestPluginManager()
         mod = types.ModuleType("x.y.pytest_hello")
         pm.register(mod)
@@ -216,23 +233,27 @@
         assert pm.get_plugin("pytest_xyz") == mod
         assert pm.is_registered(mod)

-    def test_consider_module(self, testdir, pytestpm: PytestPluginManager) -> None:
-        testdir.syspathinsert()
-        testdir.makepyfile(pytest_p1="#")
-        testdir.makepyfile(pytest_p2="#")
+    def test_consider_module(
+        self, pytester: Pytester, pytestpm: PytestPluginManager
+    ) -> None:
+        pytester.syspathinsert()
+        pytester.makepyfile(pytest_p1="#")
+        pytester.makepyfile(pytest_p2="#")
         mod = types.ModuleType("temp")
         mod.__dict__["pytest_plugins"] = ["pytest_p1", "pytest_p2"]
         pytestpm.consider_module(mod)
         assert pytestpm.get_plugin("pytest_p1").__name__ == "pytest_p1"
         assert pytestpm.get_plugin("pytest_p2").__name__ == "pytest_p2"

-    def test_consider_module_import_module(self, testdir, _config_for_test) -> None:
+    def test_consider_module_import_module(
+        self, pytester: Pytester, _config_for_test: Config
+    ) -> None:
         pytestpm = _config_for_test.pluginmanager
         mod = types.ModuleType("x")
         mod.__dict__["pytest_plugins"] = "pytest_a"
-        aplugin = testdir.makepyfile(pytest_a="#")
-        reprec = testdir.make_hook_recorder(pytestpm)
-        testdir.syspathinsert(aplugin.dirpath())
+        aplugin = pytester.makepyfile(pytest_a="#")
+        reprec = pytester.make_hook_recorder(pytestpm)
+        pytester.syspathinsert(aplugin.parent)
         pytestpm.consider_module(mod)
         call = reprec.getcall(pytestpm.hook.pytest_plugin_registered.name)
         assert call.plugin.__name__ == "pytest_a"
@@ -242,30 +263,37 @@
         values = reprec.getcalls("pytest_plugin_registered")
         assert len(values) == 1

-    def test_consider_env_fails_to_import(self, monkeypatch, pytestpm):
+    def test_consider_env_fails_to_import(
+        self, monkeypatch: MonkeyPatch, pytestpm: PytestPluginManager
+    ) -> None:
         monkeypatch.setenv("PYTEST_PLUGINS", "nonexisting", prepend=",")
         with pytest.raises(ImportError):
             pytestpm.consider_env()

     @pytest.mark.filterwarnings("always")
-    def test_plugin_skip(self, testdir, monkeypatch):
-        p = testdir.makepyfile(
+    def test_plugin_skip(self, pytester: Pytester, monkeypatch: MonkeyPatch) -> None:
+        p = pytester.makepyfile(
             skipping1="""
             import pytest
             pytest.skip("hello", allow_module_level=True)
         """
         )
-        p.copy(p.dirpath("skipping2.py"))
+        shutil.copy(p, p.with_name("skipping2.py"))
         monkeypatch.setenv("PYTEST_PLUGINS", "skipping2")
-        result = testdir.runpytest("-p", "skipping1", syspathinsert=True)
+        result = pytester.runpytest("-p", "skipping1", syspathinsert=True)
         assert result.ret == ExitCode.NO_TESTS_COLLECTED
         result.stdout.fnmatch_lines(
             ["*skipped plugin*skipping1*hello*", "*skipped plugin*skipping2*hello*"]
         )

-    def test_consider_env_plugin_instantiation(self, testdir, monkeypatch, pytestpm):
-        testdir.syspathinsert()
-        testdir.makepyfile(xy123="#")
+    def test_consider_env_plugin_instantiation(
+        self,
+        pytester: Pytester,
+        monkeypatch: MonkeyPatch,
+        pytestpm: PytestPluginManager,
+    ) -> None:
+        pytester.syspathinsert()
+        pytester.makepyfile(xy123="#")
         monkeypatch.setitem(os.environ, "PYTEST_PLUGINS", "xy123")
         l1 = len(pytestpm.get_plugins())
         pytestpm.consider_env()
@@ -276,9 +304,11 @@
         l3 = len(pytestpm.get_plugins())
         assert l2 == l3

-    def test_pluginmanager_ENV_startup(self, testdir, monkeypatch):
-        testdir.makepyfile(pytest_x500="#")
-        p = testdir.makepyfile(
+    def test_pluginmanager_ENV_startup(
+        self, pytester: Pytester, monkeypatch: MonkeyPatch
+    ) -> None:
+        pytester.makepyfile(pytest_x500="#")
+        p = pytester.makepyfile(
             """
             import pytest
             def test_hello(pytestconfig):
@@ -287,17 +317,19 @@
         """
         )
         monkeypatch.setenv("PYTEST_PLUGINS", "pytest_x500", prepend=",")
-        result = testdir.runpytest(p, syspathinsert=True)
+        result = pytester.runpytest(p, syspathinsert=True)
         assert result.ret == 0
         result.stdout.fnmatch_lines(["*1 passed*"])

-    def test_import_plugin_importname(self, testdir, pytestpm):
+    def test_import_plugin_importname(
+        self, pytester: Pytester, pytestpm: PytestPluginManager
+    ) -> None:
         pytest.raises(ImportError, pytestpm.import_plugin, "qweqwex.y")
         pytest.raises(ImportError, pytestpm.import_plugin, "pytest_qweqwx.y")

-        testdir.syspathinsert()
+        pytester.syspathinsert()
         pluginname = "pytest_hello"
-        testdir.makepyfile(**{pluginname: ""})
+        pytester.makepyfile(**{pluginname: ""})
         pytestpm.import_plugin("pytest_hello")
         len1 = len(pytestpm.get_plugins())
         pytestpm.import_plugin("pytest_hello")
@@ -308,25 +340,33 @@
         plugin2 = pytestpm.get_plugin("pytest_hello")
         assert plugin2 is plugin1

-    def test_import_plugin_dotted_name(self, testdir, pytestpm):
+    def test_import_plugin_dotted_name(
+        self, pytester: Pytester, pytestpm: PytestPluginManager
+    ) -> None:
         pytest.raises(ImportError, pytestpm.import_plugin, "qweqwex.y")
         pytest.raises(ImportError, pytestpm.import_plugin, "pytest_qweqwex.y")

-        testdir.syspathinsert()
-        testdir.mkpydir("pkg").join("plug.py").write("x=3")
+        pytester.syspathinsert()
+        pytester.mkpydir("pkg").joinpath("plug.py").write_text("x=3")
         pluginname = "pkg.plug"
         pytestpm.import_plugin(pluginname)
         mod = pytestpm.get_plugin("pkg.plug")
         assert mod.x == 3

-    def test_consider_conftest_deps(self, testdir, pytestpm):
-        mod = testdir.makepyfile("pytest_plugins='xyz'").pyimport()
+    def test_consider_conftest_deps(
+        self,
+        pytester: Pytester,
+        pytestpm: PytestPluginManager,
+    ) -> None:
+        mod = import_path(
+            pytester.makepyfile("pytest_plugins='xyz'"), root=pytester.path
+        )
         with pytest.raises(ImportError):
             pytestpm.consider_conftest(mod)


 class TestPytestPluginManagerBootstrapming:
-    def test_preparse_args(self, pytestpm):
+    def test_preparse_args(self, pytestpm: PytestPluginManager) -> None:
         pytest.raises(
             ImportError, lambda: pytestpm.consider_preparse(["xyz", "-p", "hello123"])
         )
@@ -343,7 +383,7 @@
         with pytest.raises(UsageError, match="^plugin main cannot be disabled$"):
             pytestpm.consider_preparse(["-p", "no:main"])

-    def test_plugin_prevent_register(self, pytestpm):
+    def test_plugin_prevent_register(self, pytestpm: PytestPluginManager) -> None:
         pytestpm.consider_preparse(["xyz", "-p", "no:abc"])
         l1 = pytestpm.get_plugins()
         pytestpm.register(42, name="abc")
@@ -351,7 +391,9 @@
         assert len(l2) == len(l1)
         assert 42 not in l2

-    def test_plugin_prevent_register_unregistered_alredy_registered(self, pytestpm):
+    def test_plugin_prevent_register_unregistered_alredy_registered(
+        self, pytestpm: PytestPluginManager
+    ) -> None:
         pytestpm.register(42, name="abc")
         l1 = pytestpm.get_plugins()
         assert 42 in l1
@@ -360,10 +402,10 @@
         assert 42 not in l2

     def test_plugin_prevent_register_stepwise_on_cacheprovider_unregister(
-        self, pytestpm
-    ):
+        self, pytestpm: PytestPluginManager
+    ) -> None:
         """From PR #4304: The only way to unregister a module is documented at
-        the end of https://docs.pytest.org/en/stable/plugins.html.
+        the end of https://docs.pytest.org/en/stable/how-to/plugins.html.

         When unregister cacheprovider, then unregister stepwise too.
         """
@@ -377,7 +419,7 @@
         assert 42 not in l2
         assert 43 not in l2

-    def test_blocked_plugin_can_be_used(self, pytestpm):
+    def test_blocked_plugin_can_be_used(self, pytestpm: PytestPluginManager) -> None:
         pytestpm.consider_preparse(["xyz", "-p", "no:abc", "-p", "abc"])

         assert pytestpm.has_plugin("abc")
('testing', 'test_runner.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -2,56 +2,58 @@
 import os
 import sys
 import types
+from pathlib import Path
 from typing import Dict
 from typing import List
 from typing import Tuple
-
-import py
-
-import _pytest._code
+from typing import Type
+
 import pytest
 from _pytest import outcomes
 from _pytest import reports
 from _pytest import runner
-from _pytest.compat import TYPE_CHECKING
+from _pytest._code import ExceptionInfo
+from _pytest._code.code import ExceptionChainRepr
 from _pytest.config import ExitCode
+from _pytest.monkeypatch import MonkeyPatch
 from _pytest.outcomes import OutcomeException
-
-if TYPE_CHECKING:
-    from typing import Type
+from _pytest.pytester import Pytester


 class TestSetupState:
-    def test_setup(self, testdir) -> None:
-        ss = runner.SetupState()
-        item = testdir.getitem("def test_func(): pass")
+    def test_setup(self, pytester: Pytester) -> None:
+        item = pytester.getitem("def test_func(): pass")
+        ss = item.session._setupstate
         values = [1]
-        ss.prepare(item)
-        ss.addfinalizer(values.pop, colitem=item)
+        ss.setup(item)
+        ss.addfinalizer(values.pop, item)
         assert values
-        ss._pop_and_teardown()
+        ss.teardown_exact(None)
         assert not values

-    def test_teardown_exact_stack_empty(self, testdir) -> None:
-        item = testdir.getitem("def test_func(): pass")
-        ss = runner.SetupState()
-        ss.teardown_exact(item, None)
-        ss.teardown_exact(item, None)
-        ss.teardown_exact(item, None)
-
-    def test_setup_fails_and_failure_is_cached(self, testdir) -> None:
-        item = testdir.getitem(
+    def test_teardown_exact_stack_empty(self, pytester: Pytester) -> None:
+        item = pytester.getitem("def test_func(): pass")
+        ss = item.session._setupstate
+        ss.setup(item)
+        ss.teardown_exact(None)
+        ss.teardown_exact(None)
+        ss.teardown_exact(None)
+
+    def test_setup_fails_and_failure_is_cached(self, pytester: Pytester) -> None:
+        item = pytester.getitem(
             """
             def setup_module(mod):
                 raise ValueError(42)
             def test_func(): pass
         """
         )
-        ss = runner.SetupState()
-        pytest.raises(ValueError, lambda: ss.prepare(item))
-        pytest.raises(ValueError, lambda: ss.prepare(item))
-
-    def test_teardown_multiple_one_fails(self, testdir) -> None:
+        ss = item.session._setupstate
+        with pytest.raises(ValueError):
+            ss.setup(item)
+        with pytest.raises(ValueError):
+            ss.setup(item)
+
+    def test_teardown_multiple_one_fails(self, pytester: Pytester) -> None:
         r = []

         def fin1():
@@ -63,17 +65,18 @@
         def fin3():
             r.append("fin3")

-        item = testdir.getitem("def test_func(): pass")
-        ss = runner.SetupState()
+        item = pytester.getitem("def test_func(): pass")
+        ss = item.session._setupstate
+        ss.setup(item)
         ss.addfinalizer(fin1, item)
         ss.addfinalizer(fin2, item)
         ss.addfinalizer(fin3, item)
         with pytest.raises(Exception) as err:
-            ss._callfinalizers(item)
+            ss.teardown_exact(None)
         assert err.value.args == ("oops",)
         assert r == ["fin3", "fin1"]

-    def test_teardown_multiple_fail(self, testdir) -> None:
+    def test_teardown_multiple_fail(self, pytester: Pytester) -> None:
         # Ensure the first exception is the one which is re-raised.
         # Ideally both would be reported however.
         def fin1():
@@ -82,15 +85,16 @@
         def fin2():
             raise Exception("oops2")

-        item = testdir.getitem("def test_func(): pass")
-        ss = runner.SetupState()
+        item = pytester.getitem("def test_func(): pass")
+        ss = item.session._setupstate
+        ss.setup(item)
         ss.addfinalizer(fin1, item)
         ss.addfinalizer(fin2, item)
         with pytest.raises(Exception) as err:
-            ss._callfinalizers(item)
+            ss.teardown_exact(None)
         assert err.value.args == ("oops2",)

-    def test_teardown_multiple_scopes_one_fails(self, testdir) -> None:
+    def test_teardown_multiple_scopes_one_fails(self, pytester: Pytester) -> None:
         module_teardown = []

         def fin_func():
@@ -99,19 +103,20 @@
         def fin_module():
             module_teardown.append("fin_module")

-        item = testdir.getitem("def test_func(): pass")
-        ss = runner.SetupState()
-        ss.addfinalizer(fin_module, item.listchain()[-2])
+        item = pytester.getitem("def test_func(): pass")
+        mod = item.listchain()[-2]
+        ss = item.session._setupstate
+        ss.setup(item)
+        ss.addfinalizer(fin_module, mod)
         ss.addfinalizer(fin_func, item)
-        ss.prepare(item)
         with pytest.raises(Exception, match="oops1"):
-            ss.teardown_exact(item, None)
-        assert module_teardown
+            ss.teardown_exact(None)
+        assert module_teardown == ["fin_module"]


 class BaseFunctionalTests:
-    def test_passfunction(self, testdir) -> None:
-        reports = testdir.runitem(
+    def test_passfunction(self, pytester: Pytester) -> None:
+        reports = pytester.runitem(
             """
             def test_func():
                 pass
@@ -123,8 +128,8 @@
         assert rep.outcome == "passed"
         assert not rep.longrepr

-    def test_failfunction(self, testdir) -> None:
-        reports = testdir.runitem(
+    def test_failfunction(self, pytester: Pytester) -> None:
+        reports = pytester.runitem(
             """
             def test_func():
                 assert 0
@@ -138,8 +143,8 @@
         assert rep.outcome == "failed"
         # assert isinstance(rep.longrepr, ReprExceptionInfo)

-    def test_skipfunction(self, testdir) -> None:
-        reports = testdir.runitem(
+    def test_skipfunction(self, pytester: Pytester) -> None:
+        reports = pytester.runitem(
             """
             import pytest
             def test_func():
@@ -158,8 +163,8 @@
         # assert rep.skipped.location.path
         # assert not rep.skipped.failurerepr

-    def test_skip_in_setup_function(self, testdir) -> None:
-        reports = testdir.runitem(
+    def test_skip_in_setup_function(self, pytester: Pytester) -> None:
+        reports = pytester.runitem(
             """
             import pytest
             def setup_function(func):
@@ -179,8 +184,8 @@
         assert len(reports) == 2
         assert reports[1].passed  # teardown

-    def test_failure_in_setup_function(self, testdir) -> None:
-        reports = testdir.runitem(
+    def test_failure_in_setup_function(self, pytester: Pytester) -> None:
+        reports = pytester.runitem(
             """
             import pytest
             def setup_function(func):
@@ -196,8 +201,8 @@
         assert rep.when == "setup"
         assert len(reports) == 2

-    def test_failure_in_teardown_function(self, testdir) -> None:
-        reports = testdir.runitem(
+    def test_failure_in_teardown_function(self, pytester: Pytester) -> None:
+        reports = pytester.runitem(
             """
             import pytest
             def teardown_function(func):
@@ -216,8 +221,8 @@
         # assert rep.longrepr.reprcrash.lineno == 3
         # assert rep.longrepr.reprtraceback.reprentries

-    def test_custom_failure_repr(self, testdir) -> None:
-        testdir.makepyfile(
+    def test_custom_failure_repr(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             conftest="""
             import pytest
             class Function(pytest.Function):
@@ -225,7 +230,7 @@
                     return "hello"
         """
         )
-        reports = testdir.runitem(
+        reports = pytester.runitem(
             """
             import pytest
             def test_func():
@@ -241,8 +246,8 @@
         # assert rep.failed.where.path.basename == "test_func.py"
         # assert rep.failed.failurerepr == "hello"

-    def test_teardown_final_returncode(self, testdir) -> None:
-        rec = testdir.inline_runsource(
+    def test_teardown_final_returncode(self, pytester: Pytester) -> None:
+        rec = pytester.inline_runsource(
             """
             def test_func():
                 pass
@@ -252,8 +257,8 @@
         )
         assert rec.ret == 1

-    def test_logstart_logfinish_hooks(self, testdir) -> None:
-        rec = testdir.inline_runsource(
+    def test_logstart_logfinish_hooks(self, pytester: Pytester) -> None:
+        rec = pytester.inline_runsource(
             """
             import pytest
             def test_func():
@@ -269,8 +274,8 @@
             assert rep.nodeid == "test_logstart_logfinish_hooks.py::test_func"
             assert rep.location == ("test_logstart_logfinish_hooks.py", 1, "test_func")

-    def test_exact_teardown_issue90(self, testdir) -> None:
-        rec = testdir.inline_runsource(
+    def test_exact_teardown_issue90(self, pytester: Pytester) -> None:
+        rec = pytester.inline_runsource(
             """
             import pytest

@@ -282,7 +287,7 @@

             def test_func():
                 import sys
-                # on python2 exc_info is keept till a function exits
+                # on python2 exc_info is kept till a function exits
                 # so we would end up calling test functions while
                 # sys.exc_info would return the indexerror
                 # from guessing the lastitem
@@ -309,9 +314,9 @@
         assert reps[5].nodeid.endswith("test_func")
         assert reps[5].failed

-    def test_exact_teardown_issue1206(self, testdir) -> None:
+    def test_exact_teardown_issue1206(self, pytester: Pytester) -> None:
         """Issue shadowing error with wrong number of arguments on teardown_method."""
-        rec = testdir.inline_runsource(
+        rec = pytester.inline_runsource(
             """
             import pytest

@@ -338,15 +343,19 @@
         assert reps[2].nodeid.endswith("test_method")
         assert reps[2].failed
         assert reps[2].when == "teardown"
-        assert reps[2].longrepr.reprcrash.message in (
-            # python3 error
+        longrepr = reps[2].longrepr
+        assert isinstance(longrepr, ExceptionChainRepr)
+        assert longrepr.reprcrash
+        assert longrepr.reprcrash.message in (
             "TypeError: teardown_method() missing 2 required positional arguments: 'y' and 'z'",
-            # python2 error
-            "TypeError: teardown_method() takes exactly 4 arguments (2 given)",
-        )
-
-    def test_failure_in_setup_function_ignores_custom_repr(self, testdir) -> None:
-        testdir.makepyfile(
+            # Python >= 3.10
+            "TypeError: TestClass.teardown_method() missing 2 required positional arguments: 'y' and 'z'",
+        )
+
+    def test_failure_in_setup_function_ignores_custom_repr(
+        self, pytester: Pytester
+    ) -> None:
+        pytester.makepyfile(
             conftest="""
             import pytest
             class Function(pytest.Function):
@@ -354,7 +363,7 @@
                     assert 0
         """
         )
-        reports = testdir.runitem(
+        reports = pytester.runitem(
             """
             def setup_function(func):
                 raise ValueError(42)
@@ -373,9 +382,9 @@
         # assert rep.outcome.where.path.basename == "test_func.py"
         # assert instanace(rep.failed.failurerepr, PythonFailureRepr)

-    def test_systemexit_does_not_bail_out(self, testdir) -> None:
+    def test_systemexit_does_not_bail_out(self, pytester: Pytester) -> None:
         try:
-            reports = testdir.runitem(
+            reports = pytester.runitem(
                 """
                 def test_func():
                     raise SystemExit(42)
@@ -387,9 +396,9 @@
         assert rep.failed
         assert rep.when == "call"

-    def test_exit_propagates(self, testdir) -> None:
+    def test_exit_propagates(self, pytester: Pytester) -> None:
         try:
-            testdir.runitem(
+            pytester.runitem(
                 """
                 import pytest
                 def test_func():
@@ -409,9 +418,9 @@

         return f

-    def test_keyboardinterrupt_propagates(self, testdir) -> None:
+    def test_keyboardinterrupt_propagates(self, pytester: Pytester) -> None:
         try:
-            testdir.runitem(
+            pytester.runitem(
                 """
                 def test_func():
                     raise KeyboardInterrupt("fake")
@@ -424,8 +433,8 @@


 class TestSessionReports:
-    def test_collect_result(self, testdir) -> None:
-        col = testdir.getmodulecol(
+    def test_collect_result(self, pytester: Pytester) -> None:
+        col = pytester.getmodulecol(
             """
             def test_func1():
                 pass
@@ -438,28 +447,28 @@
         assert not rep.skipped
         assert rep.passed
         locinfo = rep.location
-        assert locinfo[0] == col.fspath.basename
+        assert locinfo[0] == col.path.name
         assert not locinfo[1]
-        assert locinfo[2] == col.fspath.basename
+        assert locinfo[2] == col.path.name
         res = rep.result
         assert len(res) == 2
         assert res[0].name == "test_func1"
         assert res[1].name == "TestClass"


-reporttypes = [
+reporttypes: List[Type[reports.BaseReport]] = [
     reports.BaseReport,
     reports.TestReport,
     reports.CollectReport,
-]  # type: List[Type[reports.BaseReport]]
+]


 @pytest.mark.parametrize(
     "reporttype", reporttypes, ids=[x.__name__ for x in reporttypes]
 )
-def test_report_extra_parameters(reporttype: "Type[reports.BaseReport]") -> None:
+def test_report_extra_parameters(reporttype: Type[reports.BaseReport]) -> None:
     args = list(inspect.signature(reporttype.__init__).parameters.keys())[1:]
-    basekw = dict.fromkeys(args, [])  # type: Dict[str, List[object]]
+    basekw: Dict[str, List[object]] = dict.fromkeys(args, [])
     report = reporttype(newthing=1, **basekw)
     assert report.newthing == 1

@@ -475,7 +484,7 @@
     ci2 = runner.CallInfo.from_call(lambda: 0 / 0, "collect")
     assert ci2.when == "collect"
     assert not hasattr(ci2, "result")
-    assert repr(ci2) == "<CallInfo when='collect' excinfo={!r}>".format(ci2.excinfo)
+    assert repr(ci2) == f"<CallInfo when='collect' excinfo={ci2.excinfo!r}>"
     assert str(ci2) == repr(ci2)
     assert ci2.excinfo

@@ -484,7 +493,7 @@
         assert 0, "assert_msg"

     ci3 = runner.CallInfo.from_call(raise_assertion, "call")
-    assert repr(ci3) == "<CallInfo when='call' excinfo={!r}>".format(ci3.excinfo)
+    assert repr(ci3) == f"<CallInfo when='call' excinfo={ci3.excinfo!r}>"
     assert "\n" not in repr(ci3)


@@ -493,8 +502,8 @@


 @pytest.mark.xfail
-def test_runtest_in_module_ordering(testdir) -> None:
-    p1 = testdir.makepyfile(
+def test_runtest_in_module_ordering(pytester: Pytester) -> None:
+    p1 = pytester.makepyfile(
         """
         import pytest
         def pytest_runtest_setup(item): # runs after class-level!
@@ -521,7 +530,7 @@
             del item.function.mylist
     """
     )
-    result = testdir.runpytest(p1)
+    result = pytester.runpytest(p1)
     result.stdout.fnmatch_lines(["*2 passed*"])


@@ -551,8 +560,8 @@
     assert s.startswith("Failed")


-def test_pytest_exit_msg(testdir) -> None:
-    testdir.makeconftest(
+def test_pytest_exit_msg(pytester: Pytester) -> None:
+    pytester.makeconftest(
         """
     import pytest

@@ -560,7 +569,7 @@
         pytest.exit('oh noes')
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stderr.fnmatch_lines(["Exit: oh noes"])


@@ -574,22 +583,22 @@
     ]


-def test_pytest_exit_returncode(testdir) -> None:
-    testdir.makepyfile(
+def test_pytest_exit_returncode(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """\
         import pytest
         def test_foo():
             pytest.exit("some exit msg", 99)
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*! *Exit: some exit msg !*"])

     assert _strip_resource_warnings(result.stderr.lines) == []
     assert result.ret == 99

     # It prints to stderr also in case of exit during pytest_sessionstart.
-    testdir.makeconftest(
+    pytester.makeconftest(
         """\
         import pytest

@@ -597,7 +606,7 @@
             pytest.exit("during_sessionstart", 98)
         """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*! *Exit: during_sessionstart !*"])
     assert _strip_resource_warnings(result.stderr.lines) == [
         "Exit: during_sessionstart"
@@ -605,9 +614,9 @@
     assert result.ret == 98


-def test_pytest_fail_notrace_runtest(testdir) -> None:
+def test_pytest_fail_notrace_runtest(pytester: Pytester) -> None:
     """Test pytest.fail(..., pytrace=False) does not show tracebacks during test run."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         def test_hello():
@@ -616,14 +625,14 @@
             pytest.fail("world", pytrace=False)
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["world", "hello"])
     result.stdout.no_fnmatch_line("*def teardown_function*")


-def test_pytest_fail_notrace_collection(testdir) -> None:
+def test_pytest_fail_notrace_collection(pytester: Pytester) -> None:
     """Test pytest.fail(..., pytrace=False) does not show tracebacks during collection."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         def some_internal_function():
@@ -631,17 +640,17 @@
         some_internal_function()
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["hello"])
     result.stdout.no_fnmatch_line("*def some_internal_function()*")


-def test_pytest_fail_notrace_non_ascii(testdir) -> None:
+def test_pytest_fail_notrace_non_ascii(pytester: Pytester) -> None:
     """Fix pytest.fail with pytrace=False with non-ascii characters (#1178).

     This tests with native and unicode strings containing non-ascii chars.
     """
-    testdir.makepyfile(
+    pytester.makepyfile(
         """\
         import pytest

@@ -649,28 +658,28 @@
             pytest.fail('oh oh: ☺', pytrace=False)
         """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*test_hello*", "oh oh: ☺"])
     result.stdout.no_fnmatch_line("*def test_hello*")


-def test_pytest_no_tests_collected_exit_status(testdir) -> None:
-    result = testdir.runpytest()
+def test_pytest_no_tests_collected_exit_status(pytester: Pytester) -> None:
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*collected 0 items*"])
     assert result.ret == ExitCode.NO_TESTS_COLLECTED

-    testdir.makepyfile(
+    pytester.makepyfile(
         test_foo="""
         def test_foo():
             assert 1
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*collected 1 item*"])
     result.stdout.fnmatch_lines(["*1 passed*"])
     assert result.ret == ExitCode.OK

-    result = testdir.runpytest("-k nonmatch")
+    result = pytester.runpytest("-k nonmatch")
     result.stdout.fnmatch_lines(["*collected 1 item*"])
     result.stdout.fnmatch_lines(["*1 deselected*"])
     assert result.ret == ExitCode.NO_TESTS_COLLECTED
@@ -681,7 +690,7 @@
     try:
         pytest.skip("hello")
     except pytest.skip.Exception:
-        excinfo = _pytest._code.ExceptionInfo.from_current()
+        excinfo = ExceptionInfo.from_current()
         s = excinfo.exconly(tryshort=True)
         assert s.startswith("Skipped")

@@ -702,10 +711,10 @@
         excrepr = excinfo.getrepr()
         assert excrepr is not None
         assert excrepr.reprcrash is not None
-        path = py.path.local(excrepr.reprcrash.path)
+        path = Path(excrepr.reprcrash.path)
         # check that importorskip reports the actual call
         # in this test the test_runner.py file
-        assert path.purebasename == "test_runner"
+        assert path.stem == "test_runner"
         pytest.raises(SyntaxError, pytest.importorskip, "x y z")
         pytest.raises(SyntaxError, pytest.importorskip, "x=y")
         mod = types.ModuleType("hello123")
@@ -716,9 +725,7 @@
         mod2 = pytest.importorskip("hello123", minversion="1.3")
         assert mod2 == mod
     except pytest.skip.Exception:  # pragma: no cover
-        assert False, "spurious skip: {}".format(
-            _pytest._code.ExceptionInfo.from_current()
-        )
+        assert False, f"spurious skip: {ExceptionInfo.from_current()}"


 def test_importorskip_imports_last_module_part() -> None:
@@ -736,14 +743,12 @@
         with pytest.raises(pytest.skip.Exception):
             pytest.importorskip("mockmodule1", minversion="0.14.0")
     except pytest.skip.Exception:  # pragma: no cover
-        assert False, "spurious skip: {}".format(
-            _pytest._code.ExceptionInfo.from_current()
-        )
-
-
-def test_importorskip_module_level(testdir) -> None:
+        assert False, f"spurious skip: {ExceptionInfo.from_current()}"
+
+
+def test_importorskip_module_level(pytester: Pytester) -> None:
     """`importorskip` must be able to skip entire modules when used at module level."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         foobarbaz = pytest.importorskip("foobarbaz")
@@ -752,13 +757,13 @@
             pass
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*collected 0 items / 1 skipped*"])


-def test_importorskip_custom_reason(testdir) -> None:
+def test_importorskip_custom_reason(pytester: Pytester) -> None:
     """Make sure custom reasons are used."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         foobarbaz = pytest.importorskip("foobarbaz2", reason="just because")
@@ -767,13 +772,13 @@
             pass
     """
     )
-    result = testdir.runpytest("-ra")
+    result = pytester.runpytest("-ra")
     result.stdout.fnmatch_lines(["*just because*"])
     result.stdout.fnmatch_lines(["*collected 0 items / 1 skipped*"])


-def test_pytest_cmdline_main(testdir) -> None:
-    p = testdir.makepyfile(
+def test_pytest_cmdline_main(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
         """
         import pytest
         def test_hello():
@@ -790,8 +795,8 @@
     assert ret == 0


-def test_unicode_in_longrepr(testdir) -> None:
-    testdir.makeconftest(
+def test_unicode_in_longrepr(pytester: Pytester) -> None:
+    pytester.makeconftest(
         """\
         import pytest
         @pytest.hookimpl(hookwrapper=True)
@@ -802,19 +807,19 @@
                 rep.longrepr = 'ä'
         """
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         def test_out():
             assert 0
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert result.ret == 1
     assert "UnicodeEncodeError" not in result.stderr.str()


-def test_failure_in_setup(testdir) -> None:
-    testdir.makepyfile(
+def test_failure_in_setup(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         def setup_module():
             0/0
@@ -822,24 +827,26 @@
             pass
     """
     )
-    result = testdir.runpytest("--tb=line")
+    result = pytester.runpytest("--tb=line")
     result.stdout.no_fnmatch_line("*def setup_module*")


-def test_makereport_getsource(testdir) -> None:
-    testdir.makepyfile(
+def test_makereport_getsource(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         def test_foo():
             if False: pass
             else: assert False
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.no_fnmatch_line("*INTERNALERROR*")
     result.stdout.fnmatch_lines(["*else: assert False*"])


-def test_makereport_getsource_dynamic_code(testdir, monkeypatch) -> None:
+def test_makereport_getsource_dynamic_code(
+    pytester: Pytester, monkeypatch: MonkeyPatch
+) -> None:
     """Test that exception in dynamically generated code doesn't break getting the source line."""
     import inspect

@@ -853,7 +860,7 @@

     monkeypatch.setattr(inspect, "findsource", findsource)

-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest

@@ -865,7 +872,7 @@
             assert False
     """
     )
-    result = testdir.runpytest("-vv")
+    result = pytester.runpytest("-vv")
     result.stdout.no_fnmatch_line("*INTERNALERROR*")
     result.stdout.fnmatch_lines(["*test_fix*", "*fixture*'missing'*not found*"])

@@ -900,12 +907,12 @@
     assert not hasattr(sys, "last_traceback")


-def test_current_test_env_var(testdir, monkeypatch) -> None:
-    pytest_current_test_vars = []  # type: List[Tuple[str, str]]
+def test_current_test_env_var(pytester: Pytester, monkeypatch: MonkeyPatch) -> None:
+    pytest_current_test_vars: List[Tuple[str, str]] = []
     monkeypatch.setattr(
         sys, "pytest_current_test_vars", pytest_current_test_vars, raising=False
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         import sys
@@ -921,7 +928,7 @@
             sys.pytest_current_test_vars.append(('call', os.environ['PYTEST_CURRENT_TEST']))
     """
     )
-    result = testdir.runpytest_inprocess()
+    result = pytester.runpytest_inprocess()
     assert result.ret == 0
     test_id = "test_current_test_env_var.py::test"
     assert pytest_current_test_vars == [
@@ -938,8 +945,8 @@
     def getrunner(self):
         return lambda item: runner.runtestprotocol(item, log=False)

-    def test_longreprtext_pass(self, testdir) -> None:
-        reports = testdir.runitem(
+    def test_longreprtext_pass(self, pytester: Pytester) -> None:
+        reports = pytester.runitem(
             """
             def test_func():
                 pass
@@ -948,9 +955,9 @@
         rep = reports[1]
         assert rep.longreprtext == ""

-    def test_longreprtext_skip(self, testdir) -> None:
+    def test_longreprtext_skip(self, pytester: Pytester) -> None:
         """TestReport.longreprtext can handle non-str ``longrepr`` attributes (#7559)"""
-        reports = testdir.runitem(
+        reports = pytester.runitem(
             """
             import pytest
             def test_func():
@@ -961,22 +968,22 @@
         assert isinstance(call_rep.longrepr, tuple)
         assert "Skipped" in call_rep.longreprtext

-    def test_longreprtext_collect_skip(self, testdir) -> None:
+    def test_longreprtext_collect_skip(self, pytester: Pytester) -> None:
         """CollectReport.longreprtext can handle non-str ``longrepr`` attributes (#7559)"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest
             pytest.skip(allow_module_level=True)
             """
         )
-        rec = testdir.inline_run()
+        rec = pytester.inline_run()
         calls = rec.getcalls("pytest_collectreport")
         _, call = calls
         assert isinstance(call.report.longrepr, tuple)
         assert "Skipped" in call.report.longreprtext

-    def test_longreprtext_failure(self, testdir) -> None:
-        reports = testdir.runitem(
+    def test_longreprtext_failure(self, pytester: Pytester) -> None:
+        reports = pytester.runitem(
             """
             def test_func():
                 x = 1
@@ -986,8 +993,8 @@
         rep = reports[1]
         assert "assert 1 == 4" in rep.longreprtext

-    def test_captured_text(self, testdir) -> None:
-        reports = testdir.runitem(
+    def test_captured_text(self, pytester: Pytester) -> None:
+        reports = pytester.runitem(
             """
             import pytest
             import sys
@@ -1016,8 +1023,8 @@
         assert call.capstderr == "setup: stderr\ncall: stderr\n"
         assert teardown.capstderr == "setup: stderr\ncall: stderr\nteardown: stderr\n"

-    def test_no_captured_text(self, testdir) -> None:
-        reports = testdir.runitem(
+    def test_no_captured_text(self, pytester: Pytester) -> None:
+        reports = pytester.runitem(
             """
             def test_func():
                 pass
@@ -1027,8 +1034,8 @@
         assert rep.capstdout == ""
         assert rep.capstderr == ""

-    def test_longrepr_type(self, testdir) -> None:
-        reports = testdir.runitem(
+    def test_longrepr_type(self, pytester: Pytester) -> None:
+        reports = pytester.runitem(
             """
             import pytest
             def test_func():
@@ -1036,7 +1043,7 @@
         """
         )
         rep = reports[1]
-        assert isinstance(rep.longrepr, _pytest._code.code.ExceptionRepr)
+        assert isinstance(rep.longrepr, ExceptionChainRepr)


 def test_outcome_exception_bad_msg() -> None:
('testing', 'test_monkeypatch.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -2,18 +2,14 @@
 import re
 import sys
 import textwrap
+from pathlib import Path
 from typing import Dict
 from typing import Generator
-
-import py
+from typing import Type

 import pytest
-from _pytest.compat import TYPE_CHECKING
 from _pytest.monkeypatch import MonkeyPatch
-from _pytest.pytester import Testdir
-
-if TYPE_CHECKING:
-    from typing import Type
+from _pytest.pytester import Pytester


 @pytest.fixture
@@ -54,21 +50,24 @@

 class TestSetattrWithImportPath:
     def test_string_expression(self, monkeypatch: MonkeyPatch) -> None:
-        monkeypatch.setattr("os.path.abspath", lambda x: "hello2")
-        assert os.path.abspath("123") == "hello2"
+        with monkeypatch.context() as mp:
+            mp.setattr("os.path.abspath", lambda x: "hello2")
+            assert os.path.abspath("123") == "hello2"

     def test_string_expression_class(self, monkeypatch: MonkeyPatch) -> None:
-        monkeypatch.setattr("_pytest.config.Config", 42)
-        import _pytest
-
-        assert _pytest.config.Config == 42  # type: ignore
+        with monkeypatch.context() as mp:
+            mp.setattr("_pytest.config.Config", 42)
+            import _pytest
+
+            assert _pytest.config.Config == 42  # type: ignore

     def test_unicode_string(self, monkeypatch: MonkeyPatch) -> None:
-        monkeypatch.setattr("_pytest.config.Config", 42)
-        import _pytest
-
-        assert _pytest.config.Config == 42  # type: ignore
-        monkeypatch.delattr("_pytest.config.Config")
+        with monkeypatch.context() as mp:
+            mp.setattr("_pytest.config.Config", 42)
+            import _pytest
+
+            assert _pytest.config.Config == 42  # type: ignore
+            mp.delattr("_pytest.config.Config")

     def test_wrong_target(self, monkeypatch: MonkeyPatch) -> None:
         with pytest.raises(TypeError):
@@ -84,14 +83,16 @@

     def test_unknown_attr_non_raising(self, monkeypatch: MonkeyPatch) -> None:
         # https://github.com/pytest-dev/pytest/issues/746
-        monkeypatch.setattr("os.path.qweqwe", 42, raising=False)
-        assert os.path.qweqwe == 42  # type: ignore
+        with monkeypatch.context() as mp:
+            mp.setattr("os.path.qweqwe", 42, raising=False)
+            assert os.path.qweqwe == 42  # type: ignore

     def test_delattr(self, monkeypatch: MonkeyPatch) -> None:
-        monkeypatch.delattr("os.path.abspath")
-        assert not hasattr(os.path, "abspath")
-        monkeypatch.undo()
-        assert os.path.abspath
+        with monkeypatch.context() as mp:
+            mp.delattr("os.path.abspath")
+            assert not hasattr(os.path, "abspath")
+            mp.undo()
+            assert os.path.abspath


 def test_delattr() -> None:
@@ -133,7 +134,7 @@


 def test_setitem_deleted_meanwhile() -> None:
-    d = {}  # type: Dict[str, object]
+    d: Dict[str, object] = {}
     monkeypatch = MonkeyPatch()
     monkeypatch.setitem(d, "x", 2)
     del d["x"]
@@ -158,7 +159,7 @@


 def test_delitem() -> None:
-    d = {"x": 1}  # type: Dict[str, object]
+    d: Dict[str, object] = {"x": 1}
     monkeypatch = MonkeyPatch()
     monkeypatch.delitem(d, "x")
     assert "x" not in d
@@ -236,8 +237,8 @@
     assert "XYZ123" not in os.environ


-def test_monkeypatch_plugin(testdir: Testdir) -> None:
-    reprec = testdir.inline_runsource(
+def test_monkeypatch_plugin(pytester: Pytester) -> None:
+    reprec = pytester.inline_runsource(
         """
         def test_method(monkeypatch):
             assert monkeypatch.__class__.__name__ == "MonkeyPatch"
@@ -271,33 +272,33 @@
         sys.path[:] = old_syspath


-def test_chdir_with_path_local(mp: MonkeyPatch, tmpdir: py.path.local) -> None:
-    mp.chdir(tmpdir)
-    assert os.getcwd() == tmpdir.strpath
-
-
-def test_chdir_with_str(mp: MonkeyPatch, tmpdir: py.path.local) -> None:
-    mp.chdir(tmpdir.strpath)
-    assert os.getcwd() == tmpdir.strpath
-
-
-def test_chdir_undo(mp: MonkeyPatch, tmpdir: py.path.local) -> None:
+def test_chdir_with_path_local(mp: MonkeyPatch, tmp_path: Path) -> None:
+    mp.chdir(tmp_path)
+    assert os.getcwd() == str(tmp_path)
+
+
+def test_chdir_with_str(mp: MonkeyPatch, tmp_path: Path) -> None:
+    mp.chdir(str(tmp_path))
+    assert os.getcwd() == str(tmp_path)
+
+
+def test_chdir_undo(mp: MonkeyPatch, tmp_path: Path) -> None:
     cwd = os.getcwd()
-    mp.chdir(tmpdir)
+    mp.chdir(tmp_path)
     mp.undo()
     assert os.getcwd() == cwd


-def test_chdir_double_undo(mp: MonkeyPatch, tmpdir: py.path.local) -> None:
-    mp.chdir(tmpdir.strpath)
+def test_chdir_double_undo(mp: MonkeyPatch, tmp_path: Path) -> None:
+    mp.chdir(str(tmp_path))
     mp.undo()
-    tmpdir.chdir()
+    os.chdir(tmp_path)
     mp.undo()
-    assert os.getcwd() == tmpdir.strpath
-
-
-def test_issue185_time_breaks(testdir: Testdir) -> None:
-    testdir.makepyfile(
+    assert os.getcwd() == str(tmp_path)
+
+
+def test_issue185_time_breaks(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import time
         def test_m(monkeypatch):
@@ -306,7 +307,7 @@
             monkeypatch.setattr(time, "time", f)
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         """
         *1 passed*
@@ -314,9 +315,9 @@
     )


-def test_importerror(testdir: Testdir) -> None:
-    p = testdir.mkpydir("package")
-    p.join("a.py").write(
+def test_importerror(pytester: Pytester) -> None:
+    p = pytester.mkpydir("package")
+    p.joinpath("a.py").write_text(
         textwrap.dedent(
             """\
         import doesnotexist
@@ -325,7 +326,7 @@
     """
         )
     )
-    testdir.tmpdir.join("test_importerror.py").write(
+    pytester.path.joinpath("test_importerror.py").write_text(
         textwrap.dedent(
             """\
         def test_importerror(monkeypatch):
@@ -333,7 +334,7 @@
     """
         )
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         """
         *import error in package.a: No module named 'doesnotexist'*
@@ -352,9 +353,11 @@


 @pytest.mark.parametrize(
-    "Sample", [Sample, SampleInherit], ids=["new", "new-inherit"],
+    "Sample",
+    [Sample, SampleInherit],
+    ids=["new", "new-inherit"],
 )
-def test_issue156_undo_staticmethod(Sample: "Type[Sample]") -> None:
+def test_issue156_undo_staticmethod(Sample: Type[Sample]) -> None:
     monkeypatch = MonkeyPatch()

     monkeypatch.setattr(Sample, "hello", None)
@@ -412,17 +415,29 @@
     assert inspect.isclass(functools.partial)


+def test_context_classmethod() -> None:
+    class A:
+        x = 1
+
+    with MonkeyPatch.context() as m:
+        m.setattr(A, "x", 2)
+        assert A.x == 2
+    assert A.x == 1
+
+
 def test_syspath_prepend_with_namespace_packages(
-    testdir: Testdir, monkeypatch: MonkeyPatch
+    pytester: Pytester, monkeypatch: MonkeyPatch
 ) -> None:
     for dirname in "hello", "world":
-        d = testdir.mkdir(dirname)
-        ns = d.mkdir("ns_pkg")
-        ns.join("__init__.py").write(
+        d = pytester.mkdir(dirname)
+        ns = d.joinpath("ns_pkg")
+        ns.mkdir()
+        ns.joinpath("__init__.py").write_text(
             "__import__('pkg_resources').declare_namespace(__name__)"
         )
-        lib = ns.mkdir(dirname)
-        lib.join("__init__.py").write("def check(): return %r" % dirname)
+        lib = ns.joinpath(dirname)
+        lib.mkdir()
+        lib.joinpath("__init__.py").write_text("def check(): return %r" % dirname)

     monkeypatch.syspath_prepend("hello")
     import ns_pkg.hello
@@ -439,8 +454,7 @@
     assert ns_pkg.world.check() == "world"

     # Should invalidate caches via importlib.invalidate_caches.
-    tmpdir = testdir.tmpdir
-    modules_tmpdir = tmpdir.mkdir("modules_tmpdir")
+    modules_tmpdir = pytester.mkdir("modules_tmpdir")
     monkeypatch.syspath_prepend(str(modules_tmpdir))
-    modules_tmpdir.join("main_app.py").write("app = True")
+    modules_tmpdir.joinpath("main_app.py").write_text("app = True")
     from main_app import app  # noqa: F401
('testing', 'test_doctest.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,23 +1,26 @@
 import inspect
+import sys
 import textwrap
+from pathlib import Path
 from typing import Callable
 from typing import Optional

 import pytest
-from _pytest.compat import MODULE_NOT_FOUND_ERROR
 from _pytest.doctest import _get_checker
+from _pytest.doctest import _is_main_py
 from _pytest.doctest import _is_mocked
 from _pytest.doctest import _is_setup_py
 from _pytest.doctest import _patch_unwrap_mock_aware
 from _pytest.doctest import DoctestItem
 from _pytest.doctest import DoctestModule
 from _pytest.doctest import DoctestTextfile
+from _pytest.pytester import Pytester


 class TestDoctests:
-    def test_collect_testtextfile(self, testdir):
-        w = testdir.maketxtfile(whatever="")
-        checkfile = testdir.maketxtfile(
+    def test_collect_testtextfile(self, pytester: Pytester):
+        w = pytester.maketxtfile(whatever="")
+        checkfile = pytester.maketxtfile(
             test_something="""
             alskdjalsdk
             >>> i = 5
@@ -26,53 +29,59 @@
         """
         )

-        for x in (testdir.tmpdir, checkfile):
+        for x in (pytester.path, checkfile):
             # print "checking that %s returns custom items" % (x,)
-            items, reprec = testdir.inline_genitems(x)
+            items, reprec = pytester.inline_genitems(x)
             assert len(items) == 1
             assert isinstance(items[0], DoctestItem)
             assert isinstance(items[0].parent, DoctestTextfile)
         # Empty file has no items.
-        items, reprec = testdir.inline_genitems(w)
+        items, reprec = pytester.inline_genitems(w)
         assert len(items) == 0

-    def test_collect_module_empty(self, testdir):
-        path = testdir.makepyfile(whatever="#")
-        for p in (path, testdir.tmpdir):
-            items, reprec = testdir.inline_genitems(p, "--doctest-modules")
+    def test_collect_module_empty(self, pytester: Pytester):
+        path = pytester.makepyfile(whatever="#")
+        for p in (path, pytester.path):
+            items, reprec = pytester.inline_genitems(p, "--doctest-modules")
             assert len(items) == 0

-    def test_collect_module_single_modulelevel_doctest(self, testdir):
-        path = testdir.makepyfile(whatever='""">>> pass"""')
-        for p in (path, testdir.tmpdir):
-            items, reprec = testdir.inline_genitems(p, "--doctest-modules")
+    def test_collect_module_single_modulelevel_doctest(self, pytester: Pytester):
+        path = pytester.makepyfile(whatever='""">>> pass"""')
+        for p in (path, pytester.path):
+            items, reprec = pytester.inline_genitems(p, "--doctest-modules")
             assert len(items) == 1
             assert isinstance(items[0], DoctestItem)
             assert isinstance(items[0].parent, DoctestModule)

-    def test_collect_module_two_doctest_one_modulelevel(self, testdir):
-        path = testdir.makepyfile(
+    def test_collect_module_two_doctest_one_modulelevel(self, pytester: Pytester):
+        path = pytester.makepyfile(
             whatever="""
             '>>> x = None'
             def my_func():
                 ">>> magic = 42 "
         """
         )
-        for p in (path, testdir.tmpdir):
-            items, reprec = testdir.inline_genitems(p, "--doctest-modules")
+        for p in (path, pytester.path):
+            items, reprec = pytester.inline_genitems(p, "--doctest-modules")
             assert len(items) == 2
             assert isinstance(items[0], DoctestItem)
             assert isinstance(items[1], DoctestItem)
             assert isinstance(items[0].parent, DoctestModule)
             assert items[0].parent is items[1].parent

-    def test_collect_module_two_doctest_no_modulelevel(self, testdir):
-        path = testdir.makepyfile(
-            whatever="""
+    @pytest.mark.parametrize("filename", ["__init__", "whatever"])
+    def test_collect_module_two_doctest_no_modulelevel(
+        self,
+        pytester: Pytester,
+        filename: str,
+    ) -> None:
+        path = pytester.makepyfile(
+            **{
+                filename: """
             '# Empty'
             def my_func():
                 ">>> magic = 42 "
-            def unuseful():
+            def useless():
                 '''
                 # This is a function
                 # >>> # it doesn't have any doctest
@@ -82,74 +91,75 @@
                 # This is another function
                 >>> import os # this one does have a doctest
                 '''
-        """
-        )
-        for p in (path, testdir.tmpdir):
-            items, reprec = testdir.inline_genitems(p, "--doctest-modules")
+            """,
+            },
+        )
+        for p in (path, pytester.path):
+            items, reprec = pytester.inline_genitems(p, "--doctest-modules")
             assert len(items) == 2
             assert isinstance(items[0], DoctestItem)
             assert isinstance(items[1], DoctestItem)
             assert isinstance(items[0].parent, DoctestModule)
             assert items[0].parent is items[1].parent

-    def test_simple_doctestfile(self, testdir):
-        p = testdir.maketxtfile(
+    def test_simple_doctestfile(self, pytester: Pytester):
+        p = pytester.maketxtfile(
             test_doc="""
             >>> x = 1
             >>> x == 1
             False
         """
         )
-        reprec = testdir.inline_run(p)
+        reprec = pytester.inline_run(p)
         reprec.assertoutcome(failed=1)

-    def test_new_pattern(self, testdir):
-        p = testdir.maketxtfile(
+    def test_new_pattern(self, pytester: Pytester):
+        p = pytester.maketxtfile(
             xdoc="""
             >>> x = 1
             >>> x == 1
             False
         """
         )
-        reprec = testdir.inline_run(p, "--doctest-glob=x*.txt")
+        reprec = pytester.inline_run(p, "--doctest-glob=x*.txt")
         reprec.assertoutcome(failed=1)

-    def test_multiple_patterns(self, testdir):
+    def test_multiple_patterns(self, pytester: Pytester):
         """Test support for multiple --doctest-glob arguments (#1255)."""
-        testdir.maketxtfile(
+        pytester.maketxtfile(
             xdoc="""
             >>> 1
             1
         """
         )
-        testdir.makefile(
+        pytester.makefile(
             ".foo",
             test="""
             >>> 1
             1
         """,
         )
-        testdir.maketxtfile(
+        pytester.maketxtfile(
             test_normal="""
             >>> 1
             1
         """
         )
         expected = {"xdoc.txt", "test.foo", "test_normal.txt"}
-        assert {x.basename for x in testdir.tmpdir.listdir()} == expected
+        assert {x.name for x in pytester.path.iterdir()} == expected
         args = ["--doctest-glob=xdoc*.txt", "--doctest-glob=*.foo"]
-        result = testdir.runpytest(*args)
+        result = pytester.runpytest(*args)
         result.stdout.fnmatch_lines(["*test.foo *", "*xdoc.txt *", "*2 passed*"])
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*test_normal.txt *", "*1 passed*"])

     @pytest.mark.parametrize(
         "   test_string,    encoding",
         [("foo", "ascii"), ("öäü", "latin1"), ("öäü", "utf-8")],
     )
-    def test_encoding(self, testdir, test_string, encoding):
+    def test_encoding(self, pytester, test_string, encoding):
         """Test support for doctest_encoding ini option."""
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
             doctest_encoding={}
@@ -163,21 +173,22 @@
         """.format(
             test_string, repr(test_string)
         )
-        testdir._makefile(".txt", [doctest], {}, encoding=encoding)
-
-        result = testdir.runpytest()
+        fn = pytester.path / "test_encoding.txt"
+        fn.write_text(doctest, encoding=encoding)
+
+        result = pytester.runpytest()

         result.stdout.fnmatch_lines(["*1 passed*"])

-    def test_doctest_unexpected_exception(self, testdir):
-        testdir.maketxtfile(
+    def test_doctest_unexpected_exception(self, pytester: Pytester):
+        pytester.maketxtfile(
             """
             >>> i = 0
             >>> 0 / i
             2
         """
         )
-        result = testdir.runpytest("--doctest-modules")
+        result = pytester.runpytest("--doctest-modules")
         result.stdout.fnmatch_lines(
             [
                 "test_doctest_unexpected_exception.txt F *",
@@ -190,6 +201,7 @@
                 "Traceback (most recent call last):",
                 '  File "*/doctest.py", line *, in __run',
                 "    *",
+                *((" *^^^^*",) if sys.version_info >= (3, 11) else ()),
                 '  File "<doctest test_doctest_unexpected_exception.txt[1]>", line 1, in <module>',
                 "ZeroDivisionError: division by zero",
                 "*/test_doctest_unexpected_exception.txt:2: UnexpectedException",
@@ -197,8 +209,8 @@
             consecutive=True,
         )

-    def test_doctest_outcomes(self, testdir):
-        testdir.maketxtfile(
+    def test_doctest_outcomes(self, pytester: Pytester):
+        pytester.maketxtfile(
             test_skip="""
             >>> 1
             1
@@ -220,7 +232,7 @@
             bar
             """,
         )
-        result = testdir.runpytest("--doctest-modules")
+        result = pytester.runpytest("--doctest-modules")
         result.stdout.fnmatch_lines(
             [
                 "collected 3 items",
@@ -233,11 +245,11 @@
             ]
         )

-    def test_docstring_partial_context_around_error(self, testdir):
+    def test_docstring_partial_context_around_error(self, pytester: Pytester):
         """Test that we show some context before the actual line of a failing
         doctest.
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             '''
             def foo():
                 """
@@ -259,7 +271,7 @@
                 """
         '''
         )
-        result = testdir.runpytest("--doctest-modules")
+        result = pytester.runpytest("--doctest-modules")
         result.stdout.fnmatch_lines(
             [
                 "*docstring_partial_context_around_error*",
@@ -277,11 +289,11 @@
         result.stdout.no_fnmatch_line("*text-line-2*")
         result.stdout.no_fnmatch_line("*text-line-after*")

-    def test_docstring_full_context_around_error(self, testdir):
+    def test_docstring_full_context_around_error(self, pytester: Pytester):
         """Test that we show the whole context before the actual line of a failing
         doctest, provided that the context is up to 10 lines long.
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             '''
             def foo():
                 """
@@ -293,7 +305,7 @@
                 """
         '''
         )
-        result = testdir.runpytest("--doctest-modules")
+        result = pytester.runpytest("--doctest-modules")
         result.stdout.fnmatch_lines(
             [
                 "*docstring_full_context_around_error*",
@@ -307,8 +319,8 @@
             ]
         )

-    def test_doctest_linedata_missing(self, testdir):
-        testdir.tmpdir.join("hello.py").write(
+    def test_doctest_linedata_missing(self, pytester: Pytester):
+        pytester.path.joinpath("hello.py").write_text(
             textwrap.dedent(
                 """\
                 class Fun(object):
@@ -321,13 +333,13 @@
                 """
             )
         )
-        result = testdir.runpytest("--doctest-modules")
+        result = pytester.runpytest("--doctest-modules")
         result.stdout.fnmatch_lines(
             ["*hello*", "006*>>> 1/0*", "*UNEXPECTED*ZeroDivision*", "*1 failed*"]
         )

-    def test_doctest_linedata_on_property(self, testdir):
-        testdir.makepyfile(
+    def test_doctest_linedata_on_property(self, pytester: Pytester):
+        pytester.makepyfile(
             """
             class Sample(object):
                 @property
@@ -339,7 +351,7 @@
                     return 'something'
             """
         )
-        result = testdir.runpytest("--doctest-modules")
+        result = pytester.runpytest("--doctest-modules")
         result.stdout.fnmatch_lines(
             [
                 "*= FAILURES =*",
@@ -356,8 +368,8 @@
             ]
         )

-    def test_doctest_no_linedata_on_overriden_property(self, testdir):
-        testdir.makepyfile(
+    def test_doctest_no_linedata_on_overriden_property(self, pytester: Pytester):
+        pytester.makepyfile(
             """
             class Sample(object):
                 @property
@@ -370,7 +382,7 @@
                 some_property = property(some_property.__get__, None, None, some_property.__doc__)
             """
         )
-        result = testdir.runpytest("--doctest-modules")
+        result = pytester.runpytest("--doctest-modules")
         result.stdout.fnmatch_lines(
             [
                 "*= FAILURES =*",
@@ -387,49 +399,49 @@
             ]
         )

-    def test_doctest_unex_importerror_only_txt(self, testdir):
-        testdir.maketxtfile(
+    def test_doctest_unex_importerror_only_txt(self, pytester: Pytester):
+        pytester.maketxtfile(
             """
             >>> import asdalsdkjaslkdjasd
             >>>
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         # doctest is never executed because of error during hello.py collection
         result.stdout.fnmatch_lines(
             [
                 "*>>> import asdals*",
-                "*UNEXPECTED*{e}*".format(e=MODULE_NOT_FOUND_ERROR),
-                "{e}: No module named *asdal*".format(e=MODULE_NOT_FOUND_ERROR),
+                "*UNEXPECTED*ModuleNotFoundError*",
+                "ModuleNotFoundError: No module named *asdal*",
             ]
         )

-    def test_doctest_unex_importerror_with_module(self, testdir):
-        testdir.tmpdir.join("hello.py").write(
+    def test_doctest_unex_importerror_with_module(self, pytester: Pytester):
+        pytester.path.joinpath("hello.py").write_text(
             textwrap.dedent(
                 """\
                 import asdalsdkjaslkdjasd
                 """
             )
         )
-        testdir.maketxtfile(
+        pytester.maketxtfile(
             """
             >>> import hello
             >>>
         """
         )
-        result = testdir.runpytest("--doctest-modules")
+        result = pytester.runpytest("--doctest-modules")
         # doctest is never executed because of error during hello.py collection
         result.stdout.fnmatch_lines(
             [
                 "*ERROR collecting hello.py*",
-                "*{e}: No module named *asdals*".format(e=MODULE_NOT_FOUND_ERROR),
+                "*ModuleNotFoundError: No module named *asdals*",
                 "*Interrupted: 1 error during collection*",
             ]
         )

-    def test_doctestmodule(self, testdir):
-        p = testdir.makepyfile(
+    def test_doctestmodule(self, pytester: Pytester):
+        p = pytester.makepyfile(
             """
             '''
                 >>> x = 1
@@ -439,12 +451,12 @@
             '''
         """
         )
-        reprec = testdir.inline_run(p, "--doctest-modules")
+        reprec = pytester.inline_run(p, "--doctest-modules")
         reprec.assertoutcome(failed=1)

-    def test_doctestmodule_external_and_issue116(self, testdir):
-        p = testdir.mkpydir("hello")
-        p.join("__init__.py").write(
+    def test_doctestmodule_external_and_issue116(self, pytester: Pytester):
+        p = pytester.mkpydir("hello")
+        p.joinpath("__init__.py").write_text(
             textwrap.dedent(
                 """\
                 def somefunc():
@@ -456,7 +468,7 @@
                 """
             )
         )
-        result = testdir.runpytest(p, "--doctest-modules")
+        result = pytester.runpytest(p, "--doctest-modules")
         result.stdout.fnmatch_lines(
             [
                 "003 *>>> i = 0",
@@ -469,15 +481,15 @@
             ]
         )

-    def test_txtfile_failing(self, testdir):
-        p = testdir.maketxtfile(
+    def test_txtfile_failing(self, pytester: Pytester):
+        p = pytester.maketxtfile(
             """
             >>> i = 0
             >>> i + 1
             2
         """
         )
-        result = testdir.runpytest(p, "-s")
+        result = pytester.runpytest(p, "-s")
         result.stdout.fnmatch_lines(
             [
                 "001 >>> i = 0",
@@ -490,25 +502,25 @@
             ]
         )

-    def test_txtfile_with_fixtures(self, testdir):
-        p = testdir.maketxtfile(
-            """
-            >>> dir = getfixture('tmpdir')
-            >>> type(dir).__name__
-            'LocalPath'
-        """
-        )
-        reprec = testdir.inline_run(p)
+    def test_txtfile_with_fixtures(self, pytester: Pytester):
+        p = pytester.maketxtfile(
+            """
+            >>> p = getfixture('tmp_path')
+            >>> p.is_dir()
+            True
+        """
+        )
+        reprec = pytester.inline_run(p)
         reprec.assertoutcome(passed=1)

-    def test_txtfile_with_usefixtures_in_ini(self, testdir):
-        testdir.makeini(
+    def test_txtfile_with_usefixtures_in_ini(self, pytester: Pytester):
+        pytester.makeini(
             """
             [pytest]
             usefixtures = myfixture
         """
         )
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest
             @pytest.fixture
@@ -517,36 +529,36 @@
         """
         )

-        p = testdir.maketxtfile(
+        p = pytester.maketxtfile(
             """
             >>> import os
             >>> os.environ["HELLO"]
             'WORLD'
         """
         )
-        reprec = testdir.inline_run(p)
+        reprec = pytester.inline_run(p)
         reprec.assertoutcome(passed=1)

-    def test_doctestmodule_with_fixtures(self, testdir):
-        p = testdir.makepyfile(
+    def test_doctestmodule_with_fixtures(self, pytester: Pytester):
+        p = pytester.makepyfile(
             """
             '''
-                >>> dir = getfixture('tmpdir')
-                >>> type(dir).__name__
-                'LocalPath'
+                >>> p = getfixture('tmp_path')
+                >>> p.is_dir()
+                True
             '''
         """
         )
-        reprec = testdir.inline_run(p, "--doctest-modules")
+        reprec = pytester.inline_run(p, "--doctest-modules")
         reprec.assertoutcome(passed=1)

-    def test_doctestmodule_three_tests(self, testdir):
-        p = testdir.makepyfile(
+    def test_doctestmodule_three_tests(self, pytester: Pytester):
+        p = pytester.makepyfile(
             """
             '''
-            >>> dir = getfixture('tmpdir')
-            >>> type(dir).__name__
-            'LocalPath'
+            >>> p = getfixture('tmp_path')
+            >>> p.is_dir()
+            True
             '''
             def my_func():
                 '''
@@ -554,7 +566,7 @@
                 >>> magic - 42
                 0
                 '''
-            def unuseful():
+            def useless():
                 pass
             def another():
                 '''
@@ -564,11 +576,11 @@
                 '''
         """
         )
-        reprec = testdir.inline_run(p, "--doctest-modules")
+        reprec = pytester.inline_run(p, "--doctest-modules")
         reprec.assertoutcome(passed=3)

-    def test_doctestmodule_two_tests_one_fail(self, testdir):
-        p = testdir.makepyfile(
+    def test_doctestmodule_two_tests_one_fail(self, pytester: Pytester):
+        p = pytester.makepyfile(
             """
             class MyClass(object):
                 def bad_meth(self):
@@ -585,17 +597,17 @@
                     '''
         """
         )
-        reprec = testdir.inline_run(p, "--doctest-modules")
+        reprec = pytester.inline_run(p, "--doctest-modules")
         reprec.assertoutcome(failed=1, passed=1)

-    def test_ignored_whitespace(self, testdir):
-        testdir.makeini(
+    def test_ignored_whitespace(self, pytester: Pytester):
+        pytester.makeini(
             """
             [pytest]
             doctest_optionflags = ELLIPSIS NORMALIZE_WHITESPACE
         """
         )
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             """
             class MyClass(object):
                 '''
@@ -606,17 +618,17 @@
                 pass
         """
         )
-        reprec = testdir.inline_run(p, "--doctest-modules")
+        reprec = pytester.inline_run(p, "--doctest-modules")
         reprec.assertoutcome(passed=1)

-    def test_non_ignored_whitespace(self, testdir):
-        testdir.makeini(
+    def test_non_ignored_whitespace(self, pytester: Pytester):
+        pytester.makeini(
             """
             [pytest]
             doctest_optionflags = ELLIPSIS
         """
         )
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             """
             class MyClass(object):
                 '''
@@ -627,46 +639,46 @@
                 pass
         """
         )
-        reprec = testdir.inline_run(p, "--doctest-modules")
+        reprec = pytester.inline_run(p, "--doctest-modules")
         reprec.assertoutcome(failed=1, passed=0)

-    def test_ignored_whitespace_glob(self, testdir):
-        testdir.makeini(
+    def test_ignored_whitespace_glob(self, pytester: Pytester):
+        pytester.makeini(
             """
             [pytest]
             doctest_optionflags = ELLIPSIS NORMALIZE_WHITESPACE
         """
         )
-        p = testdir.maketxtfile(
+        p = pytester.maketxtfile(
             xdoc="""
             >>> a = "foo    "
             >>> print(a)
             foo
         """
         )
-        reprec = testdir.inline_run(p, "--doctest-glob=x*.txt")
+        reprec = pytester.inline_run(p, "--doctest-glob=x*.txt")
         reprec.assertoutcome(passed=1)

-    def test_non_ignored_whitespace_glob(self, testdir):
-        testdir.makeini(
+    def test_non_ignored_whitespace_glob(self, pytester: Pytester):
+        pytester.makeini(
             """
             [pytest]
             doctest_optionflags = ELLIPSIS
         """
         )
-        p = testdir.maketxtfile(
+        p = pytester.maketxtfile(
             xdoc="""
             >>> a = "foo    "
             >>> print(a)
             foo
         """
         )
-        reprec = testdir.inline_run(p, "--doctest-glob=x*.txt")
+        reprec = pytester.inline_run(p, "--doctest-glob=x*.txt")
         reprec.assertoutcome(failed=1, passed=0)

-    def test_contains_unicode(self, testdir):
+    def test_contains_unicode(self, pytester: Pytester):
         """Fix internal error with docstrings containing non-ascii characters."""
-        testdir.makepyfile(
+        pytester.makepyfile(
             '''\
             def foo():
                 """
@@ -675,11 +687,11 @@
                 """
             '''
         )
-        result = testdir.runpytest("--doctest-modules")
+        result = pytester.runpytest("--doctest-modules")
         result.stdout.fnmatch_lines(["Got nothing", "* 1 failed in*"])

-    def test_ignore_import_errors_on_doctest(self, testdir):
-        p = testdir.makepyfile(
+    def test_ignore_import_errors_on_doctest(self, pytester: Pytester):
+        p = pytester.makepyfile(
             """
             import asdf

@@ -692,14 +704,14 @@
         """
         )

-        reprec = testdir.inline_run(
+        reprec = pytester.inline_run(
             p, "--doctest-modules", "--doctest-ignore-import-errors"
         )
         reprec.assertoutcome(skipped=1, failed=1, passed=0)

-    def test_junit_report_for_doctest(self, testdir):
+    def test_junit_report_for_doctest(self, pytester: Pytester):
         """#713: Fix --junit-xml option when used with --doctest-modules."""
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             """
             def foo():
                 '''
@@ -709,38 +721,37 @@
                 pass
         """
         )
-        reprec = testdir.inline_run(p, "--doctest-modules", "--junit-xml=junit.xml")
+        reprec = pytester.inline_run(p, "--doctest-modules", "--junit-xml=junit.xml")
         reprec.assertoutcome(failed=1)

-    def test_unicode_doctest(self, testdir):
+    def test_unicode_doctest(self, pytester: Pytester):
         """
         Test case for issue 2434: DecodeError on Python 2 when doctest contains non-ascii
         characters.
         """
-        p = testdir.maketxtfile(
+        p = pytester.maketxtfile(
             test_unicode_doctest="""
             .. doctest::

-                >>> print(
-                ...    "Hi\\n\\nByé")
+                >>> print("Hi\\n\\nByé")
                 Hi
                 ...
                 Byé
-                >>> 1/0  # Byé
+                >>> 1 / 0  # Byé
                 1
         """
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.stdout.fnmatch_lines(
             ["*UNEXPECTED EXCEPTION: ZeroDivisionError*", "*1 failed*"]
         )

-    def test_unicode_doctest_module(self, testdir):
+    def test_unicode_doctest_module(self, pytester: Pytester):
         """
         Test case for issue 2434: DecodeError on Python 2 when doctest docstring
         contains non-ascii characters.
         """
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             test_unicode_doctest_module="""
             def fix_bad_unicode(text):
                 '''
@@ -750,15 +761,15 @@
                 return "único"
         """
         )
-        result = testdir.runpytest(p, "--doctest-modules")
+        result = pytester.runpytest(p, "--doctest-modules")
         result.stdout.fnmatch_lines(["* 1 passed *"])

-    def test_print_unicode_value(self, testdir):
+    def test_print_unicode_value(self, pytester: Pytester):
         """
         Test case for issue 3583: Printing Unicode in doctest under Python 2.7
         doesn't work
         """
-        p = testdir.maketxtfile(
+        p = pytester.maketxtfile(
             test_print_unicode_value=r"""
             Here is a doctest::

@@ -766,12 +777,12 @@
                 åéîøü
         """
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.stdout.fnmatch_lines(["* 1 passed *"])

-    def test_reportinfo(self, testdir):
+    def test_reportinfo(self, pytester: Pytester):
         """Make sure that DoctestItem.reportinfo() returns lineno."""
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             test_reportinfo="""
             def foo(x):
                 '''
@@ -781,52 +792,58 @@
                 return 'c'
         """
         )
-        items, reprec = testdir.inline_genitems(p, "--doctest-modules")
+        items, reprec = pytester.inline_genitems(p, "--doctest-modules")
         reportinfo = items[0].reportinfo()
         assert reportinfo[1] == 1

-    def test_valid_setup_py(self, testdir):
+    def test_valid_setup_py(self, pytester: Pytester):
         """
         Test to make sure that pytest ignores valid setup.py files when ran
         with --doctest-modules
         """
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             setup="""
-            from setuptools import setup, find_packages
-            setup(name='sample',
-                  version='0.0',
-                  description='description',
-                  packages=find_packages()
-            )
-        """
-        )
-        result = testdir.runpytest(p, "--doctest-modules")
+            if __name__ == '__main__':
+                from setuptools import setup, find_packages
+                setup(name='sample',
+                      version='0.0',
+                      description='description',
+                      packages=find_packages()
+                )
+        """
+        )
+        result = pytester.runpytest(p, "--doctest-modules")
         result.stdout.fnmatch_lines(["*collected 0 items*"])

-    def test_invalid_setup_py(self, testdir):
+    def test_main_py_does_not_cause_import_errors(self, pytester: Pytester):
+        p = pytester.copy_example("doctest/main_py")
+        result = pytester.runpytest(p, "--doctest-modules")
+        result.stdout.fnmatch_lines(["*collected 2 items*", "*1 failed, 1 passed*"])
+
+    def test_invalid_setup_py(self, pytester: Pytester):
         """
         Test to make sure that pytest reads setup.py files that are not used
         for python packages when ran with --doctest-modules
         """
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             setup="""
             def test_foo():
                 return 'bar'
         """
         )
-        result = testdir.runpytest(p, "--doctest-modules")
+        result = pytester.runpytest(p, "--doctest-modules")
         result.stdout.fnmatch_lines(["*collected 1 item*"])


 class TestLiterals:
     @pytest.mark.parametrize("config_mode", ["ini", "comment"])
-    def test_allow_unicode(self, testdir, config_mode):
+    def test_allow_unicode(self, pytester, config_mode):
         """Test that doctests which output unicode work in all python versions
         tested by pytest when the ALLOW_UNICODE option is used (either in
         the ini file or by an inline comment).
         """
         if config_mode == "ini":
-            testdir.makeini(
+            pytester.makeini(
                 """
             [pytest]
             doctest_optionflags = ALLOW_UNICODE
@@ -836,7 +853,7 @@
         else:
             comment = "#doctest: +ALLOW_UNICODE"

-        testdir.maketxtfile(
+        pytester.maketxtfile(
             test_doc="""
             >>> b'12'.decode('ascii') {comment}
             '12'
@@ -844,7 +861,7 @@
                 comment=comment
             )
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             foo="""
             def foo():
               '''
@@ -855,17 +872,17 @@
                 comment=comment
             )
         )
-        reprec = testdir.inline_run("--doctest-modules")
+        reprec = pytester.inline_run("--doctest-modules")
         reprec.assertoutcome(passed=2)

     @pytest.mark.parametrize("config_mode", ["ini", "comment"])
-    def test_allow_bytes(self, testdir, config_mode):
+    def test_allow_bytes(self, pytester, config_mode):
         """Test that doctests which output bytes work in all python versions
         tested by pytest when the ALLOW_BYTES option is used (either in
         the ini file or by an inline comment)(#1287).
         """
         if config_mode == "ini":
-            testdir.makeini(
+            pytester.makeini(
                 """
             [pytest]
             doctest_optionflags = ALLOW_BYTES
@@ -875,7 +892,7 @@
         else:
             comment = "#doctest: +ALLOW_BYTES"

-        testdir.maketxtfile(
+        pytester.maketxtfile(
             test_doc="""
             >>> b'foo'  {comment}
             'foo'
@@ -883,7 +900,7 @@
                 comment=comment
             )
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             foo="""
             def foo():
               '''
@@ -894,34 +911,34 @@
                 comment=comment
             )
         )
-        reprec = testdir.inline_run("--doctest-modules")
+        reprec = pytester.inline_run("--doctest-modules")
         reprec.assertoutcome(passed=2)

-    def test_unicode_string(self, testdir):
+    def test_unicode_string(self, pytester: Pytester):
         """Test that doctests which output unicode fail in Python 2 when
         the ALLOW_UNICODE option is not used. The same test should pass
         in Python 3.
         """
-        testdir.maketxtfile(
+        pytester.maketxtfile(
             test_doc="""
             >>> b'12'.decode('ascii')
             '12'
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)

-    def test_bytes_literal(self, testdir):
+    def test_bytes_literal(self, pytester: Pytester):
         """Test that doctests which output bytes fail in Python 3 when
         the ALLOW_BYTES option is not used. (#1287).
         """
-        testdir.maketxtfile(
+        pytester.maketxtfile(
             test_doc="""
             >>> b'foo'
             'foo'
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(failed=1)

     def test_number_re(self) -> None:
@@ -955,10 +972,10 @@
             assert _number_re.match(s) is None

     @pytest.mark.parametrize("config_mode", ["ini", "comment"])
-    def test_number_precision(self, testdir, config_mode):
+    def test_number_precision(self, pytester, config_mode):
         """Test the NUMBER option."""
         if config_mode == "ini":
-            testdir.makeini(
+            pytester.makeini(
                 """
                 [pytest]
                 doctest_optionflags = NUMBER
@@ -968,7 +985,7 @@
         else:
             comment = "#doctest: +NUMBER"

-        testdir.maketxtfile(
+        pytester.maketxtfile(
             test_doc="""

             Scalars:
@@ -1025,7 +1042,7 @@
                 comment=comment
             )
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)

     @pytest.mark.parametrize(
@@ -1046,11 +1063,11 @@
             ("1e3", "999"),
             # The current implementation doesn't understand that numbers inside
             # strings shouldn't be treated as numbers:
-            pytest.param("'3.1416'", "'3.14'", marks=pytest.mark.xfail),  # type: ignore
+            pytest.param("'3.1416'", "'3.14'", marks=pytest.mark.xfail),
         ],
     )
-    def test_number_non_matches(self, testdir, expression, output):
-        testdir.maketxtfile(
+    def test_number_non_matches(self, pytester, expression, output):
+        pytester.maketxtfile(
             test_doc="""
             >>> {expression} #doctest: +NUMBER
             {output}
@@ -1058,11 +1075,11 @@
                 expression=expression, output=output
             )
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=0, failed=1)

-    def test_number_and_allow_unicode(self, testdir):
-        testdir.maketxtfile(
+    def test_number_and_allow_unicode(self, pytester: Pytester):
+        pytester.maketxtfile(
             test_doc="""
             >>> from collections import namedtuple
             >>> T = namedtuple('T', 'a b c')
@@ -1070,7 +1087,7 @@
             T(a=0.233, b=u'str', c='bytes')
             """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)


@@ -1081,18 +1098,18 @@
     """

     @pytest.fixture(params=["text", "module"])
-    def makedoctest(self, testdir, request):
+    def makedoctest(self, pytester, request):
         def makeit(doctest):
             mode = request.param
             if mode == "text":
-                testdir.maketxtfile(doctest)
+                pytester.maketxtfile(doctest)
             else:
                 assert mode == "module"
-                testdir.makepyfile('"""\n%s"""' % doctest)
+                pytester.makepyfile('"""\n%s"""' % doctest)

         return makeit

-    def test_one_skipped(self, testdir, makedoctest):
+    def test_one_skipped(self, pytester, makedoctest):
         makedoctest(
             """
             >>> 1 + 1  # doctest: +SKIP
@@ -1101,10 +1118,10 @@
             4
         """
         )
-        reprec = testdir.inline_run("--doctest-modules")
+        reprec = pytester.inline_run("--doctest-modules")
         reprec.assertoutcome(passed=1)

-    def test_one_skipped_failed(self, testdir, makedoctest):
+    def test_one_skipped_failed(self, pytester, makedoctest):
         makedoctest(
             """
             >>> 1 + 1  # doctest: +SKIP
@@ -1113,10 +1130,10 @@
             200
         """
         )
-        reprec = testdir.inline_run("--doctest-modules")
+        reprec = pytester.inline_run("--doctest-modules")
         reprec.assertoutcome(failed=1)

-    def test_all_skipped(self, testdir, makedoctest):
+    def test_all_skipped(self, pytester, makedoctest):
         makedoctest(
             """
             >>> 1 + 1  # doctest: +SKIP
@@ -1125,16 +1142,16 @@
             200
         """
         )
-        reprec = testdir.inline_run("--doctest-modules")
+        reprec = pytester.inline_run("--doctest-modules")
         reprec.assertoutcome(skipped=1)

-    def test_vacuous_all_skipped(self, testdir, makedoctest):
+    def test_vacuous_all_skipped(self, pytester, makedoctest):
         makedoctest("")
-        reprec = testdir.inline_run("--doctest-modules")
+        reprec = pytester.inline_run("--doctest-modules")
         reprec.assertoutcome(passed=0, skipped=0)

-    def test_continue_on_failure(self, testdir):
-        testdir.maketxtfile(
+    def test_continue_on_failure(self, pytester: Pytester):
+        pytester.maketxtfile(
             test_something="""
             >>> i = 5
             >>> def foo():
@@ -1146,7 +1163,9 @@
             >>> i + 1
         """
         )
-        result = testdir.runpytest("--doctest-modules", "--doctest-continue-on-failure")
+        result = pytester.runpytest(
+            "--doctest-modules", "--doctest-continue-on-failure"
+        )
         result.assert_outcomes(passed=0, failed=1)
         # The lines that contains the failure are 4, 5, and 8.  The first one
         # is a stack trace and the other two are mismatches.
@@ -1154,16 +1173,51 @@
             ["*4: UnexpectedException*", "*5: DocTestFailure*", "*8: DocTestFailure*"]
         )

+    def test_skipping_wrapped_test(self, pytester):
+        """
+        Issue 8796: INTERNALERROR raised when skipping a decorated DocTest
+        through pytest_collection_modifyitems.
+        """
+        pytester.makeconftest(
+            """
+            import pytest
+            from _pytest.doctest import DoctestItem
+
+            def pytest_collection_modifyitems(config, items):
+                skip_marker = pytest.mark.skip()
+
+                for item in items:
+                    if isinstance(item, DoctestItem):
+                        item.add_marker(skip_marker)
+            """
+        )
+
+        pytester.makepyfile(
+            """
+            from contextlib import contextmanager
+
+            @contextmanager
+            def my_config_context():
+                '''
+                >>> import os
+                '''
+            """
+        )
+
+        result = pytester.runpytest("--doctest-modules")
+        assert "INTERNALERROR" not in result.stdout.str()
+        result.assert_outcomes(skipped=1)
+

 class TestDoctestAutoUseFixtures:

     SCOPES = ["module", "session", "class", "function"]

-    def test_doctest_module_session_fixture(self, testdir):
+    def test_doctest_module_session_fixture(self, pytester: Pytester):
         """Test that session fixtures are initialized for doctest modules (#768)."""
         # session fixture which changes some global data, which will
         # be accessed by doctests in a module
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest
             import sys
@@ -1176,7 +1230,7 @@
                 del sys.pytest_session_data
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             foo="""
             import sys

@@ -1191,16 +1245,16 @@
               '''
         """
         )
-        result = testdir.runpytest("--doctest-modules")
+        result = pytester.runpytest("--doctest-modules")
         result.stdout.fnmatch_lines(["*2 passed*"])

     @pytest.mark.parametrize("scope", SCOPES)
     @pytest.mark.parametrize("enable_doctest", [True, False])
-    def test_fixture_scopes(self, testdir, scope, enable_doctest):
+    def test_fixture_scopes(self, pytester, scope, enable_doctest):
         """Test that auto-use fixtures work properly with doctest modules.
         See #1057 and #1100.
         """
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest

@@ -1211,7 +1265,7 @@
                 scope=scope
             )
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             test_1='''
             def test_foo():
                 """
@@ -1224,19 +1278,19 @@
         )
         params = ("--doctest-modules",) if enable_doctest else ()
         passes = 3 if enable_doctest else 2
-        result = testdir.runpytest(*params)
+        result = pytester.runpytest(*params)
         result.stdout.fnmatch_lines(["*=== %d passed in *" % passes])

     @pytest.mark.parametrize("scope", SCOPES)
     @pytest.mark.parametrize("autouse", [True, False])
     @pytest.mark.parametrize("use_fixture_in_doctest", [True, False])
     def test_fixture_module_doctest_scopes(
-        self, testdir, scope, autouse, use_fixture_in_doctest
+        self, pytester, scope, autouse, use_fixture_in_doctest
     ):
         """Test that auto-use fixtures work properly with doctest files.
         See #1057 and #1100.
         """
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest

@@ -1248,29 +1302,29 @@
             )
         )
         if use_fixture_in_doctest:
-            testdir.maketxtfile(
+            pytester.maketxtfile(
                 test_doc="""
                 >>> getfixture('auto')
                 99
             """
             )
         else:
-            testdir.maketxtfile(
+            pytester.maketxtfile(
                 test_doc="""
                 >>> 1 + 1
                 2
             """
             )
-        result = testdir.runpytest("--doctest-modules")
+        result = pytester.runpytest("--doctest-modules")
         result.stdout.no_fnmatch_line("*FAILURES*")
         result.stdout.fnmatch_lines(["*=== 1 passed in *"])

     @pytest.mark.parametrize("scope", SCOPES)
-    def test_auto_use_request_attributes(self, testdir, scope):
+    def test_auto_use_request_attributes(self, pytester, scope):
         """Check that all attributes of a request in an autouse fixture
         behave as expected when requested for a doctest item.
         """
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest

@@ -1287,13 +1341,13 @@
                 scope=scope
             )
         )
-        testdir.maketxtfile(
+        pytester.maketxtfile(
             test_doc="""
             >>> 1 + 1
             2
         """
         )
-        result = testdir.runpytest("--doctest-modules")
+        result = pytester.runpytest("--doctest-modules")
         str(result.stdout.no_fnmatch_line("*FAILURES*"))
         result.stdout.fnmatch_lines(["*=== 1 passed in *"])

@@ -1303,12 +1357,12 @@
     SCOPES = ["module", "session", "class", "function"]

     @pytest.mark.parametrize("scope", SCOPES)
-    def test_namespace_doctestfile(self, testdir, scope):
+    def test_namespace_doctestfile(self, pytester, scope):
         """
         Check that inserting something into the namespace works in a
         simple text file doctest
         """
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest
             import contextlib
@@ -1320,22 +1374,22 @@
                 scope=scope
             )
         )
-        p = testdir.maketxtfile(
+        p = pytester.maketxtfile(
             """
             >>> print(cl.__name__)
             contextlib
         """
         )
-        reprec = testdir.inline_run(p)
+        reprec = pytester.inline_run(p)
         reprec.assertoutcome(passed=1)

     @pytest.mark.parametrize("scope", SCOPES)
-    def test_namespace_pyfile(self, testdir, scope):
+    def test_namespace_pyfile(self, pytester, scope):
         """
         Check that inserting something into the namespace works in a
         simple Python file docstring doctest
         """
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest
             import contextlib
@@ -1347,7 +1401,7 @@
                 scope=scope
             )
         )
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             """
             def foo():
                 '''
@@ -1356,13 +1410,13 @@
                 '''
         """
         )
-        reprec = testdir.inline_run(p, "--doctest-modules")
+        reprec = pytester.inline_run(p, "--doctest-modules")
         reprec.assertoutcome(passed=1)


 class TestDoctestReportingOption:
-    def _run_doctest_report(self, testdir, format):
-        testdir.makepyfile(
+    def _run_doctest_report(self, pytester, format):
+        pytester.makepyfile(
             """
             def foo():
                 '''
@@ -1378,17 +1432,17 @@
                       '2  3  6')
             """
         )
-        return testdir.runpytest("--doctest-modules", "--doctest-report", format)
+        return pytester.runpytest("--doctest-modules", "--doctest-report", format)

     @pytest.mark.parametrize("format", ["udiff", "UDIFF", "uDiFf"])
-    def test_doctest_report_udiff(self, testdir, format):
-        result = self._run_doctest_report(testdir, format)
+    def test_doctest_report_udiff(self, pytester, format):
+        result = self._run_doctest_report(pytester, format)
         result.stdout.fnmatch_lines(
             ["     0  1  4", "    -1  2  4", "    +1  2  5", "     2  3  6"]
         )

-    def test_doctest_report_cdiff(self, testdir):
-        result = self._run_doctest_report(testdir, "cdiff")
+    def test_doctest_report_cdiff(self, pytester: Pytester):
+        result = self._run_doctest_report(pytester, "cdiff")
         result.stdout.fnmatch_lines(
             [
                 "         a  b",
@@ -1403,8 +1457,8 @@
             ]
         )

-    def test_doctest_report_ndiff(self, testdir):
-        result = self._run_doctest_report(testdir, "ndiff")
+    def test_doctest_report_ndiff(self, pytester: Pytester):
+        result = self._run_doctest_report(pytester, "ndiff")
         result.stdout.fnmatch_lines(
             [
                 "         a  b",
@@ -1418,8 +1472,8 @@
         )

     @pytest.mark.parametrize("format", ["none", "only_first_failure"])
-    def test_doctest_report_none_or_only_first_failure(self, testdir, format):
-        result = self._run_doctest_report(testdir, format)
+    def test_doctest_report_none_or_only_first_failure(self, pytester, format):
+        result = self._run_doctest_report(pytester, format)
         result.stdout.fnmatch_lines(
             [
                 "Expected:",
@@ -1435,8 +1489,8 @@
             ]
         )

-    def test_doctest_report_invalid(self, testdir):
-        result = self._run_doctest_report(testdir, "obviously_invalid_format")
+    def test_doctest_report_invalid(self, pytester: Pytester):
+        result = self._run_doctest_report(pytester, "obviously_invalid_format")
         result.stderr.fnmatch_lines(
             [
                 "*error: argument --doctest-report: invalid choice: 'obviously_invalid_format' (choose from*"
@@ -1445,9 +1499,9 @@


 @pytest.mark.parametrize("mock_module", ["mock", "unittest.mock"])
-def test_doctest_mock_objects_dont_recurse_missbehaved(mock_module, testdir):
+def test_doctest_mock_objects_dont_recurse_missbehaved(mock_module, pytester: Pytester):
     pytest.importorskip(mock_module)
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         from {mock_module} import call
         class Example(object):
@@ -1459,7 +1513,7 @@
             mock_module=mock_module
         )
     )
-    result = testdir.runpytest("--doctest-modules")
+    result = pytester.runpytest("--doctest-modules")
     result.stdout.fnmatch_lines(["* 1 passed *"])


@@ -1486,25 +1540,33 @@
     assert inspect.unwrap.__module__ == "inspect"


-def test_is_setup_py_not_named_setup_py(tmpdir):
-    not_setup_py = tmpdir.join("not_setup.py")
-    not_setup_py.write('from setuptools import setup; setup(name="foo")')
+def test_is_setup_py_not_named_setup_py(tmp_path: Path) -> None:
+    not_setup_py = tmp_path.joinpath("not_setup.py")
+    not_setup_py.write_text('from setuptools import setup; setup(name="foo")')
     assert not _is_setup_py(not_setup_py)


 @pytest.mark.parametrize("mod", ("setuptools", "distutils.core"))
-def test_is_setup_py_is_a_setup_py(tmpdir, mod):
-    setup_py = tmpdir.join("setup.py")
-    setup_py.write('from {} import setup; setup(name="foo")'.format(mod))
+def test_is_setup_py_is_a_setup_py(tmp_path: Path, mod: str) -> None:
+    setup_py = tmp_path.joinpath("setup.py")
+    setup_py.write_text(f'from {mod} import setup; setup(name="foo")', "utf-8")
     assert _is_setup_py(setup_py)


 @pytest.mark.parametrize("mod", ("setuptools", "distutils.core"))
-def test_is_setup_py_different_encoding(tmpdir, mod):
-    setup_py = tmpdir.join("setup.py")
+def test_is_setup_py_different_encoding(tmp_path: Path, mod: str) -> None:
+    setup_py = tmp_path.joinpath("setup.py")
     contents = (
         "# -*- coding: cp1252 -*-\n"
         'from {} import setup; setup(name="foo", description="€")\n'.format(mod)
     )
-    setup_py.write_binary(contents.encode("cp1252"))
+    setup_py.write_bytes(contents.encode("cp1252"))
     assert _is_setup_py(setup_py)
+
+
+@pytest.mark.parametrize(
+    "name, expected", [("__main__.py", True), ("__init__.py", False)]
+)
+def test_is_main_py(tmp_path: Path, name: str, expected: bool) -> None:
+    dunder_main = tmp_path.joinpath(name)
+    assert _is_main_py(dunder_main) == expected
('testing', 'test_compat.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -2,6 +2,7 @@
 import sys
 from functools import partial
 from functools import wraps
+from typing import TYPE_CHECKING
 from typing import Union

 import pytest
@@ -12,14 +13,14 @@
 from _pytest.compat import is_generator
 from _pytest.compat import safe_getattr
 from _pytest.compat import safe_isclass
-from _pytest.compat import TYPE_CHECKING
 from _pytest.outcomes import OutcomeException
+from _pytest.pytester import Pytester

 if TYPE_CHECKING:
     from typing_extensions import Literal


-def test_is_generator():
+def test_is_generator() -> None:
     def zap():
         yield  # pragma: no cover

@@ -30,13 +31,13 @@
     assert not is_generator(foo)


-def test_real_func_loop_limit():
+def test_real_func_loop_limit() -> None:
     class Evil:
         def __init__(self):
             self.left = 1000

         def __repr__(self):
-            return "<Evil left={left}>".format(left=self.left)
+            return f"<Evil left={self.left}>"

         def __getattr__(self, attr):
             if not self.left:
@@ -56,7 +57,7 @@
         get_real_func(evil)


-def test_get_real_func():
+def test_get_real_func() -> None:
     """Check that get_real_func correctly unwraps decorators until reaching the real function"""

     def decorator(f):
@@ -81,7 +82,7 @@
     assert get_real_func(wrapped_func2) is wrapped_func


-def test_get_real_func_partial():
+def test_get_real_func_partial() -> None:
     """Test get_real_func handles partial instances correctly"""

     def foo(x):
@@ -91,8 +92,9 @@
     assert get_real_func(partial(foo)) is foo


-def test_is_generator_asyncio(testdir):
-    testdir.makepyfile(
+@pytest.mark.skipif(sys.version_info >= (3, 11), reason="couroutine removed")
+def test_is_generator_asyncio(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         from _pytest.compat import is_generator
         import asyncio
@@ -106,12 +108,12 @@
     )
     # avoid importing asyncio into pytest's own process,
     # which in turn imports logging (#8)
-    result = testdir.runpytest_subprocess()
+    result = pytester.runpytest_subprocess()
     result.stdout.fnmatch_lines(["*1 passed*"])


-def test_is_generator_async_syntax(testdir):
-    testdir.makepyfile(
+def test_is_generator_async_syntax(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         from _pytest.compat import is_generator
         def test_is_generator_py35():
@@ -125,18 +127,15 @@
             assert not is_generator(bar)
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*1 passed*"])


-@pytest.mark.skipif(
-    sys.version_info < (3, 6), reason="async gen syntax available in Python 3.6+"
-)
-def test_is_generator_async_gen_syntax(testdir):
-    testdir.makepyfile(
+def test_is_generator_async_gen_syntax(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         from _pytest.compat import is_generator
-        def test_is_generator_py36():
+        def test_is_generator():
             async def foo():
                 yield
                 await foo()
@@ -148,7 +147,7 @@
             assert not is_generator(bar)
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*1 passed*"])


@@ -159,14 +158,14 @@

     @property
     def raise_exception(self):
-        raise Exception("exception should be catched")
+        raise Exception("exception should be caught")

     @property
     def raise_fail_outcome(self):
-        pytest.fail("fail should be catched")
-
-
-def test_helper_failures():
+        pytest.fail("fail should be caught")
+
+
+def test_helper_failures() -> None:
     helper = ErrorsHelper()
     with pytest.raises(Exception):
         helper.raise_exception
@@ -174,7 +173,7 @@
         helper.raise_fail_outcome


-def test_safe_getattr():
+def test_safe_getattr() -> None:
     helper = ErrorsHelper()
     assert safe_getattr(helper, "raise_exception", "default") == "default"
     assert safe_getattr(helper, "raise_fail_outcome", "default") == "default"
@@ -182,7 +181,7 @@
         assert safe_getattr(helper, "raise_baseexception", "default")


-def test_safe_isclass():
+def test_safe_isclass() -> None:
     assert safe_isclass(type) is True

     class CrappyClass(Exception):
@@ -215,7 +214,7 @@


 def test_assert_never_union() -> None:
-    x = 10  # type: Union[int, str]
+    x: Union[int, str] = 10

     if isinstance(x, int):
         pass
@@ -233,7 +232,7 @@

 def test_assert_never_enum() -> None:
     E = enum.Enum("E", "a b")
-    x = E.a  # type: E
+    x: E = E.a

     if x is E.a:
         pass
@@ -250,7 +249,7 @@


 def test_assert_never_literal() -> None:
-    x = "a"  # type: Literal["a", "b"]
+    x: Literal["a", "b"] = "a"

     if x == "a":
         pass
('testing', 'test_config.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -2,18 +2,19 @@
 import re
 import sys
 import textwrap
+from pathlib import Path
 from typing import Dict
 from typing import List
 from typing import Sequence
 from typing import Tuple
+from typing import Type
+from typing import Union

 import attr
-import py.path

 import _pytest._code
 import pytest
 from _pytest.compat import importlib_metadata
-from _pytest.compat import TYPE_CHECKING
 from _pytest.config import _get_plugin_specs_as_list
 from _pytest.config import _iter_rewritable_modules
 from _pytest.config import _strtobool
@@ -26,11 +27,8 @@
 from _pytest.config.findpaths import get_common_ancestor
 from _pytest.config.findpaths import locate_config
 from _pytest.monkeypatch import MonkeyPatch
-from _pytest.pathlib import Path
-from _pytest.pytester import Testdir
-
-if TYPE_CHECKING:
-    from typing import Type
+from _pytest.pathlib import absolutepath
+from _pytest.pytester import Pytester


 class TestParseIni:
@@ -39,7 +37,7 @@
     )
     def test_getcfg_and_config(
         self,
-        testdir: Testdir,
+        pytester: Pytester,
         tmp_path: Path,
         section: str,
         filename: str,
@@ -61,12 +59,12 @@
         )
         _, _, cfg = locate_config([sub])
         assert cfg["name"] == "value"
-        config = testdir.parseconfigure(str(sub))
+        config = pytester.parseconfigure(str(sub))
         assert config.inicfg["name"] == "value"

-    def test_setupcfg_uses_toolpytest_with_pytest(self, testdir):
-        p1 = testdir.makepyfile("def test(): pass")
-        testdir.makefile(
+    def test_setupcfg_uses_toolpytest_with_pytest(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile("def test(): pass")
+        pytester.makefile(
             ".cfg",
             setup="""
                 [tool:pytest]
@@ -74,15 +72,17 @@
                 [pytest]
                 testpaths=ignored
         """
-            % p1.basename,
-        )
-        result = testdir.runpytest()
+            % p1.name,
+        )
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*, configfile: setup.cfg, *", "* 1 passed in *"])
         assert result.ret == 0

-    def test_append_parse_args(self, testdir, tmpdir, monkeypatch):
+    def test_append_parse_args(
+        self, pytester: Pytester, tmp_path: Path, monkeypatch: MonkeyPatch
+    ) -> None:
         monkeypatch.setenv("PYTEST_ADDOPTS", '--color no -rs --tb="short"')
-        tmpdir.join("pytest.ini").write(
+        tmp_path.joinpath("pytest.ini").write_text(
             textwrap.dedent(
                 """\
                 [pytest]
@@ -90,21 +90,21 @@
                 """
             )
         )
-        config = testdir.parseconfig(tmpdir)
+        config = pytester.parseconfig(tmp_path)
         assert config.option.color == "no"
         assert config.option.reportchars == "s"
         assert config.option.tbstyle == "short"
         assert config.option.verbose

-    def test_tox_ini_wrong_version(self, testdir):
-        testdir.makefile(
+    def test_tox_ini_wrong_version(self, pytester: Pytester) -> None:
+        pytester.makefile(
             ".ini",
             tox="""
             [pytest]
             minversion=999.0
         """,
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret != 0
         result.stderr.fnmatch_lines(
             ["*tox.ini: 'minversion' requires pytest-999.0, actual pytest-*"]
@@ -114,8 +114,8 @@
         "section, name",
         [("tool:pytest", "setup.cfg"), ("pytest", "tox.ini"), ("pytest", "pytest.ini")],
     )
-    def test_ini_names(self, testdir, name, section):
-        testdir.tmpdir.join(name).write(
+    def test_ini_names(self, pytester: Pytester, name, section) -> None:
+        pytester.path.joinpath(name).write_text(
             textwrap.dedent(
                 """
             [{section}]
@@ -125,22 +125,22 @@
                 )
             )
         )
-        config = testdir.parseconfig()
+        config = pytester.parseconfig()
         assert config.getini("minversion") == "1.0"

-    def test_pyproject_toml(self, testdir):
-        testdir.makepyprojecttoml(
+    def test_pyproject_toml(self, pytester: Pytester) -> None:
+        pytester.makepyprojecttoml(
             """
             [tool.pytest.ini_options]
             minversion = "1.0"
         """
         )
-        config = testdir.parseconfig()
+        config = pytester.parseconfig()
         assert config.getini("minversion") == "1.0"

-    def test_toxini_before_lower_pytestini(self, testdir):
-        sub = testdir.tmpdir.mkdir("sub")
-        sub.join("tox.ini").write(
+    def test_toxini_before_lower_pytestini(self, pytester: Pytester) -> None:
+        sub = pytester.mkdir("sub")
+        sub.joinpath("tox.ini").write_text(
             textwrap.dedent(
                 """
             [pytest]
@@ -148,7 +148,7 @@
         """
             )
         )
-        testdir.tmpdir.join("pytest.ini").write(
+        pytester.path.joinpath("pytest.ini").write_text(
             textwrap.dedent(
                 """
             [pytest]
@@ -156,26 +156,36 @@
         """
             )
         )
-        config = testdir.parseconfigure(sub)
+        config = pytester.parseconfigure(sub)
         assert config.getini("minversion") == "2.0"

-    def test_ini_parse_error(self, testdir):
-        testdir.tmpdir.join("pytest.ini").write("addopts = -x")
-        result = testdir.runpytest()
+    def test_ini_parse_error(self, pytester: Pytester) -> None:
+        pytester.path.joinpath("pytest.ini").write_text("addopts = -x")
+        result = pytester.runpytest()
         assert result.ret != 0
-        result.stderr.fnmatch_lines(["ERROR: *pytest.ini:1: no section header defined"])
+        result.stderr.fnmatch_lines("ERROR: *pytest.ini:1: no section header defined")
+
+    def test_toml_parse_error(self, pytester: Pytester) -> None:
+        pytester.makepyprojecttoml(
+            """
+            \\"
+            """
+        )
+        result = pytester.runpytest()
+        assert result.ret != 0
+        result.stderr.fnmatch_lines("ERROR: *pyproject.toml: Invalid statement*")

     @pytest.mark.xfail(reason="probably not needed")
-    def test_confcutdir(self, testdir):
-        sub = testdir.mkdir("sub")
-        sub.chdir()
-        testdir.makeini(
+    def test_confcutdir(self, pytester: Pytester) -> None:
+        sub = pytester.mkdir("sub")
+        os.chdir(sub)
+        pytester.makeini(
             """
             [pytest]
             addopts = --qwe
         """
         )
-        result = testdir.inline_run("--confcutdir=.")
+        result = pytester.inline_run("--confcutdir=.")
         assert result.ret == 0

     @pytest.mark.parametrize(
@@ -246,24 +256,29 @@
     )
     @pytest.mark.filterwarnings("default")
     def test_invalid_config_options(
-        self, testdir, ini_file_text, invalid_keys, warning_output, exception_text
-    ):
-        testdir.makeconftest(
+        self,
+        pytester: Pytester,
+        ini_file_text,
+        invalid_keys,
+        warning_output,
+        exception_text,
+    ) -> None:
+        pytester.makeconftest(
             """
             def pytest_addoption(parser):
                 parser.addini("conftest_ini_key", "")
             """
         )
-        testdir.makepyfile("def test(): pass")
-        testdir.makeini(ini_file_text)
-
-        config = testdir.parseconfig()
+        pytester.makepyfile("def test(): pass")
+        pytester.makeini(ini_file_text)
+
+        config = pytester.parseconfig()
         assert sorted(config._get_unknown_ini_keys()) == sorted(invalid_keys)

-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(warning_output)

-        result = testdir.runpytest("--strict-config")
+        result = pytester.runpytest("--strict-config")
         if exception_text:
             result.stderr.fnmatch_lines("ERROR: " + exception_text)
             assert result.ret == pytest.ExitCode.USAGE_ERROR
@@ -272,9 +287,9 @@
             assert result.ret == pytest.ExitCode.OK

     @pytest.mark.filterwarnings("default")
-    def test_silence_unknown_key_warning(self, testdir: Testdir) -> None:
+    def test_silence_unknown_key_warning(self, pytester: Pytester) -> None:
         """Unknown config key warnings can be silenced using filterwarnings (#7620)"""
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
             filterwarnings =
@@ -282,15 +297,15 @@
             foobar=1
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.no_fnmatch_line("*PytestConfigWarning*")

-    @pytest.mark.filterwarnings("default")
+    @pytest.mark.filterwarnings("default::pytest.PytestConfigWarning")
     def test_disable_warnings_plugin_disables_config_warnings(
-        self, testdir: Testdir
+        self, pytester: Pytester
     ) -> None:
         """Disabling 'warnings' plugin also disables config time warnings"""
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest
             def pytest_configure(config):
@@ -300,17 +315,18 @@
                 )
         """
         )
-        result = testdir.runpytest("-pno:warnings")
+        result = pytester.runpytest("-pno:warnings")
         result.stdout.no_fnmatch_line("*PytestConfigWarning*")

     @pytest.mark.parametrize(
-        "ini_file_text, exception_text",
+        "ini_file_text, plugin_version, exception_text",
         [
             pytest.param(
                 """
                 [pytest]
                 required_plugins = a z
                 """,
+                "1.5",
                 "Missing required plugins: a, z",
                 id="2-missing",
             ),
@@ -319,6 +335,7 @@
                 [pytest]
                 required_plugins = a z myplugin
                 """,
+                "1.5",
                 "Missing required plugins: a, z",
                 id="2-missing-1-ok",
             ),
@@ -327,6 +344,7 @@
                 [pytest]
                 required_plugins = myplugin
                 """,
+                "1.5",
                 None,
                 id="1-ok",
             ),
@@ -335,6 +353,7 @@
                 [pytest]
                 required_plugins = myplugin==1.5
                 """,
+                "1.5",
                 None,
                 id="1-ok-pin-exact",
             ),
@@ -343,39 +362,57 @@
                 [pytest]
                 required_plugins = myplugin>1.0,<2.0
                 """,
+                "1.5",
                 None,
                 id="1-ok-pin-loose",
             ),
             pytest.param(
                 """
                 [pytest]
-                required_plugins = pyplugin==1.6
+                required_plugins = myplugin
                 """,
-                "Missing required plugins: pyplugin==1.6",
+                "1.5a1",
+                None,
+                id="1-ok-prerelease",
+            ),
+            pytest.param(
+                """
+                [pytest]
+                required_plugins = myplugin==1.6
+                """,
+                "1.5",
+                "Missing required plugins: myplugin==1.6",
                 id="missing-version",
             ),
             pytest.param(
                 """
                 [pytest]
-                required_plugins = pyplugin==1.6 other==1.0
+                required_plugins = myplugin==1.6 other==1.0
                 """,
-                "Missing required plugins: other==1.0, pyplugin==1.6",
+                "1.5",
+                "Missing required plugins: myplugin==1.6, other==1.0",
                 id="missing-versions",
             ),
             pytest.param(
                 """
                 [some_other_header]
-                required_plugins = wont be triggered
+                required_plugins = won't be triggered
                 [pytest]
                 """,
+                "1.5",
                 None,
                 id="invalid-header",
             ),
         ],
     )
     def test_missing_required_plugins(
-        self, testdir, monkeypatch, ini_file_text, exception_text
-    ):
+        self,
+        pytester: Pytester,
+        monkeypatch: MonkeyPatch,
+        ini_file_text: str,
+        plugin_version: str,
+        exception_text: str,
+    ) -> None:
         """Check 'required_plugins' option with various settings.

         This test installs a mock "myplugin-1.5" which is used in the parametrized test cases.
@@ -399,7 +436,7 @@
         class DummyDist:
             entry_points = attr.ib()
             files = ()
-            version = "1.5"
+            version = plugin_version

             @property
             def metadata(self):
@@ -408,26 +445,28 @@
         def my_dists():
             return [DummyDist(entry_points)]

-        testdir.makepyfile(myplugin1_module="# my plugin module")
-        testdir.syspathinsert()
+        pytester.makepyfile(myplugin1_module="# my plugin module")
+        pytester.syspathinsert()

         monkeypatch.setattr(importlib_metadata, "distributions", my_dists)
-        testdir.monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", raising=False)
-
-        testdir.makeini(ini_file_text)
+        monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", raising=False)
+
+        pytester.makeini(ini_file_text)

         if exception_text:
             with pytest.raises(pytest.UsageError, match=exception_text):
-                testdir.parseconfig()
+                pytester.parseconfig()
         else:
-            testdir.parseconfig()
-
-    def test_early_config_cmdline(self, testdir, monkeypatch):
+            pytester.parseconfig()
+
+    def test_early_config_cmdline(
+        self, pytester: Pytester, monkeypatch: MonkeyPatch
+    ) -> None:
         """early_config contains options registered by third-party plugins.

         This is a regression involving pytest-cov (and possibly others) introduced in #7700.
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             myplugin="""
             def pytest_addoption(parser):
                 parser.addoption('--foo', default=None, dest='foo')
@@ -437,50 +476,52 @@
             """
         )
         monkeypatch.setenv("PYTEST_PLUGINS", "myplugin")
-        testdir.syspathinsert()
-        result = testdir.runpytest("--foo=1")
+        pytester.syspathinsert()
+        result = pytester.runpytest("--foo=1")
         result.stdout.fnmatch_lines("* no tests ran in *")


 class TestConfigCmdlineParsing:
-    def test_parsing_again_fails(self, testdir):
-        config = testdir.parseconfig()
+    def test_parsing_again_fails(self, pytester: Pytester) -> None:
+        config = pytester.parseconfig()
         pytest.raises(AssertionError, lambda: config.parse([]))

-    def test_explicitly_specified_config_file_is_loaded(self, testdir):
-        testdir.makeconftest(
+    def test_explicitly_specified_config_file_is_loaded(
+        self, pytester: Pytester
+    ) -> None:
+        pytester.makeconftest(
             """
             def pytest_addoption(parser):
                 parser.addini("custom", "")
         """
         )
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
             custom = 0
         """
         )
-        testdir.makefile(
+        pytester.makefile(
             ".ini",
             custom="""
             [pytest]
             custom = 1
         """,
         )
-        config = testdir.parseconfig("-c", "custom.ini")
+        config = pytester.parseconfig("-c", "custom.ini")
         assert config.getini("custom") == "1"

-        testdir.makefile(
+        pytester.makefile(
             ".cfg",
             custom_tool_pytest_section="""
             [tool:pytest]
             custom = 1
         """,
         )
-        config = testdir.parseconfig("-c", "custom_tool_pytest_section.cfg")
+        config = pytester.parseconfig("-c", "custom_tool_pytest_section.cfg")
         assert config.getini("custom") == "1"

-        testdir.makefile(
+        pytester.makefile(
             ".toml",
             custom="""
                 [tool.pytest.ini_options]
@@ -489,11 +530,11 @@
                 ]  # this is here on purpose, as it makes this an invalid '.ini' file
             """,
         )
-        config = testdir.parseconfig("-c", "custom.toml")
+        config = pytester.parseconfig("-c", "custom.toml")
         assert config.getini("custom") == "1"

-    def test_absolute_win32_path(self, testdir):
-        temp_ini_file = testdir.makefile(
+    def test_absolute_win32_path(self, pytester: Pytester) -> None:
+        temp_ini_file = pytester.makefile(
             ".ini",
             custom="""
             [pytest]
@@ -502,134 +543,139 @@
         )
         from os.path import normpath

-        temp_ini_file = normpath(str(temp_ini_file))
-        ret = pytest.main(["-c", temp_ini_file])
+        temp_ini_file_norm = normpath(str(temp_ini_file))
+        ret = pytest.main(["-c", temp_ini_file_norm])
         assert ret == ExitCode.OK


 class TestConfigAPI:
-    def test_config_trace(self, testdir) -> None:
-        config = testdir.parseconfig()
-        values = []  # type: List[str]
+    def test_config_trace(self, pytester: Pytester) -> None:
+        config = pytester.parseconfig()
+        values: List[str] = []
         config.trace.root.setwriter(values.append)
         config.trace("hello")
         assert len(values) == 1
         assert values[0] == "hello [config]\n"

-    def test_config_getoption(self, testdir):
-        testdir.makeconftest(
+    def test_config_getoption(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             def pytest_addoption(parser):
                 parser.addoption("--hello", "-X", dest="hello")
         """
         )
-        config = testdir.parseconfig("--hello=this")
+        config = pytester.parseconfig("--hello=this")
         for x in ("hello", "--hello", "-X"):
             assert config.getoption(x) == "this"
         pytest.raises(ValueError, config.getoption, "qweqwe")

-    def test_config_getoption_unicode(self, testdir):
-        testdir.makeconftest(
+    def test_config_getoption_unicode(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             def pytest_addoption(parser):
                 parser.addoption('--hello', type=str)
         """
         )
-        config = testdir.parseconfig("--hello=this")
+        config = pytester.parseconfig("--hello=this")
         assert config.getoption("hello") == "this"

-    def test_config_getvalueorskip(self, testdir):
-        config = testdir.parseconfig()
+    def test_config_getvalueorskip(self, pytester: Pytester) -> None:
+        config = pytester.parseconfig()
         pytest.raises(pytest.skip.Exception, config.getvalueorskip, "hello")
         verbose = config.getvalueorskip("verbose")
         assert verbose == config.option.verbose

-    def test_config_getvalueorskip_None(self, testdir):
-        testdir.makeconftest(
+    def test_config_getvalueorskip_None(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             def pytest_addoption(parser):
                 parser.addoption("--hello")
         """
         )
-        config = testdir.parseconfig()
+        config = pytester.parseconfig()
         with pytest.raises(pytest.skip.Exception):
             config.getvalueorskip("hello")

-    def test_getoption(self, testdir):
-        config = testdir.parseconfig()
+    def test_getoption(self, pytester: Pytester) -> None:
+        config = pytester.parseconfig()
         with pytest.raises(ValueError):
             config.getvalue("x")
         assert config.getoption("x", 1) == 1

-    def test_getconftest_pathlist(self, testdir, tmpdir):
-        somepath = tmpdir.join("x", "y", "z")
-        p = tmpdir.join("conftest.py")
-        p.write("pathlist = ['.', %r]" % str(somepath))
-        config = testdir.parseconfigure(p)
-        assert config._getconftest_pathlist("notexist", path=tmpdir) is None
-        pl = config._getconftest_pathlist("pathlist", path=tmpdir)
+    def test_getconftest_pathlist(self, pytester: Pytester, tmp_path: Path) -> None:
+        somepath = tmp_path.joinpath("x", "y", "z")
+        p = tmp_path.joinpath("conftest.py")
+        p.write_text(f"mylist = {['.', str(somepath)]}")
+        config = pytester.parseconfigure(p)
+        assert (
+            config._getconftest_pathlist("notexist", path=tmp_path, rootpath=tmp_path)
+            is None
+        )
+        pl = (
+            config._getconftest_pathlist("mylist", path=tmp_path, rootpath=tmp_path)
+            or []
+        )
         print(pl)
         assert len(pl) == 2
-        assert pl[0] == tmpdir
+        assert pl[0] == tmp_path
         assert pl[1] == somepath

-    def test_addini(self, testdir):
-        testdir.makeconftest(
-            """
+    @pytest.mark.parametrize("maybe_type", ["not passed", "None", '"string"'])
+    def test_addini(self, pytester: Pytester, maybe_type: str) -> None:
+        if maybe_type == "not passed":
+            type_string = ""
+        else:
+            type_string = f", {maybe_type}"
+
+        pytester.makeconftest(
+            f"""
             def pytest_addoption(parser):
-                parser.addini("myname", "my new ini value")
-        """
-        )
-        testdir.makeini(
+                parser.addini("myname", "my new ini value"{type_string})
+        """
+        )
+        pytester.makeini(
             """
             [pytest]
             myname=hello
         """
         )
-        config = testdir.parseconfig()
+        config = pytester.parseconfig()
         val = config.getini("myname")
         assert val == "hello"
         pytest.raises(ValueError, config.getini, "other")

-    def make_conftest_for_pathlist(self, testdir):
-        testdir.makeconftest(
+    @pytest.mark.parametrize("config_type", ["ini", "pyproject"])
+    def test_addini_paths(self, pytester: Pytester, config_type: str) -> None:
+        pytester.makeconftest(
             """
             def pytest_addoption(parser):
-                parser.addini("paths", "my new ini value", type="pathlist")
+                parser.addini("paths", "my new ini value", type="paths")
                 parser.addini("abc", "abc value")
         """
         )
-
-    def test_addini_pathlist_ini_files(self, testdir):
-        self.make_conftest_for_pathlist(testdir)
-        p = testdir.makeini(
-            """
-            [pytest]
-            paths=hello world/sub.py
-        """
-        )
-        self.check_config_pathlist(testdir, p)
-
-    def test_addini_pathlist_pyproject_toml(self, testdir):
-        self.make_conftest_for_pathlist(testdir)
-        p = testdir.makepyprojecttoml(
-            """
-            [tool.pytest.ini_options]
-            paths=["hello", "world/sub.py"]
-        """
-        )
-        self.check_config_pathlist(testdir, p)
-
-    def check_config_pathlist(self, testdir, config_path):
-        config = testdir.parseconfig()
+        if config_type == "ini":
+            inipath = pytester.makeini(
+                """
+                [pytest]
+                paths=hello world/sub.py
+            """
+            )
+        elif config_type == "pyproject":
+            inipath = pytester.makepyprojecttoml(
+                """
+                [tool.pytest.ini_options]
+                paths=["hello", "world/sub.py"]
+            """
+            )
+        config = pytester.parseconfig()
         values = config.getini("paths")
         assert len(values) == 2
-        assert values[0] == config_path.dirpath("hello")
-        assert values[1] == config_path.dirpath("world/sub.py")
+        assert values[0] == inipath.parent.joinpath("hello")
+        assert values[1] == inipath.parent.joinpath("world/sub.py")
         pytest.raises(ValueError, config.getini, "other")

-    def make_conftest_for_args(self, testdir):
-        testdir.makeconftest(
+    def make_conftest_for_args(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             def pytest_addoption(parser):
                 parser.addini("args", "new args", type="args")
@@ -637,35 +683,35 @@
         """
         )

-    def test_addini_args_ini_files(self, testdir):
-        self.make_conftest_for_args(testdir)
-        testdir.makeini(
+    def test_addini_args_ini_files(self, pytester: Pytester) -> None:
+        self.make_conftest_for_args(pytester)
+        pytester.makeini(
             """
             [pytest]
             args=123 "123 hello" "this"
             """
         )
-        self.check_config_args(testdir)
-
-    def test_addini_args_pyproject_toml(self, testdir):
-        self.make_conftest_for_args(testdir)
-        testdir.makepyprojecttoml(
+        self.check_config_args(pytester)
+
+    def test_addini_args_pyproject_toml(self, pytester: Pytester) -> None:
+        self.make_conftest_for_args(pytester)
+        pytester.makepyprojecttoml(
             """
             [tool.pytest.ini_options]
             args = ["123", "123 hello", "this"]
             """
         )
-        self.check_config_args(testdir)
-
-    def check_config_args(self, testdir):
-        config = testdir.parseconfig()
+        self.check_config_args(pytester)
+
+    def check_config_args(self, pytester: Pytester) -> None:
+        config = pytester.parseconfig()
         values = config.getini("args")
         assert values == ["123", "123 hello", "this"]
         values = config.getini("a2")
         assert values == list("123")

-    def make_conftest_for_linelist(self, testdir):
-        testdir.makeconftest(
+    def make_conftest_for_linelist(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             def pytest_addoption(parser):
                 parser.addini("xy", "", type="linelist")
@@ -673,29 +719,29 @@
         """
         )

-    def test_addini_linelist_ini_files(self, testdir):
-        self.make_conftest_for_linelist(testdir)
-        testdir.makeini(
+    def test_addini_linelist_ini_files(self, pytester: Pytester) -> None:
+        self.make_conftest_for_linelist(pytester)
+        pytester.makeini(
             """
             [pytest]
             xy= 123 345
                 second line
         """
         )
-        self.check_config_linelist(testdir)
-
-    def test_addini_linelist_pprojecttoml(self, testdir):
-        self.make_conftest_for_linelist(testdir)
-        testdir.makepyprojecttoml(
+        self.check_config_linelist(pytester)
+
+    def test_addini_linelist_pprojecttoml(self, pytester: Pytester) -> None:
+        self.make_conftest_for_linelist(pytester)
+        pytester.makepyprojecttoml(
             """
             [tool.pytest.ini_options]
             xy = ["123 345", "second line"]
         """
         )
-        self.check_config_linelist(testdir)
-
-    def check_config_linelist(self, testdir):
-        config = testdir.parseconfig()
+        self.check_config_linelist(pytester)
+
+    def check_config_linelist(self, pytester: Pytester) -> None:
+        config = pytester.parseconfig()
         values = config.getini("xy")
         assert len(values) == 2
         assert values == ["123 345", "second line"]
@@ -705,38 +751,40 @@
     @pytest.mark.parametrize(
         "str_val, bool_val", [("True", True), ("no", False), ("no-ini", True)]
     )
-    def test_addini_bool(self, testdir, str_val, bool_val):
-        testdir.makeconftest(
+    def test_addini_bool(
+        self, pytester: Pytester, str_val: str, bool_val: bool
+    ) -> None:
+        pytester.makeconftest(
             """
             def pytest_addoption(parser):
                 parser.addini("strip", "", type="bool", default=True)
         """
         )
         if str_val != "no-ini":
-            testdir.makeini(
+            pytester.makeini(
                 """
                 [pytest]
                 strip=%s
             """
                 % str_val
             )
-        config = testdir.parseconfig()
+        config = pytester.parseconfig()
         assert config.getini("strip") is bool_val

-    def test_addinivalue_line_existing(self, testdir):
-        testdir.makeconftest(
+    def test_addinivalue_line_existing(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             def pytest_addoption(parser):
                 parser.addini("xy", "", type="linelist")
         """
         )
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
             xy= 123
         """
         )
-        config = testdir.parseconfig()
+        config = pytester.parseconfig()
         values = config.getini("xy")
         assert len(values) == 1
         assert values == ["123"]
@@ -745,14 +793,14 @@
         assert len(values) == 2
         assert values == ["123", "456"]

-    def test_addinivalue_line_new(self, testdir):
-        testdir.makeconftest(
+    def test_addinivalue_line_new(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             def pytest_addoption(parser):
                 parser.addini("xy", "", type="linelist")
         """
         )
-        config = testdir.parseconfig()
+        config = pytester.parseconfig()
         assert not config.getini("xy")
         config.addinivalue_line("xy", "456")
         values = config.getini("xy")
@@ -763,19 +811,17 @@
         assert len(values) == 2
         assert values == ["456", "123"]

-    def test_confcutdir_check_isdir(self, testdir):
+    def test_confcutdir_check_isdir(self, pytester: Pytester) -> None:
         """Give an error if --confcutdir is not a valid directory (#2078)"""
         exp_match = r"^--confcutdir must be a directory, given: "
         with pytest.raises(pytest.UsageError, match=exp_match):
-            testdir.parseconfig(
-                "--confcutdir", testdir.tmpdir.join("file").ensure(file=1)
-            )
+            pytester.parseconfig("--confcutdir", pytester.path.joinpath("file"))
         with pytest.raises(pytest.UsageError, match=exp_match):
-            testdir.parseconfig("--confcutdir", testdir.tmpdir.join("inexistant"))
-        config = testdir.parseconfig(
-            "--confcutdir", testdir.tmpdir.join("dir").ensure(dir=1)
-        )
-        assert config.getoption("confcutdir") == str(testdir.tmpdir.join("dir"))
+            pytester.parseconfig("--confcutdir", pytester.path.joinpath("nonexistent"))
+
+        p = pytester.mkdir("dir")
+        config = pytester.parseconfig("--confcutdir", p)
+        assert config.getoption("confcutdir") == str(p)

     @pytest.mark.parametrize(
         "names, expected",
@@ -793,12 +839,12 @@
             (["source/python/bar/__init__.py", "setup.py"], ["bar"]),
         ],
     )
-    def test_iter_rewritable_modules(self, names, expected):
+    def test_iter_rewritable_modules(self, names, expected) -> None:
         assert list(_iter_rewritable_modules(names)) == expected


 class TestConfigFromdictargs:
-    def test_basic_behavior(self, _sys_snapshot):
+    def test_basic_behavior(self, _sys_snapshot) -> None:
         option_dict = {"verbose": 444, "foo": "bar", "capture": "no"}
         args = ["a", "b"]

@@ -812,7 +858,7 @@

     def test_invocation_params_args(self, _sys_snapshot) -> None:
         """Show that fromdictargs can handle args in their "orig" format"""
-        option_dict = {}  # type: Dict[str, object]
+        option_dict: Dict[str, object] = {}
         args = ["-vvvv", "-s", "a", "b"]

         config = Config.fromdictargs(option_dict, args)
@@ -821,8 +867,12 @@
         assert config.option.verbose == 4
         assert config.option.capture == "no"

-    def test_inifilename(self, tmpdir):
-        tmpdir.join("foo/bar.ini").ensure().write(
+    def test_inifilename(self, tmp_path: Path) -> None:
+        d1 = tmp_path.joinpath("foo")
+        d1.mkdir()
+        p1 = d1.joinpath("bar.ini")
+        p1.touch()
+        p1.write_text(
             textwrap.dedent(
                 """\
                 [pytest]
@@ -831,11 +881,14 @@
             )
         )

-        inifile = "../../foo/bar.ini"
-        option_dict = {"inifilename": inifile, "capture": "no"}
-
-        cwd = tmpdir.join("a/b")
-        cwd.join("pytest.ini").ensure().write(
+        inifilename = "../../foo/bar.ini"
+        option_dict = {"inifilename": inifilename, "capture": "no"}
+
+        cwd = tmp_path.joinpath("a/b")
+        cwd.mkdir(parents=True)
+        p2 = cwd.joinpath("pytest.ini")
+        p2.touch()
+        p2.write_text(
             textwrap.dedent(
                 """\
                 [pytest]
@@ -844,32 +897,35 @@
                 """
             )
         )
-        with cwd.ensure(dir=True).as_cwd():
+        with MonkeyPatch.context() as mp:
+            mp.chdir(cwd)
             config = Config.fromdictargs(option_dict, ())
-            inipath = py.path.local(inifile)
+            inipath = absolutepath(inifilename)

         assert config.args == [str(cwd)]
-        assert config.option.inifilename == inifile
+        assert config.option.inifilename == inifilename
         assert config.option.capture == "no"

         # this indicates this is the file used for getting configuration values
-        assert config.inifile == inipath
+        assert config.inipath == inipath
         assert config.inicfg.get("name") == "value"
         assert config.inicfg.get("should_not_be_set") is None


-def test_options_on_small_file_do_not_blow_up(testdir) -> None:
+def test_options_on_small_file_do_not_blow_up(pytester: Pytester) -> None:
     def runfiletest(opts: Sequence[str]) -> None:
-        reprec = testdir.inline_run(*opts)
+        reprec = pytester.inline_run(*opts)
         passed, skipped, failed = reprec.countoutcomes()
         assert failed == 2
         assert skipped == passed == 0

-    path = testdir.makepyfile(
-        """
+    path = str(
+        pytester.makepyfile(
+            """
         def test_f1(): assert 0
         def test_f2(): assert 0
     """
+        )
     )

     runfiletest([path])
@@ -884,7 +940,9 @@
     runfiletest(["-v", "-v", path])


-def test_preparse_ordering_with_setuptools(testdir, monkeypatch):
+def test_preparse_ordering_with_setuptools(
+    pytester: Pytester, monkeypatch: MonkeyPatch
+) -> None:
     monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", raising=False)

     class EntryPoint:
@@ -906,18 +964,20 @@
         return (Dist,)

     monkeypatch.setattr(importlib_metadata, "distributions", my_dists)
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         pytest_plugins = "mytestplugin",
     """
     )
     monkeypatch.setenv("PYTEST_PLUGINS", "mytestplugin")
-    config = testdir.parseconfig()
+    config = pytester.parseconfig()
     plugin = config.pluginmanager.getplugin("mytestplugin")
     assert plugin.x == 42


-def test_setuptools_importerror_issue1479(testdir, monkeypatch):
+def test_setuptools_importerror_issue1479(
+    pytester: Pytester, monkeypatch: MonkeyPatch
+) -> None:
     monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", raising=False)

     class DummyEntryPoint:
@@ -938,10 +998,12 @@

     monkeypatch.setattr(importlib_metadata, "distributions", distributions)
     with pytest.raises(ImportError):
-        testdir.parseconfig()
-
-
-def test_importlib_metadata_broken_distribution(testdir, monkeypatch):
+        pytester.parseconfig()
+
+
+def test_importlib_metadata_broken_distribution(
+    pytester: Pytester, monkeypatch: MonkeyPatch
+) -> None:
     """Integration test for broken distributions with 'files' metadata being None (#5389)"""
     monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", raising=False)

@@ -962,11 +1024,13 @@
         return (Distribution(),)

     monkeypatch.setattr(importlib_metadata, "distributions", distributions)
-    testdir.parseconfig()
+    pytester.parseconfig()


 @pytest.mark.parametrize("block_it", [True, False])
-def test_plugin_preparse_prevents_setuptools_loading(testdir, monkeypatch, block_it):
+def test_plugin_preparse_prevents_setuptools_loading(
+    pytester: Pytester, monkeypatch: MonkeyPatch, block_it: bool
+) -> None:
     monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", raising=False)

     plugin_module_placeholder = object()
@@ -989,7 +1053,7 @@

     monkeypatch.setattr(importlib_metadata, "distributions", distributions)
     args = ("-p", "no:mytestplugin") if block_it else ()
-    config = testdir.parseconfig(*args)
+    config = pytester.parseconfig(*args)
     config.pluginmanager.import_plugin("mytestplugin")
     if block_it:
         assert "mytestplugin" not in sys.modules
@@ -1003,7 +1067,12 @@
 @pytest.mark.parametrize(
     "parse_args,should_load", [(("-p", "mytestplugin"), True), ((), False)]
 )
-def test_disable_plugin_autoload(testdir, monkeypatch, parse_args, should_load):
+def test_disable_plugin_autoload(
+    pytester: Pytester,
+    monkeypatch: MonkeyPatch,
+    parse_args: Union[Tuple[str, str], Tuple[()]],
+    should_load: bool,
+) -> None:
     class DummyEntryPoint:
         project_name = name = "mytestplugin"
         group = "pytest11"
@@ -1032,8 +1101,8 @@

     monkeypatch.setenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", "1")
     monkeypatch.setattr(importlib_metadata, "distributions", distributions)
-    monkeypatch.setitem(sys.modules, "mytestplugin", PseudoPlugin())
-    config = testdir.parseconfig(*parse_args)
+    monkeypatch.setitem(sys.modules, "mytestplugin", PseudoPlugin())  # type: ignore[misc]
+    config = pytester.parseconfig(*parse_args)
     has_loaded = config.pluginmanager.get_plugin("mytestplugin") is not None
     assert has_loaded == should_load
     if should_load:
@@ -1042,9 +1111,9 @@
         assert PseudoPlugin.attrs_used == []


-def test_plugin_loading_order(testdir):
+def test_plugin_loading_order(pytester: Pytester) -> None:
     """Test order of plugin loading with `-p`."""
-    p1 = testdir.makepyfile(
+    p1 = pytester.makepyfile(
         """
         def test_terminal_plugin(request):
             import myplugin
@@ -1063,37 +1132,37 @@
             """
         },
     )
-    testdir.syspathinsert()
-    result = testdir.runpytest("-p", "myplugin", str(p1))
+    pytester.syspathinsert()
+    result = pytester.runpytest("-p", "myplugin", str(p1))
     assert result.ret == 0


-def test_cmdline_processargs_simple(testdir):
-    testdir.makeconftest(
+def test_cmdline_processargs_simple(pytester: Pytester) -> None:
+    pytester.makeconftest(
         """
         def pytest_cmdline_preparse(args):
             args.append("-h")
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*pytest*", "*-h*"])


-def test_invalid_options_show_extra_information(testdir):
+def test_invalid_options_show_extra_information(pytester: Pytester) -> None:
     """Display extra information when pytest exits due to unrecognized
     options in the command-line."""
-    testdir.makeini(
+    pytester.makeini(
         """
         [pytest]
         addopts = --invalid-option
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stderr.fnmatch_lines(
         [
             "*error: unrecognized arguments: --invalid-option*",
-            "*  inifile: %s*" % testdir.tmpdir.join("tox.ini"),
-            "*  rootdir: %s*" % testdir.tmpdir,
+            "*  inifile: %s*" % pytester.path.joinpath("tox.ini"),
+            "*  rootdir: %s*" % pytester.path,
         ]
     )

@@ -1107,42 +1176,49 @@
         ["-v", "dir2", "dir1"],
     ],
 )
-def test_consider_args_after_options_for_rootdir(testdir, args):
+def test_consider_args_after_options_for_rootdir(
+    pytester: Pytester, args: List[str]
+) -> None:
     """
     Consider all arguments in the command-line for rootdir
     discovery, even if they happen to occur after an option. #949
     """
     # replace "dir1" and "dir2" from "args" into their real directory
-    root = testdir.tmpdir.mkdir("myroot")
-    d1 = root.mkdir("dir1")
-    d2 = root.mkdir("dir2")
+    root = pytester.mkdir("myroot")
+    d1 = root.joinpath("dir1")
+    d1.mkdir()
+    d2 = root.joinpath("dir2")
+    d2.mkdir()
     for i, arg in enumerate(args):
         if arg == "dir1":
-            args[i] = d1
+            args[i] = str(d1)
         elif arg == "dir2":
-            args[i] = d2
-    with root.as_cwd():
-        result = testdir.runpytest(*args)
+            args[i] = str(d2)
+    with MonkeyPatch.context() as mp:
+        mp.chdir(root)
+        result = pytester.runpytest(*args)
     result.stdout.fnmatch_lines(["*rootdir: *myroot"])


-def test_toolongargs_issue224(testdir):
-    result = testdir.runpytest("-m", "hello" * 500)
+def test_toolongargs_issue224(pytester: Pytester) -> None:
+    result = pytester.runpytest("-m", "hello" * 500)
     assert result.ret == ExitCode.NO_TESTS_COLLECTED


-def test_config_in_subdirectory_colon_command_line_issue2148(testdir):
+def test_config_in_subdirectory_colon_command_line_issue2148(
+    pytester: Pytester,
+) -> None:
     conftest_source = """
         def pytest_addoption(parser):
             parser.addini('foo', 'foo')
     """

-    testdir.makefile(
+    pytester.makefile(
         ".ini",
         **{"pytest": "[pytest]\nfoo = root", "subdir/pytest": "[pytest]\nfoo = subdir"},
     )

-    testdir.makepyfile(
+    pytester.makepyfile(
         **{
             "conftest": conftest_source,
             "subdir/conftest": conftest_source,
@@ -1153,12 +1229,12 @@
         }
     )

-    result = testdir.runpytest("subdir/test_foo.py::test_foo")
+    result = pytester.runpytest("subdir/test_foo.py::test_foo")
     assert result.ret == 0


-def test_notify_exception(testdir, capfd):
-    config = testdir.parseconfig()
+def test_notify_exception(pytester: Pytester, capfd) -> None:
+    config = pytester.parseconfig()
     with pytest.raises(ValueError) as excinfo:
         raise ValueError(1)
     config.notify_exception(excinfo, config.option)
@@ -1174,7 +1250,7 @@
     _, err = capfd.readouterr()
     assert not err

-    config = testdir.parseconfig("-p", "no:terminal")
+    config = pytester.parseconfig("-p", "no:terminal")
     with pytest.raises(ValueError) as excinfo:
         raise ValueError(1)
     config.notify_exception(excinfo, config.option)
@@ -1182,9 +1258,9 @@
     assert "ValueError" in err


-def test_no_terminal_discovery_error(testdir):
-    testdir.makepyfile("raise TypeError('oops!')")
-    result = testdir.runpytest("-p", "no:terminal", "--collect-only")
+def test_no_terminal_discovery_error(pytester: Pytester) -> None:
+    pytester.makepyfile("raise TypeError('oops!')")
+    result = pytester.runpytest("-p", "no:terminal", "--collect-only")
     assert result.ret == ExitCode.INTERRUPTED


@@ -1198,9 +1274,21 @@
     m = My()
     pm.register(m)
     hc = pm.hook.pytest_load_initial_conftests
-    values = hc._nonwrappers + hc._wrappers
-    expected = ["_pytest.config", m.__module__, "_pytest.capture", "_pytest.warnings"]
-    assert [x.function.__module__ for x in values] == expected
+    hookimpls = [
+        (
+            hookimpl.function.__module__,
+            "wrapper" if hookimpl.hookwrapper else "nonwrapper",
+        )
+        for hookimpl in hc.get_hookimpls()
+    ]
+    assert hookimpls == [
+        ("_pytest.config", "nonwrapper"),
+        (m.__module__, "nonwrapper"),
+        ("_pytest.legacypath", "nonwrapper"),
+        ("_pytest.python_path", "nonwrapper"),
+        ("_pytest.capture", "wrapper"),
+        ("_pytest.warnings", "wrapper"),
+    ]


 def test_get_plugin_specs_as_list() -> None:
@@ -1223,10 +1311,10 @@
     assert _get_plugin_specs_as_list(("foo", "bar")) == ["foo", "bar"]


-def test_collect_pytest_prefix_bug_integration(testdir):
+def test_collect_pytest_prefix_bug_integration(pytester: Pytester) -> None:
     """Integration test for issue #3775"""
-    p = testdir.copy_example("config/collect_pytest_prefix")
-    result = testdir.runpytest(p)
+    p = pytester.copy_example("config/collect_pytest_prefix")
+    result = pytester.runpytest(p)
     result.stdout.fnmatch_lines(["* 1 passed *"])


@@ -1332,6 +1420,26 @@
         assert inipath == p
         assert ini_config == {"x": "10"}

+    def test_explicit_config_file_sets_rootdir(
+        self, tmp_path: Path, monkeypatch: pytest.MonkeyPatch
+    ) -> None:
+        tests_dir = tmp_path / "tests"
+        tests_dir.mkdir()
+
+        monkeypatch.chdir(tmp_path)
+
+        # No config file is explicitly given: rootdir is determined to be cwd.
+        rootpath, found_inipath, *_ = determine_setup(None, [str(tests_dir)])
+        assert rootpath == tmp_path
+        assert found_inipath is None
+
+        # Config file is explicitly given: rootdir is determined to be inifile's directory.
+        inipath = tmp_path / "pytest.ini"
+        inipath.touch()
+        rootpath, found_inipath, *_ = determine_setup(str(inipath), [str(tests_dir)])
+        assert rootpath == tmp_path
+        assert found_inipath == inipath
+
     def test_with_arg_outside_cwd_without_inifile(
         self, tmp_path: Path, monkeypatch: MonkeyPatch
     ) -> None:
@@ -1393,9 +1501,9 @@

 class TestOverrideIniArgs:
     @pytest.mark.parametrize("name", "setup.cfg tox.ini pytest.ini".split())
-    def test_override_ini_names(self, testdir, name):
+    def test_override_ini_names(self, pytester: Pytester, name: str) -> None:
         section = "[pytest]" if name != "setup.cfg" else "[tool:pytest]"
-        testdir.tmpdir.join(name).write(
+        pytester.path.joinpath(name).write_text(
             textwrap.dedent(
                 """
             {section}
@@ -1404,55 +1512,55 @@
                 )
             )
         )
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             def pytest_addoption(parser):
                 parser.addini("custom", "")"""
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_pass(pytestconfig):
                 ini_val = pytestconfig.getini("custom")
                 print('\\ncustom_option:%s\\n' % ini_val)"""
         )

-        result = testdir.runpytest("--override-ini", "custom=2.0", "-s")
+        result = pytester.runpytest("--override-ini", "custom=2.0", "-s")
         assert result.ret == 0
         result.stdout.fnmatch_lines(["custom_option:2.0"])

-        result = testdir.runpytest(
+        result = pytester.runpytest(
             "--override-ini", "custom=2.0", "--override-ini=custom=3.0", "-s"
         )
         assert result.ret == 0
         result.stdout.fnmatch_lines(["custom_option:3.0"])

-    def test_override_ini_pathlist(self, testdir):
-        testdir.makeconftest(
+    def test_override_ini_paths(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             def pytest_addoption(parser):
-                parser.addini("paths", "my new ini value", type="pathlist")"""
-        )
-        testdir.makeini(
+                parser.addini("paths", "my new ini value", type="paths")"""
+        )
+        pytester.makeini(
             """
             [pytest]
             paths=blah.py"""
         )
-        testdir.makepyfile(
-            """
-            import py.path
-            def test_pathlist(pytestconfig):
+        pytester.makepyfile(
+            r"""
+            def test_overriden(pytestconfig):
                 config_paths = pytestconfig.getini("paths")
                 print(config_paths)
                 for cpf in config_paths:
-                    print('\\nuser_path:%s' % cpf.basename)"""
-        )
-        result = testdir.runpytest(
+                    print('\nuser_path:%s' % cpf.name)
+            """
+        )
+        result = pytester.runpytest(
             "--override-ini", "paths=foo/bar1.py foo/bar2.py", "-s"
         )
         result.stdout.fnmatch_lines(["user_path:bar1.py", "user_path:bar2.py"])

-    def test_override_multiple_and_default(self, testdir):
-        testdir.makeconftest(
+    def test_override_multiple_and_default(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             def pytest_addoption(parser):
                 addini = parser.addini
@@ -1461,14 +1569,14 @@
                 addini("custom_option_3", "", default=False, type="bool")
                 addini("custom_option_4", "", default=True, type="bool")"""
         )
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
             custom_option_1=custom_option_1
             custom_option_2=custom_option_2
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_multiple_options(pytestconfig):
                 prefix = "custom_option"
@@ -1477,7 +1585,7 @@
                     print('\\nini%d:%s' % (x, ini_value))
         """
         )
-        result = testdir.runpytest(
+        result = pytester.runpytest(
             "--override-ini",
             "custom_option_1=fulldir=/tmp/user1",
             "-o",
@@ -1497,14 +1605,14 @@
             ]
         )

-    def test_override_ini_usage_error_bad_style(self, testdir):
-        testdir.makeini(
+    def test_override_ini_usage_error_bad_style(self, pytester: Pytester) -> None:
+        pytester.makeini(
             """
             [pytest]
             xdist_strict=False
         """
         )
-        result = testdir.runpytest("--override-ini", "xdist_strict", "True")
+        result = pytester.runpytest("--override-ini", "xdist_strict", "True")
         result.stderr.fnmatch_lines(
             [
                 "ERROR: -o/--override-ini expects option=value style (got: 'xdist_strict').",
@@ -1512,32 +1620,38 @@
         )

     @pytest.mark.parametrize("with_ini", [True, False])
-    def test_override_ini_handled_asap(self, testdir, with_ini):
+    def test_override_ini_handled_asap(
+        self, pytester: Pytester, with_ini: bool
+    ) -> None:
         """-o should be handled as soon as possible and always override what's in ini files (#2238)"""
         if with_ini:
-            testdir.makeini(
+            pytester.makeini(
                 """
                 [pytest]
                 python_files=test_*.py
             """
             )
-        testdir.makepyfile(
+        pytester.makepyfile(
             unittest_ini_handle="""
             def test():
                 pass
         """
         )
-        result = testdir.runpytest("--override-ini", "python_files=unittest_*.py")
+        result = pytester.runpytest("--override-ini", "python_files=unittest_*.py")
         result.stdout.fnmatch_lines(["*1 passed in*"])

-    def test_addopts_before_initini(self, monkeypatch, _config_for_test, _sys_snapshot):
+    def test_addopts_before_initini(
+        self, monkeypatch: MonkeyPatch, _config_for_test, _sys_snapshot
+    ) -> None:
         cache_dir = ".custom_cache"
         monkeypatch.setenv("PYTEST_ADDOPTS", "-o cache_dir=%s" % cache_dir)
         config = _config_for_test
         config._preparse([], addopts=True)
         assert config._override_ini == ["cache_dir=%s" % cache_dir]

-    def test_addopts_from_env_not_concatenated(self, monkeypatch, _config_for_test):
+    def test_addopts_from_env_not_concatenated(
+        self, monkeypatch: MonkeyPatch, _config_for_test
+    ) -> None:
         """PYTEST_ADDOPTS should not take values from normal args (#4265)."""
         monkeypatch.setenv("PYTEST_ADDOPTS", "-o")
         config = _config_for_test
@@ -1548,32 +1662,34 @@
             in excinfo.value.args[0]
         )

-    def test_addopts_from_ini_not_concatenated(self, testdir):
+    def test_addopts_from_ini_not_concatenated(self, pytester: Pytester) -> None:
         """`addopts` from ini should not take values from normal args (#4265)."""
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
             addopts=-o
         """
         )
-        result = testdir.runpytest("cache_dir=ignored")
+        result = pytester.runpytest("cache_dir=ignored")
         result.stderr.fnmatch_lines(
             [
                 "%s: error: argument -o/--override-ini: expected one argument (via addopts config)"
-                % (testdir.request.config._parser.optparser.prog,)
+                % (pytester._request.config._parser.optparser.prog,)
             ]
         )
         assert result.ret == _pytest.config.ExitCode.USAGE_ERROR

-    def test_override_ini_does_not_contain_paths(self, _config_for_test, _sys_snapshot):
+    def test_override_ini_does_not_contain_paths(
+        self, _config_for_test, _sys_snapshot
+    ) -> None:
         """Check that -o no longer swallows all options after it (#3103)"""
         config = _config_for_test
         config._preparse(["-o", "cache_dir=/cache", "/some/test/path"])
         assert config._override_ini == ["cache_dir=/cache"]

-    def test_multiple_override_ini_options(self, testdir):
+    def test_multiple_override_ini_options(self, pytester: Pytester) -> None:
         """Ensure a file path following a '-o' option does not generate an error (#3103)"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             **{
                 "conftest.py": """
                 def pytest_addoption(parser):
@@ -1591,19 +1707,19 @@
             """,
             }
         )
-        result = testdir.runpytest("-o", "foo=1", "-o", "bar=0", "test_foo.py")
+        result = pytester.runpytest("-o", "foo=1", "-o", "bar=0", "test_foo.py")
         assert "ERROR:" not in result.stderr.str()
         result.stdout.fnmatch_lines(["collected 1 item", "*= 1 passed in *="])


-def test_help_via_addopts(testdir):
-    testdir.makeini(
+def test_help_via_addopts(pytester: Pytester) -> None:
+    pytester.makeini(
         """
         [pytest]
         addopts = --unknown-option-should-allow-for-help --help
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert result.ret == 0
     result.stdout.fnmatch_lines(
         [
@@ -1615,8 +1731,8 @@
     )


-def test_help_and_version_after_argument_error(testdir):
-    testdir.makeconftest(
+def test_help_and_version_after_argument_error(pytester: Pytester) -> None:
+    pytester.makeconftest(
         """
         def validate(arg):
             raise argparse.ArgumentTypeError("argerror")
@@ -1629,13 +1745,13 @@
             )
         """
     )
-    testdir.makeini(
+    pytester.makeini(
         """
         [pytest]
         addopts = --invalid-option-should-allow-for-help
     """
     )
-    result = testdir.runpytest("--help")
+    result = pytester.runpytest("--help")
     result.stdout.fnmatch_lines(
         [
             "usage: *",
@@ -1647,19 +1763,19 @@
         [
             "ERROR: usage: *",
             "%s: error: argument --invalid-option-should-allow-for-help: expected one argument"
-            % (testdir.request.config._parser.optparser.prog,),
+            % (pytester._request.config._parser.optparser.prog,),
         ]
     )
     # Does not display full/default help.
     assert "to see available markers type: pytest --markers" not in result.stdout.lines
     assert result.ret == ExitCode.USAGE_ERROR

-    result = testdir.runpytest("--version")
-    result.stderr.fnmatch_lines(["pytest {}".format(pytest.__version__)])
+    result = pytester.runpytest("--version")
+    result.stdout.fnmatch_lines([f"pytest {pytest.__version__}"])
     assert result.ret == ExitCode.USAGE_ERROR


-def test_help_formatter_uses_py_get_terminal_width(monkeypatch):
+def test_help_formatter_uses_py_get_terminal_width(monkeypatch: MonkeyPatch) -> None:
     from _pytest.config.argparsing import DropShorterLongHelpFormatter

     monkeypatch.setenv("COLUMNS", "90")
@@ -1674,39 +1790,39 @@
     assert formatter._width == 42


-def test_config_does_not_load_blocked_plugin_from_args(testdir):
+def test_config_does_not_load_blocked_plugin_from_args(pytester: Pytester) -> None:
     """This tests that pytest's config setup handles "-p no:X"."""
-    p = testdir.makepyfile("def test(capfd): pass")
-    result = testdir.runpytest(str(p), "-pno:capture")
+    p = pytester.makepyfile("def test(capfd): pass")
+    result = pytester.runpytest(str(p), "-pno:capture")
     result.stdout.fnmatch_lines(["E       fixture 'capfd' not found"])
     assert result.ret == ExitCode.TESTS_FAILED

-    result = testdir.runpytest(str(p), "-pno:capture", "-s")
+    result = pytester.runpytest(str(p), "-pno:capture", "-s")
     result.stderr.fnmatch_lines(["*: error: unrecognized arguments: -s"])
     assert result.ret == ExitCode.USAGE_ERROR


-def test_invocation_args(testdir):
+def test_invocation_args(pytester: Pytester) -> None:
     """Ensure that Config.invocation_* arguments are correctly defined"""

     class DummyPlugin:
         pass

-    p = testdir.makepyfile("def test(): pass")
+    p = pytester.makepyfile("def test(): pass")
     plugin = DummyPlugin()
-    rec = testdir.inline_run(p, "-v", plugins=[plugin])
+    rec = pytester.inline_run(p, "-v", plugins=[plugin])
     calls = rec.getcalls("pytest_runtest_protocol")
     assert len(calls) == 1
     call = calls[0]
     config = call.item.config

-    assert config.invocation_params.args == (p, "-v")
-    assert config.invocation_params.dir == Path(str(testdir.tmpdir))
+    assert config.invocation_params.args == (str(p), "-v")
+    assert config.invocation_params.dir == pytester.path

     plugins = config.invocation_params.plugins
     assert len(plugins) == 2
     assert plugins[0] is plugin
-    assert type(plugins[1]).__name__ == "Collect"  # installed by testdir.inline_run()
+    assert type(plugins[1]).__name__ == "Collect"  # installed by pytester.inline_run()

     # args cannot be None
     with pytest.raises(TypeError):
@@ -1721,9 +1837,9 @@
         if x not in _pytest.config.essential_plugins
     ],
 )
-def test_config_blocked_default_plugins(testdir, plugin):
+def test_config_blocked_default_plugins(pytester: Pytester, plugin: str) -> None:
     if plugin == "debugging":
-        # Fixed in xdist master (after 1.27.0).
+        # Fixed in xdist (after 1.27.0).
         # https://github.com/pytest-dev/pytest-xdist/pull/422
         try:
             import xdist  # noqa: F401
@@ -1732,8 +1848,8 @@
         else:
             pytest.skip("does not work with xdist currently")

-    p = testdir.makepyfile("def test(): pass")
-    result = testdir.runpytest(str(p), "-pno:%s" % plugin)
+    p = pytester.makepyfile("def test(): pass")
+    result = pytester.runpytest(str(p), "-pno:%s" % plugin)

     if plugin == "python":
         assert result.ret == ExitCode.USAGE_ERROR
@@ -1749,8 +1865,8 @@
     if plugin != "terminal":
         result.stdout.fnmatch_lines(["* 1 passed in *"])

-    p = testdir.makepyfile("def test(): assert 0")
-    result = testdir.runpytest(str(p), "-pno:%s" % plugin)
+    p = pytester.makepyfile("def test(): assert 0")
+    result = pytester.runpytest(str(p), "-pno:%s" % plugin)
     assert result.ret == ExitCode.TESTS_FAILED
     if plugin != "terminal":
         result.stdout.fnmatch_lines(["* 1 failed in *"])
@@ -1759,8 +1875,8 @@


 class TestSetupCfg:
-    def test_pytest_setup_cfg_unsupported(self, testdir):
-        testdir.makefile(
+    def test_pytest_setup_cfg_unsupported(self, pytester: Pytester) -> None:
+        pytester.makefile(
             ".cfg",
             setup="""
             [pytest]
@@ -1768,10 +1884,10 @@
         """,
         )
         with pytest.raises(pytest.fail.Exception):
-            testdir.runpytest()
-
-    def test_pytest_custom_cfg_unsupported(self, testdir):
-        testdir.makefile(
+            pytester.runpytest()
+
+    def test_pytest_custom_cfg_unsupported(self, pytester: Pytester) -> None:
+        pytester.makefile(
             ".cfg",
             custom="""
             [pytest]
@@ -1779,38 +1895,35 @@
         """,
         )
         with pytest.raises(pytest.fail.Exception):
-            testdir.runpytest("-c", "custom.cfg")
+            pytester.runpytest("-c", "custom.cfg")


 class TestPytestPluginsVariable:
-    def test_pytest_plugins_in_non_top_level_conftest_unsupported(self, testdir):
-        testdir.makepyfile(
+    def test_pytest_plugins_in_non_top_level_conftest_unsupported(
+        self, pytester: Pytester
+    ) -> None:
+        pytester.makepyfile(
             **{
                 "subdirectory/conftest.py": """
             pytest_plugins=['capture']
         """
             }
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_func():
                 pass
         """
         )
-        res = testdir.runpytest()
+        res = pytester.runpytest()
         assert res.ret == 2
         msg = "Defining 'pytest_plugins' in a non-top-level conftest is no longer supported"
-        res.stdout.fnmatch_lines(
-            [
-                "*{msg}*".format(msg=msg),
-                "*subdirectory{sep}conftest.py*".format(sep=os.sep),
-            ]
-        )
+        res.stdout.fnmatch_lines([f"*{msg}*", f"*subdirectory{os.sep}conftest.py*"])

     @pytest.mark.parametrize("use_pyargs", [True, False])
     def test_pytest_plugins_in_non_top_level_conftest_unsupported_pyargs(
-        self, testdir, use_pyargs
-    ):
+        self, pytester: Pytester, use_pyargs: bool
+    ) -> None:
         """When using --pyargs, do not emit the warning about non-top-level conftest warnings (#4039, #4044)"""

         files = {
@@ -1821,11 +1934,11 @@
             "src/pkg/sub/conftest.py": "pytest_plugins=['capture']",
             "src/pkg/sub/test_bar.py": "def test(): pass",
         }
-        testdir.makepyfile(**files)
-        testdir.syspathinsert(testdir.tmpdir.join("src"))
+        pytester.makepyfile(**files)
+        pytester.syspathinsert(pytester.path.joinpath("src"))

         args = ("--pyargs", "pkg") if use_pyargs else ()
-        res = testdir.runpytest(*args)
+        res = pytester.runpytest(*args)
         assert res.ret == (0 if use_pyargs else 2)
         msg = (
             msg
@@ -1833,41 +1946,38 @@
         if use_pyargs:
             assert msg not in res.stdout.str()
         else:
-            res.stdout.fnmatch_lines(["*{msg}*".format(msg=msg)])
+            res.stdout.fnmatch_lines([f"*{msg}*"])

     def test_pytest_plugins_in_non_top_level_conftest_unsupported_no_top_level_conftest(
-        self, testdir
-    ):
-        subdirectory = testdir.tmpdir.join("subdirectory")
+        self, pytester: Pytester
+    ) -> None:
+        subdirectory = pytester.path.joinpath("subdirectory")
         subdirectory.mkdir()
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             pytest_plugins=['capture']
         """
         )
-        testdir.tmpdir.join("conftest.py").move(subdirectory.join("conftest.py"))
-
-        testdir.makepyfile(
+        pytester.path.joinpath("conftest.py").rename(
+            subdirectory.joinpath("conftest.py")
+        )
+
+        pytester.makepyfile(
             """
             def test_func():
                 pass
         """
         )

-        res = testdir.runpytest_subprocess()
+        res = pytester.runpytest_subprocess()
         assert res.ret == 2
         msg = "Defining 'pytest_plugins' in a non-top-level conftest is no longer supported"
-        res.stdout.fnmatch_lines(
-            [
-                "*{msg}*".format(msg=msg),
-                "*subdirectory{sep}conftest.py*".format(sep=os.sep),
-            ]
-        )
+        res.stdout.fnmatch_lines([f"*{msg}*", f"*subdirectory{os.sep}conftest.py*"])

     def test_pytest_plugins_in_non_top_level_conftest_unsupported_no_false_positives(
-        self, testdir
-    ):
-        testdir.makepyfile(
+        self, pytester: Pytester
+    ) -> None:
+        pytester.makepyfile(
             "def test_func(): pass",
             **{
                 "subdirectory/conftest": "pass",
@@ -1878,19 +1988,19 @@
                     """,
             },
         )
-        res = testdir.runpytest_subprocess()
+        res = pytester.runpytest_subprocess()
         assert res.ret == 0
         msg = "Defining 'pytest_plugins' in a non-top-level conftest is no longer supported"
         assert msg not in res.stdout.str()


-def test_conftest_import_error_repr(tmpdir):
+def test_conftest_import_error_repr(tmp_path: Path) -> None:
     """`ConftestImportFailure` should use a short error message and readable
     path to the failed conftest.py file."""
-    path = tmpdir.join("foo/conftest.py")
+    path = tmp_path.joinpath("foo/conftest.py")
     with pytest.raises(
         ConftestImportFailure,
-        match=re.escape("RuntimeError: some error (from {})".format(path)),
+        match=re.escape(f"RuntimeError: some error (from {path})"),
     ):
         try:
             raise RuntimeError("some error")
@@ -1900,7 +2010,7 @@
             raise ConftestImportFailure(path, exc_info) from exc


-def test_strtobool():
+def test_strtobool() -> None:
     assert _strtobool("YES")
     assert not _strtobool("NO")
     with pytest.raises(ValueError):
@@ -1936,14 +2046,80 @@
     ],
 )
 def test_parse_warning_filter(
-    arg: str, escape: bool, expected: "Tuple[str, str, Type[Warning], str, int]"
+    arg: str, escape: bool, expected: Tuple[str, str, Type[Warning], str, int]
 ) -> None:
     assert parse_warning_filter(arg, escape=escape) == expected


-@pytest.mark.parametrize("arg", [":" * 5, "::::-1", "::::not-a-number"])
+@pytest.mark.parametrize(
+    "arg",
+    [
+        # Too much parts.
+        ":" * 5,
+        # Invalid action.
+        "FOO::",
+        # ImportError when importing the warning class.
+        "::test_parse_warning_filter_failure.NonExistentClass::",
+        # Class is not a Warning subclass.
+        "::list::",
+        # Negative line number.
+        "::::-1",
+        # Not a line number.
+        "::::not-a-number",
+    ],
+)
 def test_parse_warning_filter_failure(arg: str) -> None:
-    import warnings
-
-    with pytest.raises(warnings._OptionError):
+    with pytest.raises(pytest.UsageError):
         parse_warning_filter(arg, escape=True)
+
+
+class TestDebugOptions:
+    def test_without_debug_does_not_write_log(self, pytester: Pytester) -> None:
+        result = pytester.runpytest()
+        result.stderr.no_fnmatch_line(
+            "*writing pytest debug information to*pytestdebug.log"
+        )
+        result.stderr.no_fnmatch_line(
+            "*wrote pytest debug information to*pytestdebug.log"
+        )
+        assert not [f.name for f in pytester.path.glob("**/*.log")]
+
+    def test_with_only_debug_writes_pytestdebug_log(self, pytester: Pytester) -> None:
+        result = pytester.runpytest("--debug")
+        result.stderr.fnmatch_lines(
+            [
+                "*writing pytest debug information to*pytestdebug.log",
+                "*wrote pytest debug information to*pytestdebug.log",
+            ]
+        )
+        assert "pytestdebug.log" in [f.name for f in pytester.path.glob("**/*.log")]
+
+    def test_multiple_custom_debug_logs(self, pytester: Pytester) -> None:
+        result = pytester.runpytest("--debug", "bar.log")
+        result.stderr.fnmatch_lines(
+            [
+                "*writing pytest debug information to*bar.log",
+                "*wrote pytest debug information to*bar.log",
+            ]
+        )
+        result = pytester.runpytest("--debug", "foo.log")
+        result.stderr.fnmatch_lines(
+            [
+                "*writing pytest debug information to*foo.log",
+                "*wrote pytest debug information to*foo.log",
+            ]
+        )
+
+        assert {"bar.log", "foo.log"} == {
+            f.name for f in pytester.path.glob("**/*.log")
+        }
+
+    def test_debug_help(self, pytester: Pytester) -> None:
+        result = pytester.runpytest("-h")
+        result.stdout.fnmatch_lines(
+            [
+                "*store internal tracing debug information in this log*",
+                "*This file is opened with 'w' and truncated as a result*",
+                "*Defaults to 'pytestdebug.log'.",
+            ]
+        )
('testing', 'test_capture.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -13,11 +13,13 @@
 import pytest
 from _pytest import capture
 from _pytest.capture import _get_multicapture
+from _pytest.capture import CaptureFixture
 from _pytest.capture import CaptureManager
 from _pytest.capture import CaptureResult
 from _pytest.capture import MultiCapture
 from _pytest.config import ExitCode
-from _pytest.pytester import Testdir
+from _pytest.monkeypatch import MonkeyPatch
+from _pytest.pytester import Pytester

 # note: py.io capture tests where copied from
 # pylib 1.4.20.dev2 (rev 13d9af95547e)
@@ -55,7 +57,7 @@

 class TestCaptureManager:
     @pytest.mark.parametrize("method", ["no", "sys", "fd"])
-    def test_capturing_basic_api(self, method):
+    def test_capturing_basic_api(self, method) -> None:
         capouter = StdCaptureFD()
         old = sys.stdout, sys.stderr, sys.stdin
         try:
@@ -96,9 +98,9 @@


 @pytest.mark.parametrize("method", ["fd", "sys"])
-def test_capturing_unicode(testdir, method):
+def test_capturing_unicode(pytester: Pytester, method: str) -> None:
     obj = "'b\u00f6y'"
-    testdir.makepyfile(
+    pytester.makepyfile(
         """\
         # taken from issue 227 from nosetests
         def test_unicode():
@@ -108,24 +110,24 @@
         """
         % obj
     )
-    result = testdir.runpytest("--capture=%s" % method)
+    result = pytester.runpytest("--capture=%s" % method)
     result.stdout.fnmatch_lines(["*1 passed*"])


 @pytest.mark.parametrize("method", ["fd", "sys"])
-def test_capturing_bytes_in_utf8_encoding(testdir, method):
-    testdir.makepyfile(
+def test_capturing_bytes_in_utf8_encoding(pytester: Pytester, method: str) -> None:
+    pytester.makepyfile(
         """\
         def test_unicode():
             print('b\\u00f6y')
         """
     )
-    result = testdir.runpytest("--capture=%s" % method)
+    result = pytester.runpytest("--capture=%s" % method)
     result.stdout.fnmatch_lines(["*1 passed*"])


-def test_collect_capturing(testdir):
-    p = testdir.makepyfile(
+def test_collect_capturing(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
         """
         import sys

@@ -134,7 +136,7 @@
         import xyz42123
     """
     )
-    result = testdir.runpytest(p)
+    result = pytester.runpytest(p)
     result.stdout.fnmatch_lines(
         [
             "*Captured stdout*",
@@ -146,8 +148,8 @@


 class TestPerTestCapturing:
-    def test_capture_and_fixtures(self, testdir):
-        p = testdir.makepyfile(
+    def test_capture_and_fixtures(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             def setup_module(mod):
                 print("setup module")
@@ -161,7 +163,7 @@
                 assert 0
         """
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.stdout.fnmatch_lines(
             [
                 "setup module*",
@@ -173,8 +175,8 @@
         )

     @pytest.mark.xfail(reason="unimplemented feature")
-    def test_capture_scope_cache(self, testdir):
-        p = testdir.makepyfile(
+    def test_capture_scope_cache(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             import sys
             def setup_module(func):
@@ -188,7 +190,7 @@
                 print("in teardown")
         """
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.stdout.fnmatch_lines(
             [
                 "*test_func():*",
@@ -200,8 +202,8 @@
             ]
         )

-    def test_no_carry_over(self, testdir):
-        p = testdir.makepyfile(
+    def test_no_carry_over(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             def test_func1():
                 print("in func1")
@@ -210,13 +212,13 @@
                 assert 0
         """
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         s = result.stdout.str()
         assert "in func1" not in s
         assert "in func2" in s

-    def test_teardown_capturing(self, testdir):
-        p = testdir.makepyfile(
+    def test_teardown_capturing(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             def setup_function(function):
                 print("setup func1")
@@ -228,7 +230,7 @@
                 pass
         """
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.stdout.fnmatch_lines(
             [
                 "*teardown_function*",
@@ -240,8 +242,8 @@
             ]
         )

-    def test_teardown_capturing_final(self, testdir):
-        p = testdir.makepyfile(
+    def test_teardown_capturing_final(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             def teardown_module(mod):
                 print("teardown module")
@@ -250,7 +252,7 @@
                 pass
         """
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.stdout.fnmatch_lines(
             [
                 "*def teardown_module(mod):*",
@@ -260,8 +262,8 @@
             ]
         )

-    def test_capturing_outerr(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_capturing_outerr(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """\
             import sys
             def test_capturing():
@@ -273,7 +275,7 @@
                 raise ValueError
             """
         )
-        result = testdir.runpytest(p1)
+        result = pytester.runpytest(p1)
         result.stdout.fnmatch_lines(
             [
                 "*test_capturing_outerr.py .F*",
@@ -289,8 +291,8 @@


 class TestLoggingInteraction:
-    def test_logging_stream_ownership(self, testdir):
-        p = testdir.makepyfile(
+    def test_logging_stream_ownership(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """\
             def test_logging():
                 import logging
@@ -300,11 +302,11 @@
                 stream.close() # to free memory/release resources
             """
         )
-        result = testdir.runpytest_subprocess(p)
+        result = pytester.runpytest_subprocess(p)
         assert result.stderr.str().find("atexit") == -1

-    def test_logging_and_immediate_setupteardown(self, testdir):
-        p = testdir.makepyfile(
+    def test_logging_and_immediate_setupteardown(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """\
             import logging
             def setup_function(function):
@@ -321,7 +323,7 @@
         )
         for optargs in (("--capture=sys",), ("--capture=fd",)):
             print(optargs)
-            result = testdir.runpytest_subprocess(p, *optargs)
+            result = pytester.runpytest_subprocess(p, *optargs)
             s = result.stdout.str()
             result.stdout.fnmatch_lines(
                 ["*WARN*hello3", "*WARN*hello1", "*WARN*hello2"]  # errors show first!
@@ -329,8 +331,8 @@
             # verify proper termination
             assert "closed" not in s

-    def test_logging_and_crossscope_fixtures(self, testdir):
-        p = testdir.makepyfile(
+    def test_logging_and_crossscope_fixtures(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """\
             import logging
             def setup_module(function):
@@ -347,7 +349,7 @@
         )
         for optargs in (("--capture=sys",), ("--capture=fd",)):
             print(optargs)
-            result = testdir.runpytest_subprocess(p, *optargs)
+            result = pytester.runpytest_subprocess(p, *optargs)
             s = result.stdout.str()
             result.stdout.fnmatch_lines(
                 ["*WARN*hello3", "*WARN*hello1", "*WARN*hello2"]  # errors come first
@@ -355,8 +357,8 @@
             # verify proper termination
             assert "closed" not in s

-    def test_conftestlogging_is_shown(self, testdir):
-        testdir.makeconftest(
+    def test_conftestlogging_is_shown(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """\
                 import logging
                 logging.basicConfig()
@@ -364,20 +366,20 @@
             """
         )
         # make sure that logging is still captured in tests
-        result = testdir.runpytest_subprocess("-s", "-p", "no:capturelog")
+        result = pytester.runpytest_subprocess("-s", "-p", "no:capturelog")
         assert result.ret == ExitCode.NO_TESTS_COLLECTED
         result.stderr.fnmatch_lines(["WARNING*hello435*"])
         assert "operation on closed file" not in result.stderr.str()

-    def test_conftestlogging_and_test_logging(self, testdir):
-        testdir.makeconftest(
+    def test_conftestlogging_and_test_logging(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """\
                 import logging
                 logging.basicConfig()
             """
         )
         # make sure that logging is still captured in tests
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             """\
             def test_hello():
                 import logging
@@ -385,14 +387,14 @@
                 assert 0
             """
         )
-        result = testdir.runpytest_subprocess(p, "-p", "no:capturelog")
+        result = pytester.runpytest_subprocess(p, "-p", "no:capturelog")
         assert result.ret != 0
         result.stdout.fnmatch_lines(["WARNING*hello433*"])
         assert "something" not in result.stderr.str()
         assert "operation on closed file" not in result.stderr.str()

-    def test_logging_after_cap_stopped(self, testdir):
-        testdir.makeconftest(
+    def test_logging_after_cap_stopped(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """\
                 import pytest
                 import logging
@@ -406,7 +408,7 @@
             """
         )
         # make sure that logging is still captured in tests
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             """\
             def test_hello(log_on_teardown):
                 import logging
@@ -415,7 +417,7 @@
                 raise KeyboardInterrupt()
             """
         )
-        result = testdir.runpytest_subprocess(p, "--log-cli-level", "info")
+        result = pytester.runpytest_subprocess(p, "--log-cli-level", "info")
         assert result.ret != 0
         result.stdout.fnmatch_lines(
             ["*WARNING*hello433*", "*WARNING*Logging on teardown*"]
@@ -428,8 +430,8 @@

 class TestCaptureFixture:
     @pytest.mark.parametrize("opt", [[], ["-s"]])
-    def test_std_functional(self, testdir, opt):
-        reprec = testdir.inline_runsource(
+    def test_std_functional(self, pytester: Pytester, opt) -> None:
+        reprec = pytester.inline_runsource(
             """\
             def test_hello(capsys):
                 print(42)
@@ -440,8 +442,8 @@
         )
         reprec.assertoutcome(passed=1)

-    def test_capsyscapfd(self, testdir):
-        p = testdir.makepyfile(
+    def test_capsyscapfd(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """\
             def test_one(capsys, capfd):
                 pass
@@ -449,7 +451,7 @@
                 pass
             """
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.stdout.fnmatch_lines(
             [
                 "*ERROR*setup*test_one*",
@@ -460,11 +462,11 @@
             ]
         )

-    def test_capturing_getfixturevalue(self, testdir):
+    def test_capturing_getfixturevalue(self, pytester: Pytester) -> None:
         """Test that asking for "capfd" and "capsys" using request.getfixturevalue
         in the same test is an error.
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             """\
             def test_one(capsys, request):
                 request.getfixturevalue("capfd")
@@ -472,7 +474,7 @@
                 request.getfixturevalue("capsys")
             """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             [
                 "*test_one*",
@@ -483,21 +485,23 @@
             ]
         )

-    def test_capsyscapfdbinary(self, testdir):
-        p = testdir.makepyfile(
+    def test_capsyscapfdbinary(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """\
             def test_one(capsys, capfdbinary):
                 pass
             """
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.stdout.fnmatch_lines(
             ["*ERROR*setup*test_one*", "E*capfdbinary*capsys*same*time*", "*1 error*"]
         )

     @pytest.mark.parametrize("method", ["sys", "fd"])
-    def test_capture_is_represented_on_failure_issue128(self, testdir, method):
-        p = testdir.makepyfile(
+    def test_capture_is_represented_on_failure_issue128(
+        self, pytester: Pytester, method
+    ) -> None:
+        p = pytester.makepyfile(
             """\
             def test_hello(cap{}):
                 print("xxx42xxx")
@@ -506,11 +510,11 @@
                 method
             )
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.stdout.fnmatch_lines(["xxx42xxx"])

-    def test_stdfd_functional(self, testdir):
-        reprec = testdir.inline_runsource(
+    def test_stdfd_functional(self, pytester: Pytester) -> None:
+        reprec = pytester.inline_runsource(
             """\
             def test_hello(capfd):
                 import os
@@ -523,13 +527,13 @@
         reprec.assertoutcome(passed=1)

     @pytest.mark.parametrize("nl", ("\n", "\r\n", "\r"))
-    def test_cafd_preserves_newlines(self, capfd, nl):
+    def test_cafd_preserves_newlines(self, capfd, nl) -> None:
         print("test", end=nl)
         out, err = capfd.readouterr()
         assert out.endswith(nl)

-    def test_capfdbinary(self, testdir):
-        reprec = testdir.inline_runsource(
+    def test_capfdbinary(self, pytester: Pytester) -> None:
+        reprec = pytester.inline_runsource(
             """\
             def test_hello(capfdbinary):
                 import os
@@ -542,8 +546,8 @@
         )
         reprec.assertoutcome(passed=1)

-    def test_capsysbinary(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_capsysbinary(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             r"""
             def test_hello(capsysbinary):
                 import sys
@@ -567,7 +571,7 @@
                 print("stderr after", file=sys.stderr)
             """
         )
-        result = testdir.runpytest(str(p1), "-rA")
+        result = pytester.runpytest(str(p1), "-rA")
         result.stdout.fnmatch_lines(
             [
                 "*- Captured stdout call -*",
@@ -578,18 +582,18 @@
             ]
         )

-    def test_partial_setup_failure(self, testdir):
-        p = testdir.makepyfile(
+    def test_partial_setup_failure(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """\
             def test_hello(capsys, missingarg):
                 pass
             """
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.stdout.fnmatch_lines(["*test_partial_setup_failure*", "*1 error*"])

-    def test_keyboardinterrupt_disables_capturing(self, testdir):
-        p = testdir.makepyfile(
+    def test_keyboardinterrupt_disables_capturing(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """\
             def test_hello(capfd):
                 import os
@@ -597,26 +601,28 @@
                 raise KeyboardInterrupt()
             """
         )
-        result = testdir.runpytest_subprocess(p)
+        result = pytester.runpytest_subprocess(p)
         result.stdout.fnmatch_lines(["*KeyboardInterrupt*"])
         assert result.ret == 2

-    def test_capture_and_logging(self, testdir):
+    def test_capture_and_logging(self, pytester: Pytester) -> None:
         """#14"""
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             """\
             import logging
             def test_log(capsys):
                 logging.error('x')
             """
         )
-        result = testdir.runpytest_subprocess(p)
+        result = pytester.runpytest_subprocess(p)
         assert "closed" not in result.stderr.str()

     @pytest.mark.parametrize("fixture", ["capsys", "capfd"])
     @pytest.mark.parametrize("no_capture", [True, False])
-    def test_disabled_capture_fixture(self, testdir, fixture, no_capture):
-        testdir.makepyfile(
+    def test_disabled_capture_fixture(
+        self, pytester: Pytester, fixture: str, no_capture: bool
+    ) -> None:
+        pytester.makepyfile(
             """\
             def test_disabled({fixture}):
                 print('captured before')
@@ -632,7 +638,7 @@
             )
         )
         args = ("-s",) if no_capture else ()
-        result = testdir.runpytest_subprocess(*args)
+        result = pytester.runpytest_subprocess(*args)
         result.stdout.fnmatch_lines(["*while capture is disabled*", "*= 2 passed in *"])
         result.stdout.no_fnmatch_line("*captured before*")
         result.stdout.no_fnmatch_line("*captured after*")
@@ -641,12 +647,12 @@
         else:
             result.stdout.no_fnmatch_line("*test_normal executed*")

-    def test_disabled_capture_fixture_twice(self, testdir: Testdir) -> None:
+    def test_disabled_capture_fixture_twice(self, pytester: Pytester) -> None:
         """Test that an inner disabled() exit doesn't undo an outer disabled().

         Issue #7148.
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_disabled(capfd):
                 print('captured before')
@@ -659,7 +665,7 @@
                 assert capfd.readouterr() == ('captured before\\ncaptured after\\n', '')
         """
         )
-        result = testdir.runpytest_subprocess()
+        result = pytester.runpytest_subprocess()
         result.stdout.fnmatch_lines(
             [
                 "*while capture is disabled 1",
@@ -670,10 +676,10 @@
         )

     @pytest.mark.parametrize("fixture", ["capsys", "capfd"])
-    def test_fixture_use_by_other_fixtures(self, testdir, fixture):
+    def test_fixture_use_by_other_fixtures(self, pytester: Pytester, fixture) -> None:
         """Ensure that capsys and capfd can be used by other fixtures during
         setup and teardown."""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """\
             import sys
             import pytest
@@ -700,15 +706,17 @@
                 fixture=fixture
             )
         )
-        result = testdir.runpytest_subprocess()
+        result = pytester.runpytest_subprocess()
         result.stdout.fnmatch_lines(["*1 passed*"])
         result.stdout.no_fnmatch_line("*stdout contents begin*")
         result.stdout.no_fnmatch_line("*stderr contents begin*")

     @pytest.mark.parametrize("cap", ["capsys", "capfd"])
-    def test_fixture_use_by_other_fixtures_teardown(self, testdir, cap):
+    def test_fixture_use_by_other_fixtures_teardown(
+        self, pytester: Pytester, cap
+    ) -> None:
         """Ensure we can access setup and teardown buffers from teardown when using capsys/capfd (##3033)"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """\
             import sys
             import pytest
@@ -730,13 +738,13 @@
                 cap=cap
             )
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)


-def test_setup_failure_does_not_kill_capturing(testdir):
-    sub1 = testdir.mkpydir("sub1")
-    sub1.join("conftest.py").write(
+def test_setup_failure_does_not_kill_capturing(pytester: Pytester) -> None:
+    sub1 = pytester.mkpydir("sub1")
+    sub1.joinpath("conftest.py").write_text(
         textwrap.dedent(
             """\
             def pytest_runtest_setup(item):
@@ -744,26 +752,26 @@
             """
         )
     )
-    sub1.join("test_mod.py").write("def test_func1(): pass")
-    result = testdir.runpytest(testdir.tmpdir, "--traceconfig")
+    sub1.joinpath("test_mod.py").write_text("def test_func1(): pass")
+    result = pytester.runpytest(pytester.path, "--traceconfig")
     result.stdout.fnmatch_lines(["*ValueError(42)*", "*1 error*"])


-def test_capture_conftest_runtest_setup(testdir):
-    testdir.makeconftest(
+def test_capture_conftest_runtest_setup(pytester: Pytester) -> None:
+    pytester.makeconftest(
         """
         def pytest_runtest_setup():
             print("hello19")
     """
     )
-    testdir.makepyfile("def test_func(): pass")
-    result = testdir.runpytest()
+    pytester.makepyfile("def test_func(): pass")
+    result = pytester.runpytest()
     assert result.ret == 0
     result.stdout.no_fnmatch_line("*hello19*")


-def test_capture_badoutput_issue412(testdir):
-    testdir.makepyfile(
+def test_capture_badoutput_issue412(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import os

@@ -773,7 +781,7 @@
             assert 0
         """
     )
-    result = testdir.runpytest("--capture=fd")
+    result = pytester.runpytest("--capture=fd")
     result.stdout.fnmatch_lines(
         """
         *def test_func*
@@ -784,21 +792,21 @@
     )


-def test_capture_early_option_parsing(testdir):
-    testdir.makeconftest(
+def test_capture_early_option_parsing(pytester: Pytester) -> None:
+    pytester.makeconftest(
         """
         def pytest_runtest_setup():
             print("hello19")
     """
     )
-    testdir.makepyfile("def test_func(): pass")
-    result = testdir.runpytest("-vs")
+    pytester.makepyfile("def test_func(): pass")
+    result = pytester.runpytest("-vs")
     assert result.ret == 0
     assert "hello19" in result.stdout.str()


-def test_capture_binary_output(testdir):
-    testdir.makepyfile(
+def test_capture_binary_output(pytester: Pytester) -> None:
+    pytester.makepyfile(
         r"""
         import pytest

@@ -814,13 +822,13 @@
             test_foo()
         """
     )
-    result = testdir.runpytest("--assert=plain")
+    result = pytester.runpytest("--assert=plain")
     result.assert_outcomes(passed=2)


-def test_error_during_readouterr(testdir):
+def test_error_during_readouterr(pytester: Pytester) -> None:
     """Make sure we suspend capturing if errors occur during readouterr"""
-    testdir.makepyfile(
+    pytester.makepyfile(
         pytest_xyz="""
         from _pytest.capture import FDCapture

@@ -831,26 +839,26 @@
         FDCapture.snap = bad_snap
     """
     )
-    result = testdir.runpytest_subprocess("-p", "pytest_xyz", "--version")
+    result = pytester.runpytest_subprocess("-p", "pytest_xyz", "--version")
     result.stderr.fnmatch_lines(
         ["*in bad_snap", "    raise Exception('boom')", "Exception: boom"]
     )


 class TestCaptureIO:
-    def test_text(self):
+    def test_text(self) -> None:
         f = capture.CaptureIO()
         f.write("hello")
         s = f.getvalue()
         assert s == "hello"
         f.close()

-    def test_unicode_and_str_mixture(self):
+    def test_unicode_and_str_mixture(self) -> None:
         f = capture.CaptureIO()
         f.write("\u00f6")
         pytest.raises(TypeError, f.write, b"hello")

-    def test_write_bytes_to_buffer(self):
+    def test_write_bytes_to_buffer(self) -> None:
         """In python3, stdout / stderr are text io wrappers (exposing a buffer
         property of the underlying bytestream).  See issue #1407
         """
@@ -860,7 +868,7 @@


 class TestTeeCaptureIO(TestCaptureIO):
-    def test_text(self):
+    def test_text(self) -> None:
         sio = io.StringIO()
         f = capture.TeeCaptureIO(sio)
         f.write("hello")
@@ -871,14 +879,14 @@
         f.close()
         sio.close()

-    def test_unicode_and_str_mixture(self):
+    def test_unicode_and_str_mixture(self) -> None:
         sio = io.StringIO()
         f = capture.TeeCaptureIO(sio)
         f.write("\u00f6")
         pytest.raises(TypeError, f.write, b"hello")


-def test_dontreadfrominput():
+def test_dontreadfrominput() -> None:
     from _pytest.capture import DontReadFromInput

     f = DontReadFromInput()
@@ -923,8 +931,8 @@


 @pytest.fixture
-def tmpfile(testdir) -> Generator[BinaryIO, None, None]:
-    f = testdir.makepyfile("").open("wb+")
+def tmpfile(pytester: Pytester) -> Generator[BinaryIO, None, None]:
+    f = pytester.makepyfile("").open("wb+")
     yield f
     if not f.closed:
         f.close()
@@ -937,7 +945,7 @@
         out = subprocess.check_output(("lsof", "-p", str(pid))).decode()
     except (OSError, subprocess.CalledProcessError, UnicodeDecodeError) as exc:
         # about UnicodeDecodeError, see note on pytester
-        pytest.skip("could not run 'lsof' ({!r})".format(exc))
+        pytest.skip(f"could not run 'lsof' ({exc!r})")
     yield
     out2 = subprocess.check_output(("lsof", "-p", str(pid))).decode()
     len1 = len([x for x in out.split("\n") if "REG" in x])
@@ -946,7 +954,7 @@


 class TestFDCapture:
-    def test_simple(self, tmpfile):
+    def test_simple(self, tmpfile: BinaryIO) -> None:
         fd = tmpfile.fileno()
         cap = capture.FDCapture(fd)
         data = b"hello"
@@ -960,22 +968,22 @@
         cap.done()
         assert s == "hello"

-    def test_simple_many(self, tmpfile):
+    def test_simple_many(self, tmpfile: BinaryIO) -> None:
         for i in range(10):
             self.test_simple(tmpfile)

-    def test_simple_many_check_open_files(self, testdir):
+    def test_simple_many_check_open_files(self, pytester: Pytester) -> None:
         with lsof_check():
-            with testdir.makepyfile("").open("wb+") as tmpfile:
+            with pytester.makepyfile("").open("wb+") as tmpfile:
                 self.test_simple_many(tmpfile)

-    def test_simple_fail_second_start(self, tmpfile):
+    def test_simple_fail_second_start(self, tmpfile: BinaryIO) -> None:
         fd = tmpfile.fileno()
         cap = capture.FDCapture(fd)
         cap.done()
         pytest.raises(AssertionError, cap.start)

-    def test_stderr(self):
+    def test_stderr(self) -> None:
         cap = capture.FDCapture(2)
         cap.start()
         print("hello", file=sys.stderr)
@@ -983,14 +991,14 @@
         cap.done()
         assert s == "hello\n"

-    def test_stdin(self):
+    def test_stdin(self) -> None:
         cap = capture.FDCapture(0)
         cap.start()
         x = os.read(0, 100).strip()
         cap.done()
         assert x == b""

-    def test_writeorg(self, tmpfile):
+    def test_writeorg(self, tmpfile: BinaryIO) -> None:
         data1, data2 = b"foo", b"bar"
         cap = capture.FDCapture(tmpfile.fileno())
         cap.start()
@@ -1004,7 +1012,7 @@
             stmp = stmp_file.read()
             assert stmp == data2

-    def test_simple_resume_suspend(self):
+    def test_simple_resume_suspend(self) -> None:
         with saved_fd(1):
             cap = capture.FDCapture(1)
             cap.start()
@@ -1038,7 +1046,7 @@
                 )
             )

-    def test_capfd_sys_stdout_mode(self, capfd):
+    def test_capfd_sys_stdout_mode(self, capfd) -> None:
         assert "b" not in sys.stdout.mode


@@ -1064,7 +1072,7 @@
         finally:
             cap.stop_capturing()

-    def test_capturing_done_simple(self):
+    def test_capturing_done_simple(self) -> None:
         with self.getcapture() as cap:
             sys.stdout.write("hello")
             sys.stderr.write("world")
@@ -1072,7 +1080,7 @@
         assert out == "hello"
         assert err == "world"

-    def test_capturing_reset_simple(self):
+    def test_capturing_reset_simple(self) -> None:
         with self.getcapture() as cap:
             print("hello world")
             sys.stderr.write("hello error\n")
@@ -1080,7 +1088,7 @@
         assert out == "hello world\n"
         assert err == "hello error\n"

-    def test_capturing_readouterr(self):
+    def test_capturing_readouterr(self) -> None:
         with self.getcapture() as cap:
             print("hello world")
             sys.stderr.write("hello error\n")
@@ -1091,7 +1099,7 @@
             out, err = cap.readouterr()
         assert err == "error2"

-    def test_capture_results_accessible_by_attribute(self):
+    def test_capture_results_accessible_by_attribute(self) -> None:
         with self.getcapture() as cap:
             sys.stdout.write("hello")
             sys.stderr.write("world")
@@ -1099,13 +1107,13 @@
         assert capture_result.out == "hello"
         assert capture_result.err == "world"

-    def test_capturing_readouterr_unicode(self):
+    def test_capturing_readouterr_unicode(self) -> None:
         with self.getcapture() as cap:
             print("hxąć")
             out, err = cap.readouterr()
         assert out == "hxąć\n"

-    def test_reset_twice_error(self):
+    def test_reset_twice_error(self) -> None:
         with self.getcapture() as cap:
             print("hello")
             out, err = cap.readouterr()
@@ -1113,7 +1121,7 @@
         assert out == "hello\n"
         assert not err

-    def test_capturing_modify_sysouterr_in_between(self):
+    def test_capturing_modify_sysouterr_in_between(self) -> None:
         oldout = sys.stdout
         olderr = sys.stderr
         with self.getcapture() as cap:
@@ -1129,7 +1137,7 @@
         assert sys.stdout == oldout
         assert sys.stderr == olderr

-    def test_capturing_error_recursive(self):
+    def test_capturing_error_recursive(self) -> None:
         with self.getcapture() as cap1:
             print("cap1")
             with self.getcapture() as cap2:
@@ -1139,7 +1147,7 @@
         assert out1 == "cap1\n"
         assert out2 == "cap2\n"

-    def test_just_out_capture(self):
+    def test_just_out_capture(self) -> None:
         with self.getcapture(out=True, err=False) as cap:
             sys.stdout.write("hello")
             sys.stderr.write("world")
@@ -1147,7 +1155,7 @@
         assert out == "hello"
         assert not err

-    def test_just_err_capture(self):
+    def test_just_err_capture(self) -> None:
         with self.getcapture(out=False, err=True) as cap:
             sys.stdout.write("hello")
             sys.stderr.write("world")
@@ -1155,14 +1163,14 @@
         assert err == "world"
         assert not out

-    def test_stdin_restored(self):
+    def test_stdin_restored(self) -> None:
         old = sys.stdin
         with self.getcapture(in_=True):
             newstdin = sys.stdin
         assert newstdin != sys.stdin
         assert sys.stdin is old

-    def test_stdin_nulled_by_default(self):
+    def test_stdin_nulled_by_default(self) -> None:
         print("XXX this test may well hang instead of crashing")
         print("XXX which indicates an error in the underlying capturing")
         print("XXX mechanisms")
@@ -1173,7 +1181,7 @@
 class TestTeeStdCapture(TestStdCapture):
     captureclass = staticmethod(TeeStdCapture)

-    def test_capturing_error_recursive(self):
+    def test_capturing_error_recursive(self) -> None:
         r"""For TeeStdCapture since we passthrough stderr/stdout, cap1
         should get all output, while cap2 should only get "cap2\n"."""

@@ -1190,8 +1198,8 @@
 class TestStdCaptureFD(TestStdCapture):
     captureclass = staticmethod(StdCaptureFD)

-    def test_simple_only_fd(self, testdir):
-        testdir.makepyfile(
+    def test_simple_only_fd(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """\
             import os
             def test_x():
@@ -1199,7 +1207,7 @@
                 assert 0
             """
         )
-        result = testdir.runpytest_subprocess()
+        result = pytester.runpytest_subprocess()
         result.stdout.fnmatch_lines(
             """
             *test_x*
@@ -1231,8 +1239,8 @@


 class TestStdCaptureFDinvalidFD:
-    def test_stdcapture_fd_invalid_fd(self, testdir):
-        testdir.makepyfile(
+    def test_stdcapture_fd_invalid_fd(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import os
             from fnmatch import fnmatch
@@ -1270,11 +1278,11 @@
                 cap.stop_capturing()
         """
         )
-        result = testdir.runpytest_subprocess("--capture=fd")
+        result = pytester.runpytest_subprocess("--capture=fd")
         assert result.ret == 0
         assert result.parseoutcomes()["passed"] == 3

-    def test_fdcapture_invalid_fd_with_fd_reuse(self, testdir):
+    def test_fdcapture_invalid_fd_with_fd_reuse(self, pytester: Pytester) -> None:
         with saved_fd(1):
             os.close(1)
             cap = capture.FDCaptureBinary(1)
@@ -1289,7 +1297,7 @@
             with pytest.raises(OSError):
                 os.write(1, b"done")

-    def test_fdcapture_invalid_fd_without_fd_reuse(self, testdir):
+    def test_fdcapture_invalid_fd_without_fd_reuse(self, pytester: Pytester) -> None:
         with saved_fd(1), saved_fd(2):
             os.close(1)
             os.close(2)
@@ -1306,12 +1314,14 @@
                 os.write(2, b"done")


-def test_capture_not_started_but_reset():
+def test_capture_not_started_but_reset() -> None:
     capsys = StdCapture()
     capsys.stop_capturing()


-def test_using_capsys_fixture_works_with_sys_stdout_encoding(capsys):
+def test_using_capsys_fixture_works_with_sys_stdout_encoding(
+    capsys: CaptureFixture[str],
+) -> None:
     test_text = "test text"

     print(test_text.encode(sys.stdout.encoding, "replace"))
@@ -1320,7 +1330,7 @@
     assert err == ""


-def test_capsys_results_accessible_by_attribute(capsys):
+def test_capsys_results_accessible_by_attribute(capsys: CaptureFixture[str]) -> None:
     sys.stdout.write("spam")
     sys.stderr.write("eggs")
     capture_result = capsys.readouterr()
@@ -1340,8 +1350,8 @@
     assert capfile2 == capfile


-def test_close_and_capture_again(testdir):
-    testdir.makepyfile(
+def test_close_and_capture_again(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import os
         def test_close():
@@ -1351,7 +1361,7 @@
             assert 0
     """
     )
-    result = testdir.runpytest_subprocess()
+    result = pytester.runpytest_subprocess()
     result.stdout.fnmatch_lines(
         """
         *test_capture_again*
@@ -1365,12 +1375,11 @@
 @pytest.mark.parametrize(
     "method", ["SysCapture(2)", "SysCapture(2, tee=True)", "FDCapture(2)"]
 )
-def test_capturing_and_logging_fundamentals(testdir, method: str) -> None:
+def test_capturing_and_logging_fundamentals(pytester: Pytester, method: str) -> None:
     # here we check a fundamental feature
-    p = testdir.makepyfile(
-        """
-        import sys, os
-        import py, logging
+    p = pytester.makepyfile(
+        """
+        import sys, os, logging
         from _pytest import capture
         cap = capture.MultiCapture(
             in_=None,
@@ -1392,7 +1401,7 @@
     """
         % (method,)
     )
-    result = testdir.runpython(p)
+    result = pytester.runpython(p)
     result.stdout.fnmatch_lines(
         """
         suspend, captured*hello1*
@@ -1407,8 +1416,8 @@
     assert "atexit" not in result.stderr.str()


-def test_error_attribute_issue555(testdir):
-    testdir.makepyfile(
+def test_error_attribute_issue555(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import sys
         def test_capattr():
@@ -1416,31 +1425,31 @@
             assert sys.stderr.errors == "replace"
     """
     )
-    reprec = testdir.inline_run()
+    reprec = pytester.inline_run()
     reprec.assertoutcome(passed=1)


 @pytest.mark.skipif(
-    not sys.platform.startswith("win") and sys.version_info[:2] >= (3, 6),
-    reason="only py3.6+ on windows",
+    not sys.platform.startswith("win"),
+    reason="only on windows",
 )
-def test_py36_windowsconsoleio_workaround_non_standard_streams() -> None:
+def test_windowsconsoleio_workaround_non_standard_streams() -> None:
     """
-    Ensure _py36_windowsconsoleio_workaround function works with objects that
+    Ensure _windowsconsoleio_workaround function works with objects that
     do not implement the full ``io``-based stream protocol, for example execnet channels (#2666).
     """
-    from _pytest.capture import _py36_windowsconsoleio_workaround
+    from _pytest.capture import _windowsconsoleio_workaround

     class DummyStream:
         def write(self, s):
             pass

     stream = cast(TextIO, DummyStream())
-    _py36_windowsconsoleio_workaround(stream)
-
-
-def test_dontreadfrominput_has_encoding(testdir):
-    testdir.makepyfile(
+    _windowsconsoleio_workaround(stream)
+
+
+def test_dontreadfrominput_has_encoding(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import sys
         def test_capattr():
@@ -1449,12 +1458,14 @@
             assert sys.stderr.encoding
     """
     )
-    reprec = testdir.inline_run()
+    reprec = pytester.inline_run()
     reprec.assertoutcome(passed=1)


-def test_crash_on_closing_tmpfile_py27(testdir):
-    p = testdir.makepyfile(
+def test_crash_on_closing_tmpfile_py27(
+    pytester: Pytester, monkeypatch: MonkeyPatch
+) -> None:
+    p = pytester.makepyfile(
         """
         import threading
         import sys
@@ -1481,19 +1492,19 @@
     """
     )
     # Do not consider plugins like hypothesis, which might output to stderr.
-    testdir.monkeypatch.setenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", "1")
-    result = testdir.runpytest_subprocess(str(p))
+    monkeypatch.setenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", "1")
+    result = pytester.runpytest_subprocess(str(p))
     assert result.ret == 0
     assert result.stderr.str() == ""
     result.stdout.no_fnmatch_line("*OSError*")


-def test_global_capture_with_live_logging(testdir):
+def test_global_capture_with_live_logging(pytester: Pytester) -> None:
     # Issue 3819
     # capture should work with live cli logging

     # Teardown report seems to have the capture for the whole process (setup, capture, teardown)
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         def pytest_runtest_logreport(report):
             if "test_global" in report.nodeid:
@@ -1505,7 +1516,7 @@
         """
     )

-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import logging
         import sys
@@ -1527,7 +1538,7 @@
             print("end test")
         """
     )
-    result = testdir.runpytest_subprocess("--log-cli-level=INFO")
+    result = pytester.runpytest_subprocess("--log-cli-level=INFO")
     assert result.ret == 0

     with open("caplog") as f:
@@ -1547,11 +1558,13 @@


 @pytest.mark.parametrize("capture_fixture", ["capsys", "capfd"])
-def test_capture_with_live_logging(testdir, capture_fixture):
+def test_capture_with_live_logging(
+    pytester: Pytester, capture_fixture: CaptureFixture[str]
+) -> None:
     # Issue 3819
     # capture should work with live cli logging

-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import logging
         import sys
@@ -1576,21 +1589,21 @@
         )
     )

-    result = testdir.runpytest_subprocess("--log-cli-level=INFO")
+    result = pytester.runpytest_subprocess("--log-cli-level=INFO")
     assert result.ret == 0


-def test_typeerror_encodedfile_write(testdir):
+def test_typeerror_encodedfile_write(pytester: Pytester) -> None:
     """It should behave the same with and without output capturing (#4861)."""
-    p = testdir.makepyfile(
+    p = pytester.makepyfile(
         """
         def test_fails():
             import sys
             sys.stdout.write(b"foo")
     """
     )
-    result_without_capture = testdir.runpytest("-s", str(p))
-    result_with_capture = testdir.runpytest(str(p))
+    result_without_capture = pytester.runpytest("-s", str(p))
+    result_with_capture = pytester.runpytest(str(p))

     assert result_with_capture.ret == result_without_capture.ret
     out = result_with_capture.stdout.str()
@@ -1599,7 +1612,7 @@
     )


-def test_stderr_write_returns_len(capsys):
+def test_stderr_write_returns_len(capsys: CaptureFixture[str]) -> None:
     """Write on Encoded files, namely captured stderr, should return number of characters written."""
     assert sys.stderr.write("Foo") == 3

@@ -1607,7 +1620,7 @@
 def test_encodedfile_writelines(tmpfile: BinaryIO) -> None:
     ef = capture.EncodedFile(tmpfile, encoding="utf-8")
     with pytest.raises(TypeError):
-        ef.writelines([b"line1", b"line2"])
+        ef.writelines([b"line1", b"line2"])  # type: ignore[list-item]
     assert ef.writelines(["line3", "line4"]) is None  # type: ignore[func-returns-value]
     ef.flush()
     tmpfile.seek(0)
@@ -1624,9 +1637,9 @@
     )


-def test_logging_while_collecting(testdir):
+def test_logging_while_collecting(pytester: Pytester) -> None:
     """Issue #6240: Calls to logging.xxx() during collection causes all logging calls to be duplicated to stderr"""
-    p = testdir.makepyfile(
+    p = pytester.makepyfile(
         """\
         import logging

@@ -1637,7 +1650,7 @@
             assert False
         """
     )
-    result = testdir.runpytest_subprocess(p)
+    result = pytester.runpytest_subprocess(p)
     assert result.ret == ExitCode.TESTS_FAILED
     result.stdout.fnmatch_lines(
         [
('testing', 'test_parseopt.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -3,22 +3,23 @@
 import shlex
 import subprocess
 import sys
-
-import py
+from pathlib import Path

 import pytest
 from _pytest.config import argparsing as parseopt
 from _pytest.config.exceptions import UsageError
+from _pytest.monkeypatch import MonkeyPatch
+from _pytest.pytester import Pytester


 @pytest.fixture
 def parser() -> parseopt.Parser:
-    return parseopt.Parser()
+    return parseopt.Parser(_ispytest=True)


 class TestParser:
     def test_no_help_by_default(self) -> None:
-        parser = parseopt.Parser(usage="xyz")
+        parser = parseopt.Parser(usage="xyz", _ispytest=True)
         pytest.raises(UsageError, lambda: parser.parse(["-h"]))

     def test_custom_prog(self, parser: parseopt.Parser) -> None:
@@ -89,13 +90,13 @@
         assert groups_names == list("132")

     def test_group_addoption(self) -> None:
-        group = parseopt.OptionGroup("hello")
+        group = parseopt.OptionGroup("hello", _ispytest=True)
         group.addoption("--option1", action="store_true")
         assert len(group.options) == 1
         assert isinstance(group.options[0], parseopt.Argument)

     def test_group_addoption_conflict(self) -> None:
-        group = parseopt.OptionGroup("hello again")
+        group = parseopt.OptionGroup("hello again", _ispytest=True)
         group.addoption("--option1", "--option-1", action="store_true")
         with pytest.raises(ValueError) as err:
             group.addoption("--option1", "--option-one", action="store_true")
@@ -122,11 +123,11 @@
         assert not getattr(args, parseopt.FILE_OR_DIR)

     def test_parse2(self, parser: parseopt.Parser) -> None:
-        args = parser.parse([py.path.local()])
-        assert getattr(args, parseopt.FILE_OR_DIR)[0] == py.path.local()
+        args = parser.parse([Path(".")])
+        assert getattr(args, parseopt.FILE_OR_DIR)[0] == "."

     def test_parse_known_args(self, parser: parseopt.Parser) -> None:
-        parser.parse_known_args([py.path.local()])
+        parser.parse_known_args([Path(".")])
         parser.addoption("--hello", action="store_true")
         ns = parser.parse_known_args(["x", "--y", "--hello", "this"])
         assert ns.hello
@@ -187,7 +188,7 @@
             elif option.type is str:
                 option.default = "world"

-        parser = parseopt.Parser(processopt=defaultget)
+        parser = parseopt.Parser(processopt=defaultget, _ispytest=True)
         parser.addoption("--this", dest="this", type=int, action="store")
         parser.addoption("--hello", dest="hello", type=str, action="store")
         parser.addoption("--no", dest="no", action="store_true")
@@ -287,14 +288,14 @@
         assert "--preferences=value1 value2 value3" in help


-def test_argcomplete(testdir, monkeypatch) -> None:
+def test_argcomplete(pytester: Pytester, monkeypatch: MonkeyPatch) -> None:
     try:
         bash_version = subprocess.run(
             ["bash", "--version"],
             stdout=subprocess.PIPE,
             stderr=subprocess.DEVNULL,
             check=True,
-            universal_newlines=True,
+            text=True,
         ).stdout
     except (OSError, subprocess.CalledProcessError):
         pytest.skip("bash is not available")
@@ -302,7 +303,7 @@
         # See #7518.
         pytest.skip("not a real bash")

-    script = str(testdir.tmpdir.join("test_argcomplete"))
+    script = str(pytester.path.joinpath("test_argcomplete"))

     with open(str(script), "w") as fp:
         # redirect output from argcomplete to stdin and stderr is not trivial
@@ -313,7 +314,7 @@
                 shlex.quote(sys.executable)
             )
         )
-    # alternative would be extended Testdir.{run(),_run(),popen()} to be able
+    # alternative would be extended Pytester.{run(),_run(),popen()} to be able
     # to handle a keyword argument env that replaces os.environ in popen or
     # extends the copy, advantage: could not forget to restore
     monkeypatch.setenv("_ARGCOMPLETE", "1")
@@ -323,7 +324,7 @@
     arg = "--fu"
     monkeypatch.setenv("COMP_LINE", "pytest " + arg)
     monkeypatch.setenv("COMP_POINT", str(len("pytest " + arg)))
-    result = testdir.run("bash", str(script), arg)
+    result = pytester.run("bash", str(script), arg)
     if result.ret == 255:
         # argcomplete not found
         pytest.skip("argcomplete not available")
@@ -339,5 +340,5 @@
     arg = "test_argc"
     monkeypatch.setenv("COMP_LINE", "pytest " + arg)
     monkeypatch.setenv("COMP_POINT", str(len("pytest " + arg)))
-    result = testdir.run("bash", str(script), arg)
+    result = pytester.run("bash", str(script), arg)
     result.stdout.fnmatch_lines(["test_argcomplete", "test_argcomplete.d/"])
('testing', 'test_link_resolve.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -3,15 +3,14 @@
 import sys
 import textwrap
 from contextlib import contextmanager
+from pathlib import Path
 from string import ascii_lowercase

-import py.path
-
-from _pytest import pytester
+from _pytest.pytester import Pytester


 @contextmanager
-def subst_path_windows(filename):
+def subst_path_windows(filepath: Path):
     for c in ascii_lowercase[7:]:  # Create a subst drive from H-Z.
         c += ":"
         if not os.path.exists(c):
@@ -20,14 +19,14 @@
     else:
         raise AssertionError("Unable to find suitable drive letter for subst.")

-    directory = filename.dirpath()
-    basename = filename.basename
+    directory = filepath.parent
+    basename = filepath.name

     args = ["subst", drive, str(directory)]
     subprocess.check_call(args)
     assert os.path.exists(drive)
     try:
-        filename = py.path.local(drive) / basename
+        filename = Path(drive, os.sep, basename)
         yield filename
     finally:
         args = ["subst", "/D", drive]
@@ -35,9 +34,9 @@


 @contextmanager
-def subst_path_linux(filename):
-    directory = filename.dirpath()
-    basename = filename.basename
+def subst_path_linux(filepath: Path):
+    directory = filepath.parent
+    basename = filepath.name

     target = directory / ".." / "sub2"
     os.symlink(str(directory), str(target), target_is_directory=True)
@@ -49,11 +48,11 @@
         pass


-def test_link_resolve(testdir: pytester.Testdir) -> None:
+def test_link_resolve(pytester: Pytester) -> None:
     """See: https://github.com/pytest-dev/pytest/issues/5965."""
-    sub1 = testdir.mkpydir("sub1")
-    p = sub1.join("test_foo.py")
-    p.write(
+    sub1 = pytester.mkpydir("sub1")
+    p = sub1.joinpath("test_foo.py")
+    p.write_text(
         textwrap.dedent(
             """
         import pytest
@@ -68,7 +67,7 @@
         subst = subst_path_windows

     with subst(p) as subst_p:
-        result = testdir.runpytest(str(subst_p), "-v")
+        result = pytester.runpytest(str(subst_p), "-v")
         # i.e.: Make sure that the error is reported as a relative path, not as a
         # resolved path.
         # See: https://github.com/pytest-dev/pytest/issues/5965
@@ -77,7 +76,5 @@

         # i.e.: Expect drive on windows because we just have drive:filename, whereas
         # we expect a relative path on Linux.
-        expect = (
-            "*{}*".format(subst_p) if sys.platform == "win32" else "*sub2/test_foo.py*"
-        )
+        expect = f"*{subst_p}*" if sys.platform == "win32" else "*sub2/test_foo.py*"
         result.stdout.fnmatch_lines([expect])
('testing', 'test_helpconfig.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,28 +1,32 @@
 import pytest
 from _pytest.config import ExitCode
+from _pytest.pytester import Pytester


-def test_version_verbose(testdir, pytestconfig):
-    testdir.monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD")
-    result = testdir.runpytest("--version", "--version")
+def test_version_verbose(pytester: Pytester, pytestconfig, monkeypatch) -> None:
+    monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD")
+    result = pytester.runpytest("--version", "--version")
     assert result.ret == 0
-    result.stderr.fnmatch_lines(
-        ["*pytest*{}*imported from*".format(pytest.__version__)]
-    )
+    result.stdout.fnmatch_lines([f"*pytest*{pytest.__version__}*imported from*"])
     if pytestconfig.pluginmanager.list_plugin_distinfo():
-        result.stderr.fnmatch_lines(["*setuptools registered plugins:", "*at*"])
+        result.stdout.fnmatch_lines(["*setuptools registered plugins:", "*at*"])


-def test_version_less_verbose(testdir, pytestconfig):
-    testdir.monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD")
-    result = testdir.runpytest("--version")
+def test_version_less_verbose(pytester: Pytester, pytestconfig, monkeypatch) -> None:
+    monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD")
+    result = pytester.runpytest("--version")
     assert result.ret == 0
-    # p = py.path.local(py.__file__).dirpath()
-    result.stderr.fnmatch_lines(["pytest {}".format(pytest.__version__)])
+    result.stdout.fnmatch_lines([f"pytest {pytest.__version__}"])


-def test_help(testdir):
-    result = testdir.runpytest("--help")
+def test_versions():
+    """Regression check for the public version attributes in pytest."""
+    assert isinstance(pytest.__version__, str)
+    assert isinstance(pytest.version_tuple, tuple)
+
+
+def test_help(pytester: Pytester) -> None:
+    result = pytester.runpytest("--help")
     assert result.ret == 0
     result.stdout.fnmatch_lines(
         """
@@ -30,6 +34,9 @@
                                 For example: -m 'mark1 and not mark2'.
         reporting:
           --durations=N *
+          -V, --version         display pytest version and information about plugins.
+                                When given twice, also display information about
+                                plugins.
         *setup.cfg*
         *minversion*
         *to see*markers*pytest --markers*
@@ -38,29 +45,29 @@
     )


-def test_none_help_param_raises_exception(testdir):
+def test_none_help_param_raises_exception(pytester: Pytester) -> None:
     """Test that a None help param raises a TypeError."""
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         def pytest_addoption(parser):
             parser.addini("test_ini", None, default=True, type="bool")
     """
     )
-    result = testdir.runpytest("--help")
+    result = pytester.runpytest("--help")
     result.stderr.fnmatch_lines(
         ["*TypeError: help argument cannot be None for test_ini*"]
     )


-def test_empty_help_param(testdir):
+def test_empty_help_param(pytester: Pytester) -> None:
     """Test that an empty help param is displayed correctly."""
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         def pytest_addoption(parser):
             parser.addini("test_ini", "", default=True, type="bool")
     """
     )
-    result = testdir.runpytest("--help")
+    result = pytester.runpytest("--help")
     assert result.ret == 0
     lines = [
         "  required_plugins (args):",
@@ -71,20 +78,20 @@
     result.stdout.fnmatch_lines(lines, consecutive=True)


-def test_hookvalidation_unknown(testdir):
-    testdir.makeconftest(
+def test_hookvalidation_unknown(pytester: Pytester) -> None:
+    pytester.makeconftest(
         """
         def pytest_hello(xyz):
             pass
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert result.ret != 0
     result.stdout.fnmatch_lines(["*unknown hook*pytest_hello*"])


-def test_hookvalidation_optional(testdir):
-    testdir.makeconftest(
+def test_hookvalidation_optional(pytester: Pytester) -> None:
+    pytester.makeconftest(
         """
         import pytest
         @pytest.hookimpl(optionalhook=True)
@@ -92,25 +99,25 @@
             pass
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert result.ret == ExitCode.NO_TESTS_COLLECTED


-def test_traceconfig(testdir):
-    result = testdir.runpytest("--traceconfig")
-    result.stdout.fnmatch_lines(["*using*pytest*py*", "*active plugins*"])
+def test_traceconfig(pytester: Pytester) -> None:
+    result = pytester.runpytest("--traceconfig")
+    result.stdout.fnmatch_lines(["*using*pytest*", "*active plugins*"])


-def test_debug(testdir):
-    result = testdir.runpytest_subprocess("--debug")
+def test_debug(pytester: Pytester) -> None:
+    result = pytester.runpytest_subprocess("--debug")
     assert result.ret == ExitCode.NO_TESTS_COLLECTED
-    p = testdir.tmpdir.join("pytestdebug.log")
-    assert "pytest_sessionstart" in p.read()
+    p = pytester.path.joinpath("pytestdebug.log")
+    assert "pytest_sessionstart" in p.read_text("utf-8")


-def test_PYTEST_DEBUG(testdir, monkeypatch):
+def test_PYTEST_DEBUG(pytester: Pytester, monkeypatch) -> None:
     monkeypatch.setenv("PYTEST_DEBUG", "1")
-    result = testdir.runpytest_subprocess()
+    result = pytester.runpytest_subprocess()
     assert result.ret == ExitCode.NO_TESTS_COLLECTED
     result.stderr.fnmatch_lines(
         ["*pytest_plugin_registered*", "*manager*PluginManager*"]
('testing', 'test_debugging.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,17 +1,12 @@
 import os
 import sys
+from typing import List

 import _pytest._code
 import pytest
 from _pytest.debugging import _validate_usepdb_cls
-
-try:
-    # Type ignored for Python <= 3.6.
-    breakpoint  # type: ignore
-except NameError:
-    SUPPORTS_BREAKPOINT_BUILTIN = False
-else:
-    SUPPORTS_BREAKPOINT_BUILTIN = True
+from _pytest.monkeypatch import MonkeyPatch
+from _pytest.pytester import Pytester


 _ENVIRON_PYTHONBREAKPOINT = os.environ.get("PYTHONBREAKPOINT", "")
@@ -19,22 +14,22 @@

 @pytest.fixture(autouse=True)
 def pdb_env(request):
-    if "testdir" in request.fixturenames:
+    if "pytester" in request.fixturenames:
         # Disable pdb++ with inner tests.
-        testdir = request.getfixturevalue("testdir")
-        testdir.monkeypatch.setenv("PDBPP_HIJACK_PDB", "0")
-
-
-def runpdb_and_get_report(testdir, source):
-    p = testdir.makepyfile(source)
-    result = testdir.runpytest_inprocess("--pdb", p)
-    reports = result.reprec.getreports("pytest_runtest_logreport")
+        pytester = request.getfixturevalue("pytester")
+        pytester._monkeypatch.setenv("PDBPP_HIJACK_PDB", "0")
+
+
+def runpdb_and_get_report(pytester: Pytester, source: str):
+    p = pytester.makepyfile(source)
+    result = pytester.runpytest_inprocess("--pdb", p)
+    reports = result.reprec.getreports("pytest_runtest_logreport")  # type: ignore[attr-defined]
     assert len(reports) == 3, reports  # setup/call/teardown
     return reports[1]


 @pytest.fixture
-def custom_pdb_calls():
+def custom_pdb_calls() -> List[str]:
     called = []

     # install dummy debugger class and track which methods were called on it
@@ -91,9 +86,9 @@
         monkeypatch.setattr(plugin, "post_mortem", mypdb)
         return pdblist

-    def test_pdb_on_fail(self, testdir, pdblist):
+    def test_pdb_on_fail(self, pytester: Pytester, pdblist) -> None:
         rep = runpdb_and_get_report(
-            testdir,
+            pytester,
             """
             def test_func():
                 assert 0
@@ -104,9 +99,9 @@
         tb = _pytest._code.Traceback(pdblist[0][0])
         assert tb[-1].name == "test_func"

-    def test_pdb_on_xfail(self, testdir, pdblist):
+    def test_pdb_on_xfail(self, pytester: Pytester, pdblist) -> None:
         rep = runpdb_and_get_report(
-            testdir,
+            pytester,
             """
             import pytest
             @pytest.mark.xfail
@@ -117,9 +112,9 @@
         assert "xfail" in rep.keywords
         assert not pdblist

-    def test_pdb_on_skip(self, testdir, pdblist):
+    def test_pdb_on_skip(self, pytester, pdblist) -> None:
         rep = runpdb_and_get_report(
-            testdir,
+            pytester,
             """
             import pytest
             def test_func():
@@ -129,9 +124,9 @@
         assert rep.skipped
         assert len(pdblist) == 0

-    def test_pdb_on_BdbQuit(self, testdir, pdblist):
+    def test_pdb_on_BdbQuit(self, pytester, pdblist) -> None:
         rep = runpdb_and_get_report(
-            testdir,
+            pytester,
             """
             import bdb
             def test_func():
@@ -141,9 +136,9 @@
         assert rep.failed
         assert len(pdblist) == 0

-    def test_pdb_on_KeyboardInterrupt(self, testdir, pdblist):
+    def test_pdb_on_KeyboardInterrupt(self, pytester, pdblist) -> None:
         rep = runpdb_and_get_report(
-            testdir,
+            pytester,
             """
             def test_func():
                 raise KeyboardInterrupt
@@ -160,8 +155,8 @@
             child.wait()
         assert not child.isalive()

-    def test_pdb_unittest_postmortem(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_pdb_unittest_postmortem(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             import unittest
             class Blub(unittest.TestCase):
@@ -172,7 +167,7 @@
                     assert 0
         """
         )
-        child = testdir.spawn_pytest("--pdb %s" % p1)
+        child = pytester.spawn_pytest(f"--pdb {p1}")
         child.expect("Pdb")
         child.sendline("p self.filename")
         child.sendeof()
@@ -180,9 +175,9 @@
         assert "debug.me" in rest
         self.flush(child)

-    def test_pdb_unittest_skip(self, testdir):
+    def test_pdb_unittest_skip(self, pytester: Pytester) -> None:
         """Test for issue #2137"""
-        p1 = testdir.makepyfile(
+        p1 = pytester.makepyfile(
             """
             import unittest
             @unittest.skipIf(True, 'Skipping also with pdb active')
@@ -191,14 +186,14 @@
                     assert 0
         """
         )
-        child = testdir.spawn_pytest("-rs --pdb %s" % p1)
+        child = pytester.spawn_pytest(f"-rs --pdb {p1}")
         child.expect("Skipping also with pdb active")
         child.expect_exact("= 1 skipped in")
         child.sendeof()
         self.flush(child)

-    def test_pdb_print_captured_stdout_and_stderr(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_pdb_print_captured_stdout_and_stderr(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             def test_1():
                 import sys
@@ -210,7 +205,7 @@
                 pass
         """
         )
-        child = testdir.spawn_pytest("--pdb %s" % p1)
+        child = pytester.spawn_pytest("--pdb %s" % p1)
         child.expect("captured stdout")
         child.expect("get rekt")
         child.expect("captured stderr")
@@ -226,14 +221,16 @@
         assert "get rekt" not in rest
         self.flush(child)

-    def test_pdb_dont_print_empty_captured_stdout_and_stderr(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_pdb_dont_print_empty_captured_stdout_and_stderr(
+        self, pytester: Pytester
+    ) -> None:
+        p1 = pytester.makepyfile(
             """
             def test_1():
                 assert False
         """
         )
-        child = testdir.spawn_pytest("--pdb %s" % p1)
+        child = pytester.spawn_pytest("--pdb %s" % p1)
         child.expect("Pdb")
         output = child.before.decode("utf8")
         child.sendeof()
@@ -242,8 +239,8 @@
         self.flush(child)

     @pytest.mark.parametrize("showcapture", ["all", "no", "log"])
-    def test_pdb_print_captured_logs(self, testdir, showcapture):
-        p1 = testdir.makepyfile(
+    def test_pdb_print_captured_logs(self, pytester, showcapture: str) -> None:
+        p1 = pytester.makepyfile(
             """
             def test_1():
                 import logging
@@ -251,9 +248,7 @@
                 assert False
         """
         )
-        child = testdir.spawn_pytest(
-            "--show-capture={} --pdb {}".format(showcapture, p1)
-        )
+        child = pytester.spawn_pytest(f"--show-capture={showcapture} --pdb {p1}")
         if showcapture in ("all", "log"):
             child.expect("captured log")
             child.expect("get rekt")
@@ -263,8 +258,8 @@
         assert "1 failed" in rest
         self.flush(child)

-    def test_pdb_print_captured_logs_nologging(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_pdb_print_captured_logs_nologging(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             def test_1():
                 import logging
@@ -272,7 +267,7 @@
                 assert False
         """
         )
-        child = testdir.spawn_pytest("--show-capture=all --pdb -p no:logging %s" % p1)
+        child = pytester.spawn_pytest("--show-capture=all --pdb -p no:logging %s" % p1)
         child.expect("get rekt")
         output = child.before.decode("utf8")
         assert "captured log" not in output
@@ -282,8 +277,8 @@
         assert "1 failed" in rest
         self.flush(child)

-    def test_pdb_interaction_exception(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_pdb_interaction_exception(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             import pytest
             def globalfunc():
@@ -292,7 +287,7 @@
                 pytest.raises(ValueError, globalfunc)
         """
         )
-        child = testdir.spawn_pytest("--pdb %s" % p1)
+        child = pytester.spawn_pytest("--pdb %s" % p1)
         child.expect(".*def test_1")
         child.expect(".*pytest.raises.*globalfunc")
         child.expect("Pdb")
@@ -302,29 +297,29 @@
         child.expect("1 failed")
         self.flush(child)

-    def test_pdb_interaction_on_collection_issue181(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_pdb_interaction_on_collection_issue181(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             import pytest
             xxx
         """
         )
-        child = testdir.spawn_pytest("--pdb %s" % p1)
+        child = pytester.spawn_pytest("--pdb %s" % p1)
         # child.expect(".*import pytest.*")
         child.expect("Pdb")
         child.sendline("c")
         child.expect("1 error")
         self.flush(child)

-    def test_pdb_interaction_on_internal_error(self, testdir):
-        testdir.makeconftest(
+    def test_pdb_interaction_on_internal_error(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             def pytest_runtest_protocol():
                 0/0
         """
         )
-        p1 = testdir.makepyfile("def test_func(): pass")
-        child = testdir.spawn_pytest("--pdb %s" % p1)
+        p1 = pytester.makepyfile("def test_func(): pass")
+        child = pytester.spawn_pytest("--pdb %s" % p1)
         child.expect("Pdb")

         # INTERNALERROR is only displayed once via terminal reporter.
@@ -342,17 +337,24 @@
         child.sendeof()
         self.flush(child)

-    def test_pdb_prevent_ConftestImportFailure_hiding_exception(self, testdir):
-        testdir.makepyfile("def test_func(): pass")
-        sub_dir = testdir.tmpdir.join("ns").ensure_dir()
-        sub_dir.join("conftest").new(ext=".py").write("import unknown")
-        sub_dir.join("test_file").new(ext=".py").write("def test_func(): pass")
-
-        result = testdir.runpytest_subprocess("--pdb", ".")
+    def test_pdb_prevent_ConftestImportFailure_hiding_exception(
+        self, pytester: Pytester
+    ) -> None:
+        pytester.makepyfile("def test_func(): pass")
+        sub_dir = pytester.path.joinpath("ns")
+        sub_dir.mkdir()
+        sub_dir.joinpath("conftest").with_suffix(".py").write_text(
+            "import unknown", "utf-8"
+        )
+        sub_dir.joinpath("test_file").with_suffix(".py").write_text(
+            "def test_func(): pass", "utf-8"
+        )
+
+        result = pytester.runpytest_subprocess("--pdb", ".")
         result.stdout.fnmatch_lines(["-> import unknown"])

-    def test_pdb_interaction_capturing_simple(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_pdb_interaction_capturing_simple(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             import pytest
             def test_1():
@@ -363,7 +365,7 @@
                 assert 0
         """
         )
-        child = testdir.spawn_pytest(str(p1))
+        child = pytester.spawn_pytest(str(p1))
         child.expect(r"test_1\(\)")
         child.expect("i == 1")
         child.expect("Pdb")
@@ -375,8 +377,8 @@
         assert "hello17" in rest  # out is captured
         self.flush(child)

-    def test_pdb_set_trace_kwargs(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_pdb_set_trace_kwargs(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             import pytest
             def test_1():
@@ -387,7 +389,7 @@
                 assert 0
         """
         )
-        child = testdir.spawn_pytest(str(p1))
+        child = pytester.spawn_pytest(str(p1))
         child.expect("== my_header ==")
         assert "PDB set_trace" not in child.before.decode()
         child.expect("Pdb")
@@ -398,15 +400,15 @@
         assert "hello17" in rest  # out is captured
         self.flush(child)

-    def test_pdb_set_trace_interception(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_pdb_set_trace_interception(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             import pdb
             def test_1():
                 pdb.set_trace()
         """
         )
-        child = testdir.spawn_pytest(str(p1))
+        child = pytester.spawn_pytest(str(p1))
         child.expect("test_1")
         child.expect("Pdb")
         child.sendline("q")
@@ -416,8 +418,8 @@
         assert "BdbQuit" not in rest
         self.flush(child)

-    def test_pdb_and_capsys(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_pdb_and_capsys(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             import pytest
             def test_1(capsys):
@@ -425,7 +427,7 @@
                 pytest.set_trace()
         """
         )
-        child = testdir.spawn_pytest(str(p1))
+        child = pytester.spawn_pytest(str(p1))
         child.expect("test_1")
         child.send("capsys.readouterr()\n")
         child.expect("hello1")
@@ -433,8 +435,8 @@
         child.read()
         self.flush(child)

-    def test_pdb_with_caplog_on_pdb_invocation(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_pdb_with_caplog_on_pdb_invocation(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             def test_1(capsys, caplog):
                 import logging
@@ -442,7 +444,7 @@
                 assert 0
         """
         )
-        child = testdir.spawn_pytest("--pdb %s" % str(p1))
+        child = pytester.spawn_pytest("--pdb %s" % str(p1))
         child.send("caplog.record_tuples\n")
         child.expect_exact(
             "[('test_pdb_with_caplog_on_pdb_invocation', 30, 'some_warning')]"
@@ -451,8 +453,8 @@
         child.read()
         self.flush(child)

-    def test_set_trace_capturing_afterwards(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_set_trace_capturing_afterwards(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             import pdb
             def test_1():
@@ -462,7 +464,7 @@
                 assert 0
         """
         )
-        child = testdir.spawn_pytest(str(p1))
+        child = pytester.spawn_pytest(str(p1))
         child.expect("test_1")
         child.send("c\n")
         child.expect("test_2")
@@ -472,8 +474,8 @@
         child.read()
         self.flush(child)

-    def test_pdb_interaction_doctest(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_pdb_interaction_doctest(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             def function_1():
                 '''
@@ -482,7 +484,7 @@
                 '''
         """
         )
-        child = testdir.spawn_pytest("--doctest-modules --pdb %s" % p1)
+        child = pytester.spawn_pytest("--doctest-modules --pdb %s" % p1)
         child.expect("Pdb")

         assert "UNEXPECTED EXCEPTION: AssertionError()" in child.before.decode("utf8")
@@ -498,8 +500,8 @@
         assert "1 failed" in rest
         self.flush(child)

-    def test_doctest_set_trace_quit(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_doctest_set_trace_quit(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             def function_1():
                 '''
@@ -509,7 +511,7 @@
         )
         # NOTE: does not use pytest.set_trace, but Python's patched pdb,
         #       therefore "-s" is required.
-        child = testdir.spawn_pytest("--doctest-modules --pdb -s %s" % p1)
+        child = pytester.spawn_pytest("--doctest-modules --pdb -s %s" % p1)
         child.expect("Pdb")
         child.sendline("q")
         rest = child.read().decode("utf8")
@@ -519,8 +521,8 @@
         assert "BdbQuit" not in rest
         assert "UNEXPECTED EXCEPTION" not in rest

-    def test_pdb_interaction_capturing_twice(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_pdb_interaction_capturing_twice(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             import pytest
             def test_1():
@@ -534,7 +536,7 @@
                 assert 0
         """
         )
-        child = testdir.spawn_pytest(str(p1))
+        child = pytester.spawn_pytest(str(p1))
         child.expect(r"PDB set_trace \(IO-capturing turned off\)")
         child.expect("test_1")
         child.expect("x = 3")
@@ -554,11 +556,11 @@
         assert "1 failed" in rest
         self.flush(child)

-    def test_pdb_with_injected_do_debug(self, testdir):
+    def test_pdb_with_injected_do_debug(self, pytester: Pytester) -> None:
         """Simulates pdbpp, which injects Pdb into do_debug, and uses
         self.__class__ in do_continue.
         """
-        p1 = testdir.makepyfile(
+        p1 = pytester.makepyfile(
             mytest="""
             import pdb
             import pytest
@@ -600,7 +602,7 @@
                 pytest.fail("expected_failure")
         """
         )
-        child = testdir.spawn_pytest("--pdbcls=mytest:CustomPdb %s" % str(p1))
+        child = pytester.spawn_pytest("--pdbcls=mytest:CustomPdb %s" % str(p1))
         child.expect(r"PDB set_trace \(IO-capturing turned off\)")
         child.expect(r"\n\(Pdb")
         child.sendline("debug foo()")
@@ -629,15 +631,15 @@
         assert "AssertionError: unexpected_failure" not in rest
         self.flush(child)

-    def test_pdb_without_capture(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_pdb_without_capture(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             import pytest
             def test_1():
                 pytest.set_trace()
         """
         )
-        child = testdir.spawn_pytest("-s %s" % p1)
+        child = pytester.spawn_pytest("-s %s" % p1)
         child.expect(r">>> PDB set_trace >>>")
         child.expect("Pdb")
         child.sendline("c")
@@ -646,13 +648,15 @@
         self.flush(child)

     @pytest.mark.parametrize("capture_arg", ("", "-s", "-p no:capture"))
-    def test_pdb_continue_with_recursive_debug(self, capture_arg, testdir):
+    def test_pdb_continue_with_recursive_debug(
+        self, capture_arg, pytester: Pytester
+    ) -> None:
         """Full coverage for do_debug without capturing.

         This is very similar to test_pdb_interaction_continue_recursive in general,
         but mocks out ``pdb.set_trace`` for providing more coverage.
         """
-        p1 = testdir.makepyfile(
+        p1 = pytester.makepyfile(
             """
             try:
                 input = raw_input
@@ -706,7 +710,7 @@
                 set_trace()
         """
         )
-        child = testdir.spawn_pytest("--tb=short {} {}".format(p1, capture_arg))
+        child = pytester.spawn_pytest(f"--tb=short {p1} {capture_arg}")
         child.expect("=== SET_TRACE ===")
         before = child.before.decode("utf8")
         if not capture_arg:
@@ -736,22 +740,22 @@
             assert "> PDB continue >" in rest
         assert "= 1 passed in" in rest

-    def test_pdb_used_outside_test(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_pdb_used_outside_test(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             import pytest
             pytest.set_trace()
             x = 5
         """
         )
-        child = testdir.spawn("{} {}".format(sys.executable, p1))
+        child = pytester.spawn(f"{sys.executable} {p1}")
         child.expect("x = 5")
         child.expect("Pdb")
         child.sendeof()
         self.flush(child)

-    def test_pdb_used_in_generate_tests(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_pdb_used_in_generate_tests(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             import pytest
             def pytest_generate_tests(metafunc):
@@ -761,22 +765,24 @@
                 pass
         """
         )
-        child = testdir.spawn_pytest(str(p1))
+        child = pytester.spawn_pytest(str(p1))
         child.expect("x = 5")
         child.expect("Pdb")
         child.sendeof()
         self.flush(child)

-    def test_pdb_collection_failure_is_shown(self, testdir):
-        p1 = testdir.makepyfile("xxx")
-        result = testdir.runpytest_subprocess("--pdb", p1)
+    def test_pdb_collection_failure_is_shown(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile("xxx")
+        result = pytester.runpytest_subprocess("--pdb", p1)
         result.stdout.fnmatch_lines(
             ["E   NameError: *xxx*", "*! *Exit: Quitting debugger !*"]  # due to EOF
         )

     @pytest.mark.parametrize("post_mortem", (False, True))
-    def test_enter_leave_pdb_hooks_are_called(self, post_mortem, testdir):
-        testdir.makeconftest(
+    def test_enter_leave_pdb_hooks_are_called(
+        self, post_mortem, pytester: Pytester
+    ) -> None:
+        pytester.makeconftest(
             """
             mypdb = None

@@ -800,7 +806,7 @@
                 assert mypdb.set_attribute == "bar"
         """
         )
-        p1 = testdir.makepyfile(
+        p1 = pytester.makepyfile(
             """
             import pytest

@@ -813,9 +819,9 @@
         """
         )
         if post_mortem:
-            child = testdir.spawn_pytest(str(p1) + " --pdb -s -k test_post_mortem")
+            child = pytester.spawn_pytest(str(p1) + " --pdb -s -k test_post_mortem")
         else:
-            child = testdir.spawn_pytest(str(p1) + " -k test_set_trace")
+            child = pytester.spawn_pytest(str(p1) + " -k test_set_trace")
         child.expect("enter_pdb_hook")
         child.sendline("c")
         if post_mortem:
@@ -828,14 +834,18 @@
         assert "1 failed" in rest
         self.flush(child)

-    def test_pdb_custom_cls(self, testdir, custom_pdb_calls):
-        p1 = testdir.makepyfile("""xxx """)
-        result = testdir.runpytest_inprocess("--pdb", "--pdbcls=_pytest:_CustomPdb", p1)
+    def test_pdb_custom_cls(
+        self, pytester: Pytester, custom_pdb_calls: List[str]
+    ) -> None:
+        p1 = pytester.makepyfile("""xxx """)
+        result = pytester.runpytest_inprocess(
+            "--pdb", "--pdbcls=_pytest:_CustomPdb", p1
+        )
         result.stdout.fnmatch_lines(["*NameError*xxx*", "*1 error*"])
         assert custom_pdb_calls == ["init", "reset", "interaction"]

-    def test_pdb_custom_cls_invalid(self, testdir):
-        result = testdir.runpytest_inprocess("--pdbcls=invalid")
+    def test_pdb_custom_cls_invalid(self, pytester: Pytester) -> None:
+        result = pytester.runpytest_inprocess("--pdbcls=invalid")
         result.stderr.fnmatch_lines(
             [
                 "*: error: argument --pdbcls: 'invalid' is not in the format 'modname:classname'"
@@ -850,14 +860,20 @@

         assert _validate_usepdb_cls("pdb:DoesNotExist") == ("pdb", "DoesNotExist")

-    def test_pdb_custom_cls_without_pdb(self, testdir, custom_pdb_calls):
-        p1 = testdir.makepyfile("""xxx """)
-        result = testdir.runpytest_inprocess("--pdbcls=_pytest:_CustomPdb", p1)
+    def test_pdb_custom_cls_without_pdb(
+        self, pytester: Pytester, custom_pdb_calls: List[str]
+    ) -> None:
+        p1 = pytester.makepyfile("""xxx """)
+        result = pytester.runpytest_inprocess("--pdbcls=_pytest:_CustomPdb", p1)
         result.stdout.fnmatch_lines(["*NameError*xxx*", "*1 error*"])
         assert custom_pdb_calls == []

-    def test_pdb_custom_cls_with_set_trace(self, testdir, monkeypatch):
-        testdir.makepyfile(
+    def test_pdb_custom_cls_with_set_trace(
+        self,
+        pytester: Pytester,
+        monkeypatch: MonkeyPatch,
+    ) -> None:
+        pytester.makepyfile(
             custom_pdb="""
             class CustomPdb(object):
                 def __init__(self, *args, **kwargs):
@@ -870,7 +886,7 @@
                     print('custom set_trace>')
          """
         )
-        p1 = testdir.makepyfile(
+        p1 = pytester.makepyfile(
             """
             import pytest

@@ -878,8 +894,8 @@
                 pytest.set_trace(skip=['foo.*'])
         """
         )
-        monkeypatch.setenv("PYTHONPATH", str(testdir.tmpdir))
-        child = testdir.spawn_pytest("--pdbcls=custom_pdb:CustomPdb %s" % str(p1))
+        monkeypatch.setenv("PYTHONPATH", str(pytester.path))
+        child = pytester.spawn_pytest("--pdbcls=custom_pdb:CustomPdb %s" % str(p1))

         child.expect("__init__")
         child.expect("custom set_trace>")
@@ -887,33 +903,22 @@


 class TestDebuggingBreakpoints:
-    def test_supports_breakpoint_module_global(self):
-        """
-        Test that supports breakpoint global marks on Python 3.7+ and not on
-        CPython 3.5, 2.7
-        """
-        if sys.version_info >= (3, 7):
-            assert SUPPORTS_BREAKPOINT_BUILTIN is True
-        if sys.version_info.major == 3 and sys.version_info.minor == 5:
-            assert SUPPORTS_BREAKPOINT_BUILTIN is False  # type: ignore[comparison-overlap]
-
-    @pytest.mark.skipif(
-        not SUPPORTS_BREAKPOINT_BUILTIN, reason="Requires breakpoint() builtin"
-    )
     @pytest.mark.parametrize("arg", ["--pdb", ""])
-    def test_sys_breakpointhook_configure_and_unconfigure(self, testdir, arg):
+    def test_sys_breakpointhook_configure_and_unconfigure(
+        self, pytester: Pytester, arg: str
+    ) -> None:
         """
         Test that sys.breakpointhook is set to the custom Pdb class once configured, test that
         hook is reset to system value once pytest has been unconfigured
         """
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import sys
             from pytest import hookimpl
             from _pytest.debugging import pytestPDB

             def pytest_configure(config):
-                config._cleanup.append(check_restored)
+                config.add_cleanup(check_restored)

             def check_restored():
                 assert sys.breakpointhook == sys.__breakpointhook__
@@ -922,37 +927,33 @@
                 assert sys.breakpointhook == pytestPDB.set_trace
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_nothing(): pass
         """
         )
         args = (arg,) if arg else ()
-        result = testdir.runpytest_subprocess(*args)
+        result = pytester.runpytest_subprocess(*args)
         result.stdout.fnmatch_lines(["*1 passed in *"])

-    @pytest.mark.skipif(
-        not SUPPORTS_BREAKPOINT_BUILTIN, reason="Requires breakpoint() builtin"
-    )
-    def test_pdb_custom_cls(self, testdir, custom_debugger_hook):
-        p1 = testdir.makepyfile(
+    def test_pdb_custom_cls(self, pytester: Pytester, custom_debugger_hook) -> None:
+        p1 = pytester.makepyfile(
             """
             def test_nothing():
                 breakpoint()
         """
         )
-        result = testdir.runpytest_inprocess(
+        result = pytester.runpytest_inprocess(
             "--pdb", "--pdbcls=_pytest:_CustomDebugger", p1
         )
         result.stdout.fnmatch_lines(["*CustomDebugger*", "*1 passed*"])
         assert custom_debugger_hook == ["init", "set_trace"]

     @pytest.mark.parametrize("arg", ["--pdb", ""])
-    @pytest.mark.skipif(
-        not SUPPORTS_BREAKPOINT_BUILTIN, reason="Requires breakpoint() builtin"
-    )
-    def test_environ_custom_class(self, testdir, custom_debugger_hook, arg):
-        testdir.makeconftest(
+    def test_environ_custom_class(
+        self, pytester: Pytester, custom_debugger_hook, arg: str
+    ) -> None:
+        pytester.makeconftest(
             """
             import os
             import sys
@@ -960,7 +961,7 @@
             os.environ['PYTHONBREAKPOINT'] = '_pytest._CustomDebugger.set_trace'

             def pytest_configure(config):
-                config._cleanup.append(check_restored)
+                config.add_cleanup(check_restored)

             def check_restored():
                 assert sys.breakpointhook == sys.__breakpointhook__
@@ -970,30 +971,27 @@
                 assert sys.breakpointhook is _pytest._CustomDebugger.set_trace
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_nothing(): pass
         """
         )
         args = (arg,) if arg else ()
-        result = testdir.runpytest_subprocess(*args)
+        result = pytester.runpytest_subprocess(*args)
         result.stdout.fnmatch_lines(["*1 passed in *"])

-    @pytest.mark.skipif(
-        not SUPPORTS_BREAKPOINT_BUILTIN, reason="Requires breakpoint() builtin"
-    )
     @pytest.mark.skipif(
         not _ENVIRON_PYTHONBREAKPOINT == "",
         reason="Requires breakpoint() default value",
     )
-    def test_sys_breakpoint_interception(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_sys_breakpoint_interception(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             def test_1():
                 breakpoint()
         """
         )
-        child = testdir.spawn_pytest(str(p1))
+        child = pytester.spawn_pytest(str(p1))
         child.expect("test_1")
         child.expect("Pdb")
         child.sendline("quit")
@@ -1002,11 +1000,8 @@
         assert "reading from stdin while output" not in rest
         TestPDB.flush(child)

-    @pytest.mark.skipif(
-        not SUPPORTS_BREAKPOINT_BUILTIN, reason="Requires breakpoint() builtin"
-    )
-    def test_pdb_not_altered(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_pdb_not_altered(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             import pdb
             def test_1():
@@ -1014,7 +1009,7 @@
                 assert 0
         """
         )
-        child = testdir.spawn_pytest(str(p1))
+        child = pytester.spawn_pytest(str(p1))
         child.expect("test_1")
         child.expect("Pdb")
         child.sendline("c")
@@ -1025,8 +1020,8 @@


 class TestTraceOption:
-    def test_trace_sets_breakpoint(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_trace_sets_breakpoint(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile(
             """
             def test_1():
                 assert True
@@ -1038,7 +1033,7 @@
                 pass
             """
         )
-        child = testdir.spawn_pytest("--trace " + str(p1))
+        child = pytester.spawn_pytest("--trace " + str(p1))
         child.expect("test_1")
         child.expect("Pdb")
         child.sendline("c")
@@ -1056,8 +1051,10 @@
         assert "Exit: Quitting debugger" not in child.before.decode("utf8")
         TestPDB.flush(child)

-    def test_trace_with_parametrize_handles_shared_fixtureinfo(self, testdir):
-        p1 = testdir.makepyfile(
+    def test_trace_with_parametrize_handles_shared_fixtureinfo(
+        self, pytester: Pytester
+    ) -> None:
+        p1 = pytester.makepyfile(
             """
             import pytest
             @pytest.mark.parametrize('myparam', [1,2])
@@ -1075,7 +1072,7 @@
                 assert request.function.__name__ == "test_func_kw"
             """
         )
-        child = testdir.spawn_pytest("--trace " + str(p1))
+        child = pytester.spawn_pytest("--trace " + str(p1))
         for func, argname in [
             ("test_1", "myparam"),
             ("test_func", "func"),
@@ -1085,12 +1082,12 @@
             child.expect_exact(func)
             child.expect_exact("Pdb")
             child.sendline("args")
-            child.expect_exact("{} = 1\r\n".format(argname))
+            child.expect_exact(f"{argname} = 1\r\n")
             child.expect_exact("Pdb")
             child.sendline("c")
             child.expect_exact("Pdb")
             child.sendline("args")
-            child.expect_exact("{} = 2\r\n".format(argname))
+            child.expect_exact(f"{argname} = 2\r\n")
             child.expect_exact("Pdb")
             child.sendline("c")
             child.expect_exact("> PDB continue (IO-capturing resumed) >")
@@ -1102,16 +1099,16 @@
         TestPDB.flush(child)


-def test_trace_after_runpytest(testdir):
+def test_trace_after_runpytest(pytester: Pytester) -> None:
     """Test that debugging's pytest_configure is re-entrant."""
-    p1 = testdir.makepyfile(
+    p1 = pytester.makepyfile(
         """
         from _pytest.debugging import pytestPDB

-        def test_outer(testdir):
+        def test_outer(pytester) -> None:
             assert len(pytestPDB._saved) == 1

-            testdir.makepyfile(
+            pytester.makepyfile(
                 \"""
                 from _pytest.debugging import pytestPDB

@@ -1122,20 +1119,20 @@
                 \"""
             )

-            result = testdir.runpytest("-s", "-k", "test_inner")
+            result = pytester.runpytest("-s", "-k", "test_inner")
             assert result.ret == 0

             assert len(pytestPDB._saved) == 1
     """
     )
-    result = testdir.runpytest_subprocess("-s", "-p", "pytester", str(p1))
+    result = pytester.runpytest_subprocess("-s", "-p", "pytester", str(p1))
     result.stdout.fnmatch_lines(["test_inner_end"])
     assert result.ret == 0


-def test_quit_with_swallowed_SystemExit(testdir):
+def test_quit_with_swallowed_SystemExit(pytester: Pytester) -> None:
     """Test that debugging's pytest_configure is re-entrant."""
-    p1 = testdir.makepyfile(
+    p1 = pytester.makepyfile(
         """
         def call_pdb_set_trace():
             __import__('pdb').set_trace()
@@ -1152,7 +1149,7 @@
             pass
     """
     )
-    child = testdir.spawn_pytest(str(p1))
+    child = pytester.spawn_pytest(str(p1))
     child.expect("Pdb")
     child.sendline("q")
     child.expect_exact("Exit: Quitting debugger")
@@ -1162,9 +1159,9 @@


 @pytest.mark.parametrize("fixture", ("capfd", "capsys"))
-def test_pdb_suspends_fixture_capturing(testdir, fixture):
+def test_pdb_suspends_fixture_capturing(pytester: Pytester, fixture: str) -> None:
     """Using "-s" with pytest should suspend/resume fixture capturing."""
-    p1 = testdir.makepyfile(
+    p1 = pytester.makepyfile(
         """
         def test_inner({fixture}):
             import sys
@@ -1185,7 +1182,7 @@
         )
     )

-    child = testdir.spawn_pytest(str(p1) + " -s")
+    child = pytester.spawn_pytest(str(p1) + " -s")

     child.expect("Pdb")
     before = child.before.decode("utf8")
@@ -1210,9 +1207,9 @@
     assert "> PDB continue (IO-capturing resumed for fixture %s) >" % (fixture) in rest


-def test_pdbcls_via_local_module(testdir):
+def test_pdbcls_via_local_module(pytester: Pytester) -> None:
     """It should be imported in pytest_configure or later only."""
-    p1 = testdir.makepyfile(
+    p1 = pytester.makepyfile(
         """
         def test():
             print("before_set_trace")
@@ -1228,7 +1225,7 @@
                     print("runcall_called", args, kwds)
         """,
     )
-    result = testdir.runpytest(
+    result = pytester.runpytest(
         str(p1), "--pdbcls=really.invalid:Value", syspathinsert=True
     )
     result.stdout.fnmatch_lines(
@@ -1239,24 +1236,24 @@
     )
     assert result.ret == 1

-    result = testdir.runpytest(
+    result = pytester.runpytest(
         str(p1), "--pdbcls=mypdb:Wrapped.MyPdb", syspathinsert=True
     )
     assert result.ret == 0
     result.stdout.fnmatch_lines(["*set_trace_called*", "* 1 passed in *"])

     # Ensure that it also works with --trace.
-    result = testdir.runpytest(
+    result = pytester.runpytest(
         str(p1), "--pdbcls=mypdb:Wrapped.MyPdb", "--trace", syspathinsert=True
     )
     assert result.ret == 0
     result.stdout.fnmatch_lines(["*runcall_called*", "* 1 passed in *"])


-def test_raises_bdbquit_with_eoferror(testdir):
+def test_raises_bdbquit_with_eoferror(pytester: Pytester) -> None:
     """It is not guaranteed that DontReadFromInput's read is called."""

-    p1 = testdir.makepyfile(
+    p1 = pytester.makepyfile(
         """
         def input_without_read(*args, **kwargs):
             raise EOFError()
@@ -1267,13 +1264,13 @@
             __import__('pdb').set_trace()
         """
     )
-    result = testdir.runpytest(str(p1))
+    result = pytester.runpytest(str(p1))
     result.stdout.fnmatch_lines(["E *BdbQuit", "*= 1 failed in*"])
     assert result.ret == 1


-def test_pdb_wrapper_class_is_reused(testdir):
-    p1 = testdir.makepyfile(
+def test_pdb_wrapper_class_is_reused(pytester: Pytester) -> None:
+    p1 = pytester.makepyfile(
         """
         def test():
             __import__("pdb").set_trace()
@@ -1295,7 +1292,7 @@
                 print("set_trace_called", args)
         """,
     )
-    result = testdir.runpytest(str(p1), "--pdbcls=mypdb:MyPdb", syspathinsert=True)
+    result = pytester.runpytest(str(p1), "--pdbcls=mypdb:MyPdb", syspathinsert=True)
     assert result.ret == 0
     result.stdout.fnmatch_lines(
         ["*set_trace_called*", "*set_trace_called*", "* 1 passed in *"]
('testing', 'test_cacheprovider.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,30 +1,33 @@
 import os
 import shutil
-import stat
-import sys
-
-import py
+from pathlib import Path
+from typing import Generator
+from typing import List

 import pytest
 from _pytest.config import ExitCode
-from _pytest.pytester import Testdir
+from _pytest.monkeypatch import MonkeyPatch
+from _pytest.pytester import Pytester
+from _pytest.tmpdir import TempPathFactory

 pytest_plugins = ("pytester",)


 class TestNewAPI:
-    def test_config_cache_makedir(self, testdir):
-        testdir.makeini("[pytest]")
-        config = testdir.parseconfigure()
+    def test_config_cache_mkdir(self, pytester: Pytester) -> None:
+        pytester.makeini("[pytest]")
+        config = pytester.parseconfigure()
+        assert config.cache is not None
         with pytest.raises(ValueError):
-            config.cache.makedir("key/name")
-
-        p = config.cache.makedir("name")
-        assert p.check()
-
-    def test_config_cache_dataerror(self, testdir):
-        testdir.makeini("[pytest]")
-        config = testdir.parseconfigure()
+            config.cache.mkdir("key/name")
+
+        p = config.cache.mkdir("name")
+        assert p.is_dir()
+
+    def test_config_cache_dataerror(self, pytester: Pytester) -> None:
+        pytester.makeini("[pytest]")
+        config = pytester.parseconfigure()
+        assert config.cache is not None
         cache = config.cache
         pytest.raises(TypeError, lambda: cache.set("key/name", cache))
         config.cache.set("key/name", 0)
@@ -33,75 +36,83 @@
         assert val == -2

     @pytest.mark.filterwarnings("ignore:could not create cache path")
-    def test_cache_writefail_cachfile_silent(self, testdir):
-        testdir.makeini("[pytest]")
-        testdir.tmpdir.join(".pytest_cache").write("gone wrong")
-        config = testdir.parseconfigure()
+    def test_cache_writefail_cachfile_silent(self, pytester: Pytester) -> None:
+        pytester.makeini("[pytest]")
+        pytester.path.joinpath(".pytest_cache").write_text("gone wrong")
+        config = pytester.parseconfigure()
         cache = config.cache
+        assert cache is not None
         cache.set("test/broken", [])

-    @pytest.mark.skipif(sys.platform.startswith("win"), reason="no chmod on windows")
+    @pytest.fixture
+    def unwritable_cache_dir(self, pytester: Pytester) -> Generator[Path, None, None]:
+        cache_dir = pytester.path.joinpath(".pytest_cache")
+        cache_dir.mkdir()
+        mode = cache_dir.stat().st_mode
+        cache_dir.chmod(0)
+        if os.access(cache_dir, os.W_OK):
+            pytest.skip("Failed to make cache dir unwritable")
+
+        yield cache_dir
+        cache_dir.chmod(mode)
+
     @pytest.mark.filterwarnings(
         "ignore:could not create cache path:pytest.PytestWarning"
     )
-    def test_cache_writefail_permissions(self, testdir):
-        testdir.makeini("[pytest]")
-        cache_dir = str(testdir.tmpdir.ensure_dir(".pytest_cache"))
-        mode = os.stat(cache_dir)[stat.ST_MODE]
-        testdir.tmpdir.ensure_dir(".pytest_cache").chmod(0)
-        try:
-            config = testdir.parseconfigure()
-            cache = config.cache
-            cache.set("test/broken", [])
-        finally:
-            testdir.tmpdir.ensure_dir(".pytest_cache").chmod(mode)
-
-    @pytest.mark.skipif(sys.platform.startswith("win"), reason="no chmod on windows")
+    def test_cache_writefail_permissions(
+        self, unwritable_cache_dir: Path, pytester: Pytester
+    ) -> None:
+        pytester.makeini("[pytest]")
+        config = pytester.parseconfigure()
+        cache = config.cache
+        assert cache is not None
+        cache.set("test/broken", [])
+
     @pytest.mark.filterwarnings("default")
-    def test_cache_failure_warns(self, testdir, monkeypatch):
+    def test_cache_failure_warns(
+        self,
+        pytester: Pytester,
+        monkeypatch: MonkeyPatch,
+        unwritable_cache_dir: Path,
+    ) -> None:
         monkeypatch.setenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", "1")
-        cache_dir = str(testdir.tmpdir.ensure_dir(".pytest_cache"))
-        mode = os.stat(cache_dir)[stat.ST_MODE]
-        testdir.tmpdir.ensure_dir(".pytest_cache").chmod(0)
-        try:
-            testdir.makepyfile("def test_error(): raise Exception")
-            result = testdir.runpytest()
-            assert result.ret == 1
-            # warnings from nodeids, lastfailed, and stepwise
-            result.stdout.fnmatch_lines(
-                [
-                    # Validate location/stacklevel of warning from cacheprovider.
-                    "*= warnings summary =*",
-                    "*/cacheprovider.py:*",
-                    "  */cacheprovider.py:*: PytestCacheWarning: could not create cache path "
-                    "{}/v/cache/nodeids".format(cache_dir),
-                    '    config.cache.set("cache/nodeids", sorted(self.cached_nodeids))',
-                    "*1 failed, 3 warnings in*",
-                ]
-            )
-        finally:
-            testdir.tmpdir.ensure_dir(".pytest_cache").chmod(mode)
-
-    def test_config_cache(self, testdir):
-        testdir.makeconftest(
+
+        pytester.makepyfile("def test_error(): raise Exception")
+        result = pytester.runpytest()
+        assert result.ret == 1
+        # warnings from nodeids, lastfailed, and stepwise
+        result.stdout.fnmatch_lines(
+            [
+                # Validate location/stacklevel of warning from cacheprovider.
+                "*= warnings summary =*",
+                "*/cacheprovider.py:*",
+                "  */cacheprovider.py:*: PytestCacheWarning: could not create cache path "
+                f"{unwritable_cache_dir}/v/cache/nodeids",
+                '    config.cache.set("cache/nodeids", sorted(self.cached_nodeids))',
+                "*1 failed, 3 warnings in*",
+            ]
+        )
+
+    def test_config_cache(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             def pytest_configure(config):
                 # see that we get cache information early on
                 assert hasattr(config, "cache")
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_session(pytestconfig):
                 assert hasattr(pytestconfig, "cache")
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret == 0
         result.stdout.fnmatch_lines(["*1 passed*"])

-    def test_cachefuncarg(self, testdir):
-        testdir.makepyfile(
+    def test_cachefuncarg(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             def test_cachefuncarg(cache):
@@ -113,13 +124,13 @@
                 assert val == [1]
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret == 0
         result.stdout.fnmatch_lines(["*1 passed*"])

-    def test_custom_rel_cache_dir(self, testdir):
+    def test_custom_rel_cache_dir(self, pytester: Pytester) -> None:
         rel_cache_dir = os.path.join("custom_cache_dir", "subdir")
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
             cache_dir = {cache_dir}
@@ -127,14 +138,16 @@
                 cache_dir=rel_cache_dir
             )
         )
-        testdir.makepyfile(test_errored="def test_error():\n    assert False")
-        testdir.runpytest()
-        assert testdir.tmpdir.join(rel_cache_dir).isdir()
-
-    def test_custom_abs_cache_dir(self, testdir, tmpdir_factory):
-        tmp = str(tmpdir_factory.mktemp("tmp"))
-        abs_cache_dir = os.path.join(tmp, "custom_cache_dir")
-        testdir.makeini(
+        pytester.makepyfile(test_errored="def test_error():\n    assert False")
+        pytester.runpytest()
+        assert pytester.path.joinpath(rel_cache_dir).is_dir()
+
+    def test_custom_abs_cache_dir(
+        self, pytester: Pytester, tmp_path_factory: TempPathFactory
+    ) -> None:
+        tmp = tmp_path_factory.mktemp("tmp")
+        abs_cache_dir = tmp / "custom_cache_dir"
+        pytester.makeini(
             """
             [pytest]
             cache_dir = {cache_dir}
@@ -142,13 +155,15 @@
                 cache_dir=abs_cache_dir
             )
         )
-        testdir.makepyfile(test_errored="def test_error():\n    assert False")
-        testdir.runpytest()
-        assert py.path.local(abs_cache_dir).isdir()
-
-    def test_custom_cache_dir_with_env_var(self, testdir, monkeypatch):
+        pytester.makepyfile(test_errored="def test_error():\n    assert False")
+        pytester.runpytest()
+        assert abs_cache_dir.is_dir()
+
+    def test_custom_cache_dir_with_env_var(
+        self, pytester: Pytester, monkeypatch: MonkeyPatch
+    ) -> None:
         monkeypatch.setenv("env_var", "custom_cache_dir")
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
             cache_dir = {cache_dir}
@@ -156,31 +171,33 @@
                 cache_dir="$env_var"
             )
         )
-        testdir.makepyfile(test_errored="def test_error():\n    assert False")
-        testdir.runpytest()
-        assert testdir.tmpdir.join("custom_cache_dir").isdir()
+        pytester.makepyfile(test_errored="def test_error():\n    assert False")
+        pytester.runpytest()
+        assert pytester.path.joinpath("custom_cache_dir").is_dir()


 @pytest.mark.parametrize("env", ((), ("TOX_ENV_DIR", "/tox_env_dir")))
-def test_cache_reportheader(env, testdir, monkeypatch):
-    testdir.makepyfile("""def test_foo(): pass""")
+def test_cache_reportheader(env, pytester: Pytester, monkeypatch: MonkeyPatch) -> None:
+    pytester.makepyfile("""def test_foo(): pass""")
     if env:
         monkeypatch.setenv(*env)
         expected = os.path.join(env[1], ".pytest_cache")
     else:
         monkeypatch.delenv("TOX_ENV_DIR", raising=False)
         expected = ".pytest_cache"
-    result = testdir.runpytest("-v")
+    result = pytester.runpytest("-v")
     result.stdout.fnmatch_lines(["cachedir: %s" % expected])


-def test_cache_reportheader_external_abspath(testdir, tmpdir_factory):
-    external_cache = tmpdir_factory.mktemp(
+def test_cache_reportheader_external_abspath(
+    pytester: Pytester, tmp_path_factory: TempPathFactory
+) -> None:
+    external_cache = tmp_path_factory.mktemp(
         "test_cache_reportheader_external_abspath_abs"
     )

-    testdir.makepyfile("def test_hello(): pass")
-    testdir.makeini(
+    pytester.makepyfile("def test_hello(): pass")
+    pytester.makeini(
         """
     [pytest]
     cache_dir = {abscache}
@@ -188,31 +205,29 @@
             abscache=external_cache
         )
     )
-    result = testdir.runpytest("-v")
-    result.stdout.fnmatch_lines(
-        ["cachedir: {abscache}".format(abscache=external_cache)]
-    )
-
-
-def test_cache_show(testdir):
-    result = testdir.runpytest("--cache-show")
+    result = pytester.runpytest("-v")
+    result.stdout.fnmatch_lines([f"cachedir: {external_cache}"])
+
+
+def test_cache_show(pytester: Pytester) -> None:
+    result = pytester.runpytest("--cache-show")
     assert result.ret == 0
     result.stdout.fnmatch_lines(["*cache is empty*"])
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         def pytest_configure(config):
             config.cache.set("my/name", [1,2,3])
             config.cache.set("my/hello", "world")
             config.cache.set("other/some", {1:2})
-            dp = config.cache.makedir("mydb")
-            dp.ensure("hello")
-            dp.ensure("world")
+            dp = config.cache.mkdir("mydb")
+            dp.joinpath("hello").touch()
+            dp.joinpath("world").touch()
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert result.ret == 5  # no tests executed

-    result = testdir.runpytest("--cache-show")
+    result = pytester.runpytest("--cache-show")
     result.stdout.fnmatch_lines(
         [
             "*cachedir:*",
@@ -229,7 +244,7 @@
     )
     assert result.ret == 0

-    result = testdir.runpytest("--cache-show", "*/hello")
+    result = pytester.runpytest("--cache-show", "*/hello")
     result.stdout.fnmatch_lines(
         [
             "*cachedir:*",
@@ -247,25 +262,27 @@


 class TestLastFailed:
-    def test_lastfailed_usecase(self, testdir, monkeypatch):
+    def test_lastfailed_usecase(
+        self, pytester: Pytester, monkeypatch: MonkeyPatch
+    ) -> None:
         monkeypatch.setattr("sys.dont_write_bytecode", True)
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             """
             def test_1(): assert 0
             def test_2(): assert 0
             def test_3(): assert 1
             """
         )
-        result = testdir.runpytest(str(p))
+        result = pytester.runpytest(str(p))
         result.stdout.fnmatch_lines(["*2 failed*"])
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             """
             def test_1(): assert 1
             def test_2(): assert 1
             def test_3(): assert 0
             """
         )
-        result = testdir.runpytest(str(p), "--lf")
+        result = pytester.runpytest(str(p), "--lf")
         result.stdout.fnmatch_lines(
             [
                 "collected 3 items / 1 deselected / 2 selected",
@@ -273,7 +290,7 @@
                 "*= 2 passed, 1 deselected in *",
             ]
         )
-        result = testdir.runpytest(str(p), "--lf")
+        result = pytester.runpytest(str(p), "--lf")
         result.stdout.fnmatch_lines(
             [
                 "collected 3 items",
@@ -281,27 +298,27 @@
                 "*1 failed*2 passed*",
             ]
         )
-        testdir.tmpdir.join(".pytest_cache").mkdir(".git")
-        result = testdir.runpytest(str(p), "--lf", "--cache-clear")
+        pytester.path.joinpath(".pytest_cache", ".git").mkdir(parents=True)
+        result = pytester.runpytest(str(p), "--lf", "--cache-clear")
         result.stdout.fnmatch_lines(["*1 failed*2 passed*"])
-        assert testdir.tmpdir.join(".pytest_cache", "README.md").isfile()
-        assert testdir.tmpdir.join(".pytest_cache", ".git").isdir()
+        assert pytester.path.joinpath(".pytest_cache", "README.md").is_file()
+        assert pytester.path.joinpath(".pytest_cache", ".git").is_dir()

         # Run this again to make sure clear-cache is robust
         if os.path.isdir(".pytest_cache"):
             shutil.rmtree(".pytest_cache")
-        result = testdir.runpytest("--lf", "--cache-clear")
+        result = pytester.runpytest("--lf", "--cache-clear")
         result.stdout.fnmatch_lines(["*1 failed*2 passed*"])

-    def test_failedfirst_order(self, testdir):
-        testdir.makepyfile(
+    def test_failedfirst_order(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             test_a="def test_always_passes(): pass",
             test_b="def test_always_fails(): assert 0",
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         # Test order will be collection order; alphabetical
         result.stdout.fnmatch_lines(["test_a.py*", "test_b.py*"])
-        result = testdir.runpytest("--ff")
+        result = pytester.runpytest("--ff")
         # Test order will be failing tests first
         result.stdout.fnmatch_lines(
             [
@@ -312,40 +329,42 @@
             ]
         )

-    def test_lastfailed_failedfirst_order(self, testdir):
-        testdir.makepyfile(
+    def test_lastfailed_failedfirst_order(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             test_a="def test_always_passes(): assert 1",
             test_b="def test_always_fails(): assert 0",
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         # Test order will be collection order; alphabetical
         result.stdout.fnmatch_lines(["test_a.py*", "test_b.py*"])
-        result = testdir.runpytest("--lf", "--ff")
+        result = pytester.runpytest("--lf", "--ff")
         # Test order will be failing tests first
         result.stdout.fnmatch_lines(["test_b.py*"])
         result.stdout.no_fnmatch_line("*test_a.py*")

-    def test_lastfailed_difference_invocations(self, testdir, monkeypatch):
+    def test_lastfailed_difference_invocations(
+        self, pytester: Pytester, monkeypatch: MonkeyPatch
+    ) -> None:
         monkeypatch.setattr("sys.dont_write_bytecode", True)
-        testdir.makepyfile(
+        pytester.makepyfile(
             test_a="""
                 def test_a1(): assert 0
                 def test_a2(): assert 1
             """,
             test_b="def test_b1(): assert 0",
         )
-        p = testdir.tmpdir.join("test_a.py")
-        p2 = testdir.tmpdir.join("test_b.py")
-
-        result = testdir.runpytest()
+        p = pytester.path.joinpath("test_a.py")
+        p2 = pytester.path.joinpath("test_b.py")
+
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*2 failed*"])
-        result = testdir.runpytest("--lf", p2)
+        result = pytester.runpytest("--lf", p2)
         result.stdout.fnmatch_lines(["*1 failed*"])

-        testdir.makepyfile(test_b="def test_b1(): assert 1")
-        result = testdir.runpytest("--lf", p2)
+        pytester.makepyfile(test_b="def test_b1(): assert 1")
+        result = pytester.runpytest("--lf", p2)
         result.stdout.fnmatch_lines(["*1 passed*"])
-        result = testdir.runpytest("--lf", p)
+        result = pytester.runpytest("--lf", p)
         result.stdout.fnmatch_lines(
             [
                 "collected 2 items / 1 deselected / 1 selected",
@@ -354,21 +373,23 @@
             ]
         )

-    def test_lastfailed_usecase_splice(self, testdir, monkeypatch):
+    def test_lastfailed_usecase_splice(
+        self, pytester: Pytester, monkeypatch: MonkeyPatch
+    ) -> None:
         monkeypatch.setattr("sys.dont_write_bytecode", True)
-        testdir.makepyfile(
+        pytester.makepyfile(
             "def test_1(): assert 0", test_something="def test_2(): assert 0"
         )
-        p2 = testdir.tmpdir.join("test_something.py")
-        result = testdir.runpytest()
+        p2 = pytester.path.joinpath("test_something.py")
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*2 failed*"])
-        result = testdir.runpytest("--lf", p2)
+        result = pytester.runpytest("--lf", p2)
         result.stdout.fnmatch_lines(["*1 failed*"])
-        result = testdir.runpytest("--lf")
+        result = pytester.runpytest("--lf")
         result.stdout.fnmatch_lines(["*2 failed*"])

-    def test_lastfailed_xpass(self, testdir):
-        testdir.inline_runsource(
+    def test_lastfailed_xpass(self, pytester: Pytester) -> None:
+        pytester.inline_runsource(
             """
             import pytest
             @pytest.mark.xfail
@@ -376,15 +397,16 @@
                 assert 1
         """
         )
-        config = testdir.parseconfigure()
+        config = pytester.parseconfigure()
+        assert config.cache is not None
         lastfailed = config.cache.get("cache/lastfailed", -1)
         assert lastfailed == -1

-    def test_non_serializable_parametrize(self, testdir):
+    def test_non_serializable_parametrize(self, pytester: Pytester) -> None:
         """Test that failed parametrized tests with unmarshable parameters
         don't break pytest-cache.
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             r"""
             import pytest

@@ -395,26 +417,26 @@
                 assert False
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*1 failed in*"])

-    def test_terminal_report_lastfailed(self, testdir):
-        test_a = testdir.makepyfile(
+    def test_terminal_report_lastfailed(self, pytester: Pytester) -> None:
+        test_a = pytester.makepyfile(
             test_a="""
             def test_a1(): pass
             def test_a2(): pass
         """
         )
-        test_b = testdir.makepyfile(
+        test_b = pytester.makepyfile(
             test_b="""
             def test_b1(): assert 0
             def test_b2(): assert 0
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["collected 4 items", "*2 failed, 2 passed in*"])

-        result = testdir.runpytest("--lf")
+        result = pytester.runpytest("--lf")
         result.stdout.fnmatch_lines(
             [
                 "collected 2 items",
@@ -423,7 +445,7 @@
             ]
         )

-        result = testdir.runpytest(test_a, "--lf")
+        result = pytester.runpytest(test_a, "--lf")
         result.stdout.fnmatch_lines(
             [
                 "collected 2 items",
@@ -432,7 +454,7 @@
             ]
         )

-        result = testdir.runpytest(test_b, "--lf")
+        result = pytester.runpytest(test_b, "--lf")
         result.stdout.fnmatch_lines(
             [
                 "collected 2 items",
@@ -441,7 +463,7 @@
             ]
         )

-        result = testdir.runpytest("test_b.py::test_b1", "--lf")
+        result = pytester.runpytest("test_b.py::test_b1", "--lf")
         result.stdout.fnmatch_lines(
             [
                 "collected 1 item",
@@ -450,17 +472,17 @@
             ]
         )

-    def test_terminal_report_failedfirst(self, testdir):
-        testdir.makepyfile(
+    def test_terminal_report_failedfirst(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             test_a="""
             def test_a1(): assert 0
             def test_a2(): pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["collected 2 items", "*1 failed, 1 passed in*"])

-        result = testdir.runpytest("--ff")
+        result = pytester.runpytest("--ff")
         result.stdout.fnmatch_lines(
             [
                 "collected 2 items",
@@ -469,9 +491,11 @@
             ]
         )

-    def test_lastfailed_collectfailure(self, testdir, monkeypatch):
-
-        testdir.makepyfile(
+    def test_lastfailed_collectfailure(
+        self, pytester: Pytester, monkeypatch: MonkeyPatch
+    ) -> None:
+
+        pytester.makepyfile(
             test_maybe="""
             import os
             env = os.environ
@@ -486,8 +510,9 @@
             monkeypatch.setenv("FAILIMPORT", str(fail_import))
             monkeypatch.setenv("FAILTEST", str(fail_run))

-            testdir.runpytest("-q")
-            config = testdir.parseconfigure()
+            pytester.runpytest("-q")
+            config = pytester.parseconfigure()
+            assert config.cache is not None
             lastfailed = config.cache.get("cache/lastfailed", -1)
             return lastfailed

@@ -500,8 +525,10 @@
         lastfailed = rlf(fail_import=0, fail_run=1)
         assert list(lastfailed) == ["test_maybe.py::test_hello"]

-    def test_lastfailed_failure_subset(self, testdir, monkeypatch):
-        testdir.makepyfile(
+    def test_lastfailed_failure_subset(
+        self, pytester: Pytester, monkeypatch: MonkeyPatch
+    ) -> None:
+        pytester.makepyfile(
             test_maybe="""
             import os
             env = os.environ
@@ -512,7 +539,7 @@
         """
         )

-        testdir.makepyfile(
+        pytester.makepyfile(
             test_maybe2="""
             import os
             env = os.environ
@@ -531,8 +558,9 @@
             monkeypatch.setenv("FAILIMPORT", str(fail_import))
             monkeypatch.setenv("FAILTEST", str(fail_run))

-            result = testdir.runpytest("-q", "--lf", *args)
-            config = testdir.parseconfigure()
+            result = pytester.runpytest("-q", "--lf", *args)
+            config = pytester.parseconfigure()
+            assert config.cache is not None
             lastfailed = config.cache.get("cache/lastfailed", -1)
             return result, lastfailed

@@ -553,61 +581,63 @@
         assert list(lastfailed) == ["test_maybe.py"]
         result.stdout.fnmatch_lines(["*2 passed*"])

-    def test_lastfailed_creates_cache_when_needed(self, testdir):
+    def test_lastfailed_creates_cache_when_needed(self, pytester: Pytester) -> None:
         # Issue #1342
-        testdir.makepyfile(test_empty="")
-        testdir.runpytest("-q", "--lf")
+        pytester.makepyfile(test_empty="")
+        pytester.runpytest("-q", "--lf")
         assert not os.path.exists(".pytest_cache/v/cache/lastfailed")

-        testdir.makepyfile(test_successful="def test_success():\n    assert True")
-        testdir.runpytest("-q", "--lf")
+        pytester.makepyfile(test_successful="def test_success():\n    assert True")
+        pytester.runpytest("-q", "--lf")
         assert not os.path.exists(".pytest_cache/v/cache/lastfailed")

-        testdir.makepyfile(test_errored="def test_error():\n    assert False")
-        testdir.runpytest("-q", "--lf")
+        pytester.makepyfile(test_errored="def test_error():\n    assert False")
+        pytester.runpytest("-q", "--lf")
         assert os.path.exists(".pytest_cache/v/cache/lastfailed")

-    def test_xfail_not_considered_failure(self, testdir):
-        testdir.makepyfile(
+    def test_xfail_not_considered_failure(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.xfail
             def test(): assert 0
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*1 xfailed*"])
-        assert self.get_cached_last_failed(testdir) == []
-
-    def test_xfail_strict_considered_failure(self, testdir):
-        testdir.makepyfile(
+        assert self.get_cached_last_failed(pytester) == []
+
+    def test_xfail_strict_considered_failure(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.xfail(strict=True)
             def test(): pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*1 failed*"])
-        assert self.get_cached_last_failed(testdir) == [
+        assert self.get_cached_last_failed(pytester) == [
             "test_xfail_strict_considered_failure.py::test"
         ]

     @pytest.mark.parametrize("mark", ["mark.xfail", "mark.skip"])
-    def test_failed_changed_to_xfail_or_skip(self, testdir, mark):
-        testdir.makepyfile(
+    def test_failed_changed_to_xfail_or_skip(
+        self, pytester: Pytester, mark: str
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest
             def test(): assert 0
         """
         )
-        result = testdir.runpytest()
-        assert self.get_cached_last_failed(testdir) == [
+        result = pytester.runpytest()
+        assert self.get_cached_last_failed(pytester) == [
             "test_failed_changed_to_xfail_or_skip.py::test"
         ]
         assert result.ret == 1

-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest
             @pytest.{mark}
@@ -616,66 +646,69 @@
                 mark=mark
             )
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret == 0
-        assert self.get_cached_last_failed(testdir) == []
+        assert self.get_cached_last_failed(pytester) == []
         assert result.ret == 0

     @pytest.mark.parametrize("quiet", [True, False])
     @pytest.mark.parametrize("opt", ["--ff", "--lf"])
-    def test_lf_and_ff_prints_no_needless_message(self, quiet, opt, testdir):
+    def test_lf_and_ff_prints_no_needless_message(
+        self, quiet: bool, opt: str, pytester: Pytester
+    ) -> None:
         # Issue 3853
-        testdir.makepyfile("def test(): assert 0")
+        pytester.makepyfile("def test(): assert 0")
         args = [opt]
         if quiet:
             args.append("-q")
-        result = testdir.runpytest(*args)
+        result = pytester.runpytest(*args)
         result.stdout.no_fnmatch_line("*run all*")

-        result = testdir.runpytest(*args)
+        result = pytester.runpytest(*args)
         if quiet:
             result.stdout.no_fnmatch_line("*run all*")
         else:
             assert "rerun previous" in result.stdout.str()

-    def get_cached_last_failed(self, testdir):
-        config = testdir.parseconfigure()
+    def get_cached_last_failed(self, pytester: Pytester) -> List[str]:
+        config = pytester.parseconfigure()
+        assert config.cache is not None
         return sorted(config.cache.get("cache/lastfailed", {}))

-    def test_cache_cumulative(self, testdir):
+    def test_cache_cumulative(self, pytester: Pytester) -> None:
         """Test workflow where user fixes errors gradually file by file using --lf."""
         # 1. initial run
-        test_bar = testdir.makepyfile(
+        test_bar = pytester.makepyfile(
             test_bar="""
             def test_bar_1(): pass
             def test_bar_2(): assert 0
         """
         )
-        test_foo = testdir.makepyfile(
+        test_foo = pytester.makepyfile(
             test_foo="""
             def test_foo_3(): pass
             def test_foo_4(): assert 0
         """
         )
-        testdir.runpytest()
-        assert self.get_cached_last_failed(testdir) == [
+        pytester.runpytest()
+        assert self.get_cached_last_failed(pytester) == [
             "test_bar.py::test_bar_2",
             "test_foo.py::test_foo_4",
         ]

         # 2. fix test_bar_2, run only test_bar.py
-        testdir.makepyfile(
+        pytester.makepyfile(
             test_bar="""
             def test_bar_1(): pass
             def test_bar_2(): pass
         """
         )
-        result = testdir.runpytest(test_bar)
+        result = pytester.runpytest(test_bar)
         result.stdout.fnmatch_lines(["*2 passed*"])
         # ensure cache does not forget that test_foo_4 failed once before
-        assert self.get_cached_last_failed(testdir) == ["test_foo.py::test_foo_4"]
-
-        result = testdir.runpytest("--last-failed")
+        assert self.get_cached_last_failed(pytester) == ["test_foo.py::test_foo_4"]
+
+        result = pytester.runpytest("--last-failed")
         result.stdout.fnmatch_lines(
             [
                 "collected 1 item",
@@ -683,16 +716,16 @@
                 "*= 1 failed in *",
             ]
         )
-        assert self.get_cached_last_failed(testdir) == ["test_foo.py::test_foo_4"]
+        assert self.get_cached_last_failed(pytester) == ["test_foo.py::test_foo_4"]

         # 3. fix test_foo_4, run only test_foo.py
-        test_foo = testdir.makepyfile(
+        test_foo = pytester.makepyfile(
             test_foo="""
             def test_foo_3(): pass
             def test_foo_4(): pass
         """
         )
-        result = testdir.runpytest(test_foo, "--last-failed")
+        result = pytester.runpytest(test_foo, "--last-failed")
         result.stdout.fnmatch_lines(
             [
                 "collected 2 items / 1 deselected / 1 selected",
@@ -700,29 +733,31 @@
                 "*= 1 passed, 1 deselected in *",
             ]
         )
-        assert self.get_cached_last_failed(testdir) == []
-
-        result = testdir.runpytest("--last-failed")
+        assert self.get_cached_last_failed(pytester) == []
+
+        result = pytester.runpytest("--last-failed")
         result.stdout.fnmatch_lines(["*4 passed*"])
-        assert self.get_cached_last_failed(testdir) == []
-
-    def test_lastfailed_no_failures_behavior_all_passed(self, testdir):
-        testdir.makepyfile(
+        assert self.get_cached_last_failed(pytester) == []
+
+    def test_lastfailed_no_failures_behavior_all_passed(
+        self, pytester: Pytester
+    ) -> None:
+        pytester.makepyfile(
             """
             def test_1(): pass
             def test_2(): pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*2 passed*"])
-        result = testdir.runpytest("--lf")
+        result = pytester.runpytest("--lf")
         result.stdout.fnmatch_lines(["*2 passed*"])
-        result = testdir.runpytest("--lf", "--lfnf", "all")
+        result = pytester.runpytest("--lf", "--lfnf", "all")
         result.stdout.fnmatch_lines(["*2 passed*"])

         # Ensure the list passed to pytest_deselected is a copy,
         # and not a reference which is cleared right after.
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             deselected = []

@@ -735,10 +770,10 @@
         """
         )

-        result = testdir.runpytest("--lf", "--lfnf", "none")
-        result.stdout.fnmatch_lines(
-            [
-                "collected 2 items / 2 deselected",
+        result = pytester.runpytest("--lf", "--lfnf", "none")
+        result.stdout.fnmatch_lines(
+            [
+                "collected 2 items / 2 deselected / 0 selected",
                 "run-last-failure: no previously failed tests, deselecting all items.",
                 "deselected=2",
                 "* 2 deselected in *",
@@ -746,26 +781,28 @@
         )
         assert result.ret == ExitCode.NO_TESTS_COLLECTED

-    def test_lastfailed_no_failures_behavior_empty_cache(self, testdir):
-        testdir.makepyfile(
+    def test_lastfailed_no_failures_behavior_empty_cache(
+        self, pytester: Pytester
+    ) -> None:
+        pytester.makepyfile(
             """
             def test_1(): pass
             def test_2(): assert 0
         """
         )
-        result = testdir.runpytest("--lf", "--cache-clear")
+        result = pytester.runpytest("--lf", "--cache-clear")
         result.stdout.fnmatch_lines(["*1 failed*1 passed*"])
-        result = testdir.runpytest("--lf", "--cache-clear", "--lfnf", "all")
+        result = pytester.runpytest("--lf", "--cache-clear", "--lfnf", "all")
         result.stdout.fnmatch_lines(["*1 failed*1 passed*"])
-        result = testdir.runpytest("--lf", "--cache-clear", "--lfnf", "none")
+        result = pytester.runpytest("--lf", "--cache-clear", "--lfnf", "none")
         result.stdout.fnmatch_lines(["*2 desel*"])

-    def test_lastfailed_skip_collection(self, testdir):
+    def test_lastfailed_skip_collection(self, pytester: Pytester) -> None:
         """
         Test --lf behavior regarding skipping collection of files that are not marked as
         failed in the cache (#5172).
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             **{
                 "pkg1/test_1.py": """
                 import pytest
@@ -783,10 +820,10 @@
             }
         )
         # first run: collects 8 items (test_1: 3, test_2: 5)
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["collected 8 items", "*2 failed*6 passed*"])
         # second run: collects only 5 items from test_2, because all tests from test_1 have passed
-        result = testdir.runpytest("--lf")
+        result = pytester.runpytest("--lf")
         result.stdout.fnmatch_lines(
             [
                 "collected 2 items",
@@ -796,14 +833,14 @@
         )

         # add another file and check if message is correct when skipping more than 1 file
-        testdir.makepyfile(
+        pytester.makepyfile(
             **{
                 "pkg1/test_3.py": """
                 def test_3(): pass
             """
             }
         )
-        result = testdir.runpytest("--lf")
+        result = pytester.runpytest("--lf")
         result.stdout.fnmatch_lines(
             [
                 "collected 2 items",
@@ -812,18 +849,20 @@
             ]
         )

-    def test_lastfailed_with_known_failures_not_being_selected(self, testdir):
-        testdir.makepyfile(
+    def test_lastfailed_with_known_failures_not_being_selected(
+        self, pytester: Pytester
+    ) -> None:
+        pytester.makepyfile(
             **{
                 "pkg1/test_1.py": """def test_1(): assert 0""",
                 "pkg1/test_2.py": """def test_2(): pass""",
             }
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["collected 2 items", "* 1 failed, 1 passed in *"])

-        py.path.local("pkg1/test_1.py").remove()
-        result = testdir.runpytest("--lf")
+        Path("pkg1/test_1.py").unlink()
+        result = pytester.runpytest("--lf")
         result.stdout.fnmatch_lines(
             [
                 "collected 1 item",
@@ -833,8 +872,8 @@
         )

         # Recreate file with known failure.
-        testdir.makepyfile(**{"pkg1/test_1.py": """def test_1(): assert 0"""})
-        result = testdir.runpytest("--lf")
+        pytester.makepyfile(**{"pkg1/test_1.py": """def test_1(): assert 0"""})
+        result = pytester.runpytest("--lf")
         result.stdout.fnmatch_lines(
             [
                 "collected 1 item",
@@ -844,8 +883,8 @@
         )

         # Remove/rename test: collects the file again.
-        testdir.makepyfile(**{"pkg1/test_1.py": """def test_renamed(): assert 0"""})
-        result = testdir.runpytest("--lf", "-rf")
+        pytester.makepyfile(**{"pkg1/test_1.py": """def test_renamed(): assert 0"""})
+        result = pytester.runpytest("--lf", "-rf")
         result.stdout.fnmatch_lines(
             [
                 "collected 2 items",
@@ -857,7 +896,7 @@
             ]
         )

-        result = testdir.runpytest("--lf", "--co")
+        result = pytester.runpytest("--lf", "--co")
         result.stdout.fnmatch_lines(
             [
                 "collected 1 item",
@@ -868,13 +907,13 @@
             ]
         )

-    def test_lastfailed_args_with_deselected(self, testdir: Testdir) -> None:
+    def test_lastfailed_args_with_deselected(self, pytester: Pytester) -> None:
         """Test regression with --lf running into NoMatch error.

         This was caused by it not collecting (non-failed) nodes given as
         arguments.
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             **{
                 "pkg1/test_1.py": """
                     def test_pass(): pass
@@ -882,11 +921,11 @@
                 """,
             }
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["collected 2 items", "* 1 failed, 1 passed in *"])
         assert result.ret == 1

-        result = testdir.runpytest("pkg1/test_1.py::test_pass", "--lf", "--co")
+        result = pytester.runpytest("pkg1/test_1.py::test_pass", "--lf", "--co")
         assert result.ret == 0
         result.stdout.fnmatch_lines(
             [
@@ -899,7 +938,7 @@
             consecutive=True,
         )

-        result = testdir.runpytest(
+        result = pytester.runpytest(
             "pkg1/test_1.py::test_pass", "pkg1/test_1.py::test_fail", "--lf", "--co"
         )
         assert result.ret == 0
@@ -910,13 +949,13 @@
                 "",
                 "<Module pkg1/test_1.py>",
                 "  <Function test_fail>",
-                "*= 1 deselected in *",
+                "*= 1/2 tests collected (1 deselected) in *",
             ],
         )

-    def test_lastfailed_with_class_items(self, testdir: Testdir) -> None:
+    def test_lastfailed_with_class_items(self, pytester: Pytester) -> None:
         """Test regression with --lf deselecting whole classes."""
-        testdir.makepyfile(
+        pytester.makepyfile(
             **{
                 "pkg1/test_1.py": """
                     class TestFoo:
@@ -927,11 +966,11 @@
                 """,
             }
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["collected 3 items", "* 2 failed, 1 passed in *"])
         assert result.ret == 1

-        result = testdir.runpytest("--lf", "--co")
+        result = pytester.runpytest("--lf", "--co")
         assert result.ret == 0
         result.stdout.fnmatch_lines(
             [
@@ -940,16 +979,16 @@
                 "",
                 "<Module pkg1/test_1.py>",
                 "  <Class TestFoo>",
-                "      <Function test_fail>",
+                "    <Function test_fail>",
                 "  <Function test_other>",
                 "",
-                "*= 1 deselected in *",
+                "*= 2/3 tests collected (1 deselected) in *",
             ],
             consecutive=True,
         )

-    def test_lastfailed_with_all_filtered(self, testdir: Testdir) -> None:
-        testdir.makepyfile(
+    def test_lastfailed_with_all_filtered(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             **{
                 "pkg1/test_1.py": """
                     def test_fail(): assert 0
@@ -957,19 +996,19 @@
                 """,
             }
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["collected 2 items", "* 1 failed, 1 passed in *"])
         assert result.ret == 1

         # Remove known failure.
-        testdir.makepyfile(
+        pytester.makepyfile(
             **{
                 "pkg1/test_1.py": """
                     def test_pass(): pass
                 """,
             }
         )
-        result = testdir.runpytest("--lf", "--co")
+        result = pytester.runpytest("--lf", "--co")
         result.stdout.fnmatch_lines(
             [
                 "collected 1 item",
@@ -978,13 +1017,13 @@
                 "<Module pkg1/test_1.py>",
                 "  <Function test_pass>",
                 "",
-                "*= no tests ran in*",
+                "*= 1 test collected in*",
             ],
             consecutive=True,
         )
         assert result.ret == 0

-    def test_packages(self, testdir: Testdir) -> None:
+    def test_packages(self, pytester: Pytester) -> None:
         """Regression test for #7758.

         The particular issue here was that Package nodes were included in the
@@ -994,7 +1033,7 @@
         The tests includes a test in an __init__.py file just to make sure the
         fix doesn't somehow regress that, it is not critical for the issue.
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             **{
                 "__init__.py": "",
                 "a/__init__.py": "def test_a_init(): assert False",
@@ -1003,21 +1042,21 @@
                 "b/test_two.py": "def test_2(): assert False",
             },
         )
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
             python_files = *.py
             """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.assert_outcomes(failed=3)
-        result = testdir.runpytest("--lf")
+        result = pytester.runpytest("--lf")
         result.assert_outcomes(failed=3)


 class TestNewFirst:
-    def test_newfirst_usecase(self, testdir):
-        testdir.makepyfile(
+    def test_newfirst_usecase(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             **{
                 "test_1/test_1.py": """
                 def test_1(): assert 1
@@ -1027,24 +1066,24 @@
             """,
             }
         )
-        testdir.tmpdir.join("test_1/test_1.py").setmtime(1)
-
-        result = testdir.runpytest("-v")
+
+        p1 = pytester.path.joinpath("test_1/test_1.py")
+        os.utime(p1, ns=(p1.stat().st_atime_ns, int(1e9)))
+
+        result = pytester.runpytest("-v")
         result.stdout.fnmatch_lines(
             ["*test_1/test_1.py::test_1 PASSED*", "*test_2/test_2.py::test_1 PASSED*"]
         )

-        result = testdir.runpytest("-v", "--nf")
+        result = pytester.runpytest("-v", "--nf")
         result.stdout.fnmatch_lines(
             ["*test_2/test_2.py::test_1 PASSED*", "*test_1/test_1.py::test_1 PASSED*"]
         )

-        testdir.tmpdir.join("test_1/test_1.py").write(
-            "def test_1(): assert 1\n" "def test_2(): assert 1\n"
-        )
-        testdir.tmpdir.join("test_1/test_1.py").setmtime(1)
-
-        result = testdir.runpytest("--nf", "--collect-only", "-q")
+        p1.write_text("def test_1(): assert 1\n" "def test_2(): assert 1\n")
+        os.utime(p1, ns=(p1.stat().st_atime_ns, int(1e9)))
+
+        result = pytester.runpytest("--nf", "--collect-only", "-q")
         result.stdout.fnmatch_lines(
             [
                 "test_1/test_1.py::test_2",
@@ -1054,15 +1093,15 @@
         )

         # Newest first with (plugin) pytest_collection_modifyitems hook.
-        testdir.makepyfile(
+        pytester.makepyfile(
             myplugin="""
             def pytest_collection_modifyitems(items):
                 items[:] = sorted(items, key=lambda item: item.nodeid)
                 print("new_items:", [x.nodeid for x in items])
             """
         )
-        testdir.syspathinsert()
-        result = testdir.runpytest("--nf", "-p", "myplugin", "--collect-only", "-q")
+        pytester.syspathinsert()
+        result = pytester.runpytest("--nf", "-p", "myplugin", "--collect-only", "-q")
         result.stdout.fnmatch_lines(
             [
                 "new_items: *test_1.py*test_1.py*test_2.py*",
@@ -1072,8 +1111,8 @@
             ]
         )

-    def test_newfirst_parametrize(self, testdir):
-        testdir.makepyfile(
+    def test_newfirst_parametrize(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             **{
                 "test_1/test_1.py": """
                 import pytest
@@ -1088,9 +1127,10 @@
             }
         )

-        testdir.tmpdir.join("test_1/test_1.py").setmtime(1)
-
-        result = testdir.runpytest("-v")
+        p1 = pytester.path.joinpath("test_1/test_1.py")
+        os.utime(p1, ns=(p1.stat().st_atime_ns, int(1e9)))
+
+        result = pytester.runpytest("-v")
         result.stdout.fnmatch_lines(
             [
                 "*test_1/test_1.py::test_1[1*",
@@ -1100,7 +1140,7 @@
             ]
         )

-        result = testdir.runpytest("-v", "--nf")
+        result = pytester.runpytest("-v", "--nf")
         result.stdout.fnmatch_lines(
             [
                 "*test_2/test_2.py::test_1[1*",
@@ -1110,20 +1150,20 @@
             ]
         )

-        testdir.tmpdir.join("test_1/test_1.py").write(
+        p1.write_text(
             "import pytest\n"
             "@pytest.mark.parametrize('num', [1, 2, 3])\n"
             "def test_1(num): assert num\n"
         )
-        testdir.tmpdir.join("test_1/test_1.py").setmtime(1)
+        os.utime(p1, ns=(p1.stat().st_atime_ns, int(1e9)))

         # Running only a subset does not forget about existing ones.
-        result = testdir.runpytest("-v", "--nf", "test_2/test_2.py")
+        result = pytester.runpytest("-v", "--nf", "test_2/test_2.py")
         result.stdout.fnmatch_lines(
             ["*test_2/test_2.py::test_1[1*", "*test_2/test_2.py::test_1[2*"]
         )

-        result = testdir.runpytest("-v", "--nf")
+        result = pytester.runpytest("-v", "--nf")
         result.stdout.fnmatch_lines(
             [
                 "*test_1/test_1.py::test_1[3*",
@@ -1136,28 +1176,29 @@


 class TestReadme:
-    def check_readme(self, testdir):
-        config = testdir.parseconfigure()
+    def check_readme(self, pytester: Pytester) -> bool:
+        config = pytester.parseconfigure()
+        assert config.cache is not None
         readme = config.cache._cachedir.joinpath("README.md")
         return readme.is_file()

-    def test_readme_passed(self, testdir):
-        testdir.makepyfile("def test_always_passes(): pass")
-        testdir.runpytest()
-        assert self.check_readme(testdir) is True
-
-    def test_readme_failed(self, testdir):
-        testdir.makepyfile("def test_always_fails(): assert 0")
-        testdir.runpytest()
-        assert self.check_readme(testdir) is True
-
-
-def test_gitignore(testdir):
+    def test_readme_passed(self, pytester: Pytester) -> None:
+        pytester.makepyfile("def test_always_passes(): pass")
+        pytester.runpytest()
+        assert self.check_readme(pytester) is True
+
+    def test_readme_failed(self, pytester: Pytester) -> None:
+        pytester.makepyfile("def test_always_fails(): assert 0")
+        pytester.runpytest()
+        assert self.check_readme(pytester) is True
+
+
+def test_gitignore(pytester: Pytester) -> None:
     """Ensure we automatically create .gitignore file in the pytest_cache directory (#3286)."""
     from _pytest.cacheprovider import Cache

-    config = testdir.parseconfig()
-    cache = Cache.for_config(config)
+    config = pytester.parseconfig()
+    cache = Cache.for_config(config, _ispytest=True)
     cache.set("foo", "bar")
     msg = "# Created by pytest automatically.\n*\n"
     gitignore_path = cache._cachedir.joinpath(".gitignore")
@@ -1169,17 +1210,28 @@
     assert gitignore_path.read_text(encoding="UTF-8") == "custom"


-def test_does_not_create_boilerplate_in_existing_dirs(testdir):
+def test_preserve_keys_order(pytester: Pytester) -> None:
+    """Ensure keys order is preserved when saving dicts (#9205)."""
     from _pytest.cacheprovider import Cache

-    testdir.makeini(
+    config = pytester.parseconfig()
+    cache = Cache.for_config(config, _ispytest=True)
+    cache.set("foo", {"z": 1, "b": 2, "a": 3, "d": 10})
+    read_back = cache.get("foo", None)
+    assert list(read_back.items()) == [("z", 1), ("b", 2), ("a", 3), ("d", 10)]
+
+
+def test_does_not_create_boilerplate_in_existing_dirs(pytester: Pytester) -> None:
+    from _pytest.cacheprovider import Cache
+
+    pytester.makeini(
         """
         [pytest]
         cache_dir = .
         """
     )
-    config = testdir.parseconfig()
-    cache = Cache.for_config(config)
+    config = pytester.parseconfig()
+    cache = Cache.for_config(config, _ispytest=True)
     cache.set("foo", "bar")

     assert os.path.isdir("v")  # cache contents
@@ -1187,13 +1239,13 @@
     assert not os.path.exists("README.md")


-def test_cachedir_tag(testdir):
+def test_cachedir_tag(pytester: Pytester) -> None:
     """Ensure we automatically create CACHEDIR.TAG file in the pytest_cache directory (#4278)."""
     from _pytest.cacheprovider import Cache
     from _pytest.cacheprovider import CACHEDIR_TAG_CONTENT

-    config = testdir.parseconfig()
-    cache = Cache.for_config(config)
+    config = pytester.parseconfig()
+    cache = Cache.for_config(config, _ispytest=True)
     cache.set("foo", "bar")
     cachedir_tag_path = cache._cachedir.joinpath("CACHEDIR.TAG")
     assert cachedir_tag_path.read_bytes() == CACHEDIR_TAG_CONTENT
('testing', 'test_meta.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -13,7 +13,7 @@


 def _modules() -> List[str]:
-    pytest_pkg = _pytest.__path__  # type: str  # type: ignore
+    pytest_pkg: str = _pytest.__path__  # type: ignore
     return sorted(
         n
         for _, n, _ in pkgutil.walk_packages(pytest_pkg, prefix=_pytest.__name__ + ".")
@@ -27,8 +27,6 @@
     subprocess.check_call((
         sys.executable,
         "-W", "error",
-        # https://github.com/pytest-dev/pytest/issues/5901
-        "-W", "ignore:The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.:DeprecationWarning",  # noqa: E501
-        "-c", "__import__({!r})".format(module),
+        "-c", f"__import__({module!r})",
     ))
     # fmt: on
('testing', 'test_findpaths.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,10 +1,11 @@
+from pathlib import Path
 from textwrap import dedent

 import pytest
+from _pytest.config import UsageError
 from _pytest.config.findpaths import get_common_ancestor
 from _pytest.config.findpaths import get_dirs_from_args
 from _pytest.config.findpaths import load_config_dict_from_file
-from _pytest.pathlib import Path


 class TestLoadConfigDictFromFile:
@@ -52,6 +53,13 @@
             load_config_dict_from_file(fn)

     def test_invalid_toml_file(self, tmp_path: Path) -> None:
+        """Invalid .toml files should raise `UsageError`."""
+        fn = tmp_path / "myconfig.toml"
+        fn.write_text("]invalid toml[", encoding="utf-8")
+        with pytest.raises(UsageError):
+            load_config_dict_from_file(fn)
+
+    def test_custom_toml_file(self, tmp_path: Path) -> None:
         """.toml files without [tool.pytest.ini_options] are not considered for configuration."""
         fn = tmp_path / "myconfig.toml"
         fn.write_text(
@@ -77,6 +85,7 @@
             y = 20.0
             values = ["tests", "integration"]
             name = "foo"
+            heterogeneous_array = [1, "str"]
             """
             ),
             encoding="utf-8",
@@ -86,6 +95,7 @@
             "y": "20.0",
             "values": ["tests", "integration"],
             "name": "foo",
+            "heterogeneous_array": [1, "str"],
         }


('testing', 'test_assertion.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,8 +1,9 @@
-import collections.abc
+import collections
 import sys
 import textwrap
 from typing import Any
 from typing import List
+from typing import MutableSequence
 from typing import Optional

 import attr
@@ -12,7 +13,8 @@
 from _pytest import outcomes
 from _pytest.assertion import truncate
 from _pytest.assertion import util
-from _pytest.compat import ATTRS_EQ_FIELD
+from _pytest.monkeypatch import MonkeyPatch
+from _pytest.pytester import Pytester


 def mock_config(verbose=0):
@@ -28,9 +30,12 @@
 class TestImportHookInstallation:
     @pytest.mark.parametrize("initial_conftest", [True, False])
     @pytest.mark.parametrize("mode", ["plain", "rewrite"])
-    def test_conftest_assertion_rewrite(self, testdir, initial_conftest, mode):
+    def test_conftest_assertion_rewrite(
+        self, pytester: Pytester, initial_conftest, mode
+    ) -> None:
         """Test that conftest files are using assertion rewrite on import (#1619)."""
-        testdir.tmpdir.join("foo/tests").ensure(dir=1)
+        pytester.mkdir("foo")
+        pytester.mkdir("foo/tests")
         conftest_path = "conftest.py" if initial_conftest else "foo/conftest.py"
         contents = {
             conftest_path: """
@@ -46,8 +51,8 @@
                     check_first([10, 30], 30)
             """,
         }
-        testdir.makepyfile(**contents)
-        result = testdir.runpytest_subprocess("--assert=%s" % mode)
+        pytester.makepyfile(**contents)
+        result = pytester.runpytest_subprocess("--assert=%s" % mode)
         if mode == "plain":
             expected = "E       AssertionError"
         elif mode == "rewrite":
@@ -56,21 +61,21 @@
             assert 0
         result.stdout.fnmatch_lines([expected])

-    def test_rewrite_assertions_pytester_plugin(self, testdir):
+    def test_rewrite_assertions_pytester_plugin(self, pytester: Pytester) -> None:
         """
         Assertions in the pytester plugin must also benefit from assertion
         rewriting (#1920).
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             pytest_plugins = ['pytester']
-            def test_dummy_failure(testdir):  # how meta!
-                testdir.makepyfile('def test(): assert 0')
-                r = testdir.inline_run()
+            def test_dummy_failure(pytester):  # how meta!
+                pytester.makepyfile('def test(): assert 0')
+                r = pytester.inline_run()
                 r.assertoutcome(passed=1)
         """
         )
-        result = testdir.runpytest_subprocess()
+        result = pytester.runpytest_subprocess()
         result.stdout.fnmatch_lines(
             [
                 ">       r.assertoutcome(passed=1)",
@@ -78,7 +83,7 @@
                 "E       assert {'failed': 1,... 'skipped': 0} == {'failed': 0,... 'skipped': 0}",
                 "E         Omitting 1 identical items, use -vv to show",
                 "E         Differing items:",
-                "E         Use -v to get the full diff",
+                "E         Use -v to get more diff",
             ]
         )
         # XXX: unstable output.
@@ -90,7 +95,7 @@
         )

     @pytest.mark.parametrize("mode", ["plain", "rewrite"])
-    def test_pytest_plugins_rewrite(self, testdir, mode):
+    def test_pytest_plugins_rewrite(self, pytester: Pytester, mode) -> None:
         contents = {
             "conftest.py": """
                 pytest_plugins = ['ham']
@@ -108,8 +113,8 @@
                     check_first([10, 30], 30)
             """,
         }
-        testdir.makepyfile(**contents)
-        result = testdir.runpytest_subprocess("--assert=%s" % mode)
+        pytester.makepyfile(**contents)
+        result = pytester.runpytest_subprocess("--assert=%s" % mode)
         if mode == "plain":
             expected = "E       AssertionError"
         elif mode == "rewrite":
@@ -119,7 +124,9 @@
         result.stdout.fnmatch_lines([expected])

     @pytest.mark.parametrize("mode", ["str", "list"])
-    def test_pytest_plugins_rewrite_module_names(self, testdir, mode):
+    def test_pytest_plugins_rewrite_module_names(
+        self, pytester: Pytester, mode
+    ) -> None:
         """Test that pluginmanager correct marks pytest_plugins variables
         for assertion rewriting if they are defined as plain strings or
         list of strings (#1888).
@@ -139,11 +146,13 @@
                     assert 'ham' in pytestconfig.pluginmanager.rewrite_hook._must_rewrite
             """,
         }
-        testdir.makepyfile(**contents)
-        result = testdir.runpytest_subprocess("--assert=rewrite")
+        pytester.makepyfile(**contents)
+        result = pytester.runpytest_subprocess("--assert=rewrite")
         assert result.ret == 0

-    def test_pytest_plugins_rewrite_module_names_correctly(self, testdir):
+    def test_pytest_plugins_rewrite_module_names_correctly(
+        self, pytester: Pytester
+    ) -> None:
         """Test that we match files correctly when they are marked for rewriting (#2939)."""
         contents = {
             "conftest.py": """\
@@ -157,16 +166,18 @@
                     assert pytestconfig.pluginmanager.rewrite_hook.find_spec('hamster') is None
             """,
         }
-        testdir.makepyfile(**contents)
-        result = testdir.runpytest_subprocess("--assert=rewrite")
+        pytester.makepyfile(**contents)
+        result = pytester.runpytest_subprocess("--assert=rewrite")
         assert result.ret == 0

     @pytest.mark.parametrize("mode", ["plain", "rewrite"])
-    def test_installed_plugin_rewrite(self, testdir, mode, monkeypatch):
+    def test_installed_plugin_rewrite(
+        self, pytester: Pytester, mode, monkeypatch
+    ) -> None:
         monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", raising=False)
         # Make sure the hook is installed early enough so that plugins
         # installed via setuptools are rewritten.
-        testdir.tmpdir.join("hampkg").ensure(dir=1)
+        pytester.mkdir("hampkg")
         contents = {
             "hampkg/__init__.py": """\
                 import pytest
@@ -220,8 +231,8 @@
                 check_first([10, 30], 30)
             """,
         }
-        testdir.makepyfile(**contents)
-        result = testdir.run(
+        pytester.makepyfile(**contents)
+        result = pytester.run(
             sys.executable, "mainwrapper.py", "-s", "--assert=%s" % mode
         )
         if mode == "plain":
@@ -232,8 +243,8 @@
             assert 0
         result.stdout.fnmatch_lines([expected])

-    def test_rewrite_ast(self, testdir):
-        testdir.tmpdir.join("pkg").ensure(dir=1)
+    def test_rewrite_ast(self, pytester: Pytester) -> None:
+        pytester.mkdir("pkg")
         contents = {
             "pkg/__init__.py": """
                 import pytest
@@ -266,8 +277,8 @@
                     pkg.other.tool()
             """,
         }
-        testdir.makepyfile(**contents)
-        result = testdir.runpytest_subprocess("--assert=rewrite")
+        pytester.makepyfile(**contents)
+        result = pytester.runpytest_subprocess("--assert=rewrite")
         result.stdout.fnmatch_lines(
             [
                 ">*assert a == b*",
@@ -286,8 +297,8 @@


 class TestBinReprIntegration:
-    def test_pytest_assertrepr_compare_called(self, testdir):
-        testdir.makeconftest(
+    def test_pytest_assertrepr_compare_called(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest
             values = []
@@ -299,7 +310,7 @@
                 return values
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_hello():
                 assert 0 == 1
@@ -307,7 +318,7 @@
                 assert list == [("==", 0, 1)]
         """
         )
-        result = testdir.runpytest("-v")
+        result = pytester.runpytest("-v")
         result.stdout.fnmatch_lines(["*test_hello*FAIL*", "*test_check*PASS*"])


@@ -321,7 +332,7 @@


 class TestAssert_reprcompare:
-    def test_different_types(self):
+    def test_different_types(self) -> None:
         assert callequal([0, 1], "foo") is None

     def test_summary(self) -> None:
@@ -330,7 +341,7 @@
         summary = lines[0]
         assert len(summary) < 65

-    def test_text_diff(self):
+    def test_text_diff(self) -> None:
         assert callequal("spam", "eggs") == [
             "'spam' == 'eggs'",
             "- eggs",
@@ -358,17 +369,17 @@
         assert "- eggs" in diff
         assert "+ spam" in diff

-    def test_bytes_diff_normal(self):
+    def test_bytes_diff_normal(self) -> None:
         """Check special handling for bytes diff (#5260)"""
         diff = callequal(b"spam", b"eggs")

         assert diff == [
             "b'spam' == b'eggs'",
             "At index 0 diff: b's' != b'e'",
-            "Use -v to get the full diff",
-        ]
-
-    def test_bytes_diff_verbose(self):
+            "Use -v to get more diff",
+        ]
+
+    def test_bytes_diff_verbose(self) -> None:
         """Check special handling for bytes diff (#5260)"""
         diff = callequal(b"spam", b"eggs", verbose=1)
         assert diff == [
@@ -433,10 +444,37 @@
         """
         expl = callequal(left, right, verbose=0)
         assert expl is not None
-        assert expl[-1] == "Use -v to get the full diff"
+        assert expl[-1] == "Use -v to get more diff"
         verbose_expl = callequal(left, right, verbose=1)
         assert verbose_expl is not None
         assert "\n".join(verbose_expl).endswith(textwrap.dedent(expected).strip())
+
+    def test_iterable_quiet(self) -> None:
+        expl = callequal([1, 2], [10, 2], verbose=-1)
+        assert expl == [
+            "[1, 2] == [10, 2]",
+            "At index 0 diff: 1 != 10",
+            "Use -v to get more diff",
+        ]
+
+    def test_iterable_full_diff_ci(
+        self, monkeypatch: MonkeyPatch, pytester: Pytester
+    ) -> None:
+        pytester.makepyfile(
+            r"""
+            def test_full_diff():
+                left = [0, 1]
+                right = [0, 2]
+                assert left == right
+        """
+        )
+        monkeypatch.setenv("CI", "true")
+        result = pytester.runpytest()
+        result.stdout.fnmatch_lines(["E         Full diff:"])
+
+        monkeypatch.delenv("CI", raising=False)
+        result = pytester.runpytest()
+        result.stdout.fnmatch_lines(["E         Use -v to get more diff"])

     def test_list_different_lengths(self) -> None:
         expl = callequal([0, 1], [0, 1, 2])
@@ -446,7 +484,7 @@
         assert expl is not None
         assert len(expl) > 1

-    def test_list_wrap_for_multiple_lines(self):
+    def test_list_wrap_for_multiple_lines(self) -> None:
         long_d = "d" * 80
         l1 = ["a", "b", "c"]
         l2 = ["a", "b", "c", long_d]
@@ -476,7 +514,7 @@
             "  ]",
         ]

-    def test_list_wrap_for_width_rewrap_same_length(self):
+    def test_list_wrap_for_width_rewrap_same_length(self) -> None:
         long_a = "a" * 30
         long_b = "b" * 30
         long_c = "c" * 30
@@ -495,7 +533,7 @@
             "  ]",
         ]

-    def test_list_dont_wrap_strings(self):
+    def test_list_dont_wrap_strings(self) -> None:
         long_a = "a" * 10
         l1 = ["a"] + [long_a for _ in range(0, 7)]
         l2 = ["should not get wrapped"]
@@ -518,7 +556,7 @@
             "  ]",
         ]

-    def test_dict_wrap(self):
+    def test_dict_wrap(self) -> None:
         d1 = {"common": 1, "env": {"env1": 1, "env2": 2}}
         d2 = {"common": 1, "env": {"env1": 1}}

@@ -582,7 +620,7 @@
         assert "Omitting" not in lines[1]
         assert lines[2] == "{'b': 1}"

-    def test_dict_different_items(self):
+    def test_dict_different_items(self) -> None:
         lines = callequal({"a": 0}, {"b": 1, "c": 2}, verbose=2)
         assert lines == [
             "{'a': 0} == {'b': 1, 'c': 2}",
@@ -606,7 +644,7 @@
             "+ {'b': 1, 'c': 2}",
         ]

-    def test_sequence_different_items(self):
+    def test_sequence_different_items(self) -> None:
         lines = callequal((1, 2), (3, 4, 5), verbose=2)
         assert lines == [
             "(1, 2) == (3, 4, 5)",
@@ -638,8 +676,7 @@

     def test_Sequence(self) -> None:
         # Test comparing with a Sequence subclass.
-        # TODO(py36): Inherit from typing.MutableSequence[int].
-        class TestSequence(collections.abc.MutableSequence):  # type: ignore[type-arg]
+        class TestSequence(MutableSequence[int]):
             def __init__(self, iterable):
                 self.elements = list(iterable)

@@ -669,32 +706,6 @@
         expl = callequal([(1, 2)], [])
         assert expl is not None
         assert len(expl) > 1
-
-    def test_repr_verbose(self) -> None:
-        class Nums:
-            def __init__(self, nums):
-                self.nums = nums
-
-            def __repr__(self):
-                return str(self.nums)
-
-        list_x = list(range(5000))
-        list_y = list(range(5000))
-        list_y[len(list_y) // 2] = 3
-        nums_x = Nums(list_x)
-        nums_y = Nums(list_y)
-
-        assert callequal(nums_x, nums_y) is None
-
-        expl = callequal(nums_x, nums_y, verbose=1)
-        assert expl is not None
-        assert "+" + repr(nums_x) in expl
-        assert "-" + repr(nums_y) in expl
-
-        expl = callequal(nums_x, nums_y, verbose=2)
-        assert expl is not None
-        assert "+" + repr(nums_x) in expl
-        assert "-" + repr(nums_y) in expl

     def test_list_bad_repr(self) -> None:
         class A:
@@ -716,7 +727,7 @@
             " Probably an object has a faulty __repr__.)",
         ]

-    def test_one_repr_empty(self):
+    def test_one_repr_empty(self) -> None:
         """The faulty empty string repr did trigger an unbound local error in _diff_text."""

         class A(str):
@@ -731,14 +742,14 @@
         assert expl is not None
         assert "raised in repr()" not in " ".join(expl)

-    def test_unicode(self):
+    def test_unicode(self) -> None:
         assert callequal("£€", "£") == [
             "'£€' == '£'",
             "- £",
             "+ £€",
         ]

-    def test_nonascii_text(self):
+    def test_nonascii_text(self) -> None:
         """
         :issue: 877
         non ascii python2 str caused a UnicodeDecodeError
@@ -751,7 +762,7 @@
         expl = callequal(A(), "1")
         assert expl == ["ÿ == '1'", "- 1"]

-    def test_format_nonascii_explanation(self):
+    def test_format_nonascii_explanation(self) -> None:
         assert util.format_explanation("λ")

     def test_mojibake(self) -> None:
@@ -767,10 +778,9 @@


 class TestAssert_reprcompare_dataclass:
-    @pytest.mark.skipif(sys.version_info < (3, 7), reason="Dataclasses in Python3.7+")
-    def test_dataclasses(self, testdir):
-        p = testdir.copy_example("dataclasses/test_compare_dataclasses.py")
-        result = testdir.runpytest(p)
+    def test_dataclasses(self, pytester: Pytester) -> None:
+        p = pytester.copy_example("dataclasses/test_compare_dataclasses.py")
+        result = pytester.runpytest(p)
         result.assert_outcomes(failed=1, passed=0)
         result.stdout.fnmatch_lines(
             [
@@ -786,10 +796,9 @@
             consecutive=True,
         )

-    @pytest.mark.skipif(sys.version_info < (3, 7), reason="Dataclasses in Python3.7+")
-    def test_recursive_dataclasses(self, testdir):
-        p = testdir.copy_example("dataclasses/test_compare_recursive_dataclasses.py")
-        result = testdir.runpytest(p)
+    def test_recursive_dataclasses(self, pytester: Pytester) -> None:
+        p = pytester.copy_example("dataclasses/test_compare_recursive_dataclasses.py")
+        result = pytester.runpytest(p)
         result.assert_outcomes(failed=1, passed=0)
         result.stdout.fnmatch_lines(
             [
@@ -805,10 +814,9 @@
             consecutive=True,
         )

-    @pytest.mark.skipif(sys.version_info < (3, 7), reason="Dataclasses in Python3.7+")
-    def test_recursive_dataclasses_verbose(self, testdir):
-        p = testdir.copy_example("dataclasses/test_compare_recursive_dataclasses.py")
-        result = testdir.runpytest(p, "-vv")
+    def test_recursive_dataclasses_verbose(self, pytester: Pytester) -> None:
+        p = pytester.copy_example("dataclasses/test_compare_recursive_dataclasses.py")
+        result = pytester.runpytest(p, "-vv")
         result.assert_outcomes(failed=1, passed=0)
         result.stdout.fnmatch_lines(
             [
@@ -825,8 +833,6 @@
                 "E           ",
                 "E           Drill down into differing attribute a:",
                 "E             a: 10 != 20",
-                "E             +10",
-                "E             -20",
                 "E           ",
                 "E           Drill down into differing attribute b:",
                 "E             b: 'ten' != 'xxx'",
@@ -838,10 +844,9 @@
             consecutive=True,
         )

-    @pytest.mark.skipif(sys.version_info < (3, 7), reason="Dataclasses in Python3.7+")
-    def test_dataclasses_verbose(self, testdir):
-        p = testdir.copy_example("dataclasses/test_compare_dataclasses_verbose.py")
-        result = testdir.runpytest(p, "-vv")
+    def test_dataclasses_verbose(self, pytester: Pytester) -> None:
+        p = pytester.copy_example("dataclasses/test_compare_dataclasses_verbose.py")
+        result = pytester.runpytest(p, "-vv")
         result.assert_outcomes(failed=1, passed=0)
         result.stdout.fnmatch_lines(
             [
@@ -852,21 +857,37 @@
             ]
         )

-    @pytest.mark.skipif(sys.version_info < (3, 7), reason="Dataclasses in Python3.7+")
-    def test_dataclasses_with_attribute_comparison_off(self, testdir):
-        p = testdir.copy_example(
+    def test_dataclasses_with_attribute_comparison_off(
+        self, pytester: Pytester
+    ) -> None:
+        p = pytester.copy_example(
             "dataclasses/test_compare_dataclasses_field_comparison_off.py"
         )
-        result = testdir.runpytest(p, "-vv")
+        result = pytester.runpytest(p, "-vv")
         result.assert_outcomes(failed=0, passed=1)

-    @pytest.mark.skipif(sys.version_info < (3, 7), reason="Dataclasses in Python3.7+")
-    def test_comparing_two_different_data_classes(self, testdir):
-        p = testdir.copy_example(
+    def test_comparing_two_different_data_classes(self, pytester: Pytester) -> None:
+        p = pytester.copy_example(
             "dataclasses/test_compare_two_different_dataclasses.py"
         )
-        result = testdir.runpytest(p, "-vv")
+        result = pytester.runpytest(p, "-vv")
         result.assert_outcomes(failed=0, passed=1)
+
+    def test_data_classes_with_custom_eq(self, pytester: Pytester) -> None:
+        p = pytester.copy_example(
+            "dataclasses/test_compare_dataclasses_with_custom_eq.py"
+        )
+        # issue 9362
+        result = pytester.runpytest(p, "-vv")
+        result.assert_outcomes(failed=1, passed=0)
+        result.stdout.no_re_match_line(".*Differing attributes.*")
+
+    def test_data_classes_with_initvar(self, pytester: Pytester) -> None:
+        p = pytester.copy_example("dataclasses/test_compare_initvar.py")
+        # issue 9820
+        result = pytester.runpytest(p, "-vv")
+        result.assert_outcomes(failed=1, passed=0)
+        result.stdout.no_re_match_line(".*AttributeError.*")


 class TestAssert_reprcompare_attrsclass:
@@ -941,17 +962,16 @@
         assert "Omitting" not in lines[2]
         assert lines[3] == "['field_a']"

-    def test_attrs_with_attribute_comparison_off(self):
+    def test_attrs_with_attribute_comparison_off(self) -> None:
         @attr.s
         class SimpleDataObject:
             field_a = attr.ib()
-            field_b = attr.ib(**{ATTRS_EQ_FIELD: False})  # type: ignore
+            field_b = attr.ib(eq=False)

         left = SimpleDataObject(1, "b")
         right = SimpleDataObject(1, "b")

         lines = callequal(left, right, verbose=2)
-        print(lines)
         assert lines is not None
         assert lines[2].startswith("Matching attributes:")
         assert "Omitting" not in lines[1]
@@ -959,7 +979,7 @@
         for line in lines[3:]:
             assert "field_b" not in line

-    def test_comparing_two_different_attrs_classes(self):
+    def test_comparing_two_different_attrs_classes(self) -> None:
         @attr.s
         class SimpleDataObjectOne:
             field_a = attr.ib()
@@ -976,50 +996,118 @@
         lines = callequal(left, right)
         assert lines is None

+    def test_attrs_with_auto_detect_and_custom_eq(self) -> None:
+        @attr.s(
+            auto_detect=True
+        )  # attr.s doesn’t ignore a custom eq if auto_detect=True
+        class SimpleDataObject:
+            field_a = attr.ib()
+
+            def __eq__(self, other):  # pragma: no cover
+                return super().__eq__(other)
+
+        left = SimpleDataObject(1)
+        right = SimpleDataObject(2)
+        # issue 9362
+        lines = callequal(left, right, verbose=2)
+        assert lines is None
+
+    def test_attrs_with_custom_eq(self) -> None:
+        @attr.define(slots=False)
+        class SimpleDataObject:
+            field_a = attr.ib()
+
+            def __eq__(self, other):  # pragma: no cover
+                return super().__eq__(other)
+
+        left = SimpleDataObject(1)
+        right = SimpleDataObject(2)
+        # issue 9362
+        lines = callequal(left, right, verbose=2)
+        assert lines is None
+
+
+class TestAssert_reprcompare_namedtuple:
+    def test_namedtuple(self) -> None:
+        NT = collections.namedtuple("NT", ["a", "b"])
+
+        left = NT(1, "b")
+        right = NT(1, "c")
+
+        lines = callequal(left, right)
+        assert lines == [
+            "NT(a=1, b='b') == NT(a=1, b='c')",
+            "",
+            "Omitting 1 identical items, use -vv to show",
+            "Differing attributes:",
+            "['b']",
+            "",
+            "Drill down into differing attribute b:",
+            "  b: 'b' != 'c'",
+            "  - c",
+            "  + b",
+            "Use -v to get more diff",
+        ]
+
+    def test_comparing_two_different_namedtuple(self) -> None:
+        NT1 = collections.namedtuple("NT1", ["a", "b"])
+        NT2 = collections.namedtuple("NT2", ["a", "b"])
+
+        left = NT1(1, "b")
+        right = NT2(2, "b")
+
+        lines = callequal(left, right)
+        # Because the types are different, uses the generic sequence matcher.
+        assert lines == [
+            "NT1(a=1, b='b') == NT2(a=2, b='b')",
+            "At index 0 diff: 1 != 2",
+            "Use -v to get more diff",
+        ]
+

 class TestFormatExplanation:
-    def test_special_chars_full(self, testdir):
+    def test_special_chars_full(self, pytester: Pytester) -> None:
         # Issue 453, for the bug this would raise IndexError
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_foo():
                 assert '\\n}' == ''
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret == 1
         result.stdout.fnmatch_lines(["*AssertionError*"])

-    def test_fmt_simple(self):
+    def test_fmt_simple(self) -> None:
         expl = "assert foo"
         assert util.format_explanation(expl) == "assert foo"

-    def test_fmt_where(self):
+    def test_fmt_where(self) -> None:
         expl = "\n".join(["assert 1", "{1 = foo", "} == 2"])
         res = "\n".join(["assert 1 == 2", " +  where 1 = foo"])
         assert util.format_explanation(expl) == res

-    def test_fmt_and(self):
+    def test_fmt_and(self) -> None:
         expl = "\n".join(["assert 1", "{1 = foo", "} == 2", "{2 = bar", "}"])
         res = "\n".join(["assert 1 == 2", " +  where 1 = foo", " +  and   2 = bar"])
         assert util.format_explanation(expl) == res

-    def test_fmt_where_nested(self):
+    def test_fmt_where_nested(self) -> None:
         expl = "\n".join(["assert 1", "{1 = foo", "{foo = bar", "}", "} == 2"])
         res = "\n".join(["assert 1 == 2", " +  where 1 = foo", " +    where foo = bar"])
         assert util.format_explanation(expl) == res

-    def test_fmt_newline(self):
+    def test_fmt_newline(self) -> None:
         expl = "\n".join(['assert "foo" == "bar"', "~- foo", "~+ bar"])
         res = "\n".join(['assert "foo" == "bar"', "  - foo", "  + bar"])
         assert util.format_explanation(expl) == res

-    def test_fmt_newline_escaped(self):
+    def test_fmt_newline_escaped(self) -> None:
         expl = "\n".join(["assert foo == bar", "baz"])
         res = "assert foo == bar\\nbaz"
         assert util.format_explanation(expl) == res

-    def test_fmt_newline_before_where(self):
+    def test_fmt_newline_before_where(self) -> None:
         expl = "\n".join(
             [
                 "the assertion message here",
@@ -1040,7 +1128,7 @@
         )
         assert util.format_explanation(expl) == res

-    def test_fmt_multi_newline_before_where(self):
+    def test_fmt_multi_newline_before_where(self) -> None:
         expl = "\n".join(
             [
                 "the assertion",
@@ -1070,16 +1158,16 @@
     LINES_IN_TRUNCATION_MSG = 2

     def test_doesnt_truncate_when_input_is_empty_list(self) -> None:
-        expl = []  # type: List[str]
+        expl: List[str] = []
         result = truncate._truncate_explanation(expl, max_lines=8, max_chars=100)
         assert result == expl

-    def test_doesnt_truncate_at_when_input_is_5_lines_and_LT_max_chars(self):
+    def test_doesnt_truncate_at_when_input_is_5_lines_and_LT_max_chars(self) -> None:
         expl = ["a" * 100 for x in range(5)]
         result = truncate._truncate_explanation(expl, max_lines=8, max_chars=8 * 80)
         assert result == expl

-    def test_truncates_at_8_lines_when_given_list_of_empty_strings(self):
+    def test_truncates_at_8_lines_when_given_list_of_empty_strings(self) -> None:
         expl = ["" for x in range(50)]
         result = truncate._truncate_explanation(expl, max_lines=8, max_chars=100)
         assert result != expl
@@ -1089,7 +1177,7 @@
         last_line_before_trunc_msg = result[-self.LINES_IN_TRUNCATION_MSG - 1]
         assert last_line_before_trunc_msg.endswith("...")

-    def test_truncates_at_8_lines_when_first_8_lines_are_LT_max_chars(self):
+    def test_truncates_at_8_lines_when_first_8_lines_are_LT_max_chars(self) -> None:
         expl = ["a" for x in range(100)]
         result = truncate._truncate_explanation(expl, max_lines=8, max_chars=8 * 80)
         assert result != expl
@@ -1099,7 +1187,7 @@
         last_line_before_trunc_msg = result[-self.LINES_IN_TRUNCATION_MSG - 1]
         assert last_line_before_trunc_msg.endswith("...")

-    def test_truncates_at_8_lines_when_first_8_lines_are_EQ_max_chars(self):
+    def test_truncates_at_8_lines_when_first_8_lines_are_EQ_max_chars(self) -> None:
         expl = ["a" * 80 for x in range(16)]
         result = truncate._truncate_explanation(expl, max_lines=8, max_chars=8 * 80)
         assert result != expl
@@ -1109,7 +1197,7 @@
         last_line_before_trunc_msg = result[-self.LINES_IN_TRUNCATION_MSG - 1]
         assert last_line_before_trunc_msg.endswith("...")

-    def test_truncates_at_4_lines_when_first_4_lines_are_GT_max_chars(self):
+    def test_truncates_at_4_lines_when_first_4_lines_are_GT_max_chars(self) -> None:
         expl = ["a" * 250 for x in range(10)]
         result = truncate._truncate_explanation(expl, max_lines=8, max_chars=999)
         assert result != expl
@@ -1119,7 +1207,7 @@
         last_line_before_trunc_msg = result[-self.LINES_IN_TRUNCATION_MSG - 1]
         assert last_line_before_trunc_msg.endswith("...")

-    def test_truncates_at_1_line_when_first_line_is_GT_max_chars(self):
+    def test_truncates_at_1_line_when_first_line_is_GT_max_chars(self) -> None:
         expl = ["a" * 250 for x in range(1000)]
         result = truncate._truncate_explanation(expl, max_lines=8, max_chars=100)
         assert result != expl
@@ -1129,13 +1217,13 @@
         last_line_before_trunc_msg = result[-self.LINES_IN_TRUNCATION_MSG - 1]
         assert last_line_before_trunc_msg.endswith("...")

-    def test_full_output_truncated(self, monkeypatch, testdir):
+    def test_full_output_truncated(self, monkeypatch, pytester: Pytester) -> None:
         """Test against full runpytest() output."""

         line_count = 7
         line_len = 100
         expected_truncated_lines = 2
-        testdir.makepyfile(
+        pytester.makepyfile(
             r"""
             def test_many_lines():
                 a = list([str(i)[0] * %d for i in range(%d)])
@@ -1148,7 +1236,7 @@
         )
         monkeypatch.delenv("CI", raising=False)

-        result = testdir.runpytest()
+        result = pytester.runpytest()
         # without -vv, truncate the message showing a few diff lines only
         result.stdout.fnmatch_lines(
             [
@@ -1159,23 +1247,23 @@
             ]
         )

-        result = testdir.runpytest("-vv")
+        result = pytester.runpytest("-vv")
         result.stdout.fnmatch_lines(["* 6*"])

         monkeypatch.setenv("CI", "1")
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["* 6*"])


-def test_python25_compile_issue257(testdir):
-    testdir.makepyfile(
+def test_python25_compile_issue257(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         def test_rewritten():
             assert 1 == 2
         # some comment
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert result.ret == 1
     result.stdout.fnmatch_lines(
         """
@@ -1185,14 +1273,14 @@
     )


-def test_rewritten(testdir):
-    testdir.makepyfile(
+def test_rewritten(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         def test_rewritten():
             assert "@py_builtins" in globals()
     """
     )
-    assert testdir.runpytest().ret == 0
+    assert pytester.runpytest().ret == 0


 def test_reprcompare_notin() -> None:
@@ -1204,7 +1292,7 @@
     ]


-def test_reprcompare_whitespaces():
+def test_reprcompare_whitespaces() -> None:
     assert callequal("\r\n", "\n") == [
         r"'\r\n' == '\n'",
         r"Strings contain only whitespace, escaping them using repr()",
@@ -1214,8 +1302,8 @@
     ]


-def test_pytest_assertrepr_compare_integration(testdir):
-    testdir.makepyfile(
+def test_pytest_assertrepr_compare_integration(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         def test_hello():
             x = set(range(100))
@@ -1224,7 +1312,7 @@
             assert x == y
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         [
             "*def test_hello():*",
@@ -1236,8 +1324,8 @@
     )


-def test_sequence_comparison_uses_repr(testdir):
-    testdir.makepyfile(
+def test_sequence_comparison_uses_repr(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         def test_hello():
             x = set("hello x")
@@ -1245,7 +1333,7 @@
             assert x == y
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         [
             "*def test_hello():*",
@@ -1258,19 +1346,20 @@
     )


-def test_assertrepr_loaded_per_dir(testdir):
-    testdir.makepyfile(test_base=["def test_base(): assert 1 == 2"])
-    a = testdir.mkdir("a")
-    a_test = a.join("test_a.py")
-    a_test.write("def test_a(): assert 1 == 2")
-    a_conftest = a.join("conftest.py")
-    a_conftest.write('def pytest_assertrepr_compare(): return ["summary a"]')
-    b = testdir.mkdir("b")
-    b_test = b.join("test_b.py")
-    b_test.write("def test_b(): assert 1 == 2")
-    b_conftest = b.join("conftest.py")
-    b_conftest.write('def pytest_assertrepr_compare(): return ["summary b"]')
-    result = testdir.runpytest()
+def test_assertrepr_loaded_per_dir(pytester: Pytester) -> None:
+    pytester.makepyfile(test_base=["def test_base(): assert 1 == 2"])
+    a = pytester.mkdir("a")
+    a.joinpath("test_a.py").write_text("def test_a(): assert 1 == 2")
+    a.joinpath("conftest.py").write_text(
+        'def pytest_assertrepr_compare(): return ["summary a"]'
+    )
+    b = pytester.mkdir("b")
+    b.joinpath("test_b.py").write_text("def test_b(): assert 1 == 2")
+    b.joinpath("conftest.py").write_text(
+        'def pytest_assertrepr_compare(): return ["summary b"]'
+    )
+
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         [
             "*def test_base():*",
@@ -1283,34 +1372,34 @@
     )


-def test_assertion_options(testdir):
-    testdir.makepyfile(
+def test_assertion_options(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         def test_hello():
             x = 3
             assert x == 4
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert "3 == 4" in result.stdout.str()
-    result = testdir.runpytest_subprocess("--assert=plain")
+    result = pytester.runpytest_subprocess("--assert=plain")
     result.stdout.no_fnmatch_line("*3 == 4*")


-def test_triple_quoted_string_issue113(testdir):
-    testdir.makepyfile(
+def test_triple_quoted_string_issue113(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         def test_hello():
             assert "" == '''
     '''"""
     )
-    result = testdir.runpytest("--fulltrace")
+    result = pytester.runpytest("--fulltrace")
     result.stdout.fnmatch_lines(["*1 failed*"])
     result.stdout.no_fnmatch_line("*SyntaxError*")


-def test_traceback_failure(testdir):
-    p1 = testdir.makepyfile(
+def test_traceback_failure(pytester: Pytester) -> None:
+    p1 = pytester.makepyfile(
         """
         def g():
             return 2
@@ -1320,7 +1409,7 @@
             f(3)
     """
     )
-    result = testdir.runpytest(p1, "--tb=long")
+    result = pytester.runpytest(p1, "--tb=long")
     result.stdout.fnmatch_lines(
         [
             "*test_traceback_failure.py F*",
@@ -1342,7 +1431,7 @@
         ]
     )

-    result = testdir.runpytest(p1)  # "auto"
+    result = pytester.runpytest(p1)  # "auto"
     result.stdout.fnmatch_lines(
         [
             "*test_traceback_failure.py F*",
@@ -1364,9 +1453,9 @@
     )


-def test_exception_handling_no_traceback(testdir):
+def test_exception_handling_no_traceback(pytester: Pytester) -> None:
     """Handle chain exceptions in tasks submitted by the multiprocess module (#1984)."""
-    p1 = testdir.makepyfile(
+    p1 = pytester.makepyfile(
         """
         from multiprocessing import Pool

@@ -1382,8 +1471,8 @@
             multitask_job()
     """
     )
-    testdir.syspathinsert()
-    result = testdir.runpytest(p1, "--tb=long")
+    pytester.syspathinsert()
+    result = pytester.runpytest(p1, "--tb=long")
     result.stdout.fnmatch_lines(
         [
             "====* FAILURES *====",
@@ -1421,27 +1510,27 @@
         ),
     ],
 )
-def test_warn_missing(testdir, cmdline_args, warning_output):
-    testdir.makepyfile("")
-
-    result = testdir.run(sys.executable, *cmdline_args)
+def test_warn_missing(pytester: Pytester, cmdline_args, warning_output) -> None:
+    pytester.makepyfile("")
+
+    result = pytester.run(sys.executable, *cmdline_args)
     result.stdout.fnmatch_lines(warning_output)


-def test_recursion_source_decode(testdir):
-    testdir.makepyfile(
+def test_recursion_source_decode(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         def test_something():
             pass
     """
     )
-    testdir.makeini(
+    pytester.makeini(
         """
         [pytest]
         python_files = *.py
     """
     )
-    result = testdir.runpytest("--collect-only")
+    result = pytester.runpytest("--collect-only")
     result.stdout.fnmatch_lines(
         """
         <Module*>
@@ -1449,15 +1538,15 @@
     )


-def test_AssertionError_message(testdir):
-    testdir.makepyfile(
+def test_AssertionError_message(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         def test_hello():
             x,y = 1,2
             assert 0, (x,y)
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         """
         *def test_hello*
@@ -1467,15 +1556,15 @@
     )


-def test_diff_newline_at_end(testdir):
-    testdir.makepyfile(
+def test_diff_newline_at_end(pytester: Pytester) -> None:
+    pytester.makepyfile(
         r"""
         def test_diff():
             assert 'asdf' == 'asdf\n'
     """
     )

-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         r"""
         *assert 'asdf' == 'asdf\n'
@@ -1487,67 +1576,67 @@


 @pytest.mark.filterwarnings("default")
-def test_assert_tuple_warning(testdir):
+def test_assert_tuple_warning(pytester: Pytester) -> None:
     msg = "assertion is always true"
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         def test_tuple():
             assert(False, 'you shall not pass')
     """
     )
-    result = testdir.runpytest()
-    result.stdout.fnmatch_lines(["*test_assert_tuple_warning.py:2:*{}*".format(msg)])
+    result = pytester.runpytest()
+    result.stdout.fnmatch_lines([f"*test_assert_tuple_warning.py:2:*{msg}*"])

     # tuples with size != 2 should not trigger the warning
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         def test_tuple():
             assert ()
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert msg not in result.stdout.str()


-def test_assert_indirect_tuple_no_warning(testdir):
-    testdir.makepyfile(
+def test_assert_indirect_tuple_no_warning(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         def test_tuple():
             tpl = ('foo', 'bar')
             assert tpl
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     output = "\n".join(result.stdout.lines)
     assert "WR1" not in output


-def test_assert_with_unicode(testdir):
-    testdir.makepyfile(
+def test_assert_with_unicode(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """\
         def test_unicode():
             assert '유니코드' == 'Unicode'
         """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*AssertionError*"])


-def test_raise_unprintable_assertion_error(testdir):
-    testdir.makepyfile(
+def test_raise_unprintable_assertion_error(pytester: Pytester) -> None:
+    pytester.makepyfile(
         r"""
         def test_raise_assertion_error():
             raise AssertionError('\xff')
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         [r">       raise AssertionError('\xff')", "E       AssertionError: *"]
     )


-def test_raise_assertion_error_raisin_repr(testdir):
-    testdir.makepyfile(
+def test_raise_assertion_error_raising_repr(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         class RaisingRepr(object):
             def __repr__(self):
@@ -1556,14 +1645,20 @@
             raise AssertionError(RaisingRepr())
     """
     )
-    result = testdir.runpytest()
-    result.stdout.fnmatch_lines(
-        ["E       AssertionError: <unprintable AssertionError object>"]
-    )
-
-
-def test_issue_1944(testdir):
-    testdir.makepyfile(
+    result = pytester.runpytest()
+    if sys.version_info >= (3, 11):
+        # python 3.11 has native support for un-str-able exceptions
+        result.stdout.fnmatch_lines(
+            ["E       AssertionError: <exception str() failed>"]
+        )
+    else:
+        result.stdout.fnmatch_lines(
+            ["E       AssertionError: <unprintable AssertionError object>"]
+        )
+
+
+def test_issue_1944(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         def f():
             return
@@ -1571,7 +1666,7 @@
         assert f() == 10
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*1 error*"])
     assert (
         "AttributeError: 'Module' object has no attribute '_obj'"
@@ -1579,7 +1674,7 @@
     )


-def test_exit_from_assertrepr_compare(monkeypatch):
+def test_exit_from_assertrepr_compare(monkeypatch) -> None:
     def raise_exit(obj):
         outcomes.exit("Quitting debugger")

@@ -1589,16 +1684,16 @@
         callequal(1, 1)


-def test_assertion_location_with_coverage(testdir):
+def test_assertion_location_with_coverage(pytester: Pytester) -> None:
     """This used to report the wrong location when run with coverage (#5754)."""
-    p = testdir.makepyfile(
+    p = pytester.makepyfile(
         """
         def test():
             assert False, 1
             assert False, 2
         """
     )
-    result = testdir.runpytest(str(p))
+    result = pytester.runpytest(str(p))
     result.stdout.fnmatch_lines(
         [
             ">       assert False, 1",
('testing', 'test_warning_types.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,18 +1,19 @@
 import inspect

-import _pytest.warning_types
 import pytest
+from _pytest import warning_types
+from _pytest.pytester import Pytester


 @pytest.mark.parametrize(
     "warning_class",
     [
         w
-        for n, w in vars(_pytest.warning_types).items()
+        for n, w in vars(warning_types).items()
         if inspect.isclass(w) and issubclass(w, Warning)
     ],
 )
-def test_warning_types(warning_class):
+def test_warning_types(warning_class: UserWarning) -> None:
     """Make sure all warnings declared in _pytest.warning_types are displayed as coming
     from 'pytest' instead of the internal module (#5452).
     """
@@ -20,11 +21,11 @@


 @pytest.mark.filterwarnings("error::pytest.PytestWarning")
-def test_pytest_warnings_repr_integration_test(testdir):
+def test_pytest_warnings_repr_integration_test(pytester: Pytester) -> None:
     """Small integration test to ensure our small hack of setting the __module__ attribute
     of our warnings actually works (#5452).
     """
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         import warnings
@@ -33,5 +34,5 @@
             warnings.warn(pytest.PytestWarning("some warning"))
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["E       pytest.PytestWarning: some warning"])
('testing', 'test_pytester.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -2,25 +2,26 @@
 import subprocess
 import sys
 import time
+from pathlib import Path
+from types import ModuleType
 from typing import List

-import py.path
-
-import _pytest.pytester as pytester
+import _pytest.pytester as pytester_mod
 import pytest
 from _pytest.config import ExitCode
 from _pytest.config import PytestPluginManager
+from _pytest.monkeypatch import MonkeyPatch
 from _pytest.pytester import CwdSnapshot
 from _pytest.pytester import HookRecorder
 from _pytest.pytester import LineMatcher
+from _pytest.pytester import Pytester
 from _pytest.pytester import SysModulesSnapshot
 from _pytest.pytester import SysPathsSnapshot
-from _pytest.pytester import Testdir
-
-
-def test_make_hook_recorder(testdir) -> None:
-    item = testdir.getitem("def test_func(): pass")
-    recorder = testdir.make_hook_recorder(item.config.pluginmanager)
+
+
+def test_make_hook_recorder(pytester: Pytester) -> None:
+    item = pytester.getitem("def test_func(): pass")
+    recorder = pytester.make_hook_recorder(item.config.pluginmanager)
     assert not recorder.getfailures()

     # (The silly condition is to fool mypy that the code below this is reachable)
@@ -34,11 +35,11 @@
         skipped = False
         when = "call"

-    recorder.hook.pytest_runtest_logreport(report=rep)
+    recorder.hook.pytest_runtest_logreport(report=rep)  # type: ignore[attr-defined]
     failures = recorder.getfailures()
-    assert failures == [rep]
+    assert failures == [rep]  # type: ignore[comparison-overlap]
     failures = recorder.getfailures()
-    assert failures == [rep]
+    assert failures == [rep]  # type: ignore[comparison-overlap]

     class rep2:
         excinfo = None
@@ -49,14 +50,14 @@

     rep2.passed = False
     rep2.skipped = True
-    recorder.hook.pytest_runtest_logreport(report=rep2)
-
-    modcol = testdir.getmodulecol("")
+    recorder.hook.pytest_runtest_logreport(report=rep2)  # type: ignore[attr-defined]
+
+    modcol = pytester.getmodulecol("")
     rep3 = modcol.config.hook.pytest_make_collect_report(collector=modcol)
     rep3.passed = False
     rep3.failed = True
     rep3.skipped = False
-    recorder.hook.pytest_collectreport(report=rep3)
+    recorder.hook.pytest_collectreport(report=rep3)  # type: ignore[attr-defined]

     passed, skipped, failed = recorder.listoutcomes()
     assert not passed and skipped and failed
@@ -67,55 +68,55 @@
     assert numfailed == 1
     assert len(recorder.getfailedcollections()) == 1

-    recorder.unregister()
+    recorder.unregister()  # type: ignore[attr-defined]
     recorder.clear()
-    recorder.hook.pytest_runtest_logreport(report=rep3)
+    recorder.hook.pytest_runtest_logreport(report=rep3)  # type: ignore[attr-defined]
     pytest.raises(ValueError, recorder.getfailures)


-def test_parseconfig(testdir) -> None:
-    config1 = testdir.parseconfig()
-    config2 = testdir.parseconfig()
+def test_parseconfig(pytester: Pytester) -> None:
+    config1 = pytester.parseconfig()
+    config2 = pytester.parseconfig()
     assert config2 is not config1


-def test_testdir_runs_with_plugin(testdir) -> None:
-    testdir.makepyfile(
+def test_pytester_runs_with_plugin(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         pytest_plugins = "pytester"
-        def test_hello(testdir):
+        def test_hello(pytester):
             assert 1
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.assert_outcomes(passed=1)


-def test_testdir_with_doctest(testdir):
-    """Check that testdir can be used within doctests.
+def test_pytester_with_doctest(pytester: Pytester) -> None:
+    """Check that pytester can be used within doctests.

     It used to use `request.function`, which is `None` with doctests."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         **{
             "sub/t-doctest.py": """
         '''
         >>> import os
-        >>> testdir = getfixture("testdir")
-        >>> str(testdir.makepyfile("content")).replace(os.sep, '/')
+        >>> pytester = getfixture("pytester")
+        >>> str(pytester.makepyfile("content")).replace(os.sep, '/')
         '.../basetemp/sub.t-doctest0/sub.py'
         '''
     """,
             "sub/__init__.py": "",
         }
     )
-    result = testdir.runpytest(
+    result = pytester.runpytest(
         "-p", "pytester", "--doctest-modules", "sub/t-doctest.py"
     )
     assert result.ret == 0


-def test_runresult_assertion_on_xfail(testdir) -> None:
-    testdir.makepyfile(
+def test_runresult_assertion_on_xfail(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import pytest

@@ -126,13 +127,13 @@
             assert False
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.assert_outcomes(xfailed=1)
     assert result.ret == 0


-def test_runresult_assertion_on_xpassed(testdir) -> None:
-    testdir.makepyfile(
+def test_runresult_assertion_on_xpassed(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import pytest

@@ -143,13 +144,13 @@
             assert True
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.assert_outcomes(xpassed=1)
     assert result.ret == 0


-def test_xpassed_with_strict_is_considered_a_failure(testdir) -> None:
-    testdir.makepyfile(
+def test_xpassed_with_strict_is_considered_a_failure(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import pytest

@@ -160,7 +161,7 @@
             assert True
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.assert_outcomes(failed=1)
     assert result.ret != 0

@@ -190,7 +191,7 @@
 def test_hookrecorder_basic(holder) -> None:
     pm = PytestPluginManager()
     pm.add_hookspecs(holder)
-    rec = HookRecorder(pm)
+    rec = HookRecorder(pm, _ispytest=True)
     pm.hook.pytest_xyz(arg=123)
     call = rec.popcall("pytest_xyz")
     assert call.arg == 123
@@ -201,33 +202,33 @@
     assert call._name == "pytest_xyz_noarg"


-def test_makepyfile_unicode(testdir) -> None:
-    testdir.makepyfile(chr(0xFFFD))
-
-
-def test_makepyfile_utf8(testdir) -> None:
+def test_makepyfile_unicode(pytester: Pytester) -> None:
+    pytester.makepyfile(chr(0xFFFD))
+
+
+def test_makepyfile_utf8(pytester: Pytester) -> None:
     """Ensure makepyfile accepts utf-8 bytes as input (#2738)"""
     utf8_contents = """
         def setup_function(function):
             mixed_encoding = 'São Paulo'
     """.encode()
-    p = testdir.makepyfile(utf8_contents)
-    assert "mixed_encoding = 'São Paulo'".encode() in p.read("rb")
+    p = pytester.makepyfile(utf8_contents)
+    assert "mixed_encoding = 'São Paulo'".encode() in p.read_bytes()


 class TestInlineRunModulesCleanup:
-    def test_inline_run_test_module_not_cleaned_up(self, testdir) -> None:
-        test_mod = testdir.makepyfile("def test_foo(): assert True")
-        result = testdir.inline_run(str(test_mod))
+    def test_inline_run_test_module_not_cleaned_up(self, pytester: Pytester) -> None:
+        test_mod = pytester.makepyfile("def test_foo(): assert True")
+        result = pytester.inline_run(str(test_mod))
         assert result.ret == ExitCode.OK
         # rewrite module, now test should fail if module was re-imported
-        test_mod.write("def test_foo(): assert False")
-        result2 = testdir.inline_run(str(test_mod))
+        test_mod.write_text("def test_foo(): assert False")
+        result2 = pytester.inline_run(str(test_mod))
         assert result2.ret == ExitCode.TESTS_FAILED

     def spy_factory(self):
         class SysModulesSnapshotSpy:
-            instances = []  # type: List[SysModulesSnapshotSpy]
+            instances: List["SysModulesSnapshotSpy"] = []  # noqa: F821

             def __init__(self, preserve=None) -> None:
                 SysModulesSnapshotSpy.instances.append(self)
@@ -242,20 +243,20 @@
         return SysModulesSnapshotSpy

     def test_inline_run_taking_and_restoring_a_sys_modules_snapshot(
-        self, testdir, monkeypatch
+        self, pytester: Pytester, monkeypatch: MonkeyPatch
     ) -> None:
         spy_factory = self.spy_factory()
-        monkeypatch.setattr(pytester, "SysModulesSnapshot", spy_factory)
-        testdir.syspathinsert()
+        monkeypatch.setattr(pytester_mod, "SysModulesSnapshot", spy_factory)
+        pytester.syspathinsert()
         original = dict(sys.modules)
-        testdir.makepyfile(import1="# you son of a silly person")
-        testdir.makepyfile(import2="# my hovercraft is full of eels")
-        test_mod = testdir.makepyfile(
+        pytester.makepyfile(import1="# you son of a silly person")
+        pytester.makepyfile(import2="# my hovercraft is full of eels")
+        test_mod = pytester.makepyfile(
             """
             import import1
             def test_foo(): import import2"""
         )
-        testdir.inline_run(str(test_mod))
+        pytester.inline_run(str(test_mod))
         assert len(spy_factory.instances) == 1
         spy = spy_factory.instances[0]
         assert spy._spy_restore_count == 1
@@ -263,51 +264,52 @@
         assert all(sys.modules[x] is original[x] for x in sys.modules)

     def test_inline_run_sys_modules_snapshot_restore_preserving_modules(
-        self, testdir, monkeypatch
+        self, pytester: Pytester, monkeypatch: MonkeyPatch
     ) -> None:
         spy_factory = self.spy_factory()
-        monkeypatch.setattr(pytester, "SysModulesSnapshot", spy_factory)
-        test_mod = testdir.makepyfile("def test_foo(): pass")
-        testdir.inline_run(str(test_mod))
+        monkeypatch.setattr(pytester_mod, "SysModulesSnapshot", spy_factory)
+        test_mod = pytester.makepyfile("def test_foo(): pass")
+        pytester.inline_run(str(test_mod))
         spy = spy_factory.instances[0]
         assert not spy._spy_preserve("black_knight")
         assert spy._spy_preserve("zope")
         assert spy._spy_preserve("zope.interface")
         assert spy._spy_preserve("zopelicious")

-    def test_external_test_module_imports_not_cleaned_up(self, testdir) -> None:
-        testdir.syspathinsert()
-        testdir.makepyfile(imported="data = 'you son of a silly person'")
+    def test_external_test_module_imports_not_cleaned_up(
+        self, pytester: Pytester
+    ) -> None:
+        pytester.syspathinsert()
+        pytester.makepyfile(imported="data = 'you son of a silly person'")
         import imported

-        test_mod = testdir.makepyfile(
+        test_mod = pytester.makepyfile(
             """
             def test_foo():
                 import imported
                 imported.data = 42"""
         )
-        testdir.inline_run(str(test_mod))
+        pytester.inline_run(str(test_mod))
         assert imported.data == 42


-def test_assert_outcomes_after_pytest_error(testdir) -> None:
-    testdir.makepyfile("def test_foo(): assert True")
-
-    result = testdir.runpytest("--unexpected-argument")
+def test_assert_outcomes_after_pytest_error(pytester: Pytester) -> None:
+    pytester.makepyfile("def test_foo(): assert True")
+
+    result = pytester.runpytest("--unexpected-argument")
     with pytest.raises(ValueError, match="Pytest terminal summary report not found"):
         result.assert_outcomes(passed=0)


-def test_cwd_snapshot(testdir: Testdir) -> None:
-    tmpdir = testdir.tmpdir
-    foo = tmpdir.ensure("foo", dir=1)
-    bar = tmpdir.ensure("bar", dir=1)
-    foo.chdir()
+def test_cwd_snapshot(pytester: Pytester) -> None:
+    foo = pytester.mkdir("foo")
+    bar = pytester.mkdir("bar")
+    os.chdir(foo)
     snapshot = CwdSnapshot()
-    bar.chdir()
-    assert py.path.local() == bar
+    os.chdir(bar)
+    assert Path().absolute() == bar
     snapshot.restore()
-    assert py.path.local() == foo
+    assert Path().absolute() == foo


 class TestSysModulesSnapshot:
@@ -317,14 +319,14 @@
         original = dict(sys.modules)
         assert self.key not in sys.modules
         snapshot = SysModulesSnapshot()
-        sys.modules[self.key] = "something"  # type: ignore
+        sys.modules[self.key] = ModuleType("something")
         assert self.key in sys.modules
         snapshot.restore()
         assert sys.modules == original

-    def test_add_removed(self, monkeypatch) -> None:
+    def test_add_removed(self, monkeypatch: MonkeyPatch) -> None:
         assert self.key not in sys.modules
-        monkeypatch.setitem(sys.modules, self.key, "something")
+        monkeypatch.setitem(sys.modules, self.key, ModuleType("something"))
         assert self.key in sys.modules
         original = dict(sys.modules)
         snapshot = SysModulesSnapshot()
@@ -333,38 +335,39 @@
         snapshot.restore()
         assert sys.modules == original

-    def test_restore_reloaded(self, monkeypatch) -> None:
+    def test_restore_reloaded(self, monkeypatch: MonkeyPatch) -> None:
         assert self.key not in sys.modules
-        monkeypatch.setitem(sys.modules, self.key, "something")
+        monkeypatch.setitem(sys.modules, self.key, ModuleType("something"))
         assert self.key in sys.modules
         original = dict(sys.modules)
         snapshot = SysModulesSnapshot()
-        sys.modules[self.key] = "something else"  # type: ignore
+        sys.modules[self.key] = ModuleType("something else")
         snapshot.restore()
         assert sys.modules == original

-    def test_preserve_modules(self, monkeypatch) -> None:
+    def test_preserve_modules(self, monkeypatch: MonkeyPatch) -> None:
         key = [self.key + str(i) for i in range(3)]
         assert not any(k in sys.modules for k in key)
         for i, k in enumerate(key):
-            monkeypatch.setitem(sys.modules, k, "something" + str(i))
+            mod = ModuleType("something" + str(i))
+            monkeypatch.setitem(sys.modules, k, mod)
         original = dict(sys.modules)

         def preserve(name):
             return name in (key[0], key[1], "some-other-key")

         snapshot = SysModulesSnapshot(preserve=preserve)
-        sys.modules[key[0]] = original[key[0]] = "something else0"  # type: ignore
-        sys.modules[key[1]] = original[key[1]] = "something else1"  # type: ignore
-        sys.modules[key[2]] = "something else2"  # type: ignore
+        sys.modules[key[0]] = original[key[0]] = ModuleType("something else0")
+        sys.modules[key[1]] = original[key[1]] = ModuleType("something else1")
+        sys.modules[key[2]] = ModuleType("something else2")
         snapshot.restore()
         assert sys.modules == original

-    def test_preserve_container(self, monkeypatch) -> None:
+    def test_preserve_container(self, monkeypatch: MonkeyPatch) -> None:
         original = dict(sys.modules)
         assert self.key not in original
         replacement = dict(sys.modules)
-        replacement[self.key] = "life of brian"  # type: ignore
+        replacement[self.key] = ModuleType("life of brian")
         snapshot = SysModulesSnapshot()
         monkeypatch.setattr(sys, "modules", replacement)
         snapshot.restore()
@@ -380,7 +383,7 @@
     def path(n: int) -> str:
         return "my-dirty-little-secret-" + str(n)

-    def test_restore(self, monkeypatch, path_type) -> None:
+    def test_restore(self, monkeypatch: MonkeyPatch, path_type) -> None:
         other_path_type = self.other_path[path_type]
         for i in range(10):
             assert self.path(i) not in getattr(sys, path_type)
@@ -403,12 +406,12 @@
         assert getattr(sys, path_type) == original
         assert getattr(sys, other_path_type) == original_other

-    def test_preserve_container(self, monkeypatch, path_type) -> None:
+    def test_preserve_container(self, monkeypatch: MonkeyPatch, path_type) -> None:
         other_path_type = self.other_path[path_type]
         original_data = list(getattr(sys, path_type))
         original_other = getattr(sys, other_path_type)
         original_other_data = list(original_other)
-        new = []  # type: List[object]
+        new: List[object] = []
         snapshot = SysPathsSnapshot()
         monkeypatch.setattr(sys, path_type, new)
         snapshot.restore()
@@ -418,49 +421,49 @@
         assert getattr(sys, other_path_type) == original_other_data


-def test_testdir_subprocess(testdir) -> None:
-    testfile = testdir.makepyfile("def test_one(): pass")
-    assert testdir.runpytest_subprocess(testfile).ret == 0
-
-
-def test_testdir_subprocess_via_runpytest_arg(testdir) -> None:
-    testfile = testdir.makepyfile(
-        """
-        def test_testdir_subprocess(testdir):
+def test_pytester_subprocess(pytester: Pytester) -> None:
+    testfile = pytester.makepyfile("def test_one(): pass")
+    assert pytester.runpytest_subprocess(testfile).ret == 0
+
+
+def test_pytester_subprocess_via_runpytest_arg(pytester: Pytester) -> None:
+    testfile = pytester.makepyfile(
+        """
+        def test_pytester_subprocess(pytester):
             import os
-            testfile = testdir.makepyfile(
+            testfile = pytester.makepyfile(
                 \"""
                 import os
                 def test_one():
                     assert {} != os.getpid()
                 \""".format(os.getpid())
             )
-            assert testdir.runpytest(testfile).ret == 0
-        """
-    )
-    result = testdir.runpytest_subprocess(
+            assert pytester.runpytest(testfile).ret == 0
+        """
+    )
+    result = pytester.runpytest_inprocess(
         "-p", "pytester", "--runpytest", "subprocess", testfile
     )
     assert result.ret == 0


-def test_unicode_args(testdir) -> None:
-    result = testdir.runpytest("-k", "אבג")
+def test_unicode_args(pytester: Pytester) -> None:
+    result = pytester.runpytest("-k", "אבג")
     assert result.ret == ExitCode.NO_TESTS_COLLECTED


-def test_testdir_run_no_timeout(testdir) -> None:
-    testfile = testdir.makepyfile("def test_no_timeout(): pass")
-    assert testdir.runpytest_subprocess(testfile).ret == ExitCode.OK
-
-
-def test_testdir_run_with_timeout(testdir) -> None:
-    testfile = testdir.makepyfile("def test_no_timeout(): pass")
+def test_pytester_run_no_timeout(pytester: Pytester) -> None:
+    testfile = pytester.makepyfile("def test_no_timeout(): pass")
+    assert pytester.runpytest_subprocess(testfile).ret == ExitCode.OK
+
+
+def test_pytester_run_with_timeout(pytester: Pytester) -> None:
+    testfile = pytester.makepyfile("def test_no_timeout(): pass")

     timeout = 120

     start = time.time()
-    result = testdir.runpytest_subprocess(testfile, timeout=timeout)
+    result = pytester.runpytest_subprocess(testfile, timeout=timeout)
     end = time.time()
     duration = end - start

@@ -468,16 +471,16 @@
     assert duration < timeout


-def test_testdir_run_timeout_expires(testdir) -> None:
-    testfile = testdir.makepyfile(
+def test_pytester_run_timeout_expires(pytester: Pytester) -> None:
+    testfile = pytester.makepyfile(
         """
         import time

         def test_timeout():
             time.sleep(10)"""
     )
-    with pytest.raises(testdir.TimeoutExpired):
-        testdir.runpytest_subprocess(testfile, timeout=1)
+    with pytest.raises(pytester.TimeoutExpired):
+        pytester.runpytest_subprocess(testfile, timeout=1)


 def test_linematcher_with_nonlist() -> None:
@@ -532,7 +535,7 @@
     ]


-def test_linematcher_consecutive():
+def test_linematcher_consecutive() -> None:
     lm = LineMatcher(["1", "", "2"])
     with pytest.raises(pytest.fail.Exception) as excinfo:
         lm.fnmatch_lines(["1", "2"], consecutive=True)
@@ -553,7 +556,7 @@


 @pytest.mark.parametrize("function", ["no_fnmatch_line", "no_re_match_line"])
-def test_linematcher_no_matching(function) -> None:
+def test_linematcher_no_matching(function: str) -> None:
     if function == "no_fnmatch_line":
         good_pattern = "*.py OK*"
         bad_pattern = "*X.py OK*"
@@ -580,20 +583,20 @@
         obtained = str(e.value).splitlines()
         if function == "no_fnmatch_line":
             assert obtained == [
-                "nomatch: '{}'".format(good_pattern),
+                f"nomatch: '{good_pattern}'",
                 "    and: 'cachedir: .pytest_cache'",
                 "    and: 'collecting ... collected 1 item'",
                 "    and: ''",
-                "fnmatch: '{}'".format(good_pattern),
+                f"fnmatch: '{good_pattern}'",
                 "   with: 'show_fixtures_per_test.py OK'",
             ]
         else:
             assert obtained == [
-                " nomatch: '{}'".format(good_pattern),
+                f" nomatch: '{good_pattern}'",
                 "     and: 'cachedir: .pytest_cache'",
                 "     and: 'collecting ... collected 1 item'",
                 "     and: ''",
-                "re.match: '{}'".format(good_pattern),
+                f"re.match: '{good_pattern}'",
                 "    with: 'show_fixtures_per_test.py OK'",
             ]

@@ -609,20 +612,20 @@
     assert str(e.value).splitlines() == ["fnmatch: '*'", "   with: '1'"]


-def test_pytester_addopts_before_testdir(request, monkeypatch) -> None:
-    orig = os.environ.get("PYTEST_ADDOPTS", None)
+def test_linematcher_string_api() -> None:
+    lm = LineMatcher(["foo", "bar"])
+    assert str(lm) == "foo\nbar"
+
+
+def test_pytest_addopts_before_pytester(request, monkeypatch: MonkeyPatch) -> None:
     monkeypatch.setenv("PYTEST_ADDOPTS", "--orig-unused")
-    testdir = request.getfixturevalue("testdir")
+    _: Pytester = request.getfixturevalue("pytester")
     assert "PYTEST_ADDOPTS" not in os.environ
-    testdir.finalize()
-    assert os.environ.get("PYTEST_ADDOPTS") == "--orig-unused"
-    monkeypatch.undo()
-    assert os.environ.get("PYTEST_ADDOPTS") == orig
-
-
-def test_run_stdin(testdir) -> None:
-    with pytest.raises(testdir.TimeoutExpired):
-        testdir.run(
+
+
+def test_run_stdin(pytester: Pytester) -> None:
+    with pytest.raises(pytester.TimeoutExpired):
+        pytester.run(
             sys.executable,
             "-c",
             "import sys, time; time.sleep(1); print(sys.stdin.read())",
@@ -630,8 +633,8 @@
             timeout=0.1,
         )

-    with pytest.raises(testdir.TimeoutExpired):
-        result = testdir.run(
+    with pytest.raises(pytester.TimeoutExpired):
+        result = pytester.run(
             sys.executable,
             "-c",
             "import sys, time; time.sleep(1); print(sys.stdin.read())",
@@ -639,7 +642,7 @@
             timeout=0.1,
         )

-    result = testdir.run(
+    result = pytester.run(
         sys.executable,
         "-c",
         "import sys; print(sys.stdin.read())",
@@ -650,8 +653,8 @@
     assert result.ret == 0


-def test_popen_stdin_pipe(testdir) -> None:
-    proc = testdir.popen(
+def test_popen_stdin_pipe(pytester: Pytester) -> None:
+    proc = pytester.popen(
         [sys.executable, "-c", "import sys; print(sys.stdin.read())"],
         stdout=subprocess.PIPE,
         stderr=subprocess.PIPE,
@@ -664,8 +667,8 @@
     assert proc.returncode == 0


-def test_popen_stdin_bytes(testdir) -> None:
-    proc = testdir.popen(
+def test_popen_stdin_bytes(pytester: Pytester) -> None:
+    proc = pytester.popen(
         [sys.executable, "-c", "import sys; print(sys.stdin.read())"],
         stdout=subprocess.PIPE,
         stderr=subprocess.PIPE,
@@ -677,18 +680,18 @@
     assert proc.returncode == 0


-def test_popen_default_stdin_stderr_and_stdin_None(testdir) -> None:
+def test_popen_default_stdin_stderr_and_stdin_None(pytester: Pytester) -> None:
     # stdout, stderr default to pipes,
     # stdin can be None to not close the pipe, avoiding
     # "ValueError: flush of closed file" with `communicate()`.
     #
     # Wraps the test to make it not hang when run with "-s".
-    p1 = testdir.makepyfile(
+    p1 = pytester.makepyfile(
         '''
         import sys

-        def test_inner(testdir):
-            p1 = testdir.makepyfile(
+        def test_inner(pytester):
+            p1 = pytester.makepyfile(
                 """
                 import sys
                 print(sys.stdin.read())  # empty
@@ -696,24 +699,24 @@
                 sys.stderr.write('stderr')
                 """
             )
-            proc = testdir.popen([sys.executable, str(p1)], stdin=None)
+            proc = pytester.popen([sys.executable, str(p1)], stdin=None)
             stdout, stderr = proc.communicate(b"ignored")
             assert stdout.splitlines() == [b"", b"stdout"]
             assert stderr.splitlines() == [b"stderr"]
             assert proc.returncode == 0
         '''
     )
-    result = testdir.runpytest("-p", "pytester", str(p1))
+    result = pytester.runpytest("-p", "pytester", str(p1))
     assert result.ret == 0


-def test_spawn_uses_tmphome(testdir) -> None:
-    tmphome = str(testdir.tmpdir)
+def test_spawn_uses_tmphome(pytester: Pytester) -> None:
+    tmphome = str(pytester.path)
     assert os.environ.get("HOME") == tmphome

-    testdir.monkeypatch.setenv("CUSTOMENV", "42")
-
-    p1 = testdir.makepyfile(
+    pytester._monkeypatch.setenv("CUSTOMENV", "42")
+
+    p1 = pytester.makepyfile(
         """
         import os

@@ -724,7 +727,7 @@
             tmphome=tmphome
         )
     )
-    child = testdir.spawn_pytest(str(p1))
+    child = pytester.spawn_pytest(str(p1))
     out = child.read()
     assert child.wait() == 0, out.decode("utf8")

@@ -734,22 +737,22 @@
     errlines = ["some", "nasty", "errors", "happened"]

     # known exit code
-    r = pytester.RunResult(1, outlines, errlines, duration=0.5)
-    assert (
-        repr(r) == "<RunResult ret=ExitCode.TESTS_FAILED len(stdout.lines)=3"
+    r = pytester_mod.RunResult(1, outlines, errlines, duration=0.5)
+    assert repr(r) == (
+        f"<RunResult ret={str(pytest.ExitCode.TESTS_FAILED)} len(stdout.lines)=3"
         " len(stderr.lines)=4 duration=0.50s>"
     )

     # unknown exit code: just the number
-    r = pytester.RunResult(99, outlines, errlines, duration=0.5)
+    r = pytester_mod.RunResult(99, outlines, errlines, duration=0.5)
     assert (
         repr(r) == "<RunResult ret=99 len(stdout.lines)=3"
         " len(stderr.lines)=4 duration=0.50s>"
     )


-def test_testdir_outcomes_with_multiple_errors(testdir):
-    p1 = testdir.makepyfile(
+def test_pytester_outcomes_with_multiple_errors(pytester: Pytester) -> None:
+    p1 = pytester.makepyfile(
         """
         import pytest

@@ -764,13 +767,13 @@
             pass
     """
     )
-    result = testdir.runpytest(str(p1))
+    result = pytester.runpytest(str(p1))
     result.assert_outcomes(errors=2)

     assert result.parseoutcomes() == {"errors": 2}


-def test_parse_summary_line_always_plural():
+def test_parse_summary_line_always_plural() -> None:
     """Parsing summaries always returns plural nouns (#6505)"""
     lines = [
         "some output 1",
@@ -778,7 +781,7 @@
         "======= 1 failed, 1 passed, 1 warning, 1 error in 0.13s ====",
         "done.",
     ]
-    assert pytester.RunResult.parse_summary_nouns(lines) == {
+    assert pytester_mod.RunResult.parse_summary_nouns(lines) == {
         "errors": 1,
         "failed": 1,
         "passed": 1,
@@ -791,7 +794,7 @@
         "======= 1 failed, 1 passed, 2 warnings, 2 errors in 0.13s ====",
         "done.",
     ]
-    assert pytester.RunResult.parse_summary_nouns(lines) == {
+    assert pytester_mod.RunResult.parse_summary_nouns(lines) == {
         "errors": 2,
         "failed": 1,
         "passed": 1,
@@ -799,11 +802,49 @@
     }


-def test_makefile_joins_absolute_path(testdir: Testdir) -> None:
-    absfile = testdir.tmpdir / "absfile"
-    if sys.platform == "win32":
-        with pytest.raises(OSError):
-            testdir.makepyfile(**{str(absfile): ""})
-    else:
-        p1 = testdir.makepyfile(**{str(absfile): ""})
-        assert str(p1) == (testdir.tmpdir / absfile) + ".py"
+def test_makefile_joins_absolute_path(pytester: Pytester) -> None:
+    absfile = pytester.path / "absfile"
+    p1 = pytester.makepyfile(**{str(absfile): ""})
+    assert str(p1) == str(pytester.path / "absfile.py")
+
+
+def test_pytester_makefile_dot_prefixes_extension_with_warning(
+    pytester: Pytester,
+) -> None:
+    with pytest.raises(
+        ValueError,
+        match="pytester.makefile expects a file extension, try .foo.bar instead of foo.bar",
+    ):
+        pytester.makefile("foo.bar", "")
+
+
+@pytest.mark.filterwarnings("default")
+def test_pytester_assert_outcomes_warnings(pytester: Pytester) -> None:
+    pytester.makepyfile(
+        """
+        import warnings
+
+        def test_with_warning():
+            warnings.warn(UserWarning("some custom warning"))
+        """
+    )
+    result = pytester.runpytest()
+    result.assert_outcomes(passed=1, warnings=1)
+    # If warnings is not passed, it is not checked at all.
+    result.assert_outcomes(passed=1)
+
+
+def test_pytester_outcomes_deselected(pytester: Pytester) -> None:
+    pytester.makepyfile(
+        """
+        def test_one():
+            pass
+
+        def test_two():
+            pass
+        """
+    )
+    result = pytester.runpytest("-k", "test_one")
+    result.assert_outcomes(passed=1, deselected=1)
+    # If deselected is not passed, it is not checked at all.
+    result.assert_outcomes(passed=1)
('testing', 'test_argcomplete.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,7 +1,9 @@
 import subprocess
 import sys
+from pathlib import Path

 import pytest
+from _pytest.monkeypatch import MonkeyPatch

 # Test for _argcomplete but not specific for any application.

@@ -11,7 +13,7 @@
     res_bash = set(fc(prefix))
     retval = set(res) == res_bash
     if out:
-        out.write("equal_with_bash({}) {} {}\n".format(prefix, retval, res))
+        out.write(f"equal_with_bash({prefix}) {retval} {res}\n")
         if not retval:
             out.write(" python - bash: %s\n" % (set(res) - res_bash))
             out.write(" bash - python: %s\n" % (res_bash - set(res)))
@@ -45,26 +47,16 @@
         completion = []
         if self.allowednames:
             if self.directories:
-                files = _wrapcall(
-                    ["bash", "-c", "compgen -A directory -- '{p}'".format(p=prefix)]
-                )
+                files = _wrapcall(["bash", "-c", f"compgen -A directory -- '{prefix}'"])
                 completion += [f + "/" for f in files]
             for x in self.allowednames:
                 completion += _wrapcall(
-                    [
-                        "bash",
-                        "-c",
-                        "compgen -A file -X '!*.{0}' -- '{p}'".format(x, p=prefix),
-                    ]
+                    ["bash", "-c", f"compgen -A file -X '!*.{x}' -- '{prefix}'"]
                 )
         else:
-            completion += _wrapcall(
-                ["bash", "-c", "compgen -A file -- '{p}'".format(p=prefix)]
-            )
+            completion += _wrapcall(["bash", "-c", f"compgen -A file -- '{prefix}'"])

-            anticomp = _wrapcall(
-                ["bash", "-c", "compgen -A directory -- '{p}'".format(p=prefix)]
-            )
+            anticomp = _wrapcall(["bash", "-c", f"compgen -A directory -- '{prefix}'"])

             completion = list(set(completion) - set(anticomp))

@@ -75,19 +67,22 @@

 class TestArgComplete:
     @pytest.mark.skipif("sys.platform in ('win32', 'darwin')")
-    def test_compare_with_compgen(self, tmpdir):
+    def test_compare_with_compgen(
+        self, tmp_path: Path, monkeypatch: MonkeyPatch
+    ) -> None:
         from _pytest._argcomplete import FastFilesCompleter

         ffc = FastFilesCompleter()
         fc = FilesCompleter()

-        with tmpdir.as_cwd():
-            assert equal_with_bash("", ffc, fc, out=sys.stdout)
+        monkeypatch.chdir(tmp_path)

-            tmpdir.ensure("data")
+        assert equal_with_bash("", ffc, fc, out=sys.stdout)

-            for x in ["d", "data", "doesnotexist", ""]:
-                assert equal_with_bash(x, ffc, fc, out=sys.stdout)
+        tmp_path.cwd().joinpath("data").touch()
+
+        for x in ["d", "data", "doesnotexist", ""]:
+            assert equal_with_bash(x, ffc, fc, out=sys.stdout)

     @pytest.mark.skipif("sys.platform in ('win32', 'darwin')")
     def test_remove_dir_prefix(self):
('testing', 'test_mark_expression.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -66,11 +66,29 @@
     assert evaluate(expr, matcher) is expected


+def test_backslash_not_treated_specially() -> None:
+    r"""When generating nodeids, if the source name contains special characters
+    like a newline, they are escaped into two characters like \n. Therefore, a
+    user will never need to insert a literal newline, only \n (two chars). So
+    mark expressions themselves do not support escaping, instead they treat
+    backslashes as regular identifier characters."""
+    matcher = {r"\nfoo\n"}.__contains__
+
+    assert evaluate(r"\nfoo\n", matcher)
+    assert not evaluate(r"foo", matcher)
+    with pytest.raises(ParseError):
+        evaluate("\nfoo\n", matcher)
+
+
 @pytest.mark.parametrize(
     ("expr", "column", "message"),
     (
         ("(", 2, "expected not OR left parenthesis OR identifier; got end of input"),
-        (" (", 3, "expected not OR left parenthesis OR identifier; got end of input",),
+        (
+            " (",
+            3,
+            "expected not OR left parenthesis OR identifier; got end of input",
+        ),
         (
             ")",
             1,
@@ -81,7 +99,11 @@
             1,
             "expected not OR left parenthesis OR identifier; got right parenthesis",
         ),
-        ("not", 4, "expected not OR left parenthesis OR identifier; got end of input",),
+        (
+            "not",
+            4,
+            "expected not OR left parenthesis OR identifier; got end of input",
+        ),
         (
             "not not",
             8,
@@ -98,7 +120,11 @@
             10,
             "expected not OR left parenthesis OR identifier; got end of input",
         ),
-        ("ident and or", 11, "expected not OR left parenthesis OR identifier; got or",),
+        (
+            "ident and or",
+            11,
+            "expected not OR left parenthesis OR identifier; got or",
+        ),
         ("ident ident", 7, "expected end of input; got identifier"),
     ),
 )
@@ -117,6 +143,8 @@
         ":::",
         "a:::c",
         "a+-b",
+        r"\nhe\\l\lo\n\t\rbye",
+        "a/b",
         "אבגד",
         "aaאבגדcc",
         "a[bcd]",
@@ -143,8 +171,6 @@
 @pytest.mark.parametrize(
     "ident",
     (
-        "/",
-        "\\",
         "^",
         "*",
         "=",
('testing', 'test_main.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,17 +1,16 @@
 import argparse
 import os
 import re
+import sys
+from pathlib import Path
 from typing import Optional
-
-import py.path

 import pytest
 from _pytest.config import ExitCode
 from _pytest.config import UsageError
 from _pytest.main import resolve_collection_argument
 from _pytest.main import validate_basetemp
-from _pytest.pathlib import Path
-from _pytest.pytester import Testdir
+from _pytest.pytester import Pytester


 @pytest.mark.parametrize(
@@ -22,9 +21,9 @@
         pytest.param((False, SystemExit)),
     ),
 )
-def test_wrap_session_notify_exception(ret_exc, testdir):
+def test_wrap_session_notify_exception(ret_exc, pytester: Pytester) -> None:
     returncode, exc = ret_exc
-    c1 = testdir.makeconftest(
+    c1 = pytester.makeconftest(
         """
         import pytest

@@ -39,45 +38,61 @@
             returncode=returncode, exc=exc.__name__
         )
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     if returncode:
         assert result.ret == returncode
     else:
         assert result.ret == ExitCode.INTERNAL_ERROR
     assert result.stdout.lines[0] == "INTERNALERROR> Traceback (most recent call last):"

+    end_lines = (
+        result.stdout.lines[-4:]
+        if sys.version_info >= (3, 11)
+        else result.stdout.lines[-3:]
+    )
+
     if exc == SystemExit:
-        assert result.stdout.lines[-3:] == [
-            'INTERNALERROR>   File "{}", line 4, in pytest_sessionstart'.format(c1),
+        assert end_lines == [
+            f'INTERNALERROR>   File "{c1}", line 4, in pytest_sessionstart',
             'INTERNALERROR>     raise SystemExit("boom")',
+            *(
+                ("INTERNALERROR>     ^^^^^^^^^^^^^^^^^^^^^^^^",)
+                if sys.version_info >= (3, 11)
+                else ()
+            ),
             "INTERNALERROR> SystemExit: boom",
         ]
     else:
-        assert result.stdout.lines[-3:] == [
-            'INTERNALERROR>   File "{}", line 4, in pytest_sessionstart'.format(c1),
+        assert end_lines == [
+            f'INTERNALERROR>   File "{c1}", line 4, in pytest_sessionstart',
             'INTERNALERROR>     raise ValueError("boom")',
+            *(
+                ("INTERNALERROR>     ^^^^^^^^^^^^^^^^^^^^^^^^",)
+                if sys.version_info >= (3, 11)
+                else ()
+            ),
             "INTERNALERROR> ValueError: boom",
         ]
     if returncode is False:
         assert result.stderr.lines == ["mainloop: caught unexpected SystemExit!"]
     else:
-        assert result.stderr.lines == ["Exit: exiting after {}...".format(exc.__name__)]
+        assert result.stderr.lines == [f"Exit: exiting after {exc.__name__}..."]


 @pytest.mark.parametrize("returncode", (None, 42))
 def test_wrap_session_exit_sessionfinish(
-    returncode: Optional[int], testdir: Testdir
+    returncode: Optional[int], pytester: Pytester
 ) -> None:
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         import pytest
         def pytest_sessionfinish():
-            pytest.exit(msg="exit_pytest_sessionfinish", returncode={returncode})
+            pytest.exit(reason="exit_pytest_sessionfinish", returncode={returncode})
     """.format(
             returncode=returncode
         )
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     if returncode:
         assert result.ret == returncode
     else:
@@ -102,47 +117,44 @@
         validate_basetemp(basetemp)


-def test_validate_basetemp_integration(testdir):
-    result = testdir.runpytest("--basetemp=.")
+def test_validate_basetemp_integration(pytester: Pytester) -> None:
+    result = pytester.runpytest("--basetemp=.")
     result.stderr.fnmatch_lines("*basetemp must not be*")


 class TestResolveCollectionArgument:
     @pytest.fixture
-    def invocation_dir(self, testdir: Testdir) -> py.path.local:
-        testdir.syspathinsert(str(testdir.tmpdir / "src"))
-        testdir.chdir()
-
-        pkg = testdir.tmpdir.join("src/pkg").ensure_dir()
-        pkg.join("__init__.py").ensure()
-        pkg.join("test.py").ensure()
-        return testdir.tmpdir
-
-    @pytest.fixture
-    def invocation_path(self, invocation_dir: py.path.local) -> Path:
-        return Path(str(invocation_dir))
-
-    def test_file(self, invocation_dir: py.path.local, invocation_path: Path) -> None:
+    def invocation_path(self, pytester: Pytester) -> Path:
+        pytester.syspathinsert(pytester.path / "src")
+        pytester.chdir()
+
+        pkg = pytester.path.joinpath("src/pkg")
+        pkg.mkdir(parents=True)
+        pkg.joinpath("__init__.py").touch()
+        pkg.joinpath("test.py").touch()
+        return pytester.path
+
+    def test_file(self, invocation_path: Path) -> None:
         """File and parts."""
         assert resolve_collection_argument(invocation_path, "src/pkg/test.py") == (
-            invocation_dir / "src/pkg/test.py",
+            invocation_path / "src/pkg/test.py",
             [],
         )
         assert resolve_collection_argument(invocation_path, "src/pkg/test.py::") == (
-            invocation_dir / "src/pkg/test.py",
+            invocation_path / "src/pkg/test.py",
             [""],
         )
         assert resolve_collection_argument(
             invocation_path, "src/pkg/test.py::foo::bar"
-        ) == (invocation_dir / "src/pkg/test.py", ["foo", "bar"])
+        ) == (invocation_path / "src/pkg/test.py", ["foo", "bar"])
         assert resolve_collection_argument(
             invocation_path, "src/pkg/test.py::foo::bar::"
-        ) == (invocation_dir / "src/pkg/test.py", ["foo", "bar", ""])
-
-    def test_dir(self, invocation_dir: py.path.local, invocation_path: Path) -> None:
+        ) == (invocation_path / "src/pkg/test.py", ["foo", "bar", ""])
+
+    def test_dir(self, invocation_path: Path) -> None:
         """Directory and parts."""
         assert resolve_collection_argument(invocation_path, "src/pkg") == (
-            invocation_dir / "src/pkg",
+            invocation_path / "src/pkg",
             [],
         )

@@ -156,16 +168,16 @@
         ):
             resolve_collection_argument(invocation_path, "src/pkg::foo::bar")

-    def test_pypath(self, invocation_dir: py.path.local, invocation_path: Path) -> None:
+    def test_pypath(self, invocation_path: Path) -> None:
         """Dotted name and parts."""
         assert resolve_collection_argument(
             invocation_path, "pkg.test", as_pypath=True
-        ) == (invocation_dir / "src/pkg/test.py", [])
+        ) == (invocation_path / "src/pkg/test.py", [])
         assert resolve_collection_argument(
             invocation_path, "pkg.test::foo::bar", as_pypath=True
-        ) == (invocation_dir / "src/pkg/test.py", ["foo", "bar"])
+        ) == (invocation_path / "src/pkg/test.py", ["foo", "bar"])
         assert resolve_collection_argument(invocation_path, "pkg", as_pypath=True) == (
-            invocation_dir / "src/pkg",
+            invocation_path / "src/pkg",
             [],
         )

@@ -175,6 +187,12 @@
             resolve_collection_argument(
                 invocation_path, "pkg::foo::bar", as_pypath=True
             )
+
+    def test_parametrized_name_with_colons(self, invocation_path: Path) -> None:
+        ret = resolve_collection_argument(
+            invocation_path, "src/pkg/test.py::test[a::b]"
+        )
+        assert ret == (invocation_path / "src/pkg/test.py", ["test[a::b]"])

     def test_does_not_exist(self, invocation_path: Path) -> None:
         """Given a file/module that does not exist raises UsageError."""
@@ -191,13 +209,11 @@
         ):
             resolve_collection_argument(invocation_path, "foobar", as_pypath=True)

-    def test_absolute_paths_are_resolved_correctly(
-        self, invocation_dir: py.path.local, invocation_path: Path
-    ) -> None:
+    def test_absolute_paths_are_resolved_correctly(self, invocation_path: Path) -> None:
         """Absolute paths resolve back to absolute paths."""
-        full_path = str(invocation_dir / "src")
+        full_path = str(invocation_path / "src")
         assert resolve_collection_argument(invocation_path, full_path) == (
-            py.path.local(os.path.abspath("src")),
+            Path(os.path.abspath("src")),
             [],
         )

@@ -206,17 +222,17 @@
         drive, full_path_without_drive = os.path.splitdrive(full_path)
         assert resolve_collection_argument(
             invocation_path, full_path_without_drive
-        ) == (py.path.local(os.path.abspath("src")), [])
-
-
-def test_module_full_path_without_drive(testdir):
+        ) == (Path(os.path.abspath("src")), [])
+
+
+def test_module_full_path_without_drive(pytester: Pytester) -> None:
     """Collect and run test using full path except for the drive letter (#7628).

-    Passing a full path without a drive letter would trigger a bug in py.path.local
+    Passing a full path without a drive letter would trigger a bug in legacy_path
     where it would keep the full path without the drive letter around, instead of resolving
     to the full path, resulting in fixtures node ids not matching against test node ids correctly.
     """
-    testdir.makepyfile(
+    pytester.makepyfile(
         **{
             "project/conftest.py": """
                 import pytest
@@ -226,7 +242,7 @@
         }
     )

-    testdir.makepyfile(
+    pytester.makepyfile(
         **{
             "project/tests/dummy_test.py": """
                 def test(fix):
@@ -234,12 +250,12 @@
             """
         }
     )
-    fn = testdir.tmpdir.join("project/tests/dummy_test.py")
-    assert fn.isfile()
+    fn = pytester.path.joinpath("project/tests/dummy_test.py")
+    assert fn.is_file()

     drive, path = os.path.splitdrive(str(fn))

-    result = testdir.runpytest(path, "-v")
+    result = pytester.runpytest(path, "-v")
     result.stdout.fnmatch_lines(
         [
             os.path.join("project", "tests", "dummy_test.py") + "::test PASSED *",
('testing', 'test_tmpdir.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,6 +1,8 @@
 import os
 import stat
 import sys
+import warnings
+from pathlib import Path
 from typing import Callable
 from typing import cast
 from typing import List
@@ -10,22 +12,22 @@
 import pytest
 from _pytest import pathlib
 from _pytest.config import Config
+from _pytest.monkeypatch import MonkeyPatch
 from _pytest.pathlib import cleanup_numbered_dir
 from _pytest.pathlib import create_cleanup_lock
 from _pytest.pathlib import make_numbered_dir
 from _pytest.pathlib import maybe_delete_a_numbered_dir
 from _pytest.pathlib import on_rm_rf_error
-from _pytest.pathlib import Path
 from _pytest.pathlib import register_cleanup_lock_removal
 from _pytest.pathlib import rm_rf
+from _pytest.pytester import Pytester
 from _pytest.tmpdir import get_user
-from _pytest.tmpdir import TempdirFactory
 from _pytest.tmpdir import TempPathFactory


-def test_tmpdir_fixture(testdir):
-    p = testdir.copy_example("tmpdir/tmpdir_fixture.py")
-    results = testdir.runpytest(p)
+def test_tmp_path_fixture(pytester: Pytester) -> None:
+    p = pytester.copy_example("tmpdir/tmp_path_fixture.py")
+    results = pytester.runpytest(p)
     results.stdout.fnmatch_lines(["*1 passed*"])


@@ -45,42 +47,42 @@
         return self


-class TestTempdirHandler:
+class TestTmpPathHandler:
     def test_mktemp(self, tmp_path):
         config = cast(Config, FakeConfig(tmp_path))
-        t = TempdirFactory(TempPathFactory.from_config(config))
+        t = TempPathFactory.from_config(config, _ispytest=True)
         tmp = t.mktemp("world")
-        assert tmp.relto(t.getbasetemp()) == "world0"
+        assert str(tmp.relative_to(t.getbasetemp())) == "world0"
         tmp = t.mktemp("this")
-        assert tmp.relto(t.getbasetemp()).startswith("this")
+        assert str(tmp.relative_to(t.getbasetemp())).startswith("this")
         tmp2 = t.mktemp("this")
-        assert tmp2.relto(t.getbasetemp()).startswith("this")
+        assert str(tmp2.relative_to(t.getbasetemp())).startswith("this")
         assert tmp2 != tmp

     def test_tmppath_relative_basetemp_absolute(self, tmp_path, monkeypatch):
         """#4425"""
         monkeypatch.chdir(tmp_path)
         config = cast(Config, FakeConfig("hello"))
-        t = TempPathFactory.from_config(config)
+        t = TempPathFactory.from_config(config, _ispytest=True)
         assert t.getbasetemp().resolve() == (tmp_path / "hello").resolve()


-class TestConfigTmpdir:
-    def test_getbasetemp_custom_removes_old(self, testdir):
-        mytemp = testdir.tmpdir.join("xyz")
-        p = testdir.makepyfile(
+class TestConfigTmpPath:
+    def test_getbasetemp_custom_removes_old(self, pytester: Pytester) -> None:
+        mytemp = pytester.path.joinpath("xyz")
+        p = pytester.makepyfile(
             """
-            def test_1(tmpdir):
+            def test_1(tmp_path):
                 pass
         """
         )
-        testdir.runpytest(p, "--basetemp=%s" % mytemp)
-        mytemp.check()
-        mytemp.ensure("hello")
-
-        testdir.runpytest(p, "--basetemp=%s" % mytemp)
-        mytemp.check()
-        assert not mytemp.join("hello").check()
+        pytester.runpytest(p, "--basetemp=%s" % mytemp)
+        assert mytemp.exists()
+        mytemp.joinpath("hello").touch()
+
+        pytester.runpytest(p, "--basetemp=%s" % mytemp)
+        assert mytemp.exists()
+        assert not mytemp.joinpath("hello").exists()


 testdata = [
@@ -96,104 +98,88 @@


 @pytest.mark.parametrize("basename, is_ok", testdata)
-def test_mktemp(testdir, basename, is_ok):
-    mytemp = testdir.tmpdir.mkdir("mytemp")
-    p = testdir.makepyfile(
-        """
-        def test_abs_path(tmpdir_factory):
-            tmpdir_factory.mktemp('{}', numbered=False)
+def test_mktemp(pytester: Pytester, basename: str, is_ok: bool) -> None:
+    mytemp = pytester.mkdir("mytemp")
+    p = pytester.makepyfile(
+        """
+        def test_abs_path(tmp_path_factory):
+            tmp_path_factory.mktemp('{}', numbered=False)
         """.format(
             basename
         )
     )

-    result = testdir.runpytest(p, "--basetemp=%s" % mytemp)
+    result = pytester.runpytest(p, "--basetemp=%s" % mytemp)
     if is_ok:
         assert result.ret == 0
-        assert mytemp.join(basename).check()
+        assert mytemp.joinpath(basename).exists()
     else:
         assert result.ret == 1
         result.stdout.fnmatch_lines("*ValueError*")


-def test_tmpdir_always_is_realpath(testdir):
-    # the reason why tmpdir should be a realpath is that
+def test_tmp_path_always_is_realpath(pytester: Pytester, monkeypatch) -> None:
+    # the reason why tmp_path should be a realpath is that
     # when you cd to it and do "os.getcwd()" you will anyway
     # get the realpath.  Using the symlinked path can thus
     # easily result in path-inequality
     # XXX if that proves to be a problem, consider using
     # os.environ["PWD"]
-    realtemp = testdir.tmpdir.mkdir("myrealtemp")
-    linktemp = testdir.tmpdir.join("symlinktemp")
-    attempt_symlink_to(linktemp, str(realtemp))
-    p = testdir.makepyfile(
-        """
-        def test_1(tmpdir):
-            import os
-            assert os.path.realpath(str(tmpdir)) == str(tmpdir)
-    """
-    )
-    result = testdir.runpytest("-s", p, "--basetemp=%s/bt" % linktemp)
-    assert not result.ret
-
-
-def test_tmp_path_always_is_realpath(testdir, monkeypatch):
-    # for reasoning see: test_tmpdir_always_is_realpath test-case
-    realtemp = testdir.tmpdir.mkdir("myrealtemp")
-    linktemp = testdir.tmpdir.join("symlinktemp")
+    realtemp = pytester.mkdir("myrealtemp")
+    linktemp = pytester.path.joinpath("symlinktemp")
     attempt_symlink_to(linktemp, str(realtemp))
     monkeypatch.setenv("PYTEST_DEBUG_TEMPROOT", str(linktemp))
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         def test_1(tmp_path):
             assert tmp_path.resolve() == tmp_path
     """
     )
-    reprec = testdir.inline_run()
+    reprec = pytester.inline_run()
     reprec.assertoutcome(passed=1)


-def test_tmpdir_too_long_on_parametrization(testdir):
-    testdir.makepyfile(
+def test_tmp_path_too_long_on_parametrization(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import pytest
         @pytest.mark.parametrize("arg", ["1"*1000])
-        def test_some(arg, tmpdir):
-            tmpdir.ensure("hello")
-    """
-    )
-    reprec = testdir.inline_run()
+        def test_some(arg, tmp_path):
+            tmp_path.joinpath("hello").touch()
+    """
+    )
+    reprec = pytester.inline_run()
     reprec.assertoutcome(passed=1)


-def test_tmpdir_factory(testdir):
-    testdir.makepyfile(
+def test_tmp_path_factory(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import pytest
         @pytest.fixture(scope='session')
-        def session_dir(tmpdir_factory):
-            return tmpdir_factory.mktemp('data', numbered=False)
+        def session_dir(tmp_path_factory):
+            return tmp_path_factory.mktemp('data', numbered=False)
         def test_some(session_dir):
-            assert session_dir.isdir()
-    """
-    )
-    reprec = testdir.inline_run()
+            assert session_dir.is_dir()
+    """
+    )
+    reprec = pytester.inline_run()
     reprec.assertoutcome(passed=1)


-def test_tmpdir_fallback_tox_env(testdir, monkeypatch):
-    """Test that tmpdir works even if environment variables required by getpass
+def test_tmp_path_fallback_tox_env(pytester: Pytester, monkeypatch) -> None:
+    """Test that tmp_path works even if environment variables required by getpass
     module are missing (#1010).
     """
     monkeypatch.delenv("USER", raising=False)
     monkeypatch.delenv("USERNAME", raising=False)
-    testdir.makepyfile(
-        """
-        def test_some(tmpdir):
-            assert tmpdir.isdir()
-    """
-    )
-    reprec = testdir.inline_run()
+    pytester.makepyfile(
+        """
+        def test_some(tmp_path):
+            assert tmp_path.is_dir()
+    """
+    )
+    reprec = pytester.inline_run()
     reprec.assertoutcome(passed=1)


@@ -207,18 +193,18 @@

 @pytest.mark.usefixtures("break_getuser")
 @pytest.mark.skipif(sys.platform.startswith("win"), reason="no os.getuid on windows")
-def test_tmpdir_fallback_uid_not_found(testdir):
-    """Test that tmpdir works even if the current process's user id does not
+def test_tmp_path_fallback_uid_not_found(pytester: Pytester) -> None:
+    """Test that tmp_path works even if the current process's user id does not
     correspond to a valid user.
     """

-    testdir.makepyfile(
-        """
-        def test_some(tmpdir):
-            assert tmpdir.isdir()
-    """
-    )
-    reprec = testdir.inline_run()
+    pytester.makepyfile(
+        """
+        def test_some(tmp_path):
+            assert tmp_path.is_dir()
+    """
+    )
+    reprec = pytester.inline_run()
     reprec.assertoutcome(passed=1)


@@ -270,7 +256,7 @@
     def test_lock_register_cleanup_removal(self, tmp_path: Path) -> None:
         lock = create_cleanup_lock(tmp_path)

-        registry = []  # type: List[Callable[..., None]]
+        registry: List[Callable[..., None]] = []
         register_cleanup_lock_removal(lock, register=registry.append)

         (cleanup_func,) = registry
@@ -399,11 +385,13 @@
             assert fn.is_file()

         # ignored function
-        with pytest.warns(None) as warninfo:
-            exc_info4 = (None, PermissionError(), None)
-            on_rm_rf_error(os.open, str(fn), exc_info4, start_path=tmp_path)
-            assert fn.is_file()
-        assert not [x.message for x in warninfo]
+        with warnings.catch_warnings():
+            warnings.simplefilter("ignore")
+            with pytest.warns(None) as warninfo:  # type: ignore[call-overload]
+                exc_info4 = (None, PermissionError(), None)
+                on_rm_rf_error(os.open, str(fn), exc_info4, start_path=tmp_path)
+                assert fn.is_file()
+            assert not [x.message for x in warninfo]

         exc_info5 = (None, PermissionError(), None)
         on_rm_rf_error(os.unlink, str(fn), exc_info5, start_path=tmp_path)
@@ -419,13 +407,9 @@
         pytest.skip("could not create symbolic link")


-def test_tmpdir_equals_tmp_path(tmpdir, tmp_path):
-    assert Path(tmpdir) == tmp_path
-
-
-def test_basetemp_with_read_only_files(testdir):
+def test_basetemp_with_read_only_files(pytester: Pytester) -> None:
     """Integration test for #5524"""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import os
         import stat
@@ -437,8 +421,60 @@
             os.chmod(str(fn), mode & ~stat.S_IREAD)
     """
     )
-    result = testdir.runpytest("--basetemp=tmp")
+    result = pytester.runpytest("--basetemp=tmp")
     assert result.ret == 0
     # running a second time and ensure we don't crash
-    result = testdir.runpytest("--basetemp=tmp")
+    result = pytester.runpytest("--basetemp=tmp")
     assert result.ret == 0
+
+
+def test_tmp_path_factory_handles_invalid_dir_characters(
+    tmp_path_factory: TempPathFactory, monkeypatch: MonkeyPatch
+) -> None:
+    monkeypatch.setattr("getpass.getuser", lambda: "os/<:*?;>agnostic")
+    # _basetemp / _given_basetemp are cached / set in parallel runs, patch them
+    monkeypatch.setattr(tmp_path_factory, "_basetemp", None)
+    monkeypatch.setattr(tmp_path_factory, "_given_basetemp", None)
+    p = tmp_path_factory.getbasetemp()
+    assert "pytest-of-unknown" in str(p)
+
+
+@pytest.mark.skipif(not hasattr(os, "getuid"), reason="checks unix permissions")
+def test_tmp_path_factory_create_directory_with_safe_permissions(
+    tmp_path: Path, monkeypatch: MonkeyPatch
+) -> None:
+    """Verify that pytest creates directories under /tmp with private permissions."""
+    # Use the test's tmp_path as the system temproot (/tmp).
+    monkeypatch.setenv("PYTEST_DEBUG_TEMPROOT", str(tmp_path))
+    tmp_factory = TempPathFactory(None, lambda *args: None, _ispytest=True)
+    basetemp = tmp_factory.getbasetemp()
+
+    # No world-readable permissions.
+    assert (basetemp.stat().st_mode & 0o077) == 0
+    # Parent too (pytest-of-foo).
+    assert (basetemp.parent.stat().st_mode & 0o077) == 0
+
+
+@pytest.mark.skipif(not hasattr(os, "getuid"), reason="checks unix permissions")
+def test_tmp_path_factory_fixes_up_world_readable_permissions(
+    tmp_path: Path, monkeypatch: MonkeyPatch
+) -> None:
+    """Verify that if a /tmp/pytest-of-foo directory already exists with
+    world-readable permissions, it is fixed.
+
+    pytest used to mkdir with such permissions, that's why we fix it up.
+    """
+    # Use the test's tmp_path as the system temproot (/tmp).
+    monkeypatch.setenv("PYTEST_DEBUG_TEMPROOT", str(tmp_path))
+    tmp_factory = TempPathFactory(None, lambda *args: None, _ispytest=True)
+    basetemp = tmp_factory.getbasetemp()
+
+    # Before - simulate bad perms.
+    os.chmod(basetemp.parent, 0o777)
+    assert (basetemp.parent.stat().st_mode & 0o077) != 0
+
+    tmp_factory = TempPathFactory(None, lambda *args: None, _ispytest=True)
+    basetemp = tmp_factory.getbasetemp()
+
+    # After - fixed.
+    assert (basetemp.parent.stat().st_mode & 0o077) == 0
('testing', 'deprecated_test.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,79 +1,27 @@
 import re
+import sys
 import warnings
-from unittest import mock
+from pathlib import Path

 import pytest
 from _pytest import deprecated
-from _pytest.pytester import Testdir
-
-
-@pytest.mark.parametrize("attribute", pytest.collect.__all__)  # type: ignore
-# false positive due to dynamic attribute
-def test_pytest_collect_module_deprecated(attribute):
-    with pytest.warns(DeprecationWarning, match=attribute):
-        getattr(pytest.collect, attribute)
+from _pytest.compat import legacy_path
+from _pytest.pytester import Pytester
+from pytest import PytestDeprecationWarning


 @pytest.mark.parametrize("plugin", sorted(deprecated.DEPRECATED_EXTERNAL_PLUGINS))
 @pytest.mark.filterwarnings("default")
-def test_external_plugins_integrated(testdir, plugin):
-    testdir.syspathinsert()
-    testdir.makepyfile(**{plugin: ""})
+def test_external_plugins_integrated(pytester: Pytester, plugin) -> None:
+    pytester.syspathinsert()
+    pytester.makepyfile(**{plugin: ""})

     with pytest.warns(pytest.PytestConfigWarning):
-        testdir.parseconfig("-p", plugin)
-
-
-def test_fillfuncargs_is_deprecated() -> None:
-    with pytest.warns(
-        pytest.PytestDeprecationWarning,
-        match=re.escape(
-            "pytest._fillfuncargs() is deprecated, use "
-            "function._request._fillfixtures() instead if you cannot avoid reaching into internals."
-        ),
-    ):
-        pytest._fillfuncargs(mock.Mock())
-
-
-def test_fillfixtures_is_deprecated() -> None:
-    import _pytest.fixtures
-
-    with pytest.warns(
-        pytest.PytestDeprecationWarning,
-        match=re.escape(
-            "_pytest.fixtures.fillfixtures() is deprecated, use "
-            "function._request._fillfixtures() instead if you cannot avoid reaching into internals."
-        ),
-    ):
-        _pytest.fixtures.fillfixtures(mock.Mock())
-
-
-def test_minus_k_dash_is_deprecated(testdir) -> None:
-    threepass = testdir.makepyfile(
-        test_threepass="""
-        def test_one(): assert 1
-        def test_two(): assert 1
-        def test_three(): assert 1
-    """
-    )
-    result = testdir.runpytest("-k=-test_two", threepass)
-    result.stdout.fnmatch_lines(["*The `-k '-expr'` syntax*deprecated*"])
-
-
-def test_minus_k_colon_is_deprecated(testdir) -> None:
-    threepass = testdir.makepyfile(
-        test_threepass="""
-        def test_one(): assert 1
-        def test_two(): assert 1
-        def test_three(): assert 1
-    """
-    )
-    result = testdir.runpytest("-k", "test_two:", threepass)
-    result.stdout.fnmatch_lines(["*The `-k 'expr:'` syntax*deprecated*"])
-
-
-def test_fscollector_gethookproxy_isinitpath(testdir: Testdir) -> None:
-    module = testdir.getmodulecol(
+        pytester.parseconfig("-p", plugin)
+
+
+def test_fscollector_gethookproxy_isinitpath(pytester: Pytester) -> None:
+    module = pytester.getmodulecol(
         """
         def test_foo(): pass
         """,
@@ -84,14 +32,202 @@
     assert isinstance(package, pytest.Package)

     with pytest.warns(pytest.PytestDeprecationWarning, match="gethookproxy"):
-        package.gethookproxy(testdir.tmpdir)
+        package.gethookproxy(pytester.path)

     with pytest.warns(pytest.PytestDeprecationWarning, match="isinitpath"):
-        package.isinitpath(testdir.tmpdir)
+        package.isinitpath(pytester.path)

     # The methods on Session are *not* deprecated.
     session = module.session
     with warnings.catch_warnings(record=True) as rec:
-        session.gethookproxy(testdir.tmpdir)
-        session.isinitpath(testdir.tmpdir)
+        session.gethookproxy(pytester.path)
+        session.isinitpath(pytester.path)
     assert len(rec) == 0
+
+
+def test_strict_option_is_deprecated(pytester: Pytester) -> None:
+    """--strict is a deprecated alias to --strict-markers (#7530)."""
+    pytester.makepyfile(
+        """
+        import pytest
+
+        @pytest.mark.unknown
+        def test_foo(): pass
+        """
+    )
+    result = pytester.runpytest("--strict")
+    result.stdout.fnmatch_lines(
+        [
+            "'unknown' not found in `markers` configuration option",
+            "*PytestRemovedIn8Warning: The --strict option is deprecated, use --strict-markers instead.",
+        ]
+    )
+
+
+def test_yield_fixture_is_deprecated() -> None:
+    with pytest.warns(DeprecationWarning, match=r"yield_fixture is deprecated"):
+
+        @pytest.yield_fixture
+        def fix():
+            assert False
+
+
+def test_private_is_deprecated() -> None:
+    class PrivateInit:
+        def __init__(self, foo: int, *, _ispytest: bool = False) -> None:
+            deprecated.check_ispytest(_ispytest)
+
+    with pytest.warns(
+        pytest.PytestDeprecationWarning, match="private pytest class or function"
+    ):
+        PrivateInit(10)
+
+    # Doesn't warn.
+    PrivateInit(10, _ispytest=True)
+
+
+@pytest.mark.parametrize("hooktype", ["hook", "ihook"])
+def test_hookproxy_warnings_for_pathlib(tmp_path, hooktype, request):
+    path = legacy_path(tmp_path)
+
+    PATH_WARN_MATCH = r".*path: py\.path\.local\) argument is deprecated, please use \(collection_path: pathlib\.Path.*"
+    if hooktype == "ihook":
+        hooks = request.node.ihook
+    else:
+        hooks = request.config.hook
+
+    with pytest.warns(PytestDeprecationWarning, match=PATH_WARN_MATCH) as r:
+        l1 = sys._getframe().f_lineno
+        hooks.pytest_ignore_collect(
+            config=request.config, path=path, collection_path=tmp_path
+        )
+        l2 = sys._getframe().f_lineno
+
+    (record,) = r
+    assert record.filename == __file__
+    assert l1 < record.lineno < l2
+
+    hooks.pytest_ignore_collect(config=request.config, collection_path=tmp_path)
+
+    # Passing entirely *different* paths is an outright error.
+    with pytest.raises(ValueError, match=r"path.*fspath.*need to be equal"):
+        with pytest.warns(PytestDeprecationWarning, match=PATH_WARN_MATCH) as r:
+            hooks.pytest_ignore_collect(
+                config=request.config, path=path, collection_path=Path("/bla/bla")
+            )
+
+
+def test_warns_none_is_deprecated():
+    with pytest.warns(
+        PytestDeprecationWarning,
+        match=re.escape(
+            "Passing None has been deprecated.\n"
+            "See https://docs.pytest.org/en/latest/how-to/capture-warnings.html"
+            "#additional-use-cases-of-warnings-in-tests"
+            " for alternatives in common use cases."
+        ),
+    ):
+        with pytest.warns(None):  # type: ignore[call-overload]
+            pass
+
+
+class TestSkipMsgArgumentDeprecated:
+    def test_skip_with_msg_is_deprecated(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
+            """
+            import pytest
+
+            def test_skipping_msg():
+                pytest.skip(msg="skippedmsg")
+            """
+        )
+        result = pytester.runpytest(p)
+        result.stdout.fnmatch_lines(
+            [
+                "*PytestRemovedIn8Warning: pytest.skip(msg=...) is now deprecated, "
+                "use pytest.skip(reason=...) instead",
+                '*pytest.skip(msg="skippedmsg")*',
+            ]
+        )
+        result.assert_outcomes(skipped=1, warnings=1)
+
+    def test_fail_with_msg_is_deprecated(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
+            """
+            import pytest
+
+            def test_failing_msg():
+                pytest.fail(msg="failedmsg")
+            """
+        )
+        result = pytester.runpytest(p)
+        result.stdout.fnmatch_lines(
+            [
+                "*PytestRemovedIn8Warning: pytest.fail(msg=...) is now deprecated, "
+                "use pytest.fail(reason=...) instead",
+                '*pytest.fail(msg="failedmsg")',
+            ]
+        )
+        result.assert_outcomes(failed=1, warnings=1)
+
+    def test_exit_with_msg_is_deprecated(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
+            """
+            import pytest
+
+            def test_exit_msg():
+                pytest.exit(msg="exitmsg")
+            """
+        )
+        result = pytester.runpytest(p)
+        result.stdout.fnmatch_lines(
+            [
+                "*PytestRemovedIn8Warning: pytest.exit(msg=...) is now deprecated, "
+                "use pytest.exit(reason=...) instead",
+            ]
+        )
+        result.assert_outcomes(warnings=1)
+
+
+def test_deprecation_of_cmdline_preparse(pytester: Pytester) -> None:
+    pytester.makeconftest(
+        """
+        def pytest_cmdline_preparse(config, args):
+            ...
+
+        """
+    )
+    result = pytester.runpytest()
+    result.stdout.fnmatch_lines(
+        [
+            "*PytestRemovedIn8Warning: The pytest_cmdline_preparse hook is deprecated*",
+            "*Please use pytest_load_initial_conftests hook instead.*",
+        ]
+    )
+
+
+def test_node_ctor_fspath_argument_is_deprecated(pytester: Pytester) -> None:
+    mod = pytester.getmodulecol("")
+
+    with pytest.warns(
+        pytest.PytestDeprecationWarning,
+        match=re.escape("The (fspath: py.path.local) argument to File is deprecated."),
+    ):
+        pytest.File.from_parent(
+            parent=mod.parent,
+            fspath=legacy_path("bla"),
+        )
+
+
+def test_importing_instance_is_deprecated(pytester: Pytester) -> None:
+    with pytest.warns(
+        pytest.PytestDeprecationWarning,
+        match=re.escape("The pytest.Instance collector type is deprecated"),
+    ):
+        pytest.Instance
+
+    with pytest.warns(
+        pytest.PytestDeprecationWarning,
+        match=re.escape("The pytest.Instance collector type is deprecated"),
+    ):
+        from _pytest.python import Instance  # noqa: F401
('testing', 'acceptance_test.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -3,16 +3,15 @@
 import types

 import attr
-import py

 import pytest
 from _pytest.compat import importlib_metadata
 from _pytest.config import ExitCode
 from _pytest.pathlib import symlink_or_skip
-from _pytest.pytester import Testdir
-
-
-def prepend_pythonpath(*dirs):
+from _pytest.pytester import Pytester
+
+
+def prepend_pythonpath(*dirs) -> str:
     cur = os.getenv("PYTHONPATH")
     if cur:
         dirs += (cur,)
@@ -20,60 +19,60 @@


 class TestGeneralUsage:
-    def test_config_error(self, testdir):
-        testdir.copy_example("conftest_usageerror/conftest.py")
-        result = testdir.runpytest(testdir.tmpdir)
+    def test_config_error(self, pytester: Pytester) -> None:
+        pytester.copy_example("conftest_usageerror/conftest.py")
+        result = pytester.runpytest(pytester.path)
         assert result.ret == ExitCode.USAGE_ERROR
         result.stderr.fnmatch_lines(["*ERROR: hello"])
         result.stdout.fnmatch_lines(["*pytest_unconfigure_called"])

-    def test_root_conftest_syntax_error(self, testdir):
-        testdir.makepyfile(conftest="raise SyntaxError\n")
-        result = testdir.runpytest()
+    def test_root_conftest_syntax_error(self, pytester: Pytester) -> None:
+        pytester.makepyfile(conftest="raise SyntaxError\n")
+        result = pytester.runpytest()
         result.stderr.fnmatch_lines(["*raise SyntaxError*"])
         assert result.ret != 0

-    def test_early_hook_error_issue38_1(self, testdir):
-        testdir.makeconftest(
+    def test_early_hook_error_issue38_1(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             def pytest_sessionstart():
                 0 / 0
         """
         )
-        result = testdir.runpytest(testdir.tmpdir)
+        result = pytester.runpytest(pytester.path)
         assert result.ret != 0
         # tracestyle is native by default for hook failures
         result.stdout.fnmatch_lines(
             ["*INTERNALERROR*File*conftest.py*line 2*", "*0 / 0*"]
         )
-        result = testdir.runpytest(testdir.tmpdir, "--fulltrace")
+        result = pytester.runpytest(pytester.path, "--fulltrace")
         assert result.ret != 0
         # tracestyle is native by default for hook failures
         result.stdout.fnmatch_lines(
             ["*INTERNALERROR*def pytest_sessionstart():*", "*INTERNALERROR*0 / 0*"]
         )

-    def test_early_hook_configure_error_issue38(self, testdir):
-        testdir.makeconftest(
+    def test_early_hook_configure_error_issue38(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             def pytest_configure():
                 0 / 0
         """
         )
-        result = testdir.runpytest(testdir.tmpdir)
+        result = pytester.runpytest(pytester.path)
         assert result.ret != 0
         # here we get it on stderr
         result.stderr.fnmatch_lines(
             ["*INTERNALERROR*File*conftest.py*line 2*", "*0 / 0*"]
         )

-    def test_file_not_found(self, testdir):
-        result = testdir.runpytest("asd")
+    def test_file_not_found(self, pytester: Pytester) -> None:
+        result = pytester.runpytest("asd")
         assert result.ret != 0
         result.stderr.fnmatch_lines(["ERROR: file or directory not found: asd"])

-    def test_file_not_found_unconfigure_issue143(self, testdir):
-        testdir.makeconftest(
+    def test_file_not_found_unconfigure_issue143(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             def pytest_configure():
                 print("---configure")
@@ -81,36 +80,38 @@
                 print("---unconfigure")
         """
         )
-        result = testdir.runpytest("-s", "asd")
+        result = pytester.runpytest("-s", "asd")
         assert result.ret == ExitCode.USAGE_ERROR
         result.stderr.fnmatch_lines(["ERROR: file or directory not found: asd"])
         result.stdout.fnmatch_lines(["*---configure", "*---unconfigure"])

-    def test_config_preparse_plugin_option(self, testdir):
-        testdir.makepyfile(
+    def test_config_preparse_plugin_option(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             pytest_xyz="""
             def pytest_addoption(parser):
                 parser.addoption("--xyz", dest="xyz", action="store")
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             test_one="""
             def test_option(pytestconfig):
                 assert pytestconfig.option.xyz == "123"
         """
         )
-        result = testdir.runpytest("-p", "pytest_xyz", "--xyz=123", syspathinsert=True)
+        result = pytester.runpytest("-p", "pytest_xyz", "--xyz=123", syspathinsert=True)
         assert result.ret == 0
         result.stdout.fnmatch_lines(["*1 passed*"])

     @pytest.mark.parametrize("load_cov_early", [True, False])
-    def test_early_load_setuptools_name(self, testdir, monkeypatch, load_cov_early):
+    def test_early_load_setuptools_name(
+        self, pytester: Pytester, monkeypatch, load_cov_early
+    ) -> None:
         monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD")

-        testdir.makepyfile(mytestplugin1_module="")
-        testdir.makepyfile(mytestplugin2_module="")
-        testdir.makepyfile(mycov_module="")
-        testdir.syspathinsert()
+        pytester.makepyfile(mytestplugin1_module="")
+        pytester.makepyfile(mytestplugin2_module="")
+        pytester.makepyfile(mycov_module="")
+        pytester.syspathinsert()

         loaded = []

@@ -141,35 +142,35 @@

         monkeypatch.setattr(importlib_metadata, "distributions", my_dists)
         params = ("-p", "mycov") if load_cov_early else ()
-        testdir.runpytest_inprocess(*params)
+        pytester.runpytest_inprocess(*params)
         if load_cov_early:
             assert loaded == ["mycov", "myplugin1", "myplugin2"]
         else:
             assert loaded == ["myplugin1", "myplugin2", "mycov"]

     @pytest.mark.parametrize("import_mode", ["prepend", "append", "importlib"])
-    def test_assertion_rewrite(self, testdir, import_mode):
-        p = testdir.makepyfile(
+    def test_assertion_rewrite(self, pytester: Pytester, import_mode) -> None:
+        p = pytester.makepyfile(
             """
             def test_this():
                 x = 0
                 assert x
         """
         )
-        result = testdir.runpytest(p, "--import-mode={}".format(import_mode))
+        result = pytester.runpytest(p, f"--import-mode={import_mode}")
         result.stdout.fnmatch_lines([">       assert x", "E       assert 0"])
         assert result.ret == 1

-    def test_nested_import_error(self, testdir):
-        p = testdir.makepyfile(
+    def test_nested_import_error(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
                 import import_fails
                 def test_this():
                     assert import_fails.a == 1
         """
         )
-        testdir.makepyfile(import_fails="import does_not_work")
-        result = testdir.runpytest(p)
+        pytester.makepyfile(import_fails="import does_not_work")
+        result = pytester.runpytest(p)
         result.stdout.fnmatch_lines(
             [
                 "ImportError while importing test module*",
@@ -178,122 +179,122 @@
         )
         assert result.ret == 2

-    def test_not_collectable_arguments(self, testdir):
-        p1 = testdir.makepyfile("")
-        p2 = testdir.makefile(".pyc", "123")
-        result = testdir.runpytest(p1, p2)
+    def test_not_collectable_arguments(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile("")
+        p2 = pytester.makefile(".pyc", "123")
+        result = pytester.runpytest(p1, p2)
         assert result.ret == ExitCode.USAGE_ERROR
         result.stderr.fnmatch_lines(
             [
-                "ERROR: not found: {}".format(p2),
-                "(no name {!r} in any of [[][]])".format(str(p2)),
+                f"ERROR: not found: {p2}",
+                f"(no name {str(p2)!r} in any of [[][]])",
                 "",
             ]
         )

     @pytest.mark.filterwarnings("default")
-    def test_better_reporting_on_conftest_load_failure(self, testdir):
+    def test_better_reporting_on_conftest_load_failure(
+        self, pytester: Pytester
+    ) -> None:
         """Show a user-friendly traceback on conftest import failures (#486, #3332)"""
-        testdir.makepyfile("")
-        conftest = testdir.makeconftest(
+        pytester.makepyfile("")
+        conftest = pytester.makeconftest(
             """
             def foo():
                 import qwerty
             foo()
         """
         )
-        result = testdir.runpytest("--help")
+        result = pytester.runpytest("--help")
         result.stdout.fnmatch_lines(
             """
             *--version*
             *warning*conftest.py*
         """
         )
-        result = testdir.runpytest()
-        exc_name = (
-            "ModuleNotFoundError" if sys.version_info >= (3, 6) else "ImportError"
-        )
+        result = pytester.runpytest()
         assert result.stdout.lines == []
         assert result.stderr.lines == [
-            "ImportError while loading conftest '{}'.".format(conftest),
+            f"ImportError while loading conftest '{conftest}'.",
             "conftest.py:3: in <module>",
             "    foo()",
             "conftest.py:2: in foo",
             "    import qwerty",
-            "E   {}: No module named 'qwerty'".format(exc_name),
+            "E   ModuleNotFoundError: No module named 'qwerty'",
         ]

-    def test_early_skip(self, testdir):
-        testdir.mkdir("xyz")
-        testdir.makeconftest(
+    def test_early_skip(self, pytester: Pytester) -> None:
+        pytester.mkdir("xyz")
+        pytester.makeconftest(
             """
             import pytest
             def pytest_collect_file():
                 pytest.skip("early")
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret == ExitCode.NO_TESTS_COLLECTED
         result.stdout.fnmatch_lines(["*1 skip*"])

-    def test_issue88_initial_file_multinodes(self, testdir):
-        testdir.copy_example("issue88_initial_file_multinodes")
-        p = testdir.makepyfile("def test_hello(): pass")
-        result = testdir.runpytest(p, "--collect-only")
+    def test_issue88_initial_file_multinodes(self, pytester: Pytester) -> None:
+        pytester.copy_example("issue88_initial_file_multinodes")
+        p = pytester.makepyfile("def test_hello(): pass")
+        result = pytester.runpytest(p, "--collect-only")
         result.stdout.fnmatch_lines(["*MyFile*test_issue88*", "*Module*test_issue88*"])

-    def test_issue93_initialnode_importing_capturing(self, testdir):
-        testdir.makeconftest(
+    def test_issue93_initialnode_importing_capturing(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import sys
             print("should not be seen")
             sys.stderr.write("stder42\\n")
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret == ExitCode.NO_TESTS_COLLECTED
         result.stdout.no_fnmatch_line("*should not be seen*")
         assert "stderr42" not in result.stderr.str()

-    def test_conftest_printing_shows_if_error(self, testdir):
-        testdir.makeconftest(
+    def test_conftest_printing_shows_if_error(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             print("should be seen")
             assert 0
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret != 0
         assert "should be seen" in result.stdout.str()

-    def test_issue109_sibling_conftests_not_loaded(self, testdir):
-        sub1 = testdir.mkdir("sub1")
-        sub2 = testdir.mkdir("sub2")
-        sub1.join("conftest.py").write("assert 0")
-        result = testdir.runpytest(sub2)
+    def test_issue109_sibling_conftests_not_loaded(self, pytester: Pytester) -> None:
+        sub1 = pytester.mkdir("sub1")
+        sub2 = pytester.mkdir("sub2")
+        sub1.joinpath("conftest.py").write_text("assert 0")
+        result = pytester.runpytest(sub2)
         assert result.ret == ExitCode.NO_TESTS_COLLECTED
-        sub2.ensure("__init__.py")
-        p = sub2.ensure("test_hello.py")
-        result = testdir.runpytest(p)
+        sub2.joinpath("__init__.py").touch()
+        p = sub2.joinpath("test_hello.py")
+        p.touch()
+        result = pytester.runpytest(p)
         assert result.ret == ExitCode.NO_TESTS_COLLECTED
-        result = testdir.runpytest(sub1)
+        result = pytester.runpytest(sub1)
         assert result.ret == ExitCode.USAGE_ERROR

-    def test_directory_skipped(self, testdir):
-        testdir.makeconftest(
+    def test_directory_skipped(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest
             def pytest_ignore_collect():
                 pytest.skip("intentional")
         """
         )
-        testdir.makepyfile("def test_hello(): pass")
-        result = testdir.runpytest()
+        pytester.makepyfile("def test_hello(): pass")
+        result = pytester.runpytest()
         assert result.ret == ExitCode.NO_TESTS_COLLECTED
         result.stdout.fnmatch_lines(["*1 skipped*"])

-    def test_multiple_items_per_collector_byid(self, testdir):
-        c = testdir.makeconftest(
+    def test_multiple_items_per_collector_byid(self, pytester: Pytester) -> None:
+        c = pytester.makeconftest(
             """
             import pytest
             class MyItem(pytest.Item):
@@ -302,17 +303,17 @@
             class MyCollector(pytest.File):
                 def collect(self):
                     return [MyItem.from_parent(name="xyz", parent=self)]
-            def pytest_collect_file(path, parent):
-                if path.basename.startswith("conftest"):
-                    return MyCollector.from_parent(fspath=path, parent=parent)
-        """
-        )
-        result = testdir.runpytest(c.basename + "::" + "xyz")
+            def pytest_collect_file(file_path, parent):
+                if file_path.name.startswith("conftest"):
+                    return MyCollector.from_parent(path=file_path, parent=parent)
+        """
+        )
+        result = pytester.runpytest(c.name + "::" + "xyz")
         assert result.ret == 0
         result.stdout.fnmatch_lines(["*1 pass*"])

-    def test_skip_on_generated_funcarg_id(self, testdir):
-        testdir.makeconftest(
+    def test_skip_on_generated_funcarg_id(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest
             def pytest_generate_tests(metafunc):
@@ -324,13 +325,13 @@
                 assert 0
         """
         )
-        p = testdir.makepyfile("""def test_func(x): pass""")
-        res = testdir.runpytest(p)
+        p = pytester.makepyfile("""def test_func(x): pass""")
+        res = pytester.runpytest(p)
         assert res.ret == 0
         res.stdout.fnmatch_lines(["*1 skipped*"])

-    def test_direct_addressing_selects(self, testdir):
-        p = testdir.makepyfile(
+    def test_direct_addressing_selects(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             def pytest_generate_tests(metafunc):
                 metafunc.parametrize('i', [1, 2], ids=["1", "2"])
@@ -338,56 +339,58 @@
                 pass
         """
         )
-        res = testdir.runpytest(p.basename + "::" + "test_func[1]")
+        res = pytester.runpytest(p.name + "::" + "test_func[1]")
         assert res.ret == 0
         res.stdout.fnmatch_lines(["*1 passed*"])

-    def test_direct_addressing_notfound(self, testdir):
-        p = testdir.makepyfile(
+    def test_direct_addressing_notfound(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             def test_func():
                 pass
         """
         )
-        res = testdir.runpytest(p.basename + "::" + "test_notfound")
+        res = pytester.runpytest(p.name + "::" + "test_notfound")
         assert res.ret
         res.stderr.fnmatch_lines(["*ERROR*not found*"])

-    def test_docstring_on_hookspec(self):
+    def test_docstring_on_hookspec(self) -> None:
         from _pytest import hookspec

         for name, value in vars(hookspec).items():
             if name.startswith("pytest_"):
                 assert value.__doc__, "no docstring for %s" % name

-    def test_initialization_error_issue49(self, testdir):
-        testdir.makeconftest(
+    def test_initialization_error_issue49(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             def pytest_configure():
                 x
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret == 3  # internal error
         result.stderr.fnmatch_lines(["INTERNAL*pytest_configure*", "INTERNAL*x*"])
         assert "sessionstarttime" not in result.stderr.str()

     @pytest.mark.parametrize("lookfor", ["test_fun.py::test_a"])
-    def test_issue134_report_error_when_collecting_member(self, testdir, lookfor):
-        testdir.makepyfile(
+    def test_issue134_report_error_when_collecting_member(
+        self, pytester: Pytester, lookfor
+    ) -> None:
+        pytester.makepyfile(
             test_fun="""
             def test_a():
                 pass
             def"""
         )
-        result = testdir.runpytest(lookfor)
+        result = pytester.runpytest(lookfor)
         result.stdout.fnmatch_lines(["*SyntaxError*"])
         if "::" in lookfor:
             result.stderr.fnmatch_lines(["*ERROR*"])
             assert result.ret == 4  # usage error only if item not found

-    def test_report_all_failed_collections_initargs(self, testdir):
-        testdir.makeconftest(
+    def test_report_all_failed_collections_initargs(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             from _pytest.config import ExitCode

@@ -396,21 +399,23 @@
                 print("pytest_sessionfinish_called")
             """
         )
-        testdir.makepyfile(test_a="def", test_b="def")
-        result = testdir.runpytest("test_a.py::a", "test_b.py::b")
+        pytester.makepyfile(test_a="def", test_b="def")
+        result = pytester.runpytest("test_a.py::a", "test_b.py::b")
         result.stderr.fnmatch_lines(["*ERROR*test_a.py::a*", "*ERROR*test_b.py::b*"])
         result.stdout.fnmatch_lines(["pytest_sessionfinish_called"])
         assert result.ret == ExitCode.USAGE_ERROR

-    def test_namespace_import_doesnt_confuse_import_hook(self, testdir):
+    def test_namespace_import_doesnt_confuse_import_hook(
+        self, pytester: Pytester
+    ) -> None:
         """Ref #383.

         Python 3.3's namespace package messed with our import hooks.
         Importing a module that didn't exist, even if the ImportError was
         gracefully handled, would make our test crash.
         """
-        testdir.mkdir("not_a_package")
-        p = testdir.makepyfile(
+        pytester.mkdir("not_a_package")
+        p = pytester.makepyfile(
             """
             try:
                 from not_a_package import doesnt_exist
@@ -422,20 +427,22 @@
                 pass
         """
         )
-        res = testdir.runpytest(p.basename)
+        res = pytester.runpytest(p.name)
         assert res.ret == 0

-    def test_unknown_option(self, testdir):
-        result = testdir.runpytest("--qwlkej")
+    def test_unknown_option(self, pytester: Pytester) -> None:
+        result = pytester.runpytest("--qwlkej")
         result.stderr.fnmatch_lines(
             """
             *unrecognized*
         """
         )

-    def test_getsourcelines_error_issue553(self, testdir, monkeypatch):
+    def test_getsourcelines_error_issue553(
+        self, pytester: Pytester, monkeypatch
+    ) -> None:
         monkeypatch.setattr("inspect.getsourcelines", None)
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             """
             def raise_error(obj):
                 raise OSError('source code not available')
@@ -447,26 +454,28 @@
                 pass
         """
         )
-        res = testdir.runpytest(p)
+        res = pytester.runpytest(p)
         res.stdout.fnmatch_lines(
             ["*source code not available*", "E*fixture 'invalid_fixture' not found"]
         )

-    def test_plugins_given_as_strings(self, tmpdir, monkeypatch, _sys_snapshot):
+    def test_plugins_given_as_strings(
+        self, pytester: Pytester, monkeypatch, _sys_snapshot
+    ) -> None:
         """Test that str values passed to main() as `plugins` arg are
         interpreted as module names to be imported and registered (#855)."""
         with pytest.raises(ImportError) as excinfo:
-            pytest.main([str(tmpdir)], plugins=["invalid.module"])
+            pytest.main([str(pytester.path)], plugins=["invalid.module"])
         assert "invalid" in str(excinfo.value)

-        p = tmpdir.join("test_test_plugins_given_as_strings.py")
-        p.write("def test_foo(): pass")
+        p = pytester.path.joinpath("test_test_plugins_given_as_strings.py")
+        p.write_text("def test_foo(): pass")
         mod = types.ModuleType("myplugin")
         monkeypatch.setitem(sys.modules, "myplugin", mod)
-        assert pytest.main(args=[str(tmpdir)], plugins=["myplugin"]) == 0
-
-    def test_parametrized_with_bytes_regex(self, testdir):
-        p = testdir.makepyfile(
+        assert pytest.main(args=[str(pytester.path)], plugins=["myplugin"]) == 0
+
+    def test_parametrized_with_bytes_regex(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             import re
             import pytest
@@ -475,12 +484,12 @@
                 pass
         """
         )
-        res = testdir.runpytest(p)
+        res = pytester.runpytest(p)
         res.stdout.fnmatch_lines(["*1 passed*"])

-    def test_parametrized_with_null_bytes(self, testdir):
+    def test_parametrized_with_null_bytes(self, pytester: Pytester) -> None:
         """Test parametrization with values that contain null bytes and unicode characters (#2644, #2957)"""
-        p = testdir.makepyfile(
+        p = pytester.makepyfile(
             """\
             import pytest

@@ -489,47 +498,29 @@
                 assert data
             """
         )
-        res = testdir.runpytest(p)
+        res = pytester.runpytest(p)
         res.assert_outcomes(passed=3)


 class TestInvocationVariants:
-    def test_earlyinit(self, testdir):
-        p = testdir.makepyfile(
+    def test_earlyinit(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             import pytest
             assert hasattr(pytest, 'mark')
         """
         )
-        result = testdir.runpython(p)
-        assert result.ret == 0
-
-    def test_pydoc(self, testdir):
-        for name in ("py.test", "pytest"):
-            result = testdir.runpython_c("import {};help({})".format(name, name))
-            assert result.ret == 0
-            s = result.stdout.str()
-            assert "MarkGenerator" in s
-
-    def test_import_star_py_dot_test(self, testdir):
-        p = testdir.makepyfile(
-            """
-            from py.test import *
-            #collect
-            #cmdline
-            #Item
-            # assert collect.Item is Item
-            # assert collect.Collector is Collector
-            main
-            skip
-            xfail
-        """
-        )
-        result = testdir.runpython(p)
-        assert result.ret == 0
-
-    def test_import_star_pytest(self, testdir):
-        p = testdir.makepyfile(
+        result = pytester.runpython(p)
+        assert result.ret == 0
+
+    def test_pydoc(self, pytester: Pytester) -> None:
+        result = pytester.runpython_c("import pytest;help(pytest)")
+        assert result.ret == 0
+        s = result.stdout.str()
+        assert "MarkGenerator" in s
+
+    def test_import_star_pytest(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             from pytest import *
             #Item
@@ -539,45 +530,41 @@
             xfail
         """
         )
-        result = testdir.runpython(p)
-        assert result.ret == 0
-
-    def test_double_pytestcmdline(self, testdir):
-        p = testdir.makepyfile(
+        result = pytester.runpython(p)
+        assert result.ret == 0
+
+    def test_double_pytestcmdline(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             run="""
             import pytest
             pytest.main()
             pytest.main()
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_hello():
                 pass
         """
         )
-        result = testdir.runpython(p)
+        result = pytester.runpython(p)
         result.stdout.fnmatch_lines(["*1 passed*", "*1 passed*"])

-    def test_python_minus_m_invocation_ok(self, testdir):
-        p1 = testdir.makepyfile("def test_hello(): pass")
-        res = testdir.run(sys.executable, "-m", "pytest", str(p1))
+    def test_python_minus_m_invocation_ok(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile("def test_hello(): pass")
+        res = pytester.run(sys.executable, "-m", "pytest", str(p1))
         assert res.ret == 0

-    def test_python_minus_m_invocation_fail(self, testdir):
-        p1 = testdir.makepyfile("def test_fail(): 0/0")
-        res = testdir.run(sys.executable, "-m", "pytest", str(p1))
+    def test_python_minus_m_invocation_fail(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile("def test_fail(): 0/0")
+        res = pytester.run(sys.executable, "-m", "pytest", str(p1))
         assert res.ret == 1

-    def test_python_pytest_package(self, testdir):
-        p1 = testdir.makepyfile("def test_pass(): pass")
-        res = testdir.run(sys.executable, "-m", "pytest", str(p1))
+    def test_python_pytest_package(self, pytester: Pytester) -> None:
+        p1 = pytester.makepyfile("def test_pass(): pass")
+        res = pytester.run(sys.executable, "-m", "pytest", str(p1))
         assert res.ret == 0
         res.stdout.fnmatch_lines(["*1 passed*"])
-
-    def test_equivalence_pytest_pydottest(self) -> None:
-        # Type ignored because `py.test` is not and will not be typed.
-        assert pytest.main == py.test.cmdline.main  # type: ignore[attr-defined]

     def test_invoke_with_invalid_type(self) -> None:
         with pytest.raises(
@@ -585,12 +572,12 @@
         ):
             pytest.main("-h")  # type: ignore[arg-type]

-    def test_invoke_with_path(self, tmpdir: py.path.local, capsys) -> None:
-        retcode = pytest.main(tmpdir)
+    def test_invoke_with_path(self, pytester: Pytester, capsys) -> None:
+        retcode = pytest.main([str(pytester.path)])
         assert retcode == ExitCode.NO_TESTS_COLLECTED
         out, err = capsys.readouterr()

-    def test_invoke_plugin_api(self, capsys):
+    def test_invoke_plugin_api(self, capsys) -> None:
         class MyPlugin:
             def pytest_addoption(self, parser):
                 parser.addoption("--myopt")
@@ -599,65 +586,71 @@
         out, err = capsys.readouterr()
         assert "--myopt" in out

-    def test_pyargs_importerror(self, testdir, monkeypatch):
+    def test_pyargs_importerror(self, pytester: Pytester, monkeypatch) -> None:
         monkeypatch.delenv("PYTHONDONTWRITEBYTECODE", False)
-        path = testdir.mkpydir("tpkg")
-        path.join("test_hello.py").write("raise ImportError")
-
-        result = testdir.runpytest("--pyargs", "tpkg.test_hello", syspathinsert=True)
+        path = pytester.mkpydir("tpkg")
+        path.joinpath("test_hello.py").write_text("raise ImportError")
+
+        result = pytester.runpytest("--pyargs", "tpkg.test_hello", syspathinsert=True)
         assert result.ret != 0

         result.stdout.fnmatch_lines(["collected*0*items*/*1*error"])

-    def test_pyargs_only_imported_once(self, testdir):
-        pkg = testdir.mkpydir("foo")
-        pkg.join("test_foo.py").write("print('hello from test_foo')\ndef test(): pass")
-        pkg.join("conftest.py").write(
+    def test_pyargs_only_imported_once(self, pytester: Pytester) -> None:
+        pkg = pytester.mkpydir("foo")
+        pkg.joinpath("test_foo.py").write_text(
+            "print('hello from test_foo')\ndef test(): pass"
+        )
+        pkg.joinpath("conftest.py").write_text(
             "def pytest_configure(config): print('configuring')"
         )

-        result = testdir.runpytest("--pyargs", "foo.test_foo", "-s", syspathinsert=True)
+        result = pytester.runpytest(
+            "--pyargs", "foo.test_foo", "-s", syspathinsert=True
+        )
         # should only import once
         assert result.outlines.count("hello from test_foo") == 1
         # should only configure once
         assert result.outlines.count("configuring") == 1

-    def test_pyargs_filename_looks_like_module(self, testdir):
-        testdir.tmpdir.join("conftest.py").ensure()
-        testdir.tmpdir.join("t.py").write("def test(): pass")
-        result = testdir.runpytest("--pyargs", "t.py")
+    def test_pyargs_filename_looks_like_module(self, pytester: Pytester) -> None:
+        pytester.path.joinpath("conftest.py").touch()
+        pytester.path.joinpath("t.py").write_text("def test(): pass")
+        result = pytester.runpytest("--pyargs", "t.py")
         assert result.ret == ExitCode.OK

-    def test_cmdline_python_package(self, testdir, monkeypatch):
+    def test_cmdline_python_package(self, pytester: Pytester, monkeypatch) -> None:
         import warnings

         monkeypatch.delenv("PYTHONDONTWRITEBYTECODE", False)
-        path = testdir.mkpydir("tpkg")
-        path.join("test_hello.py").write("def test_hello(): pass")
-        path.join("test_world.py").write("def test_world(): pass")
-        result = testdir.runpytest("--pyargs", "tpkg")
+        path = pytester.mkpydir("tpkg")
+        path.joinpath("test_hello.py").write_text("def test_hello(): pass")
+        path.joinpath("test_world.py").write_text("def test_world(): pass")
+        result = pytester.runpytest("--pyargs", "tpkg")
         assert result.ret == 0
         result.stdout.fnmatch_lines(["*2 passed*"])
-        result = testdir.runpytest("--pyargs", "tpkg.test_hello", syspathinsert=True)
+        result = pytester.runpytest("--pyargs", "tpkg.test_hello", syspathinsert=True)
         assert result.ret == 0
         result.stdout.fnmatch_lines(["*1 passed*"])

-        empty_package = testdir.mkpydir("empty_package")
+        empty_package = pytester.mkpydir("empty_package")
         monkeypatch.setenv("PYTHONPATH", str(empty_package), prepend=os.pathsep)
         # the path which is not a package raises a warning on pypy;
         # no idea why only pypy and not normal python warn about it here
         with warnings.catch_warnings():
             warnings.simplefilter("ignore", ImportWarning)
-            result = testdir.runpytest("--pyargs", ".")
+            result = pytester.runpytest("--pyargs", ".")
         assert result.ret == 0
         result.stdout.fnmatch_lines(["*2 passed*"])

-        monkeypatch.setenv("PYTHONPATH", str(testdir), prepend=os.pathsep)
-        result = testdir.runpytest("--pyargs", "tpkg.test_missing", syspathinsert=True)
+        monkeypatch.setenv("PYTHONPATH", str(pytester), prepend=os.pathsep)
+        result = pytester.runpytest("--pyargs", "tpkg.test_missing", syspathinsert=True)
         assert result.ret != 0
         result.stderr.fnmatch_lines(["*not*found*test_missing*"])

-    def test_cmdline_python_namespace_package(self, testdir, monkeypatch):
+    def test_cmdline_python_namespace_package(
+        self, pytester: Pytester, monkeypatch
+    ) -> None:
         """Test --pyargs option with namespace packages (#1567).

         Ref: https://packaging.python.org/guides/packaging-namespace-packages/
@@ -666,16 +659,18 @@

         search_path = []
         for dirname in "hello", "world":
-            d = testdir.mkdir(dirname)
+            d = pytester.mkdir(dirname)
             search_path.append(d)
-            ns = d.mkdir("ns_pkg")
-            ns.join("__init__.py").write(
+            ns = d.joinpath("ns_pkg")
+            ns.mkdir()
+            ns.joinpath("__init__.py").write_text(
                 "__import__('pkg_resources').declare_namespace(__name__)"
             )
-            lib = ns.mkdir(dirname)
-            lib.ensure("__init__.py")
-            lib.join("test_{}.py".format(dirname)).write(
-                "def test_{}(): pass\ndef test_other():pass".format(dirname)
+            lib = ns.joinpath(dirname)
+            lib.mkdir()
+            lib.joinpath("__init__.py").touch()
+            lib.joinpath(f"test_{dirname}.py").write_text(
+                f"def test_{dirname}(): pass\ndef test_other():pass"
             )

         # The structure of the test directory is now:
@@ -700,7 +695,7 @@

         # mixed module and filenames:
         monkeypatch.chdir("world")
-        result = testdir.runpytest("--pyargs", "-v", "ns_pkg.hello", "ns_pkg/world")
+        result = pytester.runpytest("--pyargs", "-v", "ns_pkg.hello", "ns_pkg/world")
         assert result.ret == 0
         result.stdout.fnmatch_lines(
             [
@@ -713,8 +708,8 @@
         )

         # specify tests within a module
-        testdir.chdir()
-        result = testdir.runpytest(
+        pytester.chdir()
+        result = pytester.runpytest(
             "--pyargs", "-v", "ns_pkg.world.test_world::test_other"
         )
         assert result.ret == 0
@@ -722,17 +717,19 @@
             ["*test_world.py::test_other*PASSED*", "*1 passed*"]
         )

-    def test_invoke_test_and_doctestmodules(self, testdir):
-        p = testdir.makepyfile(
+    def test_invoke_test_and_doctestmodules(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             def test():
                 pass
         """
         )
-        result = testdir.runpytest(str(p) + "::test", "--doctest-modules")
+        result = pytester.runpytest(str(p) + "::test", "--doctest-modules")
         result.stdout.fnmatch_lines(["*1 passed*"])

-    def test_cmdline_python_package_symlink(self, testdir, monkeypatch):
+    def test_cmdline_python_package_symlink(
+        self, pytester: Pytester, monkeypatch
+    ) -> None:
         """
         --pyargs with packages with path containing symlink can have conftest.py in
         their package (#2985)
@@ -740,19 +737,21 @@
         monkeypatch.delenv("PYTHONDONTWRITEBYTECODE", raising=False)

         dirname = "lib"
-        d = testdir.mkdir(dirname)
-        foo = d.mkdir("foo")
-        foo.ensure("__init__.py")
-        lib = foo.mkdir("bar")
-        lib.ensure("__init__.py")
-        lib.join("test_bar.py").write(
+        d = pytester.mkdir(dirname)
+        foo = d.joinpath("foo")
+        foo.mkdir()
+        foo.joinpath("__init__.py").touch()
+        lib = foo.joinpath("bar")
+        lib.mkdir()
+        lib.joinpath("__init__.py").touch()
+        lib.joinpath("test_bar.py").write_text(
             "def test_bar(): pass\ndef test_other(a_fixture):pass"
         )
-        lib.join("conftest.py").write(
+        lib.joinpath("conftest.py").write_text(
             "import pytest\n@pytest.fixture\ndef a_fixture():pass"
         )

-        d_local = testdir.mkdir("symlink_root")
+        d_local = pytester.mkdir("symlink_root")
         symlink_location = d_local / "lib"
         symlink_or_skip(d, symlink_location, target_is_directory=True)

@@ -776,8 +775,8 @@

         # module picked up in symlink-ed directory:
         # It picks up symlink_root/lib/foo/bar (symlink) via sys.path.
-        result = testdir.runpytest("--pyargs", "-v", "foo.bar")
-        testdir.chdir()
+        result = pytester.runpytest("--pyargs", "-v", "foo.bar")
+        pytester.chdir()
         assert result.ret == 0
         result.stdout.fnmatch_lines(
             [
@@ -787,14 +786,14 @@
             ]
         )

-    def test_cmdline_python_package_not_exists(self, testdir):
-        result = testdir.runpytest("--pyargs", "tpkgwhatv")
+    def test_cmdline_python_package_not_exists(self, pytester: Pytester) -> None:
+        result = pytester.runpytest("--pyargs", "tpkgwhatv")
         assert result.ret
         result.stderr.fnmatch_lines(["ERROR*module*or*package*not*found*"])

     @pytest.mark.xfail(reason="decide: feature or bug")
-    def test_noclass_discovery_if_not_testcase(self, testdir):
-        testpath = testdir.makepyfile(
+    def test_noclass_discovery_if_not_testcase(self, pytester: Pytester) -> None:
+        testpath = pytester.makepyfile(
             """
             import unittest
             class TestHello(object):
@@ -805,11 +804,11 @@
                 attr = 42
         """
         )
-        reprec = testdir.inline_run(testpath)
+        reprec = pytester.inline_run(testpath)
         reprec.assertoutcome(passed=1)

-    def test_doctest_id(self, testdir):
-        testdir.makefile(
+    def test_doctest_id(self, pytester: Pytester) -> None:
+        pytester.makefile(
             ".txt",
             """
             >>> x=3
@@ -824,16 +823,16 @@
             "FAILED test_doctest_id.txt::test_doctest_id.txt",
             "*= 1 failed in*",
         ]
-        result = testdir.runpytest(testid, "-rf", "--tb=short")
+        result = pytester.runpytest(testid, "-rf", "--tb=short")
         result.stdout.fnmatch_lines(expected_lines)

         # Ensure that re-running it will still handle it as
         # doctest.DocTestFailure, which was not the case before when
         # re-importing doctest, but not creating a new RUNNER_CLASS.
-        result = testdir.runpytest(testid, "-rf", "--tb=short")
+        result = pytester.runpytest(testid, "-rf", "--tb=short")
         result.stdout.fnmatch_lines(expected_lines)

-    def test_core_backward_compatibility(self):
+    def test_core_backward_compatibility(self) -> None:
         """Test backward compatibility for get_plugin_manager function. See #787."""
         import _pytest.config

@@ -842,7 +841,7 @@
             is _pytest.config.PytestPluginManager
         )

-    def test_has_plugin(self, request):
+    def test_has_plugin(self, request) -> None:
         """Test hasplugin function of the plugin manager (#932)."""
         assert request.config.pluginmanager.hasplugin("python")

@@ -860,9 +859,9 @@
             timing.sleep(0.020)
     """

-    def test_calls(self, testdir, mock_timing):
-        testdir.makepyfile(self.source)
-        result = testdir.runpytest_inprocess("--durations=10")
+    def test_calls(self, pytester: Pytester, mock_timing) -> None:
+        pytester.makepyfile(self.source)
+        result = pytester.runpytest_inprocess("--durations=10")
         assert result.ret == 0

         result.stdout.fnmatch_lines_random(
@@ -873,18 +872,18 @@
             ["(8 durations < 0.005s hidden.  Use -vv to show these durations.)"]
         )

-    def test_calls_show_2(self, testdir, mock_timing):
-
-        testdir.makepyfile(self.source)
-        result = testdir.runpytest_inprocess("--durations=2")
+    def test_calls_show_2(self, pytester: Pytester, mock_timing) -> None:
+
+        pytester.makepyfile(self.source)
+        result = pytester.runpytest_inprocess("--durations=2")
         assert result.ret == 0

         lines = result.stdout.get_lines_after("*slowest*durations*")
         assert "4 passed" in lines[2]

-    def test_calls_showall(self, testdir, mock_timing):
-        testdir.makepyfile(self.source)
-        result = testdir.runpytest_inprocess("--durations=0")
+    def test_calls_showall(self, pytester: Pytester, mock_timing) -> None:
+        pytester.makepyfile(self.source)
+        result = pytester.runpytest_inprocess("--durations=0")
         assert result.ret == 0

         tested = "3"
@@ -894,11 +893,11 @@
                     if ("test_%s" % x) in line and y in line:
                         break
                 else:
-                    raise AssertionError("not found {} {}".format(x, y))
-
-    def test_calls_showall_verbose(self, testdir, mock_timing):
-        testdir.makepyfile(self.source)
-        result = testdir.runpytest_inprocess("--durations=0", "-vv")
+                    raise AssertionError(f"not found {x} {y}")
+
+    def test_calls_showall_verbose(self, pytester: Pytester, mock_timing) -> None:
+        pytester.makepyfile(self.source)
+        result = pytester.runpytest_inprocess("--durations=0", "-vv")
         assert result.ret == 0

         for x in "123":
@@ -907,19 +906,19 @@
                     if ("test_%s" % x) in line and y in line:
                         break
                 else:
-                    raise AssertionError("not found {} {}".format(x, y))
-
-    def test_with_deselected(self, testdir, mock_timing):
-        testdir.makepyfile(self.source)
-        result = testdir.runpytest_inprocess("--durations=2", "-k test_3")
+                    raise AssertionError(f"not found {x} {y}")
+
+    def test_with_deselected(self, pytester: Pytester, mock_timing) -> None:
+        pytester.makepyfile(self.source)
+        result = pytester.runpytest_inprocess("--durations=2", "-k test_3")
         assert result.ret == 0

         result.stdout.fnmatch_lines(["*durations*", "*call*test_3*"])

-    def test_with_failing_collection(self, testdir, mock_timing):
-        testdir.makepyfile(self.source)
-        testdir.makepyfile(test_collecterror="""xyz""")
-        result = testdir.runpytest_inprocess("--durations=2", "-k test_1")
+    def test_with_failing_collection(self, pytester: Pytester, mock_timing) -> None:
+        pytester.makepyfile(self.source)
+        pytester.makepyfile(test_collecterror="""xyz""")
+        result = pytester.runpytest_inprocess("--durations=2", "-k test_1")
         assert result.ret == 2

         result.stdout.fnmatch_lines(["*Interrupted: 1 error during collection*"])
@@ -927,9 +926,9 @@
         # output
         result.stdout.no_fnmatch_line("*duration*")

-    def test_with_not(self, testdir, mock_timing):
-        testdir.makepyfile(self.source)
-        result = testdir.runpytest_inprocess("-k not 1")
+    def test_with_not(self, pytester: Pytester, mock_timing) -> None:
+        pytester.makepyfile(self.source)
+        result = pytester.runpytest_inprocess("-k not 1")
         assert result.ret == 0


@@ -946,9 +945,9 @@
             timing.sleep(5)
     """

-    def test_setup_function(self, testdir, mock_timing):
-        testdir.makepyfile(self.source)
-        result = testdir.runpytest_inprocess("--durations=10")
+    def test_setup_function(self, pytester: Pytester, mock_timing) -> None:
+        pytester.makepyfile(self.source)
+        result = pytester.runpytest_inprocess("--durations=10")
         assert result.ret == 0

         result.stdout.fnmatch_lines_random(
@@ -960,11 +959,11 @@
         )


-def test_zipimport_hook(testdir, tmpdir):
+def test_zipimport_hook(pytester: Pytester) -> None:
     """Test package loader is being used correctly (see #1837)."""
     zipapp = pytest.importorskip("zipapp")
-    testdir.tmpdir.join("app").ensure(dir=1)
-    testdir.makepyfile(
+    pytester.path.joinpath("app").mkdir()
+    pytester.makepyfile(
         **{
             "app/foo.py": """
             import pytest
@@ -973,25 +972,27 @@
         """
         }
     )
-    target = tmpdir.join("foo.zip")
-    zipapp.create_archive(str(testdir.tmpdir.join("app")), str(target), main="foo:main")
-    result = testdir.runpython(target)
+    target = pytester.path.joinpath("foo.zip")
+    zipapp.create_archive(
+        str(pytester.path.joinpath("app")), str(target), main="foo:main"
+    )
+    result = pytester.runpython(target)
     assert result.ret == 0
     result.stderr.fnmatch_lines(["*not found*foo*"])
     result.stdout.no_fnmatch_line("*INTERNALERROR>*")


-def test_import_plugin_unicode_name(testdir):
-    testdir.makepyfile(myplugin="")
-    testdir.makepyfile("def test(): pass")
-    testdir.makeconftest("pytest_plugins = ['myplugin']")
-    r = testdir.runpytest()
+def test_import_plugin_unicode_name(pytester: Pytester) -> None:
+    pytester.makepyfile(myplugin="")
+    pytester.makepyfile("def test(): pass")
+    pytester.makeconftest("pytest_plugins = ['myplugin']")
+    r = pytester.runpytest()
     assert r.ret == 0


-def test_pytest_plugins_as_module(testdir):
+def test_pytest_plugins_as_module(pytester: Pytester) -> None:
     """Do not raise an error if pytest_plugins attribute is a module (#3899)"""
-    testdir.makepyfile(
+    pytester.makepyfile(
         **{
             "__init__.py": "",
             "pytest_plugins.py": "",
@@ -999,14 +1000,14 @@
             "test_foo.py": "def test(): pass",
         }
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["* 1 passed in *"])


-def test_deferred_hook_checking(testdir):
+def test_deferred_hook_checking(pytester: Pytester) -> None:
     """Check hooks as late as possible (#1821)."""
-    testdir.syspathinsert()
-    testdir.makepyfile(
+    pytester.syspathinsert()
+    pytester.makepyfile(
         **{
             "plugin.py": """
         class Hooks(object):
@@ -1027,15 +1028,15 @@
         """,
         }
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["* 1 passed *"])


-def test_fixture_values_leak(testdir):
+def test_fixture_values_leak(pytester: Pytester) -> None:
     """Ensure that fixture objects are properly destroyed by the garbage collector at the end of their expected
     life-times (#2981).
     """
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import attr
         import gc
@@ -1075,13 +1076,13 @@
     # Running on subprocess does not activate the HookRecorder
     # which holds itself a reference to objects in case of the
     # pytest_assert_reprcompare hook
-    result = testdir.runpytest_subprocess()
+    result = pytester.runpytest_subprocess()
     result.stdout.fnmatch_lines(["* 2 passed *"])


-def test_fixture_order_respects_scope(testdir):
+def test_fixture_order_respects_scope(pytester: Pytester) -> None:
     """Ensure that fixtures are created according to scope order (#2405)."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest

@@ -1100,11 +1101,11 @@
             assert data.get('value')
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert result.ret == 0


-def test_frame_leak_on_failing_test(testdir):
+def test_frame_leak_on_failing_test(pytester: Pytester) -> None:
     """Pytest would leak garbage referencing the frames of tests that failed
     that could never be reclaimed (#2798).

@@ -1112,7 +1113,7 @@
     are made of traceback objects which cannot be weakly referenced. Those objects at least
     can be eventually claimed by the garbage collector.
     """
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import gc
         import weakref
@@ -1133,28 +1134,28 @@
             assert ref() is None
     """
     )
-    result = testdir.runpytest_subprocess()
+    result = pytester.runpytest_subprocess()
     result.stdout.fnmatch_lines(["*1 failed, 1 passed in*"])


-def test_fixture_mock_integration(testdir):
+def test_fixture_mock_integration(pytester: Pytester) -> None:
     """Test that decorators applied to fixture are left working (#3774)"""
-    p = testdir.copy_example("acceptance/fixture_mock_integration.py")
-    result = testdir.runpytest(p)
+    p = pytester.copy_example("acceptance/fixture_mock_integration.py")
+    result = pytester.runpytest(p)
     result.stdout.fnmatch_lines(["*1 passed*"])


-def test_usage_error_code(testdir):
-    result = testdir.runpytest("-unknown-option-")
+def test_usage_error_code(pytester: Pytester) -> None:
+    result = pytester.runpytest("-unknown-option-")
     assert result.ret == ExitCode.USAGE_ERROR


-@pytest.mark.filterwarnings("default")
-def test_warn_on_async_function(testdir):
+@pytest.mark.filterwarnings("default::pytest.PytestUnhandledCoroutineWarning")
+def test_warn_on_async_function(pytester: Pytester) -> None:
     # In the below we .close() the coroutine only to avoid
     # "RuntimeWarning: coroutine 'test_2' was never awaited"
     # which messes with other tests.
-    testdir.makepyfile(
+    pytester.makepyfile(
         test_async="""
         async def test_1():
             pass
@@ -1166,7 +1167,7 @@
             return coro
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         [
             "test_async.py::test_1",
@@ -1182,12 +1183,9 @@
     )


-@pytest.mark.filterwarnings("default")
-@pytest.mark.skipif(
-    sys.version_info < (3, 6), reason="async gen syntax available in Python 3.6+"
-)
-def test_warn_on_async_gen_function(testdir):
-    testdir.makepyfile(
+@pytest.mark.filterwarnings("default::pytest.PytestUnhandledCoroutineWarning")
+def test_warn_on_async_gen_function(pytester: Pytester) -> None:
+    pytester.makepyfile(
         test_async="""
         async def test_1():
             yield
@@ -1197,7 +1195,7 @@
             return test_2()
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         [
             "test_async.py::test_1",
@@ -1213,8 +1211,8 @@
     )


-def test_pdb_can_be_rewritten(testdir):
-    testdir.makepyfile(
+def test_pdb_can_be_rewritten(pytester: Pytester) -> None:
+    pytester.makepyfile(
         **{
             "conftest.py": """
                 import pytest
@@ -1234,14 +1232,12 @@
     )
     # Disable debugging plugin itself to avoid:
     # > INTERNALERROR> AttributeError: module 'pdb' has no attribute 'set_trace'
-    result = testdir.runpytest_subprocess("-p", "no:debugging", "-vv")
+    result = pytester.runpytest_subprocess("-p", "no:debugging", "-vv")
     result.stdout.fnmatch_lines(
         [
             "    def check():",
             ">       assert 1 == 2",
             "E       assert 1 == 2",
-            "E         +1",
-            "E         -2",
             "",
             "pdb.py:2: AssertionError",
             "*= 1 failed in *",
@@ -1250,8 +1246,8 @@
     assert result.ret == 1


-def test_tee_stdio_captures_and_live_prints(testdir):
-    testpath = testdir.makepyfile(
+def test_tee_stdio_captures_and_live_prints(pytester: Pytester) -> None:
+    testpath = pytester.makepyfile(
         """
         import sys
         def test_simple():
@@ -1259,7 +1255,7 @@
             print ("@this is stderr@", file=sys.stderr)
     """
     )
-    result = testdir.runpytest_subprocess(
+    result = pytester.runpytest_subprocess(
         testpath,
         "--capture=tee-sys",
         "--junitxml=output.xml",
@@ -1272,7 +1268,7 @@
     result.stderr.fnmatch_lines(["*@this is stderr@*"])

     # now ensure the output is in the junitxml
-    with open(os.path.join(testdir.tmpdir.strpath, "output.xml")) as f:
+    with open(pytester.path.joinpath("output.xml")) as f:
         fullXml = f.read()
     assert "@this is stdout@\n" in fullXml
     assert "@this is stderr@\n" in fullXml
@@ -1282,15 +1278,18 @@
     sys.platform == "win32",
     reason="Windows raises `OSError: [Errno 22] Invalid argument` instead",
 )
-def test_no_brokenpipeerror_message(testdir: Testdir) -> None:
-    """Ensure that the broken pipe error message is supressed.
+def test_no_brokenpipeerror_message(pytester: Pytester) -> None:
+    """Ensure that the broken pipe error message is suppressed.

     In some Python versions, it reaches sys.unraisablehook, in others
     a BrokenPipeError exception is propagated, but either way it prints
     to stderr on shutdown, so checking nothing is printed is enough.
     """
-    popen = testdir.popen((*testdir._getpytestargs(), "--help"))
+    popen = pytester.popen((*pytester._getpytestargs(), "--help"))
     popen.stdout.close()
     ret = popen.wait()
     assert popen.stderr.read() == b""
     assert ret == 1
+
+    # Cleanup.
+    popen.stderr.close()
('testing', 'test_junitxml.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,54 +1,65 @@
 import os
 import platform
 from datetime import datetime
+from pathlib import Path
 from typing import cast
 from typing import List
+from typing import Optional
 from typing import Tuple
+from typing import TYPE_CHECKING
+from typing import Union
 from xml.dom import minidom

-import py
 import xmlschema

 import pytest
-from _pytest.compat import TYPE_CHECKING
 from _pytest.config import Config
 from _pytest.junitxml import bin_xml_escape
 from _pytest.junitxml import LogXML
-from _pytest.pathlib import Path
+from _pytest.monkeypatch import MonkeyPatch
+from _pytest.pytester import Pytester
+from _pytest.pytester import RunResult
 from _pytest.reports import BaseReport
 from _pytest.reports import TestReport
-from _pytest.store import Store
+from _pytest.stash import Stash


 @pytest.fixture(scope="session")
-def schema():
+def schema() -> xmlschema.XMLSchema:
     """Return an xmlschema.XMLSchema object for the junit-10.xsd file."""
     fn = Path(__file__).parent / "example_scripts/junit-10.xsd"
     with fn.open() as f:
         return xmlschema.XMLSchema(f)


+class RunAndParse:
+    def __init__(self, pytester: Pytester, schema: xmlschema.XMLSchema) -> None:
+        self.pytester = pytester
+        self.schema = schema
+
+    def __call__(
+        self, *args: Union[str, "os.PathLike[str]"], family: Optional[str] = "xunit1"
+    ) -> Tuple[RunResult, "DomNode"]:
+        if family:
+            args = ("-o", "junit_family=" + family) + args
+        xml_path = self.pytester.path.joinpath("junit.xml")
+        result = self.pytester.runpytest("--junitxml=%s" % xml_path, *args)
+        if family == "xunit2":
+            with xml_path.open() as f:
+                self.schema.validate(f)
+        xmldoc = minidom.parse(str(xml_path))
+        return result, DomNode(xmldoc)
+
+
 @pytest.fixture
-def run_and_parse(testdir, schema):
+def run_and_parse(pytester: Pytester, schema: xmlschema.XMLSchema) -> RunAndParse:
     """Fixture that returns a function that can be used to execute pytest and
     return the parsed ``DomNode`` of the root xml node.

     The ``family`` parameter is used to configure the ``junit_family`` of the written report.
     "xunit2" is also automatically validated against the schema.
     """
-
-    def run(*args, family="xunit1"):
-        if family:
-            args = ("-o", "junit_family=" + family) + args
-        xml_path = testdir.tmpdir.join("junit.xml")
-        result = testdir.runpytest("--junitxml=%s" % xml_path, *args)
-        if family == "xunit2":
-            with xml_path.open() as f:
-                schema.validate(f)
-        xmldoc = minidom.parse(str(xml_path))
-        return result, DomNode(xmldoc)
-
-    return run
+    return RunAndParse(pytester, schema)


 def assert_attr(node, **kwargs):
@@ -130,8 +141,10 @@

 class TestPython:
     @parametrize_families
-    def test_summing_simple(self, testdir, run_and_parse, xunit_family):
-        testdir.makepyfile(
+    def test_summing_simple(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest
             def test_pass():
@@ -154,8 +167,10 @@
         node.assert_attr(name="pytest", errors=0, failures=1, skipped=2, tests=5)

     @parametrize_families
-    def test_summing_simple_with_errors(self, testdir, run_and_parse, xunit_family):
-        testdir.makepyfile(
+    def test_summing_simple_with_errors(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture
@@ -181,8 +196,10 @@
         node.assert_attr(name="pytest", errors=1, failures=2, skipped=1, tests=5)

     @parametrize_families
-    def test_hostname_in_xml(self, testdir, run_and_parse, xunit_family):
-        testdir.makepyfile(
+    def test_hostname_in_xml(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makepyfile(
             """
             def test_pass():
                 pass
@@ -193,8 +210,10 @@
         node.assert_attr(hostname=platform.node())

     @parametrize_families
-    def test_timestamp_in_xml(self, testdir, run_and_parse, xunit_family):
-        testdir.makepyfile(
+    def test_timestamp_in_xml(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makepyfile(
             """
             def test_pass():
                 pass
@@ -206,8 +225,10 @@
         timestamp = datetime.strptime(node["timestamp"], "%Y-%m-%dT%H:%M:%S.%f")
         assert start_time <= timestamp < datetime.now()

-    def test_timing_function(self, testdir, run_and_parse, mock_timing):
-        testdir.makepyfile(
+    def test_timing_function(
+        self, pytester: Pytester, run_and_parse: RunAndParse, mock_timing
+    ) -> None:
+        pytester.makepyfile(
             """
             from _pytest import timing
             def setup_module():
@@ -226,8 +247,12 @@

     @pytest.mark.parametrize("duration_report", ["call", "total"])
     def test_junit_duration_report(
-        self, testdir, monkeypatch, duration_report, run_and_parse
-    ):
+        self,
+        pytester: Pytester,
+        monkeypatch: MonkeyPatch,
+        duration_report: str,
+        run_and_parse: RunAndParse,
+    ) -> None:

         # mock LogXML.node_reporter so it always sets a known duration to each test report object
         original_node_reporter = LogXML.node_reporter
@@ -239,15 +264,13 @@

         monkeypatch.setattr(LogXML, "node_reporter", node_reporter_wrapper)

-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_foo():
                 pass
         """
         )
-        result, dom = run_and_parse(
-            "-o", "junit_duration_report={}".format(duration_report)
-        )
+        result, dom = run_and_parse("-o", f"junit_duration_report={duration_report}")
         node = dom.find_first_by_tag("testsuite")
         tnode = node.find_first_by_tag("testcase")
         val = float(tnode["time"])
@@ -258,8 +281,10 @@
             assert val == 1.0

     @parametrize_families
-    def test_setup_error(self, testdir, run_and_parse, xunit_family):
-        testdir.makepyfile(
+    def test_setup_error(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -281,8 +306,10 @@
         assert "ValueError" in fnode.toxml()

     @parametrize_families
-    def test_teardown_error(self, testdir, run_and_parse, xunit_family):
-        testdir.makepyfile(
+    def test_teardown_error(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -304,8 +331,10 @@
         assert "ValueError" in fnode.toxml()

     @parametrize_families
-    def test_call_failure_teardown_error(self, testdir, run_and_parse, xunit_family):
-        testdir.makepyfile(
+    def test_call_failure_teardown_error(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -333,8 +362,10 @@
         )

     @parametrize_families
-    def test_skip_contains_name_reason(self, testdir, run_and_parse, xunit_family):
-        testdir.makepyfile(
+    def test_skip_contains_name_reason(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest
             def test_skip():
@@ -351,8 +382,10 @@
         snode.assert_attr(type="pytest.skip", message="hello23")

     @parametrize_families
-    def test_mark_skip_contains_name_reason(self, testdir, run_and_parse, xunit_family):
-        testdir.makepyfile(
+    def test_mark_skip_contains_name_reason(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.skip(reason="hello24")
@@ -373,9 +406,9 @@

     @parametrize_families
     def test_mark_skipif_contains_name_reason(
-        self, testdir, run_and_parse, xunit_family
-    ):
-        testdir.makepyfile(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest
             GLOBAL_CONDITION = True
@@ -397,9 +430,9 @@

     @parametrize_families
     def test_mark_skip_doesnt_capture_output(
-        self, testdir, run_and_parse, xunit_family
-    ):
-        testdir.makepyfile(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.skip(reason="foo")
@@ -413,8 +446,10 @@
         assert "bar!" not in node_xml

     @parametrize_families
-    def test_classname_instance(self, testdir, run_and_parse, xunit_family):
-        testdir.makepyfile(
+    def test_classname_instance(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makepyfile(
             """
             class TestClass(object):
                 def test_method(self):
@@ -431,9 +466,11 @@
         )

     @parametrize_families
-    def test_classname_nested_dir(self, testdir, run_and_parse, xunit_family):
-        p = testdir.tmpdir.ensure("sub", "test_hello.py")
-        p.write("def test_func(): 0/0")
+    def test_classname_nested_dir(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        p = pytester.mkdir("sub").joinpath("test_hello.py")
+        p.write_text("def test_func(): 0/0")
         result, dom = run_and_parse(family=xunit_family)
         assert result.ret
         node = dom.find_first_by_tag("testsuite")
@@ -442,9 +479,11 @@
         tnode.assert_attr(classname="sub.test_hello", name="test_func")

     @parametrize_families
-    def test_internal_error(self, testdir, run_and_parse, xunit_family):
-        testdir.makeconftest("def pytest_runtest_protocol(): 0 / 0")
-        testdir.makepyfile("def test_function(): pass")
+    def test_internal_error(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makeconftest("def pytest_runtest_protocol(): 0 / 0")
+        pytester.makepyfile("def test_function(): pass")
         result, dom = run_and_parse(family=xunit_family)
         assert result.ret
         node = dom.find_first_by_tag("testsuite")
@@ -460,9 +499,13 @@
     )
     @parametrize_families
     def test_failure_function(
-        self, testdir, junit_logging, run_and_parse, xunit_family
-    ):
-        testdir.makepyfile(
+        self,
+        pytester: Pytester,
+        junit_logging,
+        run_and_parse: RunAndParse,
+        xunit_family,
+    ) -> None:
+        pytester.makepyfile(
             """
             import logging
             import sys
@@ -523,8 +566,10 @@
             ), "Found unexpected content: system-err"

     @parametrize_families
-    def test_failure_verbose_message(self, testdir, run_and_parse, xunit_family):
-        testdir.makepyfile(
+    def test_failure_verbose_message(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makepyfile(
             """
             import sys
             def test_fail():
@@ -538,8 +583,10 @@
         fnode.assert_attr(message="AssertionError: An error\nassert 0")

     @parametrize_families
-    def test_failure_escape(self, testdir, run_and_parse, xunit_family):
-        testdir.makepyfile(
+    def test_failure_escape(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.parametrize('arg1', "<&'", ids="<&'")
@@ -566,8 +613,10 @@
             assert "%s\n" % char in text

     @parametrize_families
-    def test_junit_prefixing(self, testdir, run_and_parse, xunit_family):
-        testdir.makepyfile(
+    def test_junit_prefixing(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makepyfile(
             """
             def test_func():
                 assert 0
@@ -588,8 +637,10 @@
         )

     @parametrize_families
-    def test_xfailure_function(self, testdir, run_and_parse, xunit_family):
-        testdir.makepyfile(
+    def test_xfailure_function(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest
             def test_xfail():
@@ -606,8 +657,10 @@
         fnode.assert_attr(type="pytest.xfail", message="42")

     @parametrize_families
-    def test_xfailure_marker(self, testdir, run_and_parse, xunit_family):
-        testdir.makepyfile(
+    def test_xfailure_marker(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.xfail(reason="42")
@@ -627,8 +680,10 @@
     @pytest.mark.parametrize(
         "junit_logging", ["no", "log", "system-out", "system-err", "out-err", "all"]
     )
-    def test_xfail_captures_output_once(self, testdir, junit_logging, run_and_parse):
-        testdir.makepyfile(
+    def test_xfail_captures_output_once(
+        self, pytester: Pytester, junit_logging: str, run_and_parse: RunAndParse
+    ) -> None:
+        pytester.makepyfile(
             """
             import sys
             import pytest
@@ -654,8 +709,10 @@
             assert len(tnode.find_by_tag("system-out")) == 0

     @parametrize_families
-    def test_xfailure_xpass(self, testdir, run_and_parse, xunit_family):
-        testdir.makepyfile(
+    def test_xfailure_xpass(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.xfail
@@ -671,8 +728,10 @@
         tnode.assert_attr(classname="test_xfailure_xpass", name="test_xpass")

     @parametrize_families
-    def test_xfailure_xpass_strict(self, testdir, run_and_parse, xunit_family):
-        testdir.makepyfile(
+    def test_xfailure_xpass_strict(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.xfail(strict=True, reason="This needs to fail!")
@@ -690,8 +749,10 @@
         fnode.assert_attr(message="[XPASS(strict)] This needs to fail!")

     @parametrize_families
-    def test_collect_error(self, testdir, run_and_parse, xunit_family):
-        testdir.makepyfile("syntax error")
+    def test_collect_error(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makepyfile("syntax error")
         result, dom = run_and_parse(family=xunit_family)
         assert result.ret
         node = dom.find_first_by_tag("testsuite")
@@ -701,9 +762,9 @@
         fnode.assert_attr(message="collection failure")
         assert "SyntaxError" in fnode.toxml()

-    def test_unicode(self, testdir, run_and_parse):
+    def test_unicode(self, pytester: Pytester, run_and_parse: RunAndParse) -> None:
         value = "hx\xc4\x85\xc4\x87\n"
-        testdir.makepyfile(
+        pytester.makepyfile(
             """\
             # coding: latin1
             def test_hello():
@@ -718,9 +779,11 @@
         fnode = tnode.find_first_by_tag("failure")
         assert "hx" in fnode.toxml()

-    def test_assertion_binchars(self, testdir, run_and_parse):
+    def test_assertion_binchars(
+        self, pytester: Pytester, run_and_parse: RunAndParse
+    ) -> None:
         """This test did fail when the escaping wasn't strict."""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """

             M1 = '\x01\x02\x03\x04'
@@ -734,8 +797,10 @@
         print(dom.toxml())

     @pytest.mark.parametrize("junit_logging", ["no", "system-out"])
-    def test_pass_captures_stdout(self, testdir, run_and_parse, junit_logging):
-        testdir.makepyfile(
+    def test_pass_captures_stdout(
+        self, pytester: Pytester, run_and_parse: RunAndParse, junit_logging: str
+    ) -> None:
+        pytester.makepyfile(
             """
             def test_pass():
                 print('hello-stdout')
@@ -755,8 +820,10 @@
             ), "'hello-stdout' should be in system-out"

     @pytest.mark.parametrize("junit_logging", ["no", "system-err"])
-    def test_pass_captures_stderr(self, testdir, run_and_parse, junit_logging):
-        testdir.makepyfile(
+    def test_pass_captures_stderr(
+        self, pytester: Pytester, run_and_parse: RunAndParse, junit_logging: str
+    ) -> None:
+        pytester.makepyfile(
             """
             import sys
             def test_pass():
@@ -777,8 +844,10 @@
             ), "'hello-stderr' should be in system-err"

     @pytest.mark.parametrize("junit_logging", ["no", "system-out"])
-    def test_setup_error_captures_stdout(self, testdir, run_and_parse, junit_logging):
-        testdir.makepyfile(
+    def test_setup_error_captures_stdout(
+        self, pytester: Pytester, run_and_parse: RunAndParse, junit_logging: str
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -804,8 +873,10 @@
             ), "'hello-stdout' should be in system-out"

     @pytest.mark.parametrize("junit_logging", ["no", "system-err"])
-    def test_setup_error_captures_stderr(self, testdir, run_and_parse, junit_logging):
-        testdir.makepyfile(
+    def test_setup_error_captures_stderr(
+        self, pytester: Pytester, run_and_parse: RunAndParse, junit_logging: str
+    ) -> None:
+        pytester.makepyfile(
             """
             import sys
             import pytest
@@ -832,8 +903,10 @@
             ), "'hello-stderr' should be in system-err"

     @pytest.mark.parametrize("junit_logging", ["no", "system-out"])
-    def test_avoid_double_stdout(self, testdir, run_and_parse, junit_logging):
-        testdir.makepyfile(
+    def test_avoid_double_stdout(
+        self, pytester: Pytester, run_and_parse: RunAndParse, junit_logging: str
+    ) -> None:
+        pytester.makepyfile(
             """
             import sys
             import pytest
@@ -860,16 +933,16 @@
             assert "hello-stdout teardown" in systemout.toxml()


-def test_mangle_test_address():
+def test_mangle_test_address() -> None:
     from _pytest.junitxml import mangle_test_address

-    address = "::".join(["a/my.py.thing.py", "Class", "()", "method", "[a-1-::]"])
+    address = "::".join(["a/my.py.thing.py", "Class", "method", "[a-1-::]"])
     newnames = mangle_test_address(address)
     assert newnames == ["a.my.py.thing", "Class", "method", "[a-1-::]"]


-def test_dont_configure_on_workers(tmpdir) -> None:
-    gotten = []  # type: List[object]
+def test_dont_configure_on_workers(tmp_path: Path) -> None:
+    gotten: List[object] = []

     class FakeConfig:
         if TYPE_CHECKING:
@@ -878,14 +951,14 @@
         def __init__(self):
             self.pluginmanager = self
             self.option = self
-            self._store = Store()
+            self.stash = Stash()

         def getini(self, name):
             return "pytest"

         junitprefix = None
-        # XXX: shouldn't need tmpdir ?
-        xmlpath = str(tmpdir.join("junix.xml"))
+        # XXX: shouldn't need tmp_path ?
+        xmlpath = str(tmp_path.joinpath("junix.xml"))
         register = gotten.append

     fake_config = cast(Config, FakeConfig())
@@ -900,13 +973,15 @@

 class TestNonPython:
     @parametrize_families
-    def test_summing_simple(self, testdir, run_and_parse, xunit_family):
-        testdir.makeconftest(
-            """
-            import pytest
-            def pytest_collect_file(path, parent):
-                if path.ext == ".xyz":
-                    return MyItem.from_parent(name=path.basename, parent=parent)
+    def test_summing_simple(
+        self, pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+    ) -> None:
+        pytester.makeconftest(
+            """
+            import pytest
+            def pytest_collect_file(file_path, parent):
+                if file_path.suffix == ".xyz":
+                    return MyItem.from_parent(name=file_path.name, parent=parent)
             class MyItem(pytest.Item):
                 def runtest(self):
                     raise ValueError(42)
@@ -914,7 +989,7 @@
                     return "custom item runtest failed"
         """
         )
-        testdir.tmpdir.join("myfile.xyz").write("hello")
+        pytester.path.joinpath("myfile.xyz").write_text("hello")
         result, dom = run_and_parse(family=xunit_family)
         assert result.ret
         node = dom.find_first_by_tag("testsuite")
@@ -927,9 +1002,9 @@


 @pytest.mark.parametrize("junit_logging", ["no", "system-out"])
-def test_nullbyte(testdir, junit_logging):
+def test_nullbyte(pytester: Pytester, junit_logging: str) -> None:
     # A null byte can not occur in XML (see section 2.2 of the spec)
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import sys
         def test_print_nullbyte():
@@ -938,9 +1013,9 @@
             assert False
     """
     )
-    xmlf = testdir.tmpdir.join("junit.xml")
-    testdir.runpytest("--junitxml=%s" % xmlf, "-o", "junit_logging=%s" % junit_logging)
-    text = xmlf.read()
+    xmlf = pytester.path.joinpath("junit.xml")
+    pytester.runpytest("--junitxml=%s" % xmlf, "-o", "junit_logging=%s" % junit_logging)
+    text = xmlf.read_text()
     assert "\x00" not in text
     if junit_logging == "system-out":
         assert "#x00" in text
@@ -949,9 +1024,9 @@


 @pytest.mark.parametrize("junit_logging", ["no", "system-out"])
-def test_nullbyte_replace(testdir, junit_logging):
+def test_nullbyte_replace(pytester: Pytester, junit_logging: str) -> None:
     # Check if the null byte gets replaced
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import sys
         def test_print_nullbyte():
@@ -960,16 +1035,16 @@
             assert False
     """
     )
-    xmlf = testdir.tmpdir.join("junit.xml")
-    testdir.runpytest("--junitxml=%s" % xmlf, "-o", "junit_logging=%s" % junit_logging)
-    text = xmlf.read()
+    xmlf = pytester.path.joinpath("junit.xml")
+    pytester.runpytest("--junitxml=%s" % xmlf, "-o", "junit_logging=%s" % junit_logging)
+    text = xmlf.read_text()
     if junit_logging == "system-out":
         assert "#x0" in text
     if junit_logging == "no":
         assert "#x0" not in text


-def test_invalid_xml_escape():
+def test_invalid_xml_escape() -> None:
     # Test some more invalid xml chars, the full range should be
     # tested really but let's just test the edges of the ranges
     # instead.
@@ -1005,52 +1080,54 @@
         assert chr(i) == bin_xml_escape(chr(i))


-def test_logxml_path_expansion(tmpdir, monkeypatch):
-    home_tilde = py.path.local(os.path.expanduser("~")).join("test.xml")
-    xml_tilde = LogXML("~%stest.xml" % tmpdir.sep, None)
-    assert xml_tilde.logfile == home_tilde
-
-    monkeypatch.setenv("HOME", str(tmpdir))
+def test_logxml_path_expansion(tmp_path: Path, monkeypatch: MonkeyPatch) -> None:
+    home_tilde = Path(os.path.expanduser("~")).joinpath("test.xml")
+    xml_tilde = LogXML(Path("~", "test.xml"), None)
+    assert xml_tilde.logfile == str(home_tilde)
+
+    monkeypatch.setenv("HOME", str(tmp_path))
     home_var = os.path.normpath(os.path.expandvars("$HOME/test.xml"))
-    xml_var = LogXML("$HOME%stest.xml" % tmpdir.sep, None)
-    assert xml_var.logfile == home_var
-
-
-def test_logxml_changingdir(testdir):
-    testdir.makepyfile(
+    xml_var = LogXML(Path("$HOME", "test.xml"), None)
+    assert xml_var.logfile == str(home_var)
+
+
+def test_logxml_changingdir(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         def test_func():
             import os
             os.chdir("a")
     """
     )
-    testdir.tmpdir.mkdir("a")
-    result = testdir.runpytest("--junitxml=a/x.xml")
+    pytester.mkdir("a")
+    result = pytester.runpytest("--junitxml=a/x.xml")
     assert result.ret == 0
-    assert testdir.tmpdir.join("a/x.xml").check()
-
-
-def test_logxml_makedir(testdir):
+    assert pytester.path.joinpath("a/x.xml").exists()
+
+
+def test_logxml_makedir(pytester: Pytester) -> None:
     """--junitxml should automatically create directories for the xml file"""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         def test_pass():
             pass
     """
     )
-    result = testdir.runpytest("--junitxml=path/to/results.xml")
+    result = pytester.runpytest("--junitxml=path/to/results.xml")
     assert result.ret == 0
-    assert testdir.tmpdir.join("path/to/results.xml").check()
-
-
-def test_logxml_check_isdir(testdir):
+    assert pytester.path.joinpath("path/to/results.xml").exists()
+
+
+def test_logxml_check_isdir(pytester: Pytester) -> None:
     """Give an error if --junit-xml is a directory (#2089)"""
-    result = testdir.runpytest("--junit-xml=.")
+    result = pytester.runpytest("--junit-xml=.")
     result.stderr.fnmatch_lines(["*--junitxml must be a filename*"])


-def test_escaped_parametrized_names_xml(testdir, run_and_parse):
-    testdir.makepyfile(
+def test_escaped_parametrized_names_xml(
+    pytester: Pytester, run_and_parse: RunAndParse
+) -> None:
+    pytester.makepyfile(
         """\
         import pytest
         @pytest.mark.parametrize('char', ["\\x00"])
@@ -1064,8 +1141,10 @@
     node.assert_attr(name="test_func[\\x00]")


-def test_double_colon_split_function_issue469(testdir, run_and_parse):
-    testdir.makepyfile(
+def test_double_colon_split_function_issue469(
+    pytester: Pytester, run_and_parse: RunAndParse
+) -> None:
+    pytester.makepyfile(
         """
         import pytest
         @pytest.mark.parametrize('param', ["double::colon"])
@@ -1080,8 +1159,10 @@
     node.assert_attr(name="test_func[double::colon]")


-def test_double_colon_split_method_issue469(testdir, run_and_parse):
-    testdir.makepyfile(
+def test_double_colon_split_method_issue469(
+    pytester: Pytester, run_and_parse: RunAndParse
+) -> None:
+    pytester.makepyfile(
         """
         import pytest
         class TestClass(object):
@@ -1097,16 +1178,17 @@
     node.assert_attr(name="test_func[double::colon]")


-def test_unicode_issue368(testdir) -> None:
-    path = testdir.tmpdir.join("test.xml")
+def test_unicode_issue368(pytester: Pytester) -> None:
+    path = pytester.path.joinpath("test.xml")
     log = LogXML(str(path), None)
     ustr = "ВНИ!"

     class Report(BaseReport):
         longrepr = ustr
-        sections = []  # type: List[Tuple[str, str]]
+        sections: List[Tuple[str, str]] = []
         nodeid = "something"
         location = "tests/filename.py", 42, "TestClass.method"
+        when = "teardown"

     test_report = cast(TestReport, Report())

@@ -1126,8 +1208,8 @@
     log.pytest_sessionfinish()


-def test_record_property(testdir, run_and_parse):
-    testdir.makepyfile(
+def test_record_property(pytester: Pytester, run_and_parse: RunAndParse) -> None:
+    pytester.makepyfile(
         """
         import pytest

@@ -1148,8 +1230,10 @@
     result.stdout.fnmatch_lines(["*= 1 passed in *"])


-def test_record_property_same_name(testdir, run_and_parse):
-    testdir.makepyfile(
+def test_record_property_same_name(
+    pytester: Pytester, run_and_parse: RunAndParse
+) -> None:
+    pytester.makepyfile(
         """
         def test_record_with_same_name(record_property):
             record_property("foo", "bar")
@@ -1166,8 +1250,10 @@


 @pytest.mark.parametrize("fixture_name", ["record_property", "record_xml_attribute"])
-def test_record_fixtures_without_junitxml(testdir, fixture_name):
-    testdir.makepyfile(
+def test_record_fixtures_without_junitxml(
+    pytester: Pytester, fixture_name: str
+) -> None:
+    pytester.makepyfile(
         """
         def test_record({fixture_name}):
             {fixture_name}("foo", "bar")
@@ -1175,19 +1261,19 @@
             fixture_name=fixture_name
         )
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert result.ret == 0


 @pytest.mark.filterwarnings("default")
-def test_record_attribute(testdir, run_and_parse):
-    testdir.makeini(
+def test_record_attribute(pytester: Pytester, run_and_parse: RunAndParse) -> None:
+    pytester.makeini(
         """
         [pytest]
         junit_family = xunit1
     """
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest

@@ -1210,15 +1296,17 @@

 @pytest.mark.filterwarnings("default")
 @pytest.mark.parametrize("fixture_name", ["record_xml_attribute", "record_property"])
-def test_record_fixtures_xunit2(testdir, fixture_name, run_and_parse):
+def test_record_fixtures_xunit2(
+    pytester: Pytester, fixture_name: str, run_and_parse: RunAndParse
+) -> None:
     """Ensure record_xml_attribute and record_property drop values when outside of legacy family."""
-    testdir.makeini(
+    pytester.makeini(
         """
         [pytest]
         junit_family = xunit2
     """
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest

@@ -1247,13 +1335,15 @@
     result.stdout.fnmatch_lines(expected_lines)


-def test_random_report_log_xdist(testdir, monkeypatch, run_and_parse):
+def test_random_report_log_xdist(
+    pytester: Pytester, monkeypatch: MonkeyPatch, run_and_parse: RunAndParse
+) -> None:
     """`xdist` calls pytest_runtest_logreport as they are executed by the workers,
     with nodes from several nodes overlapping, so junitxml must cope with that
     to produce correct reports (#1064)."""
     pytest.importorskip("xdist")
     monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD", raising=False)
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest, time
         @pytest.mark.parametrize('i', list(range(30)))
@@ -1272,8 +1362,10 @@


 @parametrize_families
-def test_root_testsuites_tag(testdir, run_and_parse, xunit_family):
-    testdir.makepyfile(
+def test_root_testsuites_tag(
+    pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+) -> None:
+    pytester.makepyfile(
         """
         def test_x():
             pass
@@ -1286,8 +1378,8 @@
     assert suite_node.tag == "testsuite"


-def test_runs_twice(testdir, run_and_parse):
-    f = testdir.makepyfile(
+def test_runs_twice(pytester: Pytester, run_and_parse: RunAndParse) -> None:
+    f = pytester.makepyfile(
         """
         def test_pass():
             pass
@@ -1296,14 +1388,16 @@

     result, dom = run_and_parse(f, f)
     result.stdout.no_fnmatch_line("*INTERNALERROR*")
-    first, second = [x["classname"] for x in dom.find_by_tag("testcase")]
+    first, second = (x["classname"] for x in dom.find_by_tag("testcase"))
     assert first == second


-def test_runs_twice_xdist(testdir, run_and_parse):
+def test_runs_twice_xdist(
+    pytester: Pytester, monkeypatch: MonkeyPatch, run_and_parse: RunAndParse
+) -> None:
     pytest.importorskip("xdist")
-    testdir.monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD")
-    f = testdir.makepyfile(
+    monkeypatch.delenv("PYTEST_DISABLE_PLUGIN_AUTOLOAD")
+    f = pytester.makepyfile(
         """
         def test_pass():
             pass
@@ -1312,13 +1406,13 @@

     result, dom = run_and_parse(f, "--dist", "each", "--tx", "2*popen")
     result.stdout.no_fnmatch_line("*INTERNALERROR*")
-    first, second = [x["classname"] for x in dom.find_by_tag("testcase")]
+    first, second = (x["classname"] for x in dom.find_by_tag("testcase"))
     assert first == second


-def test_fancy_items_regression(testdir, run_and_parse):
+def test_fancy_items_regression(pytester: Pytester, run_and_parse: RunAndParse) -> None:
     # issue 1259
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         import pytest
         class FunItem(pytest.Item):
@@ -1336,13 +1430,13 @@
                     NoFunItem.from_parent(name='b', parent=self),
                 ]

-        def pytest_collect_file(path, parent):
-            if path.check(ext='.py'):
-                return FunCollector.from_parent(fspath=path, parent=parent)
-    """
-    )
-
-    testdir.makepyfile(
+        def pytest_collect_file(file_path, parent):
+            if file_path.suffix == '.py':
+                return FunCollector.from_parent(path=file_path, parent=parent)
+    """
+    )
+
+    pytester.makepyfile(
         """
         def test_pass():
             pass
@@ -1369,12 +1463,12 @@


 @parametrize_families
-def test_global_properties(testdir, xunit_family) -> None:
-    path = testdir.tmpdir.join("test_global_properties.xml")
+def test_global_properties(pytester: Pytester, xunit_family: str) -> None:
+    path = pytester.path.joinpath("test_global_properties.xml")
     log = LogXML(str(path), None, family=xunit_family)

     class Report(BaseReport):
-        sections = []  # type: List[Tuple[str, str]]
+        sections: List[Tuple[str, str]] = []
         nodeid = "test_node_id"

     log.pytest_sessionstart()
@@ -1403,14 +1497,14 @@
     assert actual == expected


-def test_url_property(testdir) -> None:
+def test_url_property(pytester: Pytester) -> None:
     test_url = "http://www.github.com/pytest-dev"
-    path = testdir.tmpdir.join("test_url_property.xml")
+    path = pytester.path.joinpath("test_url_property.xml")
     log = LogXML(str(path), None)

     class Report(BaseReport):
         longrepr = "FooBarBaz"
-        sections = []  # type: List[Tuple[str, str]]
+        sections: List[Tuple[str, str]] = []
         nodeid = "something"
         location = "tests/filename.py", 42, "TestClass.method"
         url = test_url
@@ -1430,8 +1524,10 @@


 @parametrize_families
-def test_record_testsuite_property(testdir, run_and_parse, xunit_family):
-    testdir.makepyfile(
+def test_record_testsuite_property(
+    pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+) -> None:
+    pytester.makepyfile(
         """
         def test_func1(record_testsuite_property):
             record_testsuite_property("stats", "all good")
@@ -1450,27 +1546,29 @@
     p2_node.assert_attr(name="stats", value="10")


-def test_record_testsuite_property_junit_disabled(testdir):
-    testdir.makepyfile(
+def test_record_testsuite_property_junit_disabled(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         def test_func1(record_testsuite_property):
             record_testsuite_property("stats", "all good")
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert result.ret == 0


 @pytest.mark.parametrize("junit", [True, False])
-def test_record_testsuite_property_type_checking(testdir, junit):
-    testdir.makepyfile(
+def test_record_testsuite_property_type_checking(
+    pytester: Pytester, junit: bool
+) -> None:
+    pytester.makepyfile(
         """
         def test_func1(record_testsuite_property):
             record_testsuite_property(1, 2)
     """
     )
     args = ("--junitxml=tests.xml",) if junit else ()
-    result = testdir.runpytest(*args)
+    result = pytester.runpytest(*args)
     assert result.ret == 1
     result.stdout.fnmatch_lines(
         ["*TypeError: name parameter needs to be a string, but int given"]
@@ -1479,9 +1577,11 @@

 @pytest.mark.parametrize("suite_name", ["my_suite", ""])
 @parametrize_families
-def test_set_suite_name(testdir, suite_name, run_and_parse, xunit_family):
+def test_set_suite_name(
+    pytester: Pytester, suite_name: str, run_and_parse: RunAndParse, xunit_family: str
+) -> None:
     if suite_name:
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
             junit_suite_name={suite_name}
@@ -1493,7 +1593,7 @@
         expected = suite_name
     else:
         expected = "pytest"
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest

@@ -1507,8 +1607,10 @@
     node.assert_attr(name=expected)


-def test_escaped_skipreason_issue3533(testdir, run_and_parse):
-    testdir.makepyfile(
+def test_escaped_skipreason_issue3533(
+    pytester: Pytester, run_and_parse: RunAndParse
+) -> None:
+    pytester.makepyfile(
         """
         import pytest
         @pytest.mark.skip(reason='1 <> 2')
@@ -1525,9 +1627,9 @@

 @parametrize_families
 def test_logging_passing_tests_disabled_does_not_log_test_output(
-    testdir, run_and_parse, xunit_family
-):
-    testdir.makeini(
+    pytester: Pytester, run_and_parse: RunAndParse, xunit_family: str
+) -> None:
+    pytester.makeini(
         """
         [pytest]
         junit_log_passing_tests=False
@@ -1537,7 +1639,7 @@
             family=xunit_family
         )
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         import logging
@@ -1559,9 +1661,12 @@
 @parametrize_families
 @pytest.mark.parametrize("junit_logging", ["no", "system-out", "system-err"])
 def test_logging_passing_tests_disabled_logs_output_for_failing_test_issue5430(
-    testdir, junit_logging, run_and_parse, xunit_family
-):
-    testdir.makeini(
+    pytester: Pytester,
+    junit_logging: str,
+    run_and_parse: RunAndParse,
+    xunit_family: str,
+) -> None:
+    pytester.makeini(
         """
         [pytest]
         junit_log_passing_tests=False
@@ -1570,7 +1675,7 @@
             family=xunit_family
         )
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         import logging
('testing', 'test_runner_xunit.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -2,10 +2,11 @@
 from typing import List

 import pytest
-
-
-def test_module_and_function_setup(testdir):
-    reprec = testdir.inline_runsource(
+from _pytest.pytester import Pytester
+
+
+def test_module_and_function_setup(pytester: Pytester) -> None:
+    reprec = pytester.inline_runsource(
         """
         modlevel = []
         def setup_module(module):
@@ -37,8 +38,8 @@
     assert rep.passed


-def test_module_setup_failure_no_teardown(testdir):
-    reprec = testdir.inline_runsource(
+def test_module_setup_failure_no_teardown(pytester: Pytester) -> None:
+    reprec = pytester.inline_runsource(
         """
         values = []
         def setup_module(module):
@@ -57,8 +58,8 @@
     assert calls[0].item.module.values == [1]


-def test_setup_function_failure_no_teardown(testdir):
-    reprec = testdir.inline_runsource(
+def test_setup_function_failure_no_teardown(pytester: Pytester) -> None:
+    reprec = pytester.inline_runsource(
         """
         modlevel = []
         def setup_function(function):
@@ -76,8 +77,8 @@
     assert calls[0].item.module.modlevel == [1]


-def test_class_setup(testdir):
-    reprec = testdir.inline_runsource(
+def test_class_setup(pytester: Pytester) -> None:
+    reprec = pytester.inline_runsource(
         """
         class TestSimpleClassSetup(object):
             clslevel = []
@@ -102,8 +103,8 @@
     reprec.assertoutcome(passed=1 + 2 + 1)


-def test_class_setup_failure_no_teardown(testdir):
-    reprec = testdir.inline_runsource(
+def test_class_setup_failure_no_teardown(pytester: Pytester) -> None:
+    reprec = pytester.inline_runsource(
         """
         class TestSimpleClassSetup(object):
             clslevel = []
@@ -123,8 +124,8 @@
     reprec.assertoutcome(failed=1, passed=1)


-def test_method_setup(testdir):
-    reprec = testdir.inline_runsource(
+def test_method_setup(pytester: Pytester) -> None:
+    reprec = pytester.inline_runsource(
         """
         class TestSetupMethod(object):
             def setup_method(self, meth):
@@ -142,8 +143,8 @@
     reprec.assertoutcome(passed=2)


-def test_method_setup_failure_no_teardown(testdir):
-    reprec = testdir.inline_runsource(
+def test_method_setup_failure_no_teardown(pytester: Pytester) -> None:
+    reprec = pytester.inline_runsource(
         """
         class TestMethodSetup(object):
             clslevel = []
@@ -164,8 +165,8 @@
     reprec.assertoutcome(failed=1, passed=1)


-def test_method_setup_uses_fresh_instances(testdir):
-    reprec = testdir.inline_runsource(
+def test_method_setup_uses_fresh_instances(pytester: Pytester) -> None:
+    reprec = pytester.inline_runsource(
         """
         class TestSelfState1(object):
             memory = []
@@ -179,8 +180,8 @@
     reprec.assertoutcome(passed=2, failed=0)


-def test_setup_that_skips_calledagain(testdir):
-    p = testdir.makepyfile(
+def test_setup_that_skips_calledagain(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
         """
         import pytest
         def setup_module(mod):
@@ -191,12 +192,12 @@
             pass
     """
     )
-    reprec = testdir.inline_run(p)
+    reprec = pytester.inline_run(p)
     reprec.assertoutcome(skipped=2)


-def test_setup_fails_again_on_all_tests(testdir):
-    p = testdir.makepyfile(
+def test_setup_fails_again_on_all_tests(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
         """
         import pytest
         def setup_module(mod):
@@ -207,12 +208,12 @@
             pass
     """
     )
-    reprec = testdir.inline_run(p)
+    reprec = pytester.inline_run(p)
     reprec.assertoutcome(failed=2)


-def test_setup_funcarg_setup_when_outer_scope_fails(testdir):
-    p = testdir.makepyfile(
+def test_setup_funcarg_setup_when_outer_scope_fails(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
         """
         import pytest
         def setup_module(mod):
@@ -226,7 +227,7 @@
             pass
     """
     )
-    result = testdir.runpytest(p)
+    result = pytester.runpytest(p)
     result.stdout.fnmatch_lines(
         [
             "*function1*",
@@ -241,16 +242,18 @@

 @pytest.mark.parametrize("arg", ["", "arg"])
 def test_setup_teardown_function_level_with_optional_argument(
-    testdir, monkeypatch, arg: str,
+    pytester: Pytester,
+    monkeypatch,
+    arg: str,
 ) -> None:
     """Parameter to setup/teardown xunit-style functions parameter is now optional (#1728)."""
     import sys

-    trace_setups_teardowns = []  # type: List[str]
+    trace_setups_teardowns: List[str] = []
     monkeypatch.setattr(
         sys, "trace_setups_teardowns", trace_setups_teardowns, raising=False
     )
-    p = testdir.makepyfile(
+    p = pytester.makepyfile(
         """
         import pytest
         import sys
@@ -276,7 +279,7 @@
             arg=arg
         )
     )
-    result = testdir.inline_run(p)
+    result = pytester.inline_run(p)
     result.assertoutcome(passed=4)

     expected = [
('testing', 'test_stepwise.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,11 +1,13 @@
 import pytest
+from _pytest.monkeypatch import MonkeyPatch
+from _pytest.pytester import Pytester


 @pytest.fixture
-def stepwise_testdir(testdir):
+def stepwise_pytester(pytester: Pytester) -> Pytester:
     # Rather than having to modify our testfile between tests, we introduce
     # a flag for whether or not the second test should fail.
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
 def pytest_addoption(parser):
     group = parser.getgroup('general')
@@ -15,7 +17,7 @@
     )

     # Create a simple test suite.
-    testdir.makepyfile(
+    pytester.makepyfile(
         test_a="""
 def test_success_before_fail():
     assert 1
@@ -34,7 +36,7 @@
 """
     )

-    testdir.makepyfile(
+    pytester.makepyfile(
         test_b="""
 def test_success():
     assert 1
@@ -42,19 +44,19 @@
     )

     # customize cache directory so we don't use the tox's cache directory, which makes tests in this module flaky
-    testdir.makeini(
+    pytester.makeini(
         """
         [pytest]
         cache_dir = .cache
     """
     )

-    return testdir
+    return pytester


 @pytest.fixture
-def error_testdir(testdir):
-    testdir.makepyfile(
+def error_pytester(pytester: Pytester) -> Pytester:
+    pytester.makepyfile(
         test_a="""
 def test_error(nonexisting_fixture):
     assert 1
@@ -64,15 +66,15 @@
 """
     )

-    return testdir
+    return pytester


 @pytest.fixture
-def broken_testdir(testdir):
-    testdir.makepyfile(
+def broken_pytester(pytester: Pytester) -> Pytester:
+    pytester.makepyfile(
         working_testfile="def test_proper(): assert 1", broken_testfile="foobar"
     )
-    return testdir
+    return pytester


 def _strip_resource_warnings(lines):
@@ -85,17 +87,33 @@
     ]


-def test_run_without_stepwise(stepwise_testdir):
-    result = stepwise_testdir.runpytest("-v", "--strict-markers", "--fail")
-
+def test_run_without_stepwise(stepwise_pytester: Pytester) -> None:
+    result = stepwise_pytester.runpytest("-v", "--strict-markers", "--fail")
     result.stdout.fnmatch_lines(["*test_success_before_fail PASSED*"])
     result.stdout.fnmatch_lines(["*test_fail_on_flag FAILED*"])
     result.stdout.fnmatch_lines(["*test_success_after_fail PASSED*"])


-def test_fail_and_continue_with_stepwise(stepwise_testdir):
+def test_stepwise_output_summary(pytester: Pytester) -> None:
+    pytester.makepyfile(
+        """
+        import pytest
+        @pytest.mark.parametrize("expected", [True, True, True, True, False])
+        def test_data(expected):
+            assert expected
+        """
+    )
+    result = pytester.runpytest("-v", "--stepwise")
+    result.stdout.fnmatch_lines(["stepwise: no previously failed tests, not skipping."])
+    result = pytester.runpytest("-v", "--stepwise")
+    result.stdout.fnmatch_lines(
+        ["stepwise: skipping 4 already passed items.", "*1 failed, 4 deselected*"]
+    )
+
+
+def test_fail_and_continue_with_stepwise(stepwise_pytester: Pytester) -> None:
     # Run the tests with a failing second test.
-    result = stepwise_testdir.runpytest(
+    result = stepwise_pytester.runpytest(
         "-v", "--strict-markers", "--stepwise", "--fail"
     )
     assert _strip_resource_warnings(result.stderr.lines) == []
@@ -107,7 +125,7 @@
     assert "test_success_after_fail" not in stdout

     # "Fix" the test that failed in the last run and run it again.
-    result = stepwise_testdir.runpytest("-v", "--strict-markers", "--stepwise")
+    result = stepwise_pytester.runpytest("-v", "--strict-markers", "--stepwise")
     assert _strip_resource_warnings(result.stderr.lines) == []

     stdout = result.stdout.str()
@@ -117,12 +135,13 @@
     assert "test_success_after_fail PASSED" in stdout


-def test_run_with_skip_option(stepwise_testdir):
-    result = stepwise_testdir.runpytest(
+@pytest.mark.parametrize("stepwise_skip", ["--stepwise-skip", "--sw-skip"])
+def test_run_with_skip_option(stepwise_pytester: Pytester, stepwise_skip: str) -> None:
+    result = stepwise_pytester.runpytest(
         "-v",
         "--strict-markers",
         "--stepwise",
-        "--stepwise-skip",
+        stepwise_skip,
         "--fail",
         "--fail-last",
     )
@@ -136,8 +155,8 @@
     assert "test_success_after_last_fail" not in stdout


-def test_fail_on_errors(error_testdir):
-    result = error_testdir.runpytest("-v", "--strict-markers", "--stepwise")
+def test_fail_on_errors(error_pytester: Pytester) -> None:
+    result = error_pytester.runpytest("-v", "--strict-markers", "--stepwise")

     assert _strip_resource_warnings(result.stderr.lines) == []
     stdout = result.stdout.str()
@@ -146,8 +165,8 @@
     assert "test_success_after_fail" not in stdout


-def test_change_testfile(stepwise_testdir):
-    result = stepwise_testdir.runpytest(
+def test_change_testfile(stepwise_pytester: Pytester) -> None:
+    result = stepwise_pytester.runpytest(
         "-v", "--strict-markers", "--stepwise", "--fail", "test_a.py"
     )
     assert _strip_resource_warnings(result.stderr.lines) == []
@@ -157,7 +176,7 @@

     # Make sure the second test run starts from the beginning, since the
     # test to continue from does not exist in testfile_b.
-    result = stepwise_testdir.runpytest(
+    result = stepwise_pytester.runpytest(
         "-v", "--strict-markers", "--stepwise", "test_b.py"
     )
     assert _strip_resource_warnings(result.stderr.lines) == []
@@ -167,17 +186,19 @@


 @pytest.mark.parametrize("broken_first", [True, False])
-def test_stop_on_collection_errors(broken_testdir, broken_first):
+def test_stop_on_collection_errors(
+    broken_pytester: Pytester, broken_first: bool
+) -> None:
     """Stop during collection errors. Broken test first or broken test last
     actually surfaced a bug (#5444), so we test both situations."""
     files = ["working_testfile.py", "broken_testfile.py"]
     if broken_first:
         files.reverse()
-    result = broken_testdir.runpytest("-v", "--strict-markers", "--stepwise", *files)
+    result = broken_pytester.runpytest("-v", "--strict-markers", "--stepwise", *files)
     result.stdout.fnmatch_lines("*error during collection*")


-def test_xfail_handling(testdir, monkeypatch):
+def test_xfail_handling(pytester: Pytester, monkeypatch: MonkeyPatch) -> None:
     """Ensure normal xfail is ignored, and strict xfail interrupts the session in sw mode

     (#5547)
@@ -194,8 +215,8 @@
         def test_c(): pass
         def test_d(): pass
     """
-    testdir.makepyfile(contents.format(assert_value="0", strict="False"))
-    result = testdir.runpytest("--sw", "-v")
+    pytester.makepyfile(contents.format(assert_value="0", strict="False"))
+    result = pytester.runpytest("--sw", "-v")
     result.stdout.fnmatch_lines(
         [
             "*::test_a PASSED *",
@@ -206,8 +227,8 @@
         ]
     )

-    testdir.makepyfile(contents.format(assert_value="1", strict="True"))
-    result = testdir.runpytest("--sw", "-v")
+    pytester.makepyfile(contents.format(assert_value="1", strict="True"))
+    result = pytester.runpytest("--sw", "-v")
     result.stdout.fnmatch_lines(
         [
             "*::test_a PASSED *",
@@ -217,8 +238,8 @@
         ]
     )

-    testdir.makepyfile(contents.format(assert_value="0", strict="True"))
-    result = testdir.runpytest("--sw", "-v")
+    pytester.makepyfile(contents.format(assert_value="0", strict="True"))
+    result = pytester.runpytest("--sw", "-v")
     result.stdout.fnmatch_lines(
         [
             "*::test_b XFAIL *",
@@ -227,3 +248,33 @@
             "* 2 passed, 1 deselected, 1 xfailed in *",
         ]
     )
+
+
+def test_stepwise_skip_is_independent(pytester: Pytester) -> None:
+    pytester.makepyfile(
+        """
+        def test_one():
+            assert False
+
+        def test_two():
+            assert False
+
+        def test_three():
+            assert False
+
+        """
+    )
+    result = pytester.runpytest("--tb", "no", "--stepwise-skip")
+    result.assert_outcomes(failed=2)
+    result.stdout.fnmatch_lines(
+        [
+            "FAILED test_stepwise_skip_is_independent.py::test_one - assert False",
+            "FAILED test_stepwise_skip_is_independent.py::test_two - assert False",
+            "*Interrupted: Test failed, continuing from this test next run.*",
+        ]
+    )
+
+
+def test_sw_skip_help(pytester: Pytester) -> None:
+    result = pytester.runpytest("-h")
+    result.stdout.fnmatch_lines("*implicitly enables --stepwise.")
('testing', 'test_pathlib.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,11 +1,15 @@
 import os.path
+import pickle
 import sys
 import unittest.mock
+from pathlib import Path
 from textwrap import dedent
-
-import py
+from types import ModuleType
+from typing import Any
+from typing import Generator

 import pytest
+from _pytest.monkeypatch import MonkeyPatch
 from _pytest.pathlib import bestrelpath
 from _pytest.pathlib import commonpath
 from _pytest.pathlib import ensure_deletable
@@ -14,29 +18,17 @@
 from _pytest.pathlib import get_lock_path
 from _pytest.pathlib import import_path
 from _pytest.pathlib import ImportPathMismatchError
+from _pytest.pathlib import insert_missing_modules
 from _pytest.pathlib import maybe_delete_a_numbered_dir
-from _pytest.pathlib import Path
+from _pytest.pathlib import module_name_from_path
 from _pytest.pathlib import resolve_package_path
+from _pytest.pathlib import symlink_or_skip
+from _pytest.pathlib import visit
+from _pytest.tmpdir import TempPathFactory


 class TestFNMatcherPort:
-    """Test that our port of py.common.FNMatcher (fnmatch_ex) produces the
-    same results as the original py.path.local.fnmatch method."""
-
-    @pytest.fixture(params=["pathlib", "py.path"])
-    def match(self, request):
-        if request.param == "py.path":
-
-            def match_(pattern, path):
-                return py.path.local(path).fnmatch(pattern)
-
-        else:
-            assert request.param == "pathlib"
-
-            def match_(pattern, path):
-                return fnmatch_ex(pattern, path)
-
-        return match_
+    """Test our port of py.common.FNMatcher (fnmatch_ex)."""

     if sys.platform == "win32":
         drv1 = "c:"
@@ -52,19 +44,19 @@
             ("*.py", "bar/foo.py"),
             ("test_*.py", "foo/test_foo.py"),
             ("tests/*.py", "tests/foo.py"),
-            (drv1 + "/*.py", drv1 + "/foo.py"),
-            (drv1 + "/foo/*.py", drv1 + "/foo/foo.py"),
+            (f"{drv1}/*.py", f"{drv1}/foo.py"),
+            (f"{drv1}/foo/*.py", f"{drv1}/foo/foo.py"),
             ("tests/**/test*.py", "tests/foo/test_foo.py"),
             ("tests/**/doc/test*.py", "tests/foo/bar/doc/test_foo.py"),
             ("tests/**/doc/**/test*.py", "tests/foo/doc/bar/test_foo.py"),
         ],
     )
-    def test_matching(self, match, pattern, path):
-        assert match(pattern, path)
-
-    def test_matching_abspath(self, match):
+    def test_matching(self, pattern: str, path: str) -> None:
+        assert fnmatch_ex(pattern, path)
+
+    def test_matching_abspath(self) -> None:
         abspath = os.path.abspath(os.path.join("tests/foo.py"))
-        assert match("tests/foo.py", abspath)
+        assert fnmatch_ex("tests/foo.py", abspath)

     @pytest.mark.parametrize(
         "pattern, path",
@@ -72,16 +64,16 @@
             ("*.py", "foo.pyc"),
             ("*.py", "foo/foo.pyc"),
             ("tests/*.py", "foo/foo.py"),
-            (drv1 + "/*.py", drv2 + "/foo.py"),
-            (drv1 + "/foo/*.py", drv2 + "/foo/foo.py"),
+            (f"{drv1}/*.py", f"{drv2}/foo.py"),
+            (f"{drv1}/foo/*.py", f"{drv2}/foo/foo.py"),
             ("tests/**/test*.py", "tests/foo.py"),
             ("tests/**/test*.py", "foo/test_foo.py"),
             ("tests/**/doc/test*.py", "tests/foo/bar/doc/foo.py"),
             ("tests/**/doc/test*.py", "tests/foo/bar/test_foo.py"),
         ],
     )
-    def test_not_matching(self, match, pattern, path):
-        assert not match(pattern, path)
+    def test_not_matching(self, pattern: str, path: str) -> None:
+        assert not fnmatch_ex(pattern, path)


 class TestImportPath:
@@ -93,197 +85,225 @@
     """

     @pytest.fixture(scope="session")
-    def path1(self, tmpdir_factory):
-        path = tmpdir_factory.mktemp("path")
+    def path1(self, tmp_path_factory: TempPathFactory) -> Generator[Path, None, None]:
+        path = tmp_path_factory.mktemp("path")
         self.setuptestfs(path)
         yield path
-        assert path.join("samplefile").check()
-
-    def setuptestfs(self, path):
+        assert path.joinpath("samplefile").exists()
+
+    def setuptestfs(self, path: Path) -> None:
         # print "setting up test fs for", repr(path)
-        samplefile = path.ensure("samplefile")
-        samplefile.write("samplefile\n")
-
-        execfile = path.ensure("execfile")
-        execfile.write("x=42")
-
-        execfilepy = path.ensure("execfile.py")
-        execfilepy.write("x=42")
+        samplefile = path / "samplefile"
+        samplefile.write_text("samplefile\n")
+
+        execfile = path / "execfile"
+        execfile.write_text("x=42")
+
+        execfilepy = path / "execfile.py"
+        execfilepy.write_text("x=42")

         d = {1: 2, "hello": "world", "answer": 42}
-        path.ensure("samplepickle").dump(d)
-
-        sampledir = path.ensure("sampledir", dir=1)
-        sampledir.ensure("otherfile")
-
-        otherdir = path.ensure("otherdir", dir=1)
-        otherdir.ensure("__init__.py")
-
-        module_a = otherdir.ensure("a.py")
-        module_a.write("from .b import stuff as result\n")
-        module_b = otherdir.ensure("b.py")
-        module_b.write('stuff="got it"\n')
-        module_c = otherdir.ensure("c.py")
-        module_c.write(
+        path.joinpath("samplepickle").write_bytes(pickle.dumps(d, 1))
+
+        sampledir = path / "sampledir"
+        sampledir.mkdir()
+        sampledir.joinpath("otherfile").touch()
+
+        otherdir = path / "otherdir"
+        otherdir.mkdir()
+        otherdir.joinpath("__init__.py").touch()
+
+        module_a = otherdir / "a.py"
+        module_a.write_text("from .b import stuff as result\n")
+        module_b = otherdir / "b.py"
+        module_b.write_text('stuff="got it"\n')
+        module_c = otherdir / "c.py"
+        module_c.write_text(
             dedent(
                 """
-            import py;
+            import pluggy;
             import otherdir.a
             value = otherdir.a.result
         """
             )
         )
-        module_d = otherdir.ensure("d.py")
-        module_d.write(
+        module_d = otherdir / "d.py"
+        module_d.write_text(
             dedent(
                 """
-            import py;
+            import pluggy;
             from otherdir import a
             value2 = a.result
         """
             )
         )

-    def test_smoke_test(self, path1):
-        obj = import_path(path1.join("execfile.py"))
+    def test_smoke_test(self, path1: Path) -> None:
+        obj = import_path(path1 / "execfile.py", root=path1)
         assert obj.x == 42  # type: ignore[attr-defined]
         assert obj.__name__ == "execfile"

-    def test_renamed_dir_creates_mismatch(self, tmpdir, monkeypatch):
-        p = tmpdir.ensure("a", "test_x123.py")
-        import_path(p)
-        tmpdir.join("a").move(tmpdir.join("b"))
+    def test_import_path_missing_file(self, path1: Path) -> None:
         with pytest.raises(ImportPathMismatchError):
-            import_path(tmpdir.join("b", "test_x123.py"))
+            import_path(path1 / "sampledir", root=path1)
+
+    def test_renamed_dir_creates_mismatch(
+        self, tmp_path: Path, monkeypatch: MonkeyPatch
+    ) -> None:
+        tmp_path.joinpath("a").mkdir()
+        p = tmp_path.joinpath("a", "test_x123.py")
+        p.touch()
+        import_path(p, root=tmp_path)
+        tmp_path.joinpath("a").rename(tmp_path.joinpath("b"))
+        with pytest.raises(ImportPathMismatchError):
+            import_path(tmp_path.joinpath("b", "test_x123.py"), root=tmp_path)

         # Errors can be ignored.
         monkeypatch.setenv("PY_IGNORE_IMPORTMISMATCH", "1")
-        import_path(tmpdir.join("b", "test_x123.py"))
+        import_path(tmp_path.joinpath("b", "test_x123.py"), root=tmp_path)

         # PY_IGNORE_IMPORTMISMATCH=0 does not ignore error.
         monkeypatch.setenv("PY_IGNORE_IMPORTMISMATCH", "0")
         with pytest.raises(ImportPathMismatchError):
-            import_path(tmpdir.join("b", "test_x123.py"))
-
-    def test_messy_name(self, tmpdir):
-        # http://bitbucket.org/hpk42/py-trunk/issue/129
-        path = tmpdir.ensure("foo__init__.py")
-        module = import_path(path)
+            import_path(tmp_path.joinpath("b", "test_x123.py"), root=tmp_path)
+
+    def test_messy_name(self, tmp_path: Path) -> None:
+        # https://bitbucket.org/hpk42/py-trunk/issue/129
+        path = tmp_path / "foo__init__.py"
+        path.touch()
+        module = import_path(path, root=tmp_path)
         assert module.__name__ == "foo__init__"

-    def test_dir(self, tmpdir):
-        p = tmpdir.join("hello_123")
-        p_init = p.ensure("__init__.py")
-        m = import_path(p)
+    def test_dir(self, tmp_path: Path) -> None:
+        p = tmp_path / "hello_123"
+        p.mkdir()
+        p_init = p / "__init__.py"
+        p_init.touch()
+        m = import_path(p, root=tmp_path)
         assert m.__name__ == "hello_123"
-        m = import_path(p_init)
+        m = import_path(p_init, root=tmp_path)
         assert m.__name__ == "hello_123"

-    def test_a(self, path1):
-        otherdir = path1.join("otherdir")
-        mod = import_path(otherdir.join("a.py"))
+    def test_a(self, path1: Path) -> None:
+        otherdir = path1 / "otherdir"
+        mod = import_path(otherdir / "a.py", root=path1)
         assert mod.result == "got it"  # type: ignore[attr-defined]
         assert mod.__name__ == "otherdir.a"

-    def test_b(self, path1):
-        otherdir = path1.join("otherdir")
-        mod = import_path(otherdir.join("b.py"))
+    def test_b(self, path1: Path) -> None:
+        otherdir = path1 / "otherdir"
+        mod = import_path(otherdir / "b.py", root=path1)
         assert mod.stuff == "got it"  # type: ignore[attr-defined]
         assert mod.__name__ == "otherdir.b"

-    def test_c(self, path1):
-        otherdir = path1.join("otherdir")
-        mod = import_path(otherdir.join("c.py"))
+    def test_c(self, path1: Path) -> None:
+        otherdir = path1 / "otherdir"
+        mod = import_path(otherdir / "c.py", root=path1)
         assert mod.value == "got it"  # type: ignore[attr-defined]

-    def test_d(self, path1):
-        otherdir = path1.join("otherdir")
-        mod = import_path(otherdir.join("d.py"))
+    def test_d(self, path1: Path) -> None:
+        otherdir = path1 / "otherdir"
+        mod = import_path(otherdir / "d.py", root=path1)
         assert mod.value2 == "got it"  # type: ignore[attr-defined]

-    def test_import_after(self, tmpdir):
-        tmpdir.ensure("xxxpackage", "__init__.py")
-        mod1path = tmpdir.ensure("xxxpackage", "module1.py")
-        mod1 = import_path(mod1path)
+    def test_import_after(self, tmp_path: Path) -> None:
+        tmp_path.joinpath("xxxpackage").mkdir()
+        tmp_path.joinpath("xxxpackage", "__init__.py").touch()
+        mod1path = tmp_path.joinpath("xxxpackage", "module1.py")
+        mod1path.touch()
+        mod1 = import_path(mod1path, root=tmp_path)
         assert mod1.__name__ == "xxxpackage.module1"
         from xxxpackage import module1

         assert module1 is mod1

-    def test_check_filepath_consistency(self, monkeypatch, tmpdir):
+    def test_check_filepath_consistency(
+        self, monkeypatch: MonkeyPatch, tmp_path: Path
+    ) -> None:
         name = "pointsback123"
-        ModuleType = type(os)
-        p = tmpdir.ensure(name + ".py")
+        p = tmp_path.joinpath(name + ".py")
+        p.touch()
         for ending in (".pyc", ".pyo"):
             mod = ModuleType(name)
-            pseudopath = tmpdir.ensure(name + ending)
+            pseudopath = tmp_path.joinpath(name + ending)
+            pseudopath.touch()
             mod.__file__ = str(pseudopath)
             monkeypatch.setitem(sys.modules, name, mod)
-            newmod = import_path(p)
+            newmod = import_path(p, root=tmp_path)
             assert mod == newmod
         monkeypatch.undo()
         mod = ModuleType(name)
-        pseudopath = tmpdir.ensure(name + "123.py")
+        pseudopath = tmp_path.joinpath(name + "123.py")
+        pseudopath.touch()
         mod.__file__ = str(pseudopath)
         monkeypatch.setitem(sys.modules, name, mod)
         with pytest.raises(ImportPathMismatchError) as excinfo:
-            import_path(p)
+            import_path(p, root=tmp_path)
         modname, modfile, orig = excinfo.value.args
         assert modname == name
-        assert modfile == pseudopath
+        assert modfile == str(pseudopath)
         assert orig == p
         assert issubclass(ImportPathMismatchError, ImportError)

-    def test_issue131_on__init__(self, tmpdir):
+    def test_issue131_on__init__(self, tmp_path: Path) -> None:
         # __init__.py files may be namespace packages, and thus the
         # __file__ of an imported module may not be ourselves
         # see issue
-        p1 = tmpdir.ensure("proja", "__init__.py")
-        p2 = tmpdir.ensure("sub", "proja", "__init__.py")
-        m1 = import_path(p1)
-        m2 = import_path(p2)
+        tmp_path.joinpath("proja").mkdir()
+        p1 = tmp_path.joinpath("proja", "__init__.py")
+        p1.touch()
+        tmp_path.joinpath("sub", "proja").mkdir(parents=True)
+        p2 = tmp_path.joinpath("sub", "proja", "__init__.py")
+        p2.touch()
+        m1 = import_path(p1, root=tmp_path)
+        m2 = import_path(p2, root=tmp_path)
         assert m1 == m2

-    def test_ensuresyspath_append(self, tmpdir):
-        root1 = tmpdir.mkdir("root1")
-        file1 = root1.ensure("x123.py")
+    def test_ensuresyspath_append(self, tmp_path: Path) -> None:
+        root1 = tmp_path / "root1"
+        root1.mkdir()
+        file1 = root1 / "x123.py"
+        file1.touch()
         assert str(root1) not in sys.path
-        import_path(file1, mode="append")
+        import_path(file1, mode="append", root=tmp_path)
         assert str(root1) == sys.path[-1]
         assert str(root1) not in sys.path[:-1]

-    def test_invalid_path(self, tmpdir):
+    def test_invalid_path(self, tmp_path: Path) -> None:
         with pytest.raises(ImportError):
-            import_path(tmpdir.join("invalid.py"))
+            import_path(tmp_path / "invalid.py", root=tmp_path)

     @pytest.fixture
-    def simple_module(self, tmpdir):
-        fn = tmpdir.join("mymod.py")
-        fn.write(
-            dedent(
-                """
-            def foo(x): return 40 + x
-            """
-            )
-        )
+    def simple_module(self, tmp_path: Path) -> Path:
+        fn = tmp_path / "_src/tests/mymod.py"
+        fn.parent.mkdir(parents=True)
+        fn.write_text("def foo(x): return 40 + x")
         return fn

-    def test_importmode_importlib(self, simple_module):
+    def test_importmode_importlib(self, simple_module: Path, tmp_path: Path) -> None:
         """`importlib` mode does not change sys.path."""
-        module = import_path(simple_module, mode="importlib")
+        module = import_path(simple_module, mode="importlib", root=tmp_path)
         assert module.foo(2) == 42  # type: ignore[attr-defined]
-        assert simple_module.dirname not in sys.path
-
-    def test_importmode_twice_is_different_module(self, simple_module):
+        assert str(simple_module.parent) not in sys.path
+        assert module.__name__ in sys.modules
+        assert module.__name__ == "_src.tests.mymod"
+        assert "_src" in sys.modules
+        assert "_src.tests" in sys.modules
+
+    def test_importmode_twice_is_different_module(
+        self, simple_module: Path, tmp_path: Path
+    ) -> None:
         """`importlib` mode always returns a new module."""
-        module1 = import_path(simple_module, mode="importlib")
-        module2 = import_path(simple_module, mode="importlib")
+        module1 = import_path(simple_module, mode="importlib", root=tmp_path)
+        module2 = import_path(simple_module, mode="importlib", root=tmp_path)
         assert module1 is not module2

-    def test_no_meta_path_found(self, simple_module, monkeypatch):
+    def test_no_meta_path_found(
+        self, simple_module: Path, monkeypatch: MonkeyPatch, tmp_path: Path
+    ) -> None:
         """Even without any meta_path should still import module."""
         monkeypatch.setattr(sys, "meta_path", [])
-        module = import_path(simple_module, mode="importlib")
+        module = import_path(simple_module, mode="importlib", root=tmp_path)
         assert module.foo(2) == 42  # type: ignore[attr-defined]

         # mode='importlib' fails if no spec is found to load the module
@@ -293,10 +313,10 @@
             importlib.util, "spec_from_file_location", lambda *args: None
         )
         with pytest.raises(ImportError):
-            import_path(simple_module, mode="importlib")
-
-
-def test_resolve_package_path(tmp_path):
+            import_path(simple_module, mode="importlib", root=tmp_path)
+
+
+def test_resolve_package_path(tmp_path: Path) -> None:
     pkg = tmp_path / "pkg1"
     pkg.mkdir()
     (pkg / "__init__.py").touch()
@@ -306,7 +326,7 @@
     assert resolve_package_path(pkg.joinpath("subdir", "__init__.py")) == pkg


-def test_package_unimportable(tmp_path):
+def test_package_unimportable(tmp_path: Path) -> None:
     pkg = tmp_path / "pkg1-1"
     pkg.mkdir()
     pkg.joinpath("__init__.py").touch()
@@ -320,7 +340,7 @@
     assert not resolve_package_path(pkg)


-def test_access_denied_during_cleanup(tmp_path, monkeypatch):
+def test_access_denied_during_cleanup(tmp_path: Path, monkeypatch: MonkeyPatch) -> None:
     """Ensure that deleting a numbered dir does not fail because of OSErrors (#4262)."""
     path = tmp_path / "temp-1"
     path.mkdir()
@@ -335,7 +355,7 @@
     assert not lock_path.is_file()


-def test_long_path_during_cleanup(tmp_path):
+def test_long_path_during_cleanup(tmp_path: Path) -> None:
     """Ensure that deleting long path works (particularly on Windows (#6775))."""
     path = (tmp_path / ("a" * 250)).resolve()
     if sys.platform == "win32":
@@ -351,14 +371,14 @@
     assert not os.path.isdir(extended_path)


-def test_get_extended_length_path_str():
+def test_get_extended_length_path_str() -> None:
     assert get_extended_length_path_str(r"c:\foo") == r"\\?\c:\foo"
     assert get_extended_length_path_str(r"\\share\foo") == r"\\?\UNC\share\foo"
     assert get_extended_length_path_str(r"\\?\UNC\share\foo") == r"\\?\UNC\share\foo"
     assert get_extended_length_path_str(r"\\?\c:\foo") == r"\\?\c:\foo"


-def test_suppress_error_removing_lock(tmp_path):
+def test_suppress_error_removing_lock(tmp_path: Path) -> None:
     """ensure_deletable should be resilient if lock file cannot be removed (#5456, #7491)"""
     path = tmp_path / "dir"
     path.mkdir()
@@ -401,3 +421,162 @@
     assert commonpath(subpath, path) == path
     assert commonpath(Path(str(path) + "suffix"), path) == path.parent
     assert commonpath(path, path.parent.parent) == path.parent.parent
+
+
+def test_visit_ignores_errors(tmp_path: Path) -> None:
+    symlink_or_skip("recursive", tmp_path / "recursive")
+    tmp_path.joinpath("foo").write_bytes(b"")
+    tmp_path.joinpath("bar").write_bytes(b"")
+
+    assert [
+        entry.name for entry in visit(str(tmp_path), recurse=lambda entry: False)
+    ] == ["bar", "foo"]
+
+
+@pytest.mark.skipif(not sys.platform.startswith("win"), reason="Windows only")
+def test_samefile_false_negatives(tmp_path: Path, monkeypatch: MonkeyPatch) -> None:
+    """
+    import_file() should not raise ImportPathMismatchError if the paths are exactly
+    equal on Windows. It seems directories mounted as UNC paths make os.path.samefile
+    return False, even when they are clearly equal.
+    """
+    module_path = tmp_path.joinpath("my_module.py")
+    module_path.write_text("def foo(): return 42")
+    monkeypatch.syspath_prepend(tmp_path)
+
+    with monkeypatch.context() as mp:
+        # Forcibly make os.path.samefile() return False here to ensure we are comparing
+        # the paths too. Using a context to narrow the patch as much as possible given
+        # this is an important system function.
+        mp.setattr(os.path, "samefile", lambda x, y: False)
+        module = import_path(module_path, root=tmp_path)
+    assert getattr(module, "foo")() == 42
+
+
+class TestImportLibMode:
+    def test_importmode_importlib_with_dataclass(self, tmp_path: Path) -> None:
+        """Ensure that importlib mode works with a module containing dataclasses (#7856)."""
+        fn = tmp_path.joinpath("_src/tests/test_dataclass.py")
+        fn.parent.mkdir(parents=True)
+        fn.write_text(
+            dedent(
+                """
+                from dataclasses import dataclass
+
+                @dataclass
+                class Data:
+                    value: str
+                """
+            )
+        )
+
+        module = import_path(fn, mode="importlib", root=tmp_path)
+        Data: Any = getattr(module, "Data")
+        data = Data(value="foo")
+        assert data.value == "foo"
+        assert data.__module__ == "_src.tests.test_dataclass"
+
+    def test_importmode_importlib_with_pickle(self, tmp_path: Path) -> None:
+        """Ensure that importlib mode works with pickle (#7859)."""
+        fn = tmp_path.joinpath("_src/tests/test_pickle.py")
+        fn.parent.mkdir(parents=True)
+        fn.write_text(
+            dedent(
+                """
+                import pickle
+
+                def _action():
+                    return 42
+
+                def round_trip():
+                    s = pickle.dumps(_action)
+                    return pickle.loads(s)
+                """
+            )
+        )
+
+        module = import_path(fn, mode="importlib", root=tmp_path)
+        round_trip = getattr(module, "round_trip")
+        action = round_trip()
+        assert action() == 42
+
+    def test_importmode_importlib_with_pickle_separate_modules(
+        self, tmp_path: Path
+    ) -> None:
+        """
+        Ensure that importlib mode works can load pickles that look similar but are
+        defined in separate modules.
+        """
+        fn1 = tmp_path.joinpath("_src/m1/tests/test.py")
+        fn1.parent.mkdir(parents=True)
+        fn1.write_text(
+            dedent(
+                """
+                import attr
+                import pickle
+
+                @attr.s(auto_attribs=True)
+                class Data:
+                    x: int = 42
+                """
+            )
+        )
+
+        fn2 = tmp_path.joinpath("_src/m2/tests/test.py")
+        fn2.parent.mkdir(parents=True)
+        fn2.write_text(
+            dedent(
+                """
+                import attr
+                import pickle
+
+                @attr.s(auto_attribs=True)
+                class Data:
+                    x: str = ""
+                """
+            )
+        )
+
+        import pickle
+
+        def round_trip(obj):
+            s = pickle.dumps(obj)
+            return pickle.loads(s)
+
+        module = import_path(fn1, mode="importlib", root=tmp_path)
+        Data1 = getattr(module, "Data")
+
+        module = import_path(fn2, mode="importlib", root=tmp_path)
+        Data2 = getattr(module, "Data")
+
+        assert round_trip(Data1(20)) == Data1(20)
+        assert round_trip(Data2("hello")) == Data2("hello")
+        assert Data1.__module__ == "_src.m1.tests.test"
+        assert Data2.__module__ == "_src.m2.tests.test"
+
+    def test_module_name_from_path(self, tmp_path: Path) -> None:
+        result = module_name_from_path(tmp_path / "src/tests/test_foo.py", tmp_path)
+        assert result == "src.tests.test_foo"
+
+        # Path is not relative to root dir: use the full path to obtain the module name.
+        result = module_name_from_path(Path("/home/foo/test_foo.py"), Path("/bar"))
+        assert result == "home.foo.test_foo"
+
+    def test_insert_missing_modules(
+        self, monkeypatch: MonkeyPatch, tmp_path: Path
+    ) -> None:
+        monkeypatch.chdir(tmp_path)
+        # Use 'xxx' and 'xxy' as parent names as they are unlikely to exist and
+        # don't end up being imported.
+        modules = {"xxx.tests.foo": ModuleType("xxx.tests.foo")}
+        insert_missing_modules(modules, "xxx.tests.foo")
+        assert sorted(modules) == ["xxx", "xxx.tests", "xxx.tests.foo"]
+
+        mod = ModuleType("mod", doc="My Module")
+        modules = {"xxy": mod}
+        insert_missing_modules(modules, "xxy")
+        assert modules == {"xxy": mod}
+
+        modules = {}
+        insert_missing_modules(modules, "")
+        assert modules == {}
('testing', 'test_nose.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,12 +1,13 @@
 import pytest
+from _pytest.pytester import Pytester


 def setup_module(mod):
     mod.nose = pytest.importorskip("nose")


-def test_nose_setup(testdir):
-    p = testdir.makepyfile(
+def test_nose_setup(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
         """
         values = []
         from nose.tools import with_setup
@@ -22,11 +23,11 @@
         test_hello.teardown = lambda: values.append(2)
     """
     )
-    result = testdir.runpytest(p, "-p", "nose")
+    result = pytester.runpytest(p, "-p", "nose")
     result.assert_outcomes(passed=2)


-def test_setup_func_with_setup_decorator():
+def test_setup_func_with_setup_decorator() -> None:
     from _pytest.nose import call_optional

     values = []
@@ -40,7 +41,7 @@
     assert not values


-def test_setup_func_not_callable():
+def test_setup_func_not_callable() -> None:
     from _pytest.nose import call_optional

     class A:
@@ -49,8 +50,8 @@
     call_optional(A(), "f")


-def test_nose_setup_func(testdir):
-    p = testdir.makepyfile(
+def test_nose_setup_func(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
         """
         from nose.tools import with_setup

@@ -75,12 +76,12 @@

     """
     )
-    result = testdir.runpytest(p, "-p", "nose")
+    result = pytester.runpytest(p, "-p", "nose")
     result.assert_outcomes(passed=2)


-def test_nose_setup_func_failure(testdir):
-    p = testdir.makepyfile(
+def test_nose_setup_func_failure(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
         """
         from nose.tools import with_setup

@@ -99,12 +100,12 @@

     """
     )
-    result = testdir.runpytest(p, "-p", "nose")
+    result = pytester.runpytest(p, "-p", "nose")
     result.stdout.fnmatch_lines(["*TypeError: <lambda>()*"])


-def test_nose_setup_func_failure_2(testdir):
-    testdir.makepyfile(
+def test_nose_setup_func_failure_2(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         values = []

@@ -118,13 +119,13 @@
         test_hello.teardown = my_teardown
     """
     )
-    reprec = testdir.inline_run()
+    reprec = pytester.inline_run()
     reprec.assertoutcome(passed=1)


-def test_nose_setup_partial(testdir):
+def test_nose_setup_partial(pytester: Pytester) -> None:
     pytest.importorskip("functools")
-    p = testdir.makepyfile(
+    p = pytester.makepyfile(
         """
         from functools import partial

@@ -153,43 +154,51 @@
         test_hello.teardown = my_teardown_partial
     """
     )
-    result = testdir.runpytest(p, "-p", "nose")
+    result = pytester.runpytest(p, "-p", "nose")
     result.stdout.fnmatch_lines(["*2 passed*"])


-def test_module_level_setup(testdir):
-    testdir.makepyfile(
+def test_module_level_setup(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         from nose.tools import with_setup
         items = {}

         def setup():
-            items[1]=1
+            items.setdefault("setup", []).append("up")

         def teardown():
-            del items[1]
+            items.setdefault("setup", []).append("down")

         def setup2():
-            items[2] = 2
+            items.setdefault("setup2", []).append("up")

         def teardown2():
-            del items[2]
+            items.setdefault("setup2", []).append("down")

         def test_setup_module_setup():
-            assert items[1] == 1
+            assert items["setup"] == ["up"]
+
+        def test_setup_module_setup_again():
+            assert items["setup"] == ["up"]

         @with_setup(setup2, teardown2)
         def test_local_setup():
-            assert items[2] == 2
-            assert 1 not in items
-    """
-    )
-    result = testdir.runpytest("-p", "nose")
-    result.stdout.fnmatch_lines(["*2 passed*"])
-
-
-def test_nose_style_setup_teardown(testdir):
-    testdir.makepyfile(
+            assert items["setup"] == ["up"]
+            assert items["setup2"] == ["up"]
+
+        @with_setup(setup2, teardown2)
+        def test_local_setup_again():
+            assert items["setup"] == ["up"]
+            assert items["setup2"] == ["up", "down", "up"]
+    """
+    )
+    result = pytester.runpytest("-p", "nose")
+    result.stdout.fnmatch_lines(["*4 passed*"])
+
+
+def test_nose_style_setup_teardown(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         values = []

@@ -206,12 +215,56 @@
             assert values == [1]
         """
     )
-    result = testdir.runpytest("-p", "nose")
+    result = pytester.runpytest("-p", "nose")
     result.stdout.fnmatch_lines(["*2 passed*"])


-def test_nose_setup_ordering(testdir):
-    testdir.makepyfile(
+def test_fixtures_nose_setup_issue8394(pytester: Pytester) -> None:
+    pytester.makepyfile(
+        """
+        def setup_module():
+            pass
+
+        def teardown_module():
+            pass
+
+        def setup_function(func):
+            pass
+
+        def teardown_function(func):
+            pass
+
+        def test_world():
+            pass
+
+        class Test(object):
+            def setup_class(cls):
+                pass
+
+            def teardown_class(cls):
+                pass
+
+            def setup_method(self, meth):
+                pass
+
+            def teardown_method(self, meth):
+                pass
+
+            def test_method(self): pass
+        """
+    )
+    match = "*no docstring available*"
+    result = pytester.runpytest("--fixtures")
+    assert result.ret == 0
+    result.stdout.no_fnmatch_line(match)
+
+    result = pytester.runpytest("--fixtures", "-v")
+    assert result.ret == 0
+    result.stdout.fnmatch_lines([match, match, match, match])
+
+
+def test_nose_setup_ordering(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         def setup_module(mod):
             mod.visited = True
@@ -219,18 +272,20 @@
         class TestClass(object):
             def setup(self):
                 assert visited
+                self.visited_cls = True
             def test_first(self):
-                pass
-        """
-    )
-    result = testdir.runpytest()
+                assert visited
+                assert self.visited_cls
+        """
+    )
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*1 passed*"])


-def test_apiwrapper_problem_issue260(testdir):
+def test_apiwrapper_problem_issue260(pytester: Pytester) -> None:
     # this would end up trying a call an optional teardown on the class
     # for plain unittests we don't want nose behaviour
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import unittest
         class TestCase(unittest.TestCase):
@@ -248,14 +303,14 @@
                 pass
         """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.assert_outcomes(passed=1)


-def test_setup_teardown_linking_issue265(testdir):
+def test_setup_teardown_linking_issue265(pytester: Pytester) -> None:
     # we accidentally didn't integrate nose setupstate with normal setupstate
     # this test ensures that won't happen again
-    testdir.makepyfile(
+    pytester.makepyfile(
         '''
         import pytest

@@ -276,12 +331,12 @@
                 raise Exception("should not call teardown for skipped tests")
         '''
     )
-    reprec = testdir.runpytest()
+    reprec = pytester.runpytest()
     reprec.assert_outcomes(passed=1, skipped=1)


-def test_SkipTest_during_collection(testdir):
-    p = testdir.makepyfile(
+def test_SkipTest_during_collection(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
         """
         import nose
         raise nose.SkipTest("during collection")
@@ -289,12 +344,12 @@
             assert False
         """
     )
-    result = testdir.runpytest(p)
-    result.assert_outcomes(skipped=1)
-
-
-def test_SkipTest_in_test(testdir):
-    testdir.makepyfile(
+    result = pytester.runpytest(p)
+    result.assert_outcomes(skipped=1, warnings=0)
+
+
+def test_SkipTest_in_test(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import nose

@@ -302,12 +357,12 @@
             raise nose.SkipTest("in test")
         """
     )
-    reprec = testdir.inline_run()
+    reprec = pytester.inline_run()
     reprec.assertoutcome(skipped=1)


-def test_istest_function_decorator(testdir):
-    p = testdir.makepyfile(
+def test_istest_function_decorator(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
         """
         import nose.tools
         @nose.tools.istest
@@ -315,12 +370,12 @@
             pass
         """
     )
-    result = testdir.runpytest(p)
+    result = pytester.runpytest(p)
     result.assert_outcomes(passed=1)


-def test_nottest_function_decorator(testdir):
-    testdir.makepyfile(
+def test_nottest_function_decorator(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import nose.tools
         @nose.tools.nottest
@@ -328,14 +383,14 @@
             pass
         """
     )
-    reprec = testdir.inline_run()
+    reprec = pytester.inline_run()
     assert not reprec.getfailedcollections()
     calls = reprec.getreports("pytest_runtest_logreport")
     assert not calls


-def test_istest_class_decorator(testdir):
-    p = testdir.makepyfile(
+def test_istest_class_decorator(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
         """
         import nose.tools
         @nose.tools.istest
@@ -344,12 +399,12 @@
                 pass
         """
     )
-    result = testdir.runpytest(p)
+    result = pytester.runpytest(p)
     result.assert_outcomes(passed=1)


-def test_nottest_class_decorator(testdir):
-    testdir.makepyfile(
+def test_nottest_class_decorator(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import nose.tools
         @nose.tools.nottest
@@ -358,14 +413,14 @@
                 pass
         """
     )
-    reprec = testdir.inline_run()
+    reprec = pytester.inline_run()
     assert not reprec.getfailedcollections()
     calls = reprec.getreports("pytest_runtest_logreport")
     assert not calls


-def test_skip_test_with_unicode(testdir):
-    testdir.makepyfile(
+def test_skip_test_with_unicode(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """\
         import unittest
         class TestClass():
@@ -373,12 +428,12 @@
                 raise unittest.SkipTest('😊')
         """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["* 1 skipped *"])


-def test_raises(testdir):
-    testdir.makepyfile(
+def test_raises(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         from nose.tools import raises

@@ -395,7 +450,7 @@
             raise BaseException
         """
     )
-    result = testdir.runpytest("-vv")
+    result = pytester.runpytest("-vv")
     result.stdout.fnmatch_lines(
         [
             "test_raises.py::test_raises_runtimeerror PASSED*",
@@ -422,3 +477,22 @@
             "* 1 failed, 2 passed *",
         ]
     )
+
+
+def test_nose_setup_skipped_if_non_callable(pytester: Pytester) -> None:
+    """Regression test for #9391."""
+    p = pytester.makepyfile(
+        __init__="",
+        setup="""
+        """,
+        teardown="""
+        """,
+        test_it="""
+        from . import setup, teardown
+
+        def test_it():
+            pass
+        """,
+    )
+    result = pytester.runpytest(p, "-p", "nose")
+    assert result.ret == 0
('testing/python', 'approx.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,4 +1,5 @@
 import operator
+from contextlib import contextmanager
 from decimal import Decimal
 from fractions import Fraction
 from operator import eq
@@ -6,6 +7,7 @@
 from typing import Optional

 import pytest
+from _pytest.pytester import Pytester
 from pytest import approx

 inf, nan = float("inf"), float("nan")
@@ -41,7 +43,238 @@
     return MyDocTestRunner()


+@contextmanager
+def temporary_verbosity(config, verbosity=0):
+    original_verbosity = config.getoption("verbose")
+    config.option.verbose = verbosity
+    try:
+        yield
+    finally:
+        config.option.verbose = original_verbosity
+
+
+@pytest.fixture
+def assert_approx_raises_regex(pytestconfig):
+    def do_assert(lhs, rhs, expected_message, verbosity_level=0):
+        import re
+
+        with temporary_verbosity(pytestconfig, verbosity_level):
+            with pytest.raises(AssertionError) as e:
+                assert lhs == approx(rhs)
+
+        nl = "\n"
+        obtained_message = str(e.value).splitlines()[1:]
+        assert len(obtained_message) == len(expected_message), (
+            "Regex message length doesn't match obtained.\n"
+            "Obtained:\n"
+            f"{nl.join(obtained_message)}\n\n"
+            "Expected regex:\n"
+            f"{nl.join(expected_message)}\n\n"
+        )
+
+        for i, (obtained_line, expected_line) in enumerate(
+            zip(obtained_message, expected_message)
+        ):
+            regex = re.compile(expected_line)
+            assert regex.match(obtained_line) is not None, (
+                "Unexpected error message:\n"
+                f"{nl.join(obtained_message)}\n\n"
+                "Did not match regex:\n"
+                f"{nl.join(expected_message)}\n\n"
+                f"With verbosity level = {verbosity_level}, on line {i}"
+            )
+
+    return do_assert
+
+
+SOME_FLOAT = r"[+-]?([0-9]*[.])?[0-9]+\s*"
+SOME_INT = r"[0-9]+\s*"
+
+
 class TestApprox:
+    def test_error_messages_native_dtypes(self, assert_approx_raises_regex):
+        assert_approx_raises_regex(
+            2.0,
+            1.0,
+            [
+                "  comparison failed",
+                f"  Obtained: {SOME_FLOAT}",
+                f"  Expected: {SOME_FLOAT} ± {SOME_FLOAT}",
+            ],
+        )
+
+        assert_approx_raises_regex(
+            {"a": 1.0, "b": 1000.0, "c": 1000000.0},
+            {
+                "a": 2.0,
+                "b": 1000.0,
+                "c": 3000000.0,
+            },
+            [
+                r"  comparison failed. Mismatched elements: 2 / 3:",
+                rf"  Max absolute difference: {SOME_FLOAT}",
+                rf"  Max relative difference: {SOME_FLOAT}",
+                r"  Index \| Obtained\s+\| Expected           ",
+                rf"  a     \| {SOME_FLOAT} \| {SOME_FLOAT} ± {SOME_FLOAT}",
+                rf"  c     \| {SOME_FLOAT} \| {SOME_FLOAT} ± {SOME_FLOAT}",
+            ],
+        )
+
+        assert_approx_raises_regex(
+            [1.0, 2.0, 3.0, 4.0],
+            [1.0, 3.0, 3.0, 5.0],
+            [
+                r"  comparison failed. Mismatched elements: 2 / 4:",
+                rf"  Max absolute difference: {SOME_FLOAT}",
+                rf"  Max relative difference: {SOME_FLOAT}",
+                r"  Index \| Obtained\s+\| Expected   ",
+                rf"  1     \| {SOME_FLOAT} \| {SOME_FLOAT} ± {SOME_FLOAT}",
+                rf"  3     \| {SOME_FLOAT} \| {SOME_FLOAT} ± {SOME_FLOAT}",
+            ],
+        )
+
+        # Specific test for comparison with 0.0 (relative diff will be 'inf')
+        assert_approx_raises_regex(
+            [0.0],
+            [1.0],
+            [
+                r"  comparison failed. Mismatched elements: 1 / 1:",
+                rf"  Max absolute difference: {SOME_FLOAT}",
+                r"  Max relative difference: inf",
+                r"  Index \| Obtained\s+\| Expected   ",
+                rf"\s*0\s*\| {SOME_FLOAT} \| {SOME_FLOAT} ± {SOME_FLOAT}",
+            ],
+        )
+
+    def test_error_messages_numpy_dtypes(self, assert_approx_raises_regex):
+        np = pytest.importorskip("numpy")
+
+        a = np.linspace(0, 100, 20)
+        b = np.linspace(0, 100, 20)
+        a[10] += 0.5
+        assert_approx_raises_regex(
+            a,
+            b,
+            [
+                r"  comparison failed. Mismatched elements: 1 / 20:",
+                rf"  Max absolute difference: {SOME_FLOAT}",
+                rf"  Max relative difference: {SOME_FLOAT}",
+                r"  Index \| Obtained\s+\| Expected",
+                rf"  \(10,\) \| {SOME_FLOAT} \| {SOME_FLOAT} ± {SOME_FLOAT}",
+            ],
+        )
+
+        assert_approx_raises_regex(
+            np.array(
+                [
+                    [[1.1987311, 12412342.3], [3.214143244, 1423412423415.677]],
+                    [[1, 2], [3, 219371297321973]],
+                ]
+            ),
+            np.array(
+                [
+                    [[1.12313, 12412342.3], [3.214143244, 534523542345.677]],
+                    [[1, 2], [3, 7]],
+                ]
+            ),
+            [
+                r"  comparison failed. Mismatched elements: 3 / 8:",
+                rf"  Max absolute difference: {SOME_FLOAT}",
+                rf"  Max relative difference: {SOME_FLOAT}",
+                r"  Index\s+\| Obtained\s+\| Expected\s+",
+                rf"  \(0, 0, 0\) \| {SOME_FLOAT} \| {SOME_FLOAT} ± {SOME_FLOAT}",
+                rf"  \(0, 1, 1\) \| {SOME_FLOAT} \| {SOME_FLOAT} ± {SOME_FLOAT}",
+                rf"  \(1, 1, 1\) \| {SOME_FLOAT} \| {SOME_FLOAT} ± {SOME_FLOAT}",
+            ],
+        )
+
+        # Specific test for comparison with 0.0 (relative diff will be 'inf')
+        assert_approx_raises_regex(
+            np.array([0.0]),
+            np.array([1.0]),
+            [
+                r"  comparison failed. Mismatched elements: 1 / 1:",
+                rf"  Max absolute difference: {SOME_FLOAT}",
+                r"  Max relative difference: inf",
+                r"  Index \| Obtained\s+\| Expected   ",
+                rf"\s*\(0,\)\s*\| {SOME_FLOAT} \| {SOME_FLOAT} ± {SOME_FLOAT}",
+            ],
+        )
+
+    def test_error_messages_invalid_args(self, assert_approx_raises_regex):
+        np = pytest.importorskip("numpy")
+        with pytest.raises(AssertionError) as e:
+            assert np.array([[1.2, 3.4], [4.0, 5.0]]) == pytest.approx(
+                np.array([[4.0], [5.0]])
+            )
+        message = "\n".join(str(e.value).split("\n")[1:])
+        assert message == "\n".join(
+            [
+                "  Impossible to compare arrays with different shapes.",
+                "  Shapes: (2, 1) and (2, 2)",
+            ]
+        )
+
+        with pytest.raises(AssertionError) as e:
+            assert [1.0, 2.0, 3.0] == pytest.approx([4.0, 5.0])
+        message = "\n".join(str(e.value).split("\n")[1:])
+        assert message == "\n".join(
+            [
+                "  Impossible to compare lists with different sizes.",
+                "  Lengths: 2 and 3",
+            ]
+        )
+
+    def test_error_messages_with_different_verbosity(self, assert_approx_raises_regex):
+        np = pytest.importorskip("numpy")
+        for v in [0, 1, 2]:
+            # Verbosity level doesn't affect the error message for scalars
+            assert_approx_raises_regex(
+                2.0,
+                1.0,
+                [
+                    "  comparison failed",
+                    f"  Obtained: {SOME_FLOAT}",
+                    f"  Expected: {SOME_FLOAT} ± {SOME_FLOAT}",
+                ],
+                verbosity_level=v,
+            )
+
+        a = np.linspace(1, 101, 20)
+        b = np.linspace(2, 102, 20)
+        assert_approx_raises_regex(
+            a,
+            b,
+            [
+                r"  comparison failed. Mismatched elements: 20 / 20:",
+                rf"  Max absolute difference: {SOME_FLOAT}",
+                rf"  Max relative difference: {SOME_FLOAT}",
+                r"  Index \| Obtained\s+\| Expected",
+                rf"  \(0,\)\s+\| {SOME_FLOAT} \| {SOME_FLOAT} ± {SOME_FLOAT}",
+                rf"  \(1,\)\s+\| {SOME_FLOAT} \| {SOME_FLOAT} ± {SOME_FLOAT}",
+                rf"  \(2,\)\s+\| {SOME_FLOAT} \| {SOME_FLOAT} ± {SOME_FLOAT}...",
+                "",
+                rf"\s*...Full output truncated \({SOME_INT} lines hidden\), use '-vv' to show",
+            ],
+            verbosity_level=0,
+        )
+
+        assert_approx_raises_regex(
+            a,
+            b,
+            [
+                r"  comparison failed. Mismatched elements: 20 / 20:",
+                rf"  Max absolute difference: {SOME_FLOAT}",
+                rf"  Max relative difference: {SOME_FLOAT}",
+                r"  Index \| Obtained\s+\| Expected",
+            ]
+            + [
+                rf"  \({i},\)\s+\| {SOME_FLOAT} \| {SOME_FLOAT} ± {SOME_FLOAT}"
+                for i in range(20)
+            ],
+            verbosity_level=2,
+        )
+
     def test_repr_string(self):
         assert repr(approx(1.0)) == "1.0 ± 1.0e-06"
         assert repr(approx([1.0, 2.0])) == "approx([1.0 ± 1.0e-06, 2.0 ± 2.0e-06])"
@@ -86,6 +319,12 @@
         np = pytest.importorskip("numpy")
         np_array = np.array(value)
         assert repr(approx(np_array)) == expected_repr_string
+
+    def test_bool(self):
+        with pytest.raises(AssertionError) as err:
+            assert approx(1)
+
+        assert err.match(r"approx\(\) is not supported in a boolean context")

     def test_operator_overloading(self):
         assert 1 == approx(1, rel=1e-6, abs=1e-12)
@@ -139,6 +378,13 @@
         with pytest.raises(ValueError):
             1.1 == approx(1, rel, abs)

+    def test_negative_tolerance_message(self):
+        # Error message for negative tolerance should include the value.
+        with pytest.raises(ValueError, match="-3"):
+            0 == approx(1, abs=-3)
+        with pytest.raises(ValueError, match="-3"):
+            0 == approx(1, rel=-3)
+
     def test_inf_tolerance(self):
         # Everything should be equal if the tolerance is infinite.
         large_diffs = [(1, 1000), (1e-50, 1e50), (-1.0, -1e300), (0.0, 10)]
@@ -311,6 +557,12 @@
         assert approx(expected, rel=5e-7, abs=0) == actual
         assert approx(expected, rel=5e-8, abs=0) != actual

+    def test_list_decimal(self):
+        actual = [Decimal("1.000001"), Decimal("2.000001")]
+        expected = [Decimal("1"), Decimal("2")]
+
+        assert actual == approx(expected)
+
     def test_list_wrong_len(self):
         assert [1, 2] != approx([1])
         assert [1, 2] != approx([1, 2, 3])
@@ -329,6 +581,9 @@
         assert (1, 2) != approx((1,))
         assert (1, 2) != approx((1, 2, 3))

+    def test_tuple_vs_other(self):
+        assert 1 != approx((1,))
+
     def test_dict(self):
         actual = {"a": 1 + 1e-7, "b": 2 + 1e-8}
         # Dictionaries became ordered in python3.6, so switch up the order here
@@ -341,10 +596,25 @@
         assert approx(expected, rel=5e-7, abs=0) == actual
         assert approx(expected, rel=5e-8, abs=0) != actual

+    def test_dict_decimal(self):
+        actual = {"a": Decimal("1.000001"), "b": Decimal("2.000001")}
+        # Dictionaries became ordered in python3.6, so switch up the order here
+        # to make sure it doesn't matter.
+        expected = {"b": Decimal("2"), "a": Decimal("1")}
+
+        assert actual == approx(expected)
+
     def test_dict_wrong_len(self):
         assert {"a": 1, "b": 2} != approx({"a": 1})
         assert {"a": 1, "b": 2} != approx({"a": 1, "c": 2})
         assert {"a": 1, "b": 2} != approx({"a": 1, "b": 2, "c": 3})
+
+    def test_dict_nonnumeric(self):
+        assert {"a": 1.0, "b": None} == pytest.approx({"a": 1.0, "b": None})
+        assert {"a": 1.0, "b": 1} != pytest.approx({"a": 1.0, "b": None})
+
+    def test_dict_vs_other(self):
+        assert 1 != approx({"a": 0})

     def test_numpy_array(self):
         np = pytest.importorskip("numpy")
@@ -435,6 +705,36 @@
         assert a12 != approx(a21)
         assert a21 != approx(a12)

+    def test_numpy_array_protocol(self):
+        """
+        array-like objects such as tensorflow's DeviceArray are handled like ndarray.
+        See issue #8132
+        """
+        np = pytest.importorskip("numpy")
+
+        class DeviceArray:
+            def __init__(self, value, size):
+                self.value = value
+                self.size = size
+
+            def __array__(self):
+                return self.value * np.ones(self.size)
+
+        class DeviceScalar:
+            def __init__(self, value):
+                self.value = value
+
+            def __array__(self):
+                return np.array(self.value)
+
+        expected = 1
+        actual = 1 + 1e-6
+        assert approx(expected) == DeviceArray(actual, size=1)
+        assert approx(expected) == DeviceArray(actual, size=2)
+        assert approx(expected) == DeviceScalar(actual)
+        assert approx(DeviceScalar(expected)) == actual
+        assert approx(DeviceScalar(expected)) == DeviceScalar(actual)
+
     def test_doctests(self, mocked_doctest_runner) -> None:
         import doctest

@@ -445,12 +745,12 @@
         )
         mocked_doctest_runner.run(test)

-    def test_unicode_plus_minus(self, testdir):
+    def test_unicode_plus_minus(self, pytester: Pytester) -> None:
         """
         Comparing approx instances inside lists should not produce an error in the detailed diff.
         Integration test for issue #2111.
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest
             def test_foo():
@@ -458,10 +758,24 @@
         """
         )
         expected = "4.0e-06"
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
-            ["*At index 0 diff: 3 != 4 ± {}".format(expected), "=* 1 failed in *="]
-        )
+            [f"*At index 0 diff: 3 != 4 ± {expected}", "=* 1 failed in *="]
+        )
+
+    @pytest.mark.parametrize(
+        "x, name",
+        [
+            pytest.param([[1]], "data structures", id="nested-list"),
+            pytest.param({"key": {"key": 1}}, "dictionaries", id="nested-dict"),
+        ],
+    )
+    def test_expected_value_type_error(self, x, name):
+        with pytest.raises(
+            TypeError,
+            match=rf"pytest.approx\(\) does not support nested {name}:",
+        ):
+            approx(x)

     @pytest.mark.parametrize(
         "x",
@@ -469,14 +783,46 @@
             pytest.param(None),
             pytest.param("string"),
             pytest.param(["string"], id="nested-str"),
-            pytest.param([[1]], id="nested-list"),
             pytest.param({"key": "string"}, id="dict-with-string"),
-            pytest.param({"key": {"key": 1}}, id="nested-dict"),
         ],
     )
-    def test_expected_value_type_error(self, x):
-        with pytest.raises(TypeError):
-            approx(x)
+    def test_nonnumeric_okay_if_equal(self, x):
+        assert x == approx(x)
+
+    @pytest.mark.parametrize(
+        "x",
+        [
+            pytest.param("string"),
+            pytest.param(["string"], id="nested-str"),
+            pytest.param({"key": "string"}, id="dict-with-string"),
+        ],
+    )
+    def test_nonnumeric_false_if_unequal(self, x):
+        """For nonnumeric types, x != pytest.approx(y) reduces to x != y"""
+        assert "ab" != approx("abc")
+        assert ["ab"] != approx(["abc"])
+        # in particular, both of these should return False
+        assert {"a": 1.0} != approx({"a": None})
+        assert {"a": None} != approx({"a": 1.0})
+
+        assert 1.0 != approx(None)
+        assert None != approx(1.0)  # noqa: E711
+
+        assert 1.0 != approx([None])
+        assert None != approx([1.0])  # noqa: E711
+
+    def test_nonnumeric_dict_repr(self):
+        """Dicts with non-numerics and infinites have no tolerances"""
+        x1 = {"foo": 1.0000005, "bar": None, "foobar": inf}
+        assert (
+            repr(approx(x1))
+            == "approx({'foo': 1.0000005 ± 1.0e-06, 'bar': None, 'foobar': inf})"
+        )
+
+    def test_nonnumeric_list_repr(self):
+        """Lists with non-numerics and infinites have no tolerances"""
+        x1 = [1.0000005, None, inf]
+        assert repr(approx(x1)) == "approx([1.0000005 ± 1.0e-06, None, inf])"

     @pytest.mark.parametrize(
         "op",
@@ -514,13 +860,21 @@
         assert approx(expected, rel=5e-7, abs=0) == actual
         assert approx(expected, rel=5e-8, abs=0) != actual

-    def test_generic_sized_iterable_object(self):
-        class MySizedIterable:
-            def __iter__(self):
-                return iter([1, 2, 3, 4])
+    def test_generic_ordered_sequence(self):
+        class MySequence:
+            def __getitem__(self, i):
+                return [1, 2, 3, 4][i]

             def __len__(self):
                 return 4

-        expected = MySizedIterable()
-        assert [1, 2, 3, 4] == approx(expected)
+        expected = MySequence()
+        assert [1, 2, 3, 4] == approx(expected, abs=1e-4)
+
+        expected_repr = "approx([1 ± 1.0e-06, 2 ± 2.0e-06, 3 ± 3.0e-06, 4 ± 4.0e-06])"
+        assert repr(approx(expected)) == expected_repr
+
+    def test_allow_ordered_sequences_only(self) -> None:
+        """pytest.approx() should raise an error on unordered sequences (#9692)."""
+        with pytest.raises(TypeError, match="only supports ordered sequences"):
+            assert {1, 2, 3} == approx({1, 2, 3})
('testing/python', 'show_fixtures_per_test.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,11 +1,14 @@
-def test_no_items_should_not_show_output(testdir):
-    result = testdir.runpytest("--fixtures-per-test")
+from _pytest.pytester import Pytester
+
+
+def test_no_items_should_not_show_output(pytester: Pytester) -> None:
+    result = pytester.runpytest("--fixtures-per-test")
     result.stdout.no_fnmatch_line("*fixtures used by*")
     assert result.ret == 0


-def test_fixtures_in_module(testdir):
-    p = testdir.makepyfile(
+def test_fixtures_in_module(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
         '''
         import pytest
         @pytest.fixture
@@ -19,22 +22,22 @@
     '''
     )

-    result = testdir.runpytest("--fixtures-per-test", p)
+    result = pytester.runpytest("--fixtures-per-test", p)
     assert result.ret == 0

     result.stdout.fnmatch_lines(
         [
             "*fixtures used by test_arg1*",
             "*(test_fixtures_in_module.py:9)*",
-            "arg1",
+            "arg1 -- test_fixtures_in_module.py:6",
             "    arg1 docstring",
         ]
     )
     result.stdout.no_fnmatch_line("*_arg0*")


-def test_fixtures_in_conftest(testdir):
-    testdir.makeconftest(
+def test_fixtures_in_conftest(pytester: Pytester) -> None:
+    pytester.makeconftest(
         '''
         import pytest
         @pytest.fixture
@@ -50,7 +53,7 @@
             """
     '''
     )
-    p = testdir.makepyfile(
+    p = pytester.makepyfile(
         """
         def test_arg2(arg2):
             pass
@@ -58,30 +61,29 @@
             pass
     """
     )
-    result = testdir.runpytest("--fixtures-per-test", p)
+    result = pytester.runpytest("--fixtures-per-test", p)
     assert result.ret == 0

     result.stdout.fnmatch_lines(
         [
             "*fixtures used by test_arg2*",
             "*(test_fixtures_in_conftest.py:2)*",
-            "arg2",
+            "arg2 -- conftest.py:6",
             "    arg2 docstring",
             "*fixtures used by test_arg3*",
             "*(test_fixtures_in_conftest.py:4)*",
-            "arg1",
+            "arg1 -- conftest.py:3",
             "    arg1 docstring",
-            "arg2",
+            "arg2 -- conftest.py:6",
             "    arg2 docstring",
-            "arg3",
+            "arg3 -- conftest.py:9",
             "    arg3",
-            "    docstring",
-        ]
-    )
-
-
-def test_should_show_fixtures_used_by_test(testdir):
-    testdir.makeconftest(
+        ]
+    )
+
+
+def test_should_show_fixtures_used_by_test(pytester: Pytester) -> None:
+    pytester.makeconftest(
         '''
         import pytest
         @pytest.fixture
@@ -92,7 +94,7 @@
             """arg2 from conftest"""
     '''
     )
-    p = testdir.makepyfile(
+    p = pytester.makepyfile(
         '''
         import pytest
         @pytest.fixture
@@ -102,23 +104,23 @@
             pass
     '''
     )
-    result = testdir.runpytest("--fixtures-per-test", p)
+    result = pytester.runpytest("--fixtures-per-test", p)
     assert result.ret == 0

     result.stdout.fnmatch_lines(
         [
             "*fixtures used by test_args*",
             "*(test_should_show_fixtures_used_by_test.py:6)*",
-            "arg1",
+            "arg1 -- test_should_show_fixtures_used_by_test.py:3",
             "    arg1 from testmodule",
-            "arg2",
+            "arg2 -- conftest.py:6",
             "    arg2 from conftest",
         ]
     )


-def test_verbose_include_private_fixtures_and_loc(testdir):
-    testdir.makeconftest(
+def test_verbose_include_private_fixtures_and_loc(pytester: Pytester) -> None:
+    pytester.makeconftest(
         '''
         import pytest
         @pytest.fixture
@@ -129,7 +131,7 @@
             """arg2 from conftest"""
     '''
     )
-    p = testdir.makepyfile(
+    p = pytester.makepyfile(
         '''
         import pytest
         @pytest.fixture
@@ -139,7 +141,7 @@
             pass
     '''
     )
-    result = testdir.runpytest("--fixtures-per-test", "-v", p)
+    result = pytester.runpytest("--fixtures-per-test", "-v", p)
     assert result.ret == 0

     result.stdout.fnmatch_lines(
@@ -156,8 +158,8 @@
     )


-def test_doctest_items(testdir):
-    testdir.makepyfile(
+def test_doctest_items(pytester: Pytester) -> None:
+    pytester.makepyfile(
         '''
         def foo():
             """
@@ -166,15 +168,87 @@
             """
     '''
     )
-    testdir.maketxtfile(
+    pytester.maketxtfile(
         """
         >>> 1 + 1
         2
     """
     )
-    result = testdir.runpytest(
+    result = pytester.runpytest(
         "--fixtures-per-test", "--doctest-modules", "--doctest-glob=*.txt", "-v"
     )
     assert result.ret == 0

     result.stdout.fnmatch_lines(["*collected 2 items*"])
+
+
+def test_multiline_docstring_in_module(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
+        '''
+        import pytest
+        @pytest.fixture
+        def arg1():
+            """Docstring content that spans across multiple lines,
+            through second line,
+            and through third line.
+
+            Docstring content that extends into a second paragraph.
+
+            Docstring content that extends into a third paragraph.
+            """
+        def test_arg1(arg1):
+            pass
+    '''
+    )
+
+    result = pytester.runpytest("--fixtures-per-test", p)
+    assert result.ret == 0
+
+    result.stdout.fnmatch_lines(
+        [
+            "*fixtures used by test_arg1*",
+            "*(test_multiline_docstring_in_module.py:13)*",
+            "arg1 -- test_multiline_docstring_in_module.py:3",
+            "    Docstring content that spans across multiple lines,",
+            "    through second line,",
+            "    and through third line.",
+        ]
+    )
+
+
+def test_verbose_include_multiline_docstring(pytester: Pytester) -> None:
+    p = pytester.makepyfile(
+        '''
+        import pytest
+        @pytest.fixture
+        def arg1():
+            """Docstring content that spans across multiple lines,
+            through second line,
+            and through third line.
+
+            Docstring content that extends into a second paragraph.
+
+            Docstring content that extends into a third paragraph.
+            """
+        def test_arg1(arg1):
+            pass
+    '''
+    )
+
+    result = pytester.runpytest("--fixtures-per-test", "-v", p)
+    assert result.ret == 0
+
+    result.stdout.fnmatch_lines(
+        [
+            "*fixtures used by test_arg1*",
+            "*(test_verbose_include_multiline_docstring.py:13)*",
+            "arg1 -- test_verbose_include_multiline_docstring.py:3",
+            "    Docstring content that spans across multiple lines,",
+            "    through second line,",
+            "    and through third line.",
+            "    ",
+            "    Docstring content that extends into a second paragraph.",
+            "    ",
+            "    Docstring content that extends into a third paragraph.",
+        ]
+    )
('testing/python', 'collect.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,3 +1,4 @@
+import os
 import sys
 import textwrap
 from typing import Any
@@ -6,42 +7,51 @@
 import _pytest._code
 import pytest
 from _pytest.config import ExitCode
+from _pytest.main import Session
+from _pytest.monkeypatch import MonkeyPatch
 from _pytest.nodes import Collector
-from _pytest.pytester import Testdir
+from _pytest.pytester import Pytester
+from _pytest.python import Class
+from _pytest.python import Function


 class TestModule:
-    def test_failing_import(self, testdir):
-        modcol = testdir.getmodulecol("import alksdjalskdjalkjals")
+    def test_failing_import(self, pytester: Pytester) -> None:
+        modcol = pytester.getmodulecol("import alksdjalskdjalkjals")
         pytest.raises(Collector.CollectError, modcol.collect)

-    def test_import_duplicate(self, testdir):
-        a = testdir.mkdir("a")
-        b = testdir.mkdir("b")
-        p = a.ensure("test_whatever.py")
-        p.pyimport()
-        del sys.modules["test_whatever"]
-        b.ensure("test_whatever.py")
-        result = testdir.runpytest()
+    def test_import_duplicate(self, pytester: Pytester) -> None:
+        a = pytester.mkdir("a")
+        b = pytester.mkdir("b")
+        p1 = a.joinpath("test_whatever.py")
+        p1.touch()
+        p2 = b.joinpath("test_whatever.py")
+        p2.touch()
+        # ensure we don't have it imported already
+        sys.modules.pop(p1.stem, None)
+
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             [
                 "*import*mismatch*",
                 "*imported*test_whatever*",
-                "*%s*" % a.join("test_whatever.py"),
+                "*%s*" % p1,
                 "*not the same*",
-                "*%s*" % b.join("test_whatever.py"),
+                "*%s*" % p2,
                 "*HINT*",
             ]
         )

-    def test_import_prepend_append(self, testdir, monkeypatch):
-        root1 = testdir.mkdir("root1")
-        root2 = testdir.mkdir("root2")
-        root1.ensure("x456.py")
-        root2.ensure("x456.py")
-        p = root2.join("test_x456.py")
+    def test_import_prepend_append(
+        self, pytester: Pytester, monkeypatch: MonkeyPatch
+    ) -> None:
+        root1 = pytester.mkdir("root1")
+        root2 = pytester.mkdir("root2")
+        root1.joinpath("x456.py").touch()
+        root2.joinpath("x456.py").touch()
+        p = root2.joinpath("test_x456.py")
         monkeypatch.syspath_prepend(str(root1))
-        p.write(
+        p.write_text(
             textwrap.dedent(
                 """\
                 import x456
@@ -52,25 +62,26 @@
                 )
             )
         )
-        with root2.as_cwd():
-            reprec = testdir.inline_run("--import-mode=append")
+        with monkeypatch.context() as mp:
+            mp.chdir(root2)
+            reprec = pytester.inline_run("--import-mode=append")
             reprec.assertoutcome(passed=0, failed=1)
-            reprec = testdir.inline_run()
+            reprec = pytester.inline_run()
             reprec.assertoutcome(passed=1)

-    def test_syntax_error_in_module(self, testdir):
-        modcol = testdir.getmodulecol("this is a syntax error")
+    def test_syntax_error_in_module(self, pytester: Pytester) -> None:
+        modcol = pytester.getmodulecol("this is a syntax error")
         pytest.raises(modcol.CollectError, modcol.collect)
         pytest.raises(modcol.CollectError, modcol.collect)

-    def test_module_considers_pluginmanager_at_import(self, testdir):
-        modcol = testdir.getmodulecol("pytest_plugins='xasdlkj',")
+    def test_module_considers_pluginmanager_at_import(self, pytester: Pytester) -> None:
+        modcol = pytester.getmodulecol("pytest_plugins='xasdlkj',")
         pytest.raises(ImportError, lambda: modcol.obj)

-    def test_invalid_test_module_name(self, testdir):
-        a = testdir.mkdir("a")
-        a.ensure("test_one.part1.py")
-        result = testdir.runpytest()
+    def test_invalid_test_module_name(self, pytester: Pytester) -> None:
+        a = pytester.mkdir("a")
+        a.joinpath("test_one.part1.py").touch()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             [
                 "ImportError while importing test module*test_one.part1*",
@@ -79,24 +90,26 @@
         )

     @pytest.mark.parametrize("verbose", [0, 1, 2])
-    def test_show_traceback_import_error(self, testdir, verbose):
+    def test_show_traceback_import_error(
+        self, pytester: Pytester, verbose: int
+    ) -> None:
         """Import errors when collecting modules should display the traceback (#1976).

         With low verbosity we omit pytest and internal modules, otherwise show all traceback entries.
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             foo_traceback_import_error="""
                from bar_traceback_import_error import NOT_AVAILABLE
            """,
             bar_traceback_import_error="",
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
                import foo_traceback_import_error
         """
         )
         args = ("-v",) * verbose
-        result = testdir.runpytest(*args)
+        result = pytester.runpytest(*args)
         result.stdout.fnmatch_lines(
             [
                 "ImportError while importing test module*",
@@ -113,12 +126,12 @@
         else:
             assert "_pytest" not in stdout

-    def test_show_traceback_import_error_unicode(self, testdir):
+    def test_show_traceback_import_error_unicode(self, pytester: Pytester) -> None:
         """Check test modules collected which raise ImportError with unicode messages
         are handled properly (#2336).
         """
-        testdir.makepyfile("raise ImportError('Something bad happened ☺')")
-        result = testdir.runpytest()
+        pytester.makepyfile("raise ImportError('Something bad happened ☺')")
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             [
                 "ImportError while importing test module*",
@@ -130,15 +143,15 @@


 class TestClass:
-    def test_class_with_init_warning(self, testdir):
-        testdir.makepyfile(
+    def test_class_with_init_warning(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             class TestClass1(object):
                 def __init__(self):
                     pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             [
                 "*cannot collect test class 'TestClass1' because it has "
@@ -146,15 +159,15 @@
             ]
         )

-    def test_class_with_new_warning(self, testdir):
-        testdir.makepyfile(
+    def test_class_with_new_warning(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             class TestClass1(object):
                 def __new__(self):
                     pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             [
                 "*cannot collect test class 'TestClass1' because it has "
@@ -162,19 +175,19 @@
             ]
         )

-    def test_class_subclassobject(self, testdir):
-        testdir.getmodulecol(
+    def test_class_subclassobject(self, pytester: Pytester) -> None:
+        pytester.getmodulecol(
             """
             class test(object):
                 pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*collected 0*"])

-    def test_static_method(self, testdir):
+    def test_static_method(self, pytester: Pytester) -> None:
         """Support for collecting staticmethod tests (#2528, #2699)"""
-        testdir.getmodulecol(
+        pytester.getmodulecol(
             """
             import pytest
             class Test(object):
@@ -191,11 +204,11 @@
                     assert fix == 1
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*collected 2 items*", "*2 passed in*"])

-    def test_setup_teardown_class_as_classmethod(self, testdir):
-        testdir.makepyfile(
+    def test_setup_teardown_class_as_classmethod(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             test_mod1="""
             class TestClassMethod(object):
                 @classmethod
@@ -208,11 +221,11 @@
                     pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*1 passed*"])

-    def test_issue1035_obj_has_getattr(self, testdir):
-        modcol = testdir.getmodulecol(
+    def test_issue1035_obj_has_getattr(self, pytester: Pytester) -> None:
+        modcol = pytester.getmodulecol(
             """
             class Chameleon(object):
                 def __getattr__(self, name):
@@ -223,22 +236,22 @@
         colitems = modcol.collect()
         assert len(colitems) == 0

-    def test_issue1579_namedtuple(self, testdir):
-        testdir.makepyfile(
+    def test_issue1579_namedtuple(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import collections

             TestCase = collections.namedtuple('TestCase', ['a'])
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             "*cannot collect test class 'TestCase' "
             "because it has a __new__ constructor*"
         )

-    def test_issue2234_property(self, testdir):
-        testdir.makepyfile(
+    def test_issue2234_property(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             class TestCase(object):
                 @property
@@ -246,29 +259,29 @@
                     raise NotImplementedError()
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret == ExitCode.NO_TESTS_COLLECTED


 class TestFunction:
-    def test_getmodulecollector(self, testdir):
-        item = testdir.getitem("def test_func(): pass")
+    def test_getmodulecollector(self, pytester: Pytester) -> None:
+        item = pytester.getitem("def test_func(): pass")
         modcol = item.getparent(pytest.Module)
         assert isinstance(modcol, pytest.Module)
         assert hasattr(modcol.obj, "test_func")

     @pytest.mark.filterwarnings("default")
-    def test_function_as_object_instance_ignored(self, testdir):
-        testdir.makepyfile(
+    def test_function_as_object_instance_ignored(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             class A(object):
-                def __call__(self, tmpdir):
+                def __call__(self, tmp_path):
                     0/0

             test_a = A()
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             [
                 "collected 0 items",
@@ -278,37 +291,37 @@
         )

     @staticmethod
-    def make_function(testdir, **kwargs):
+    def make_function(pytester: Pytester, **kwargs: Any) -> Any:
         from _pytest.fixtures import FixtureManager

-        config = testdir.parseconfigure()
-        session = testdir.Session.from_config(config)
+        config = pytester.parseconfigure()
+        session = Session.from_config(config)
         session._fixturemanager = FixtureManager(session)

         return pytest.Function.from_parent(parent=session, **kwargs)

-    def test_function_equality(self, testdir):
+    def test_function_equality(self, pytester: Pytester) -> None:
         def func1():
             pass

         def func2():
             pass

-        f1 = self.make_function(testdir, name="name", callobj=func1)
+        f1 = self.make_function(pytester, name="name", callobj=func1)
         assert f1 == f1
         f2 = self.make_function(
-            testdir, name="name", callobj=func2, originalname="foobar"
+            pytester, name="name", callobj=func2, originalname="foobar"
         )
         assert f1 != f2

-    def test_repr_produces_actual_test_id(self, testdir):
+    def test_repr_produces_actual_test_id(self, pytester: Pytester) -> None:
         f = self.make_function(
-            testdir, name=r"test[\xe5]", callobj=self.test_repr_produces_actual_test_id
+            pytester, name=r"test[\xe5]", callobj=self.test_repr_produces_actual_test_id
         )
         assert repr(f) == r"<Function test[\xe5]>"

-    def test_issue197_parametrize_emptyset(self, testdir):
-        testdir.makepyfile(
+    def test_issue197_parametrize_emptyset(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.parametrize('arg', [])
@@ -316,11 +329,11 @@
                 pass
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(skipped=1)

-    def test_single_tuple_unwraps_values(self, testdir):
-        testdir.makepyfile(
+    def test_single_tuple_unwraps_values(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.parametrize(('arg',), [(1,)])
@@ -328,11 +341,11 @@
                 assert arg == 1
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)

-    def test_issue213_parametrize_value_no_equal(self, testdir):
-        testdir.makepyfile(
+    def test_issue213_parametrize_value_no_equal(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             class A(object):
@@ -343,12 +356,12 @@
                 assert arg.__class__.__name__ == "A"
         """
         )
-        reprec = testdir.inline_run("--fulltrace")
+        reprec = pytester.inline_run("--fulltrace")
         reprec.assertoutcome(passed=1)

-    def test_parametrize_with_non_hashable_values(self, testdir):
+    def test_parametrize_with_non_hashable_values(self, pytester: Pytester) -> None:
         """Test parametrization with non-hashable values."""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             archival_mapping = {
                 '1.0': {'tag': '1.0'},
@@ -363,12 +376,14 @@
                 assert value == archival_mapping[key]
         """
         )
-        rec = testdir.inline_run()
+        rec = pytester.inline_run()
         rec.assertoutcome(passed=2)

-    def test_parametrize_with_non_hashable_values_indirect(self, testdir):
+    def test_parametrize_with_non_hashable_values_indirect(
+        self, pytester: Pytester
+    ) -> None:
         """Test parametrization with non-hashable values with indirect parametrization."""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             archival_mapping = {
                 '1.0': {'tag': '1.0'},
@@ -392,12 +407,12 @@
                 assert value == archival_mapping[key]
         """
         )
-        rec = testdir.inline_run()
+        rec = pytester.inline_run()
         rec.assertoutcome(passed=2)

-    def test_parametrize_overrides_fixture(self, testdir):
+    def test_parametrize_overrides_fixture(self, pytester: Pytester) -> None:
         """Test parametrization when parameter overrides existing fixture with same name."""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -421,12 +436,14 @@
                 assert value == 'overridden'
         """
         )
-        rec = testdir.inline_run()
+        rec = pytester.inline_run()
         rec.assertoutcome(passed=3)

-    def test_parametrize_overrides_parametrized_fixture(self, testdir):
+    def test_parametrize_overrides_parametrized_fixture(
+        self, pytester: Pytester
+    ) -> None:
         """Test parametrization when parameter overrides existing parametrized fixture with same name."""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -440,12 +457,14 @@
                 assert value == 'overridden'
         """
         )
-        rec = testdir.inline_run()
+        rec = pytester.inline_run()
         rec.assertoutcome(passed=1)

-    def test_parametrize_overrides_indirect_dependency_fixture(self, testdir):
+    def test_parametrize_overrides_indirect_dependency_fixture(
+        self, pytester: Pytester
+    ) -> None:
         """Test parametrization when parameter overrides a fixture that a test indirectly depends on"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -471,11 +490,11 @@
                assert not fix3_instantiated
         """
         )
-        rec = testdir.inline_run()
+        rec = pytester.inline_run()
         rec.assertoutcome(passed=1)

-    def test_parametrize_with_mark(self, testdir):
-        items = testdir.getitems(
+    def test_parametrize_with_mark(self, pytester: Pytester) -> None:
+        items = pytester.getitems(
             """
             import pytest
             @pytest.mark.foo
@@ -495,8 +514,8 @@
         )
         assert "foo" in keywords[1] and "bar" in keywords[1] and "baz" in keywords[1]

-    def test_parametrize_with_empty_string_arguments(self, testdir):
-        items = testdir.getitems(
+    def test_parametrize_with_empty_string_arguments(self, pytester: Pytester) -> None:
+        items = pytester.getitems(
             """\
             import pytest

@@ -508,8 +527,8 @@
         names = {item.name for item in items}
         assert names == {"test[-]", "test[ -]", "test[- ]", "test[ - ]"}

-    def test_function_equality_with_callspec(self, testdir):
-        items = testdir.getitems(
+    def test_function_equality_with_callspec(self, pytester: Pytester) -> None:
+        items = pytester.getitems(
             """
             import pytest
             @pytest.mark.parametrize('arg', [1,2])
@@ -520,8 +539,8 @@
         assert items[0] != items[1]
         assert not (items[0] == items[1])

-    def test_pyfunc_call(self, testdir):
-        item = testdir.getitem("def test_func(): raise ValueError")
+    def test_pyfunc_call(self, pytester: Pytester) -> None:
+        item = pytester.getitem("def test_func(): raise ValueError")
         config = item.config

         class MyPlugin1:
@@ -537,8 +556,8 @@
         config.hook.pytest_runtest_setup(item=item)
         config.hook.pytest_pyfunc_call(pyfuncitem=item)

-    def test_multiple_parametrize(self, testdir):
-        modcol = testdir.getmodulecol(
+    def test_multiple_parametrize(self, pytester: Pytester) -> None:
+        modcol = pytester.getmodulecol(
             """
             import pytest
             @pytest.mark.parametrize('x', [0, 1])
@@ -553,8 +572,8 @@
         assert colitems[2].name == "test1[3-0]"
         assert colitems[3].name == "test1[3-1]"

-    def test_issue751_multiple_parametrize_with_ids(self, testdir):
-        modcol = testdir.getmodulecol(
+    def test_issue751_multiple_parametrize_with_ids(self, pytester: Pytester) -> None:
+        modcol = pytester.getmodulecol(
             """
             import pytest
             @pytest.mark.parametrize('x', [0], ids=['c'])
@@ -566,14 +585,14 @@
                     pass
         """
         )
-        colitems = modcol.collect()[0].collect()[0].collect()
+        colitems = modcol.collect()[0].collect()
         assert colitems[0].name == "test1[a-c]"
         assert colitems[1].name == "test1[b-c]"
         assert colitems[2].name == "test2[a-c]"
         assert colitems[3].name == "test2[b-c]"

-    def test_parametrize_skipif(self, testdir):
-        testdir.makepyfile(
+    def test_parametrize_skipif(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -584,11 +603,11 @@
                 assert x < 2
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["* 2 passed, 1 skipped in *"])

-    def test_parametrize_skip(self, testdir):
-        testdir.makepyfile(
+    def test_parametrize_skip(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -599,11 +618,11 @@
                 assert x < 2
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["* 2 passed, 1 skipped in *"])

-    def test_parametrize_skipif_no_skip(self, testdir):
-        testdir.makepyfile(
+    def test_parametrize_skipif_no_skip(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -614,11 +633,11 @@
                 assert x < 2
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["* 1 failed, 2 passed in *"])

-    def test_parametrize_xfail(self, testdir):
-        testdir.makepyfile(
+    def test_parametrize_xfail(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -629,11 +648,11 @@
                 assert x < 2
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["* 2 passed, 1 xfailed in *"])

-    def test_parametrize_passed(self, testdir):
-        testdir.makepyfile(
+    def test_parametrize_passed(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -644,11 +663,11 @@
                 pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["* 2 passed, 1 xpassed in *"])

-    def test_parametrize_xfail_passed(self, testdir):
-        testdir.makepyfile(
+    def test_parametrize_xfail_passed(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -659,11 +678,11 @@
                 pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["* 3 passed in *"])

-    def test_function_originalname(self, testdir: Testdir) -> None:
-        items = testdir.getitems(
+    def test_function_originalname(self, pytester: Pytester) -> None:
+        items = pytester.getitems(
             """
             import pytest

@@ -685,14 +704,14 @@
             "test_no_param",
         ]

-    def test_function_with_square_brackets(self, testdir: Testdir) -> None:
+    def test_function_with_square_brackets(self, pytester: Pytester) -> None:
         """Check that functions with square brackets don't cause trouble."""
-        p1 = testdir.makepyfile(
+        p1 = pytester.makepyfile(
             """
             locals()["test_foo[name]"] = lambda: None
             """
         )
-        result = testdir.runpytest("-v", str(p1))
+        result = pytester.runpytest("-v", str(p1))
         result.stdout.fnmatch_lines(
             [
                 "test_function_with_square_brackets.py::test_foo[[]name[]] PASSED *",
@@ -702,23 +721,23 @@


 class TestSorting:
-    def test_check_equality(self, testdir) -> None:
-        modcol = testdir.getmodulecol(
+    def test_check_equality(self, pytester: Pytester) -> None:
+        modcol = pytester.getmodulecol(
             """
             def test_pass(): pass
             def test_fail(): assert 0
         """
         )
-        fn1 = testdir.collect_by_name(modcol, "test_pass")
+        fn1 = pytester.collect_by_name(modcol, "test_pass")
         assert isinstance(fn1, pytest.Function)
-        fn2 = testdir.collect_by_name(modcol, "test_pass")
+        fn2 = pytester.collect_by_name(modcol, "test_pass")
         assert isinstance(fn2, pytest.Function)

         assert fn1 == fn2
         assert fn1 != modcol
         assert hash(fn1) == hash(fn2)

-        fn3 = testdir.collect_by_name(modcol, "test_fail")
+        fn3 = pytester.collect_by_name(modcol, "test_fail")
         assert isinstance(fn3, pytest.Function)
         assert not (fn1 == fn3)
         assert fn1 != fn3
@@ -730,8 +749,8 @@
             assert [1, 2, 3] != fn  # type: ignore[comparison-overlap]
             assert modcol != fn

-    def test_allow_sane_sorting_for_decorators(self, testdir):
-        modcol = testdir.getmodulecol(
+    def test_allow_sane_sorting_for_decorators(self, pytester: Pytester) -> None:
+        modcol = pytester.getmodulecol(
             """
             def dec(f):
                 g = lambda: f(2)
@@ -752,27 +771,58 @@
         assert len(colitems) == 2
         assert [item.name for item in colitems] == ["test_b", "test_a"]

+    def test_ordered_by_definition_order(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
+            """\
+            class Test1:
+                def test_foo(): pass
+                def test_bar(): pass
+            class Test2:
+                def test_foo(): pass
+                test_bar = Test1.test_bar
+            class Test3(Test2):
+                def test_baz(): pass
+            """
+        )
+        result = pytester.runpytest("--collect-only")
+        result.stdout.fnmatch_lines(
+            [
+                "*Class Test1*",
+                "*Function test_foo*",
+                "*Function test_bar*",
+                "*Class Test2*",
+                # previously the order was flipped due to Test1.test_bar reference
+                "*Function test_foo*",
+                "*Function test_bar*",
+                "*Class Test3*",
+                "*Function test_foo*",
+                "*Function test_bar*",
+                "*Function test_baz*",
+            ]
+        )
+

 class TestConftestCustomization:
-    def test_pytest_pycollect_module(self, testdir):
-        testdir.makeconftest(
+    def test_pytest_pycollect_module(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest
             class MyModule(pytest.Module):
                 pass
-            def pytest_pycollect_makemodule(path, parent):
-                if path.basename == "test_xyz.py":
-                    return MyModule.from_parent(fspath=path, parent=parent)
-        """
-        )
-        testdir.makepyfile("def test_some(): pass")
-        testdir.makepyfile(test_xyz="def test_func(): pass")
-        result = testdir.runpytest("--collect-only")
+            def pytest_pycollect_makemodule(module_path, parent):
+                if module_path.name == "test_xyz.py":
+                    return MyModule.from_parent(path=module_path, parent=parent)
+        """
+        )
+        pytester.makepyfile("def test_some(): pass")
+        pytester.makepyfile(test_xyz="def test_func(): pass")
+        result = pytester.runpytest("--collect-only")
         result.stdout.fnmatch_lines(["*<Module*test_pytest*", "*<MyModule*xyz*"])

-    def test_customized_pymakemodule_issue205_subdir(self, testdir):
-        b = testdir.mkdir("a").mkdir("b")
-        b.join("conftest.py").write(
+    def test_customized_pymakemodule_issue205_subdir(self, pytester: Pytester) -> None:
+        b = pytester.path.joinpath("a", "b")
+        b.mkdir(parents=True)
+        b.joinpath("conftest.py").write_text(
             textwrap.dedent(
                 """\
                 import pytest
@@ -784,7 +834,7 @@
                 """
             )
         )
-        b.join("test_module.py").write(
+        b.joinpath("test_module.py").write_text(
             textwrap.dedent(
                 """\
                 def test_hello():
@@ -792,12 +842,13 @@
                 """
             )
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)

-    def test_customized_pymakeitem(self, testdir):
-        b = testdir.mkdir("a").mkdir("b")
-        b.join("conftest.py").write(
+    def test_customized_pymakeitem(self, pytester: Pytester) -> None:
+        b = pytester.path.joinpath("a", "b")
+        b.mkdir(parents=True)
+        b.joinpath("conftest.py").write_text(
             textwrap.dedent(
                 """\
                 import pytest
@@ -812,7 +863,7 @@
                 """
             )
         )
-        b.join("test_module.py").write(
+        b.joinpath("test_module.py").write_text(
             textwrap.dedent(
                 """\
                 import pytest
@@ -825,11 +876,11 @@
                 """
             )
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)

-    def test_pytest_pycollect_makeitem(self, testdir):
-        testdir.makeconftest(
+    def test_pytest_pycollect_makeitem(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest
             class MyFunction(pytest.Function):
@@ -839,16 +890,16 @@
                     return MyFunction.from_parent(name=name, parent=collector)
         """
         )
-        testdir.makepyfile("def some(): pass")
-        result = testdir.runpytest("--collect-only")
+        pytester.makepyfile("def some(): pass")
+        result = pytester.runpytest("--collect-only")
         result.stdout.fnmatch_lines(["*MyFunction*some*"])

-    def test_issue2369_collect_module_fileext(self, testdir):
+    def test_issue2369_collect_module_fileext(self, pytester: Pytester) -> None:
         """Ensure we can collect files with weird file extensions as Python
         modules (#2369)"""
         # We'll implement a little finder and loader to import files containing
         # Python source code whose file extension is ".narf".
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import sys, os, imp
             from _pytest.python import Module
@@ -862,21 +913,21 @@
                         return Loader()
             sys.meta_path.append(Finder())

-            def pytest_collect_file(path, parent):
-                if path.ext == ".narf":
-                    return Module.from_parent(fspath=path, parent=parent)"""
-        )
-        testdir.makefile(
+            def pytest_collect_file(file_path, parent):
+                if file_path.suffix == ".narf":
+                    return Module.from_parent(path=file_path, parent=parent)"""
+        )
+        pytester.makefile(
             ".narf",
             """\
             def test_something():
                 assert 1 + 1 == 2""",
         )
         # Use runpytest_subprocess, since we're futzing with sys.meta_path.
-        result = testdir.runpytest_subprocess()
+        result = pytester.runpytest_subprocess()
         result.stdout.fnmatch_lines(["*1 passed*"])

-    def test_early_ignored_attributes(self, testdir: Testdir) -> None:
+    def test_early_ignored_attributes(self, pytester: Pytester) -> None:
         """Builtin attributes should be ignored early on, even if
         configuration would otherwise allow them.

@@ -884,14 +935,14 @@
         although it tests PytestCollectionWarning is not raised, while
         it would have been raised otherwise.
         """
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
             python_classes=*
             python_functions=*
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             class TestEmpty:
                 pass
@@ -900,48 +951,48 @@
                 pass
         """
         )
-        items, rec = testdir.inline_genitems()
+        items, rec = pytester.inline_genitems()
         assert rec.ret == 0
         assert len(items) == 1


-def test_setup_only_available_in_subdir(testdir):
-    sub1 = testdir.mkpydir("sub1")
-    sub2 = testdir.mkpydir("sub2")
-    sub1.join("conftest.py").write(
+def test_setup_only_available_in_subdir(pytester: Pytester) -> None:
+    sub1 = pytester.mkpydir("sub1")
+    sub2 = pytester.mkpydir("sub2")
+    sub1.joinpath("conftest.py").write_text(
         textwrap.dedent(
             """\
             import pytest
             def pytest_runtest_setup(item):
-                assert item.fspath.purebasename == "test_in_sub1"
+                assert item.path.stem == "test_in_sub1"
             def pytest_runtest_call(item):
-                assert item.fspath.purebasename == "test_in_sub1"
+                assert item.path.stem == "test_in_sub1"
             def pytest_runtest_teardown(item):
-                assert item.fspath.purebasename == "test_in_sub1"
-            """
-        )
-    )
-    sub2.join("conftest.py").write(
+                assert item.path.stem == "test_in_sub1"
+            """
+        )
+    )
+    sub2.joinpath("conftest.py").write_text(
         textwrap.dedent(
             """\
             import pytest
             def pytest_runtest_setup(item):
-                assert item.fspath.purebasename == "test_in_sub2"
+                assert item.path.stem == "test_in_sub2"
             def pytest_runtest_call(item):
-                assert item.fspath.purebasename == "test_in_sub2"
+                assert item.path.stem == "test_in_sub2"
             def pytest_runtest_teardown(item):
-                assert item.fspath.purebasename == "test_in_sub2"
-            """
-        )
-    )
-    sub1.join("test_in_sub1.py").write("def test_1(): pass")
-    sub2.join("test_in_sub2.py").write("def test_2(): pass")
-    result = testdir.runpytest("-v", "-s")
+                assert item.path.stem == "test_in_sub2"
+            """
+        )
+    )
+    sub1.joinpath("test_in_sub1.py").write_text("def test_1(): pass")
+    sub2.joinpath("test_in_sub2.py").write_text("def test_2(): pass")
+    result = pytester.runpytest("-v", "-s")
     result.assert_outcomes(passed=2)


-def test_modulecol_roundtrip(testdir):
-    modcol = testdir.getmodulecol("pass", withinit=False)
+def test_modulecol_roundtrip(pytester: Pytester) -> None:
+    modcol = pytester.getmodulecol("pass", withinit=False)
     trail = modcol.nodeid
     newcol = modcol.session.perform_collect([trail], genitems=0)[0]
     assert modcol.name == newcol.name
@@ -956,8 +1007,8 @@
         assert excinfo.traceback[-2].frame.code.name == "test_skip_simple"
         assert not excinfo.traceback[-2].ishidden()

-    def test_traceback_argsetup(self, testdir):
-        testdir.makeconftest(
+    def test_traceback_argsetup(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest

@@ -966,8 +1017,8 @@
                 raise ValueError("xyz")
         """
         )
-        p = testdir.makepyfile("def test(hello): pass")
-        result = testdir.runpytest(p)
+        p = pytester.makepyfile("def test(hello): pass")
+        result = pytester.runpytest(p)
         assert result.ret != 0
         out = result.stdout.str()
         assert "xyz" in out
@@ -975,14 +1026,14 @@
         numentries = out.count("_ _ _")  # separator for traceback entries
         assert numentries == 0

-        result = testdir.runpytest("--fulltrace", p)
+        result = pytester.runpytest("--fulltrace", p)
         out = result.stdout.str()
         assert "conftest.py:5: ValueError" in out
         numentries = out.count("_ _ _ _")  # separator for traceback entries
         assert numentries > 3

-    def test_traceback_error_during_import(self, testdir):
-        testdir.makepyfile(
+    def test_traceback_error_during_import(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             x = 1
             x = 2
@@ -990,21 +1041,23 @@
             asd
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret != 0
         out = result.stdout.str()
         assert "x = 1" not in out
         assert "x = 2" not in out
         result.stdout.fnmatch_lines([" *asd*", "E*NameError*"])
-        result = testdir.runpytest("--fulltrace")
+        result = pytester.runpytest("--fulltrace")
         out = result.stdout.str()
         assert "x = 1" in out
         assert "x = 2" in out
         result.stdout.fnmatch_lines([">*asd*", "E*NameError*"])

-    def test_traceback_filter_error_during_fixture_collection(self, testdir):
+    def test_traceback_filter_error_during_fixture_collection(
+        self, pytester: Pytester
+    ) -> None:
         """Integration test for issue #995."""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -1022,7 +1075,7 @@
                pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret != 0
         out = result.stdout.str()
         assert "INTERNALERROR>" not in out
@@ -1039,8 +1092,9 @@
         """
         from _pytest._code import filter_traceback

+        tb = None
         try:
-            ns = {}  # type: Dict[str, Any]
+            ns: Dict[str, Any] = {}
             exec("def foo(): raise ValueError", ns)
             ns["foo"]()
         except ValueError:
@@ -1051,7 +1105,7 @@
         assert isinstance(traceback[-1].path, str)
         assert not filter_traceback(traceback[-1])

-    def test_filter_traceback_path_no_longer_valid(self, testdir) -> None:
+    def test_filter_traceback_path_no_longer_valid(self, pytester: Pytester) -> None:
         """Test that filter_traceback() works with the fact that
         _pytest._code.code.Code.path attribute might return an str object.

@@ -1060,13 +1114,14 @@
         """
         from _pytest._code import filter_traceback

-        testdir.syspathinsert()
-        testdir.makepyfile(
+        pytester.syspathinsert()
+        pytester.makepyfile(
             filter_traceback_entry_as_str="""
             def foo():
                 raise ValueError
         """
         )
+        tb = None
         try:
             import filter_traceback_entry_as_str

@@ -1075,15 +1130,15 @@
             _, _, tb = sys.exc_info()

         assert tb is not None
-        testdir.tmpdir.join("filter_traceback_entry_as_str.py").remove()
+        pytester.path.joinpath("filter_traceback_entry_as_str.py").unlink()
         traceback = _pytest._code.Traceback(tb)
         assert isinstance(traceback[-1].path, str)
         assert filter_traceback(traceback[-1])


 class TestReportInfo:
-    def test_itemreport_reportinfo(self, testdir):
-        testdir.makeconftest(
+    def test_itemreport_reportinfo(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest
             class MyFunction(pytest.Function):
@@ -1094,54 +1149,64 @@
                     return MyFunction.from_parent(name=name, parent=collector)
         """
         )
-        item = testdir.getitem("def test_func(): pass")
+        item = pytester.getitem("def test_func(): pass")
         item.config.pluginmanager.getplugin("runner")
         assert item.location == ("ABCDE", 42, "custom")

-    def test_func_reportinfo(self, testdir):
-        item = testdir.getitem("def test_func(): pass")
-        fspath, lineno, modpath = item.reportinfo()
-        assert fspath == item.fspath
+    def test_func_reportinfo(self, pytester: Pytester) -> None:
+        item = pytester.getitem("def test_func(): pass")
+        path, lineno, modpath = item.reportinfo()
+        assert os.fspath(path) == str(item.path)
         assert lineno == 0
         assert modpath == "test_func"

-    def test_class_reportinfo(self, testdir):
-        modcol = testdir.getmodulecol(
+    def test_class_reportinfo(self, pytester: Pytester) -> None:
+        modcol = pytester.getmodulecol(
             """
             # lineno 0
             class TestClass(object):
                 def test_hello(self): pass
         """
         )
-        classcol = testdir.collect_by_name(modcol, "TestClass")
-        fspath, lineno, msg = classcol.reportinfo()
-        assert fspath == modcol.fspath
+        classcol = pytester.collect_by_name(modcol, "TestClass")
+        assert isinstance(classcol, Class)
+        path, lineno, msg = classcol.reportinfo()
+        assert os.fspath(path) == str(modcol.path)
         assert lineno == 1
         assert msg == "TestClass"

     @pytest.mark.filterwarnings(
         "ignore:usage of Generator.Function is deprecated, please use pytest.Function instead"
     )
-    def test_reportinfo_with_nasty_getattr(self, testdir):
+    def test_reportinfo_with_nasty_getattr(self, pytester: Pytester) -> None:
         # https://github.com/pytest-dev/pytest/issues/1204
-        modcol = testdir.getmodulecol(
+        modcol = pytester.getmodulecol(
             """
             # lineno 0
-            class TestClass(object):
+            class TestClass:
                 def __getattr__(self, name):
                     return "this is not an int"

-                def test_foo(self):
+                def __class_getattr__(cls, name):
+                    return "this is not an int"
+
+                def intest_foo(self):
                     pass
-        """
-        )
-        classcol = testdir.collect_by_name(modcol, "TestClass")
-        instance = classcol.collect()[0]
-        fspath, lineno, msg = instance.reportinfo()
-
-
-def test_customized_python_discovery(testdir):
-    testdir.makeini(
+
+                def test_bar(self):
+                    pass
+        """
+        )
+        classcol = pytester.collect_by_name(modcol, "TestClass")
+        assert isinstance(classcol, Class)
+        path, lineno, msg = classcol.reportinfo()
+        func = list(classcol.collect())[0]
+        assert isinstance(func, Function)
+        path, lineno, msg = func.reportinfo()
+
+
+def test_customized_python_discovery(pytester: Pytester) -> None:
+    pytester.makeini(
         """
         [pytest]
         python_files=check_*.py
@@ -1149,7 +1214,7 @@
         python_functions=check
     """
     )
-    p = testdir.makepyfile(
+    p = pytester.makepyfile(
         """
         def check_simple():
             pass
@@ -1158,41 +1223,41 @@
                 pass
     """
     )
-    p2 = p.new(basename=p.basename.replace("test", "check"))
-    p.move(p2)
-    result = testdir.runpytest("--collect-only", "-s")
+    p2 = p.with_name(p.name.replace("test", "check"))
+    p.rename(p2)
+    result = pytester.runpytest("--collect-only", "-s")
     result.stdout.fnmatch_lines(
         ["*check_customized*", "*check_simple*", "*CheckMyApp*", "*check_meth*"]
     )

-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert result.ret == 0
     result.stdout.fnmatch_lines(["*2 passed*"])


-def test_customized_python_discovery_functions(testdir):
-    testdir.makeini(
+def test_customized_python_discovery_functions(pytester: Pytester) -> None:
+    pytester.makeini(
         """
         [pytest]
         python_functions=_test
     """
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         def _test_underscore():
             pass
     """
     )
-    result = testdir.runpytest("--collect-only", "-s")
+    result = pytester.runpytest("--collect-only", "-s")
     result.stdout.fnmatch_lines(["*_test_underscore*"])

-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert result.ret == 0
     result.stdout.fnmatch_lines(["*1 passed*"])


-def test_unorderable_types(testdir):
-    testdir.makepyfile(
+def test_unorderable_types(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         class TestJoinEmpty(object):
             pass
@@ -1205,19 +1270,19 @@
         TestFoo = make_test()
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.no_fnmatch_line("*TypeError*")
     assert result.ret == ExitCode.NO_TESTS_COLLECTED


-@pytest.mark.filterwarnings("default")
-def test_dont_collect_non_function_callable(testdir):
+@pytest.mark.filterwarnings("default::pytest.PytestCollectionWarning")
+def test_dont_collect_non_function_callable(pytester: Pytester) -> None:
     """Test for issue https://github.com/pytest-dev/pytest/issues/331

     In this case an INTERNALERROR occurred trying to report the failure of
     a test like this one because pytest failed to get the source lines.
     """
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         class Oh(object):
             def __call__(self):
@@ -1229,7 +1294,7 @@
             pass
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         [
             "*collected 1 item*",
@@ -1239,21 +1304,21 @@
     )


-def test_class_injection_does_not_break_collection(testdir):
+def test_class_injection_does_not_break_collection(pytester: Pytester) -> None:
     """Tests whether injection during collection time will terminate testing.

     In this case the error should not occur if the TestClass itself
     is modified during collection time, and the original method list
     is still used for collection.
     """
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         from test_inject import TestClass
         def pytest_generate_tests(metafunc):
             TestClass.changed_var = {}
     """
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         test_inject='''
          class TestClass(object):
             def test_injection(self):
@@ -1261,7 +1326,7 @@
                 pass
     '''
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert (
         "RuntimeError: dictionary changed size during iteration"
         not in result.stdout.str()
@@ -1269,16 +1334,16 @@
     result.stdout.fnmatch_lines(["*1 passed*"])


-def test_syntax_error_with_non_ascii_chars(testdir):
+def test_syntax_error_with_non_ascii_chars(pytester: Pytester) -> None:
     """Fix decoding issue while formatting SyntaxErrors during collection (#578)."""
-    testdir.makepyfile("☃")
-    result = testdir.runpytest()
+    pytester.makepyfile("☃")
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*ERROR collecting*", "*SyntaxError*", "*1 error in*"])


-def test_collect_error_with_fulltrace(testdir):
-    testdir.makepyfile("assert 0")
-    result = testdir.runpytest("--fulltrace")
+def test_collect_error_with_fulltrace(pytester: Pytester) -> None:
+    pytester.makepyfile("assert 0")
+    result = pytester.runpytest("--fulltrace")
     result.stdout.fnmatch_lines(
         [
             "collected 0 items / 1 error",
@@ -1295,14 +1360,14 @@
     )


-def test_skip_duplicates_by_default(testdir):
+def test_skip_duplicates_by_default(pytester: Pytester) -> None:
     """Test for issue https://github.com/pytest-dev/pytest/issues/1609 (#1609)

     Ignore duplicate directories.
     """
-    a = testdir.mkdir("a")
-    fh = a.join("test_a.py")
-    fh.write(
+    a = pytester.mkdir("a")
+    fh = a.joinpath("test_a.py")
+    fh.write_text(
         textwrap.dedent(
             """\
             import pytest
@@ -1311,18 +1376,18 @@
             """
         )
     )
-    result = testdir.runpytest(a.strpath, a.strpath)
+    result = pytester.runpytest(str(a), str(a))
     result.stdout.fnmatch_lines(["*collected 1 item*"])


-def test_keep_duplicates(testdir):
+def test_keep_duplicates(pytester: Pytester) -> None:
     """Test for issue https://github.com/pytest-dev/pytest/issues/1609 (#1609)

     Use --keep-duplicates to collect tests from duplicate directories.
     """
-    a = testdir.mkdir("a")
-    fh = a.join("test_a.py")
-    fh.write(
+    a = pytester.mkdir("a")
+    fh = a.joinpath("test_a.py")
+    fh.write_text(
         textwrap.dedent(
             """\
             import pytest
@@ -1331,24 +1396,24 @@
             """
         )
     )
-    result = testdir.runpytest("--keep-duplicates", a.strpath, a.strpath)
+    result = pytester.runpytest("--keep-duplicates", str(a), str(a))
     result.stdout.fnmatch_lines(["*collected 2 item*"])


-def test_package_collection_infinite_recursion(testdir):
-    testdir.copy_example("collect/package_infinite_recursion")
-    result = testdir.runpytest()
+def test_package_collection_infinite_recursion(pytester: Pytester) -> None:
+    pytester.copy_example("collect/package_infinite_recursion")
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*1 passed*"])


-def test_package_collection_init_given_as_argument(testdir):
+def test_package_collection_init_given_as_argument(pytester: Pytester) -> None:
     """Regression test for #3749"""
-    p = testdir.copy_example("collect/package_init_given_as_arg")
-    result = testdir.runpytest(p / "pkg" / "__init__.py")
+    p = pytester.copy_example("collect/package_init_given_as_arg")
+    result = pytester.runpytest(p / "pkg" / "__init__.py")
     result.stdout.fnmatch_lines(["*1 passed*"])


-def test_package_with_modules(testdir):
+def test_package_with_modules(pytester: Pytester) -> None:
     """
     .
     └── root
@@ -1363,32 +1428,35 @@
                 └── test_in_sub2.py

     """
-    root = testdir.mkpydir("root")
-    sub1 = root.mkdir("sub1")
-    sub1.ensure("__init__.py")
-    sub1_test = sub1.mkdir("sub1_1")
-    sub1_test.ensure("__init__.py")
-    sub2 = root.mkdir("sub2")
-    sub2_test = sub2.mkdir("sub2")
-
-    sub1_test.join("test_in_sub1.py").write("def test_1(): pass")
-    sub2_test.join("test_in_sub2.py").write("def test_2(): pass")
+    root = pytester.mkpydir("root")
+    sub1 = root.joinpath("sub1")
+    sub1_test = sub1.joinpath("sub1_1")
+    sub1_test.mkdir(parents=True)
+    for d in (sub1, sub1_test):
+        d.joinpath("__init__.py").touch()
+
+    sub2 = root.joinpath("sub2")
+    sub2_test = sub2.joinpath("test")
+    sub2_test.mkdir(parents=True)
+
+    sub1_test.joinpath("test_in_sub1.py").write_text("def test_1(): pass")
+    sub2_test.joinpath("test_in_sub2.py").write_text("def test_2(): pass")

     # Execute from .
-    result = testdir.runpytest("-v", "-s")
+    result = pytester.runpytest("-v", "-s")
     result.assert_outcomes(passed=2)

     # Execute from . with one argument "root"
-    result = testdir.runpytest("-v", "-s", "root")
+    result = pytester.runpytest("-v", "-s", "root")
     result.assert_outcomes(passed=2)

     # Chdir into package's root and execute with no args
-    root.chdir()
-    result = testdir.runpytest("-v", "-s")
+    os.chdir(root)
+    result = pytester.runpytest("-v", "-s")
     result.assert_outcomes(passed=2)


-def test_package_ordering(testdir):
+def test_package_ordering(pytester: Pytester) -> None:
     """
     .
     └── root
@@ -1402,22 +1470,24 @@
                 └── test_sub2.py

     """
-    testdir.makeini(
+    pytester.makeini(
         """
         [pytest]
         python_files=*.py
     """
     )
-    root = testdir.mkpydir("root")
-    sub1 = root.mkdir("sub1")
-    sub1.ensure("__init__.py")
-    sub2 = root.mkdir("sub2")
-    sub2_test = sub2.mkdir("sub2")
-
-    root.join("Test_root.py").write("def test_1(): pass")
-    sub1.join("Test_sub1.py").write("def test_2(): pass")
-    sub2_test.join("test_sub2.py").write("def test_3(): pass")
+    root = pytester.mkpydir("root")
+    sub1 = root.joinpath("sub1")
+    sub1.mkdir()
+    sub1.joinpath("__init__.py").touch()
+    sub2 = root.joinpath("sub2")
+    sub2_test = sub2.joinpath("test")
+    sub2_test.mkdir(parents=True)
+
+    root.joinpath("Test_root.py").write_text("def test_1(): pass")
+    sub1.joinpath("Test_sub1.py").write_text("def test_2(): pass")
+    sub2_test.joinpath("test_sub2.py").write_text("def test_3(): pass")

     # Execute from .
-    result = testdir.runpytest("-v", "-s")
+    result = pytester.runpytest("-v", "-s")
     result.assert_outcomes(passed=3)
('testing/python', 'metafunc.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -23,9 +23,9 @@
 from _pytest.compat import getfuncargnames
 from _pytest.compat import NOTSET
 from _pytest.outcomes import fail
-from _pytest.pytester import Testdir
-from _pytest.python import _idval
-from _pytest.python import idmaker
+from _pytest.pytester import Pytester
+from _pytest.python import IdMaker
+from _pytest.scope import Scope


 class TestMetafunc:
@@ -45,9 +45,9 @@
             _nodeid = attr.ib()

         names = getfuncargnames(func)
-        fixtureinfo = FuncFixtureInfoMock(names)  # type: Any
-        definition = DefinitionMock._create(func, "mock::nodeid")  # type: Any
-        return python.Metafunc(definition, fixtureinfo, config)
+        fixtureinfo: Any = FuncFixtureInfoMock(names)
+        definition: Any = DefinitionMock._create(func, "mock::nodeid")
+        return python.Metafunc(definition, fixtureinfo, config, _ispytest=True)

     def test_no_funcargs(self) -> None:
         def function():
@@ -106,8 +106,8 @@
         with pytest.raises(
             fail.Exception,
             match=(
-                r"In func: ids must be list of string/float/int/bool, found:"
-                r" Exc\(from_gen\) \(type: <class .*Exc'>\) at index 2"
+                r"In func: ids contains unsupported value Exc\(from_gen\) \(type: <class .*Exc'>\) at index 2. "
+                r"Supported types are: .*"
             ),
         ):
             metafunc.parametrize("x", [1, 2, 3], ids=gen())  # type: ignore[arg-type]
@@ -123,7 +123,7 @@
         ):
             metafunc.parametrize("x", [1], scope="doggy")  # type: ignore[arg-type]

-    def test_parametrize_request_name(self, testdir: Testdir) -> None:
+    def test_parametrize_request_name(self, pytester: Pytester) -> None:
         """Show proper error  when 'request' is used as a parameter name in parametrize (#6183)"""

         def func(request):
@@ -142,16 +142,16 @@

         @attr.s
         class DummyFixtureDef:
-            scope = attr.ib()
+            _scope = attr.ib()

         fixtures_defs = cast(
             Dict[str, Sequence[fixtures.FixtureDef[object]]],
             dict(
-                session_fix=[DummyFixtureDef("session")],
-                package_fix=[DummyFixtureDef("package")],
-                module_fix=[DummyFixtureDef("module")],
-                class_fix=[DummyFixtureDef("class")],
-                func_fix=[DummyFixtureDef("function")],
+                session_fix=[DummyFixtureDef(Scope.Session)],
+                package_fix=[DummyFixtureDef(Scope.Package)],
+                module_fix=[DummyFixtureDef(Scope.Module)],
+                class_fix=[DummyFixtureDef(Scope.Class)],
+                func_fix=[DummyFixtureDef(Scope.Function)],
             ),
         )

@@ -160,29 +160,33 @@
         def find_scope(argnames, indirect):
             return _find_parametrized_scope(argnames, fixtures_defs, indirect=indirect)

-        assert find_scope(["func_fix"], indirect=True) == "function"
-        assert find_scope(["class_fix"], indirect=True) == "class"
-        assert find_scope(["module_fix"], indirect=True) == "module"
-        assert find_scope(["package_fix"], indirect=True) == "package"
-        assert find_scope(["session_fix"], indirect=True) == "session"
-
-        assert find_scope(["class_fix", "func_fix"], indirect=True) == "function"
-        assert find_scope(["func_fix", "session_fix"], indirect=True) == "function"
-        assert find_scope(["session_fix", "class_fix"], indirect=True) == "class"
-        assert find_scope(["package_fix", "session_fix"], indirect=True) == "package"
-        assert find_scope(["module_fix", "session_fix"], indirect=True) == "module"
+        assert find_scope(["func_fix"], indirect=True) == Scope.Function
+        assert find_scope(["class_fix"], indirect=True) == Scope.Class
+        assert find_scope(["module_fix"], indirect=True) == Scope.Module
+        assert find_scope(["package_fix"], indirect=True) == Scope.Package
+        assert find_scope(["session_fix"], indirect=True) == Scope.Session
+
+        assert find_scope(["class_fix", "func_fix"], indirect=True) == Scope.Function
+        assert find_scope(["func_fix", "session_fix"], indirect=True) == Scope.Function
+        assert find_scope(["session_fix", "class_fix"], indirect=True) == Scope.Class
+        assert (
+            find_scope(["package_fix", "session_fix"], indirect=True) == Scope.Package
+        )
+        assert find_scope(["module_fix", "session_fix"], indirect=True) == Scope.Module

         # when indirect is False or is not for all scopes, always use function
-        assert find_scope(["session_fix", "module_fix"], indirect=False) == "function"
+        assert (
+            find_scope(["session_fix", "module_fix"], indirect=False) == Scope.Function
+        )
         assert (
             find_scope(["session_fix", "module_fix"], indirect=["module_fix"])
-            == "function"
+            == Scope.Function
         )
         assert (
             find_scope(
                 ["session_fix", "module_fix"], indirect=["session_fix", "module_fix"]
             )
-            == "module"
+            == Scope.Module
         )

     def test_parametrize_and_id(self) -> None:
@@ -281,7 +285,7 @@
         deadline=400.0
     )  # very close to std deadline and CI boxes are not reliable in CPU power
     def test_idval_hypothesis(self, value) -> None:
-        escaped = _idval(value, "a", 6, None, nodeid=None, config=None)
+        escaped = IdMaker([], [], None, None, None, None, None)._idval(value, "a", 6)
         assert isinstance(escaped, str)
         escaped.encode("ascii")

@@ -303,7 +307,10 @@
             ),
         ]
         for val, expected in values:
-            assert _idval(val, "a", 6, None, nodeid=None, config=None) == expected
+            assert (
+                IdMaker([], [], None, None, None, None, None)._idval(val, "a", 6)
+                == expected
+            )

     def test_unicode_idval_with_config(self) -> None:
         """Unit test for expected behavior to obtain ids with
@@ -326,12 +333,12 @@

         option = "disable_test_id_escaping_and_forfeit_all_rights_to_community_support"

-        values = [
+        values: List[Tuple[str, Any, str]] = [
             ("ação", MockConfig({option: True}), "ação"),
             ("ação", MockConfig({option: False}), "a\\xe7\\xe3o"),
-        ]  # type: List[Tuple[str, Any, str]]
+        ]
         for val, config, expected in values:
-            actual = _idval(val, "a", 6, None, nodeid=None, config=config)
+            actual = IdMaker([], [], None, None, config, None, None)._idval(val, "a", 6)
             assert actual == expected

     def test_bytes_idval(self) -> None:
@@ -344,7 +351,10 @@
             ("αρά".encode(), r"\xce\xb1\xcf\x81\xce\xac"),
         ]
         for val, expected in values:
-            assert _idval(val, "a", 6, idfn=None, nodeid=None, config=None) == expected
+            assert (
+                IdMaker([], [], None, None, None, None, None)._idval(val, "a", 6)
+                == expected
+            )

     def test_class_or_function_idval(self) -> None:
         """Unit test for the expected behavior to obtain ids for parametrized
@@ -358,7 +368,10 @@

         values = [(TestClass, "TestClass"), (test_function, "test_function")]
         for val, expected in values:
-            assert _idval(val, "a", 6, None, nodeid=None, config=None) == expected
+            assert (
+                IdMaker([], [], None, None, None, None, None)._idval(val, "a", 6)
+                == expected
+            )

     def test_notset_idval(self) -> None:
         """Test that a NOTSET value (used by an empty parameterset) generates
@@ -366,29 +379,47 @@

         Regression test for #7686.
         """
-        assert _idval(NOTSET, "a", 0, None, nodeid=None, config=None) == "a0"
+        assert (
+            IdMaker([], [], None, None, None, None, None)._idval(NOTSET, "a", 0) == "a0"
+        )

     def test_idmaker_autoname(self) -> None:
         """#250"""
-        result = idmaker(
-            ("a", "b"), [pytest.param("string", 1.0), pytest.param("st-ring", 2.0)]
-        )
+        result = IdMaker(
+            ("a", "b"),
+            [pytest.param("string", 1.0), pytest.param("st-ring", 2.0)],
+            None,
+            None,
+            None,
+            None,
+            None,
+        ).make_unique_parameterset_ids()
         assert result == ["string-1.0", "st-ring-2.0"]

-        result = idmaker(
-            ("a", "b"), [pytest.param(object(), 1.0), pytest.param(object(), object())]
-        )
+        result = IdMaker(
+            ("a", "b"),
+            [pytest.param(object(), 1.0), pytest.param(object(), object())],
+            None,
+            None,
+            None,
+            None,
+            None,
+        ).make_unique_parameterset_ids()
         assert result == ["a0-1.0", "a1-b1"]
         # unicode mixing, issue250
-        result = idmaker(("a", "b"), [pytest.param({}, b"\xc3\xb4")])
+        result = IdMaker(
+            ("a", "b"), [pytest.param({}, b"\xc3\xb4")], None, None, None, None, None
+        ).make_unique_parameterset_ids()
         assert result == ["a0-\\xc3\\xb4"]

     def test_idmaker_with_bytes_regex(self) -> None:
-        result = idmaker(("a"), [pytest.param(re.compile(b"foo"), 1.0)])
+        result = IdMaker(
+            ("a"), [pytest.param(re.compile(b"foo"), 1.0)], None, None, None, None, None
+        ).make_unique_parameterset_ids()
         assert result == ["foo"]

     def test_idmaker_native_strings(self) -> None:
-        result = idmaker(
+        result = IdMaker(
             ("a", "b"),
             [
                 pytest.param(1.0, -1.1),
@@ -403,8 +434,14 @@
                 pytest.param(tuple("eight"), (8, -8, 8)),
                 pytest.param(b"\xc3\xb4", b"name"),
                 pytest.param(b"\xc3\xb4", "other"),
+                pytest.param(1.0j, -2.0j),
             ],
-        )
+            None,
+            None,
+            None,
+            None,
+            None,
+        ).make_unique_parameterset_ids()
         assert result == [
             "1.0--1.1",
             "2--202",
@@ -418,10 +455,11 @@
             "a9-b9",
             "\\xc3\\xb4-name",
             "\\xc3\\xb4-other",
+            "1j-(-0-2j)",
         ]

     def test_idmaker_non_printable_characters(self) -> None:
-        result = idmaker(
+        result = IdMaker(
             ("s", "n"),
             [
                 pytest.param("\x00", 1),
@@ -431,23 +469,35 @@
                 pytest.param("\t", 5),
                 pytest.param(b"\t", 6),
             ],
-        )
+            None,
+            None,
+            None,
+            None,
+            None,
+        ).make_unique_parameterset_ids()
         assert result == ["\\x00-1", "\\x05-2", "\\x00-3", "\\x05-4", "\\t-5", "\\t-6"]

     def test_idmaker_manual_ids_must_be_printable(self) -> None:
-        result = idmaker(
+        result = IdMaker(
             ("s",),
             [
                 pytest.param("x00", id="hello \x00"),
                 pytest.param("x05", id="hello \x05"),
             ],
-        )
+            None,
+            None,
+            None,
+            None,
+            None,
+        ).make_unique_parameterset_ids()
         assert result == ["hello \\x00", "hello \\x05"]

     def test_idmaker_enum(self) -> None:
         enum = pytest.importorskip("enum")
         e = enum.Enum("Foo", "one, two")
-        result = idmaker(("a", "b"), [pytest.param(e.one, e.two)])
+        result = IdMaker(
+            ("a", "b"), [pytest.param(e.one, e.two)], None, None, None, None, None
+        ).make_unique_parameterset_ids()
         assert result == ["Foo.one-Foo.two"]

     def test_idmaker_idfn(self) -> None:
@@ -458,15 +508,19 @@
                 return repr(val)
             return None

-        result = idmaker(
+        result = IdMaker(
             ("a", "b"),
             [
                 pytest.param(10.0, IndexError()),
                 pytest.param(20, KeyError()),
                 pytest.param("three", [1, 2, 3]),
             ],
-            idfn=ids,
-        )
+            ids,
+            None,
+            None,
+            None,
+            None,
+        ).make_unique_parameterset_ids()
         assert result == ["10.0-IndexError()", "20-KeyError()", "three-b2"]

     def test_idmaker_idfn_unique_names(self) -> None:
@@ -475,15 +529,19 @@
         def ids(val: object) -> str:
             return "a"

-        result = idmaker(
+        result = IdMaker(
             ("a", "b"),
             [
                 pytest.param(10.0, IndexError()),
                 pytest.param(20, KeyError()),
                 pytest.param("three", [1, 2, 3]),
             ],
-            idfn=ids,
-        )
+            ids,
+            None,
+            None,
+            None,
+            None,
+        ).make_unique_parameterset_ids()
         assert result == ["a-a0", "a-a1", "a-a2"]

     def test_idmaker_with_idfn_and_config(self) -> None:
@@ -508,14 +566,20 @@

         option = "disable_test_id_escaping_and_forfeit_all_rights_to_community_support"

-        values = [
+        values: List[Tuple[Any, str]] = [
             (MockConfig({option: True}), "ação"),
             (MockConfig({option: False}), "a\\xe7\\xe3o"),
-        ]  # type: List[Tuple[Any, str]]
+        ]
         for config, expected in values:
-            result = idmaker(
-                ("a",), [pytest.param("string")], idfn=lambda _: "ação", config=config,
-            )
+            result = IdMaker(
+                ("a",),
+                [pytest.param("string")],
+                lambda _: "ação",
+                None,
+                config,
+                None,
+                None,
+            ).make_unique_parameterset_ids()
             assert result == [expected]

     def test_idmaker_with_ids_and_config(self) -> None:
@@ -540,22 +604,22 @@

         option = "disable_test_id_escaping_and_forfeit_all_rights_to_community_support"

-        values = [
+        values: List[Tuple[Any, str]] = [
             (MockConfig({option: True}), "ação"),
             (MockConfig({option: False}), "a\\xe7\\xe3o"),
-        ]  # type: List[Tuple[Any, str]]
+        ]
         for config, expected in values:
-            result = idmaker(
-                ("a",), [pytest.param("string")], ids=["ação"], config=config,
-            )
+            result = IdMaker(
+                ("a",), [pytest.param("string")], None, ["ação"], config, None, None
+            ).make_unique_parameterset_ids()
             assert result == [expected]

-    def test_parametrize_ids_exception(self, testdir: Testdir) -> None:
-        """
-        :param testdir: the instance of Testdir class, a temporary
+    def test_parametrize_ids_exception(self, pytester: Pytester) -> None:
+        """
+        :param pytester: the instance of Pytester class, a temporary
         test directory.
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
                 import pytest

@@ -567,7 +631,7 @@
                     pass
             """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             [
                 "*Exception: bad ids",
@@ -575,8 +639,8 @@
             ]
         )

-    def test_parametrize_ids_returns_non_string(self, testdir: Testdir) -> None:
-        testdir.makepyfile(
+    def test_parametrize_ids_returns_non_string(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """\
             import pytest

@@ -592,7 +656,7 @@
                 assert arg
             """
         )
-        result = testdir.runpytest("-vv", "-s")
+        result = pytester.runpytest("-vv", "-s")
         result.stdout.fnmatch_lines(
             [
                 "test_parametrize_ids_returns_non_string.py::test[arg0] PASSED",
@@ -604,23 +668,39 @@
         )

     def test_idmaker_with_ids(self) -> None:
-        result = idmaker(
-            ("a", "b"), [pytest.param(1, 2), pytest.param(3, 4)], ids=["a", None]
-        )
+        result = IdMaker(
+            ("a", "b"),
+            [pytest.param(1, 2), pytest.param(3, 4)],
+            None,
+            ["a", None],
+            None,
+            None,
+            None,
+        ).make_unique_parameterset_ids()
         assert result == ["a", "3-4"]

     def test_idmaker_with_paramset_id(self) -> None:
-        result = idmaker(
+        result = IdMaker(
             ("a", "b"),
             [pytest.param(1, 2, id="me"), pytest.param(3, 4, id="you")],
-            ids=["a", None],
-        )
+            None,
+            ["a", None],
+            None,
+            None,
+            None,
+        ).make_unique_parameterset_ids()
         assert result == ["me", "you"]

     def test_idmaker_with_ids_unique_names(self) -> None:
-        result = idmaker(
-            ("a"), map(pytest.param, [1, 2, 3, 4, 5]), ids=["a", "a", "b", "c", "b"]
-        )
+        result = IdMaker(
+            ("a"),
+            list(map(pytest.param, [1, 2, 3, 4, 5])),
+            None,
+            ["a", "a", "b", "c", "b"],
+            None,
+            None,
+            None,
+        ).make_unique_parameterset_ids()
         assert result == ["a0", "a1", "b0", "c", "b1"]

     def test_parametrize_indirect(self) -> None:
@@ -682,18 +762,17 @@
         ):
             metafunc.parametrize("x, y", [("a", "b")], indirect={})  # type: ignore[arg-type]

-    def test_parametrize_indirect_list_functional(self, testdir: Testdir) -> None:
+    def test_parametrize_indirect_list_functional(self, pytester: Pytester) -> None:
         """
         #714
         Test parametrization with 'indirect' parameter applied on
-        particular arguments. As y is is direct, its value should
-        be used directly rather than being passed to the fixture
-        y.
-
-        :param testdir: the instance of Testdir class, a temporary
+        particular arguments. As y is direct, its value should
+        be used directly rather than being passed to the fixture y.
+
+        :param pytester: the instance of Pytester class, a temporary
         test directory.
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture(scope='function')
@@ -708,7 +787,7 @@
                 assert len(y) == 1
         """
         )
-        result = testdir.runpytest("-v")
+        result = pytester.runpytest("-v")
         result.stdout.fnmatch_lines(["*test_simple*a-b*", "*1 passed*"])

     def test_parametrize_indirect_list_error(self) -> None:
@@ -722,7 +801,7 @@
             metafunc.parametrize("x, y", [("a", "b")], indirect=["x", "z"])

     def test_parametrize_uses_no_fixture_error_indirect_false(
-        self, testdir: Testdir
+        self, pytester: Pytester
     ) -> None:
         """The 'uses no fixture' error tells the user at collection time
         that the parametrize data they've set up doesn't correspond to the
@@ -731,7 +810,7 @@

         #714
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -740,14 +819,14 @@
                 assert len(x) == 3
         """
         )
-        result = testdir.runpytest("--collect-only")
+        result = pytester.runpytest("--collect-only")
         result.stdout.fnmatch_lines(["*uses no argument 'y'*"])

     def test_parametrize_uses_no_fixture_error_indirect_true(
-        self, testdir: Testdir
+        self, pytester: Pytester
     ) -> None:
         """#714"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture(scope='function')
@@ -762,14 +841,14 @@
                 assert len(x) == 3
         """
         )
-        result = testdir.runpytest("--collect-only")
+        result = pytester.runpytest("--collect-only")
         result.stdout.fnmatch_lines(["*uses no fixture 'y'*"])

     def test_parametrize_indirect_uses_no_fixture_error_indirect_string(
-        self, testdir: Testdir
+        self, pytester: Pytester
     ) -> None:
         """#714"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture(scope='function')
@@ -781,14 +860,14 @@
                 assert len(x) == 3
         """
         )
-        result = testdir.runpytest("--collect-only")
+        result = pytester.runpytest("--collect-only")
         result.stdout.fnmatch_lines(["*uses no fixture 'y'*"])

     def test_parametrize_indirect_uses_no_fixture_error_indirect_list(
-        self, testdir: Testdir
+        self, pytester: Pytester
     ) -> None:
         """#714"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture(scope='function')
@@ -800,12 +879,14 @@
                 assert len(x) == 3
         """
         )
-        result = testdir.runpytest("--collect-only")
+        result = pytester.runpytest("--collect-only")
         result.stdout.fnmatch_lines(["*uses no fixture 'y'*"])

-    def test_parametrize_argument_not_in_indirect_list(self, testdir: Testdir) -> None:
+    def test_parametrize_argument_not_in_indirect_list(
+        self, pytester: Pytester
+    ) -> None:
         """#714"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture(scope='function')
@@ -817,13 +898,13 @@
                 assert len(x) == 3
         """
         )
-        result = testdir.runpytest("--collect-only")
+        result = pytester.runpytest("--collect-only")
         result.stdout.fnmatch_lines(["*uses no argument 'y'*"])

     def test_parametrize_gives_indicative_error_on_function_with_default_argument(
-        self, testdir
+        self, pytester: Pytester
     ) -> None:
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -832,13 +913,13 @@
                 assert len(x) == 1
         """
         )
-        result = testdir.runpytest("--collect-only")
+        result = pytester.runpytest("--collect-only")
         result.stdout.fnmatch_lines(
             ["*already takes an argument 'y' with a default value"]
         )

-    def test_parametrize_functional(self, testdir: Testdir) -> None:
-        testdir.makepyfile(
+    def test_parametrize_functional(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             def pytest_generate_tests(metafunc):
@@ -853,7 +934,7 @@
                 assert y == 2
         """
         )
-        result = testdir.runpytest("-v")
+        result = pytester.runpytest("-v")
         result.stdout.fnmatch_lines(
             ["*test_simple*1-2*", "*test_simple*2-2*", "*2 passed*"]
         )
@@ -884,8 +965,8 @@
         assert metafunc._calls[1].funcargs == dict(x=3, y=4)
         assert metafunc._calls[1].id == "3-4"

-    def test_parametrize_multiple_times(self, testdir: Testdir) -> None:
-        testdir.makepyfile(
+    def test_parametrize_multiple_times(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             pytestmark = pytest.mark.parametrize("x", [1,2])
@@ -897,12 +978,12 @@
                     assert 0, x
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret == 1
         result.assert_outcomes(failed=6)

-    def test_parametrize_CSV(self, testdir: Testdir) -> None:
-        testdir.makepyfile(
+    def test_parametrize_CSV(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.mark.parametrize("x, y,", [(1,2), (2,3)])
@@ -910,11 +991,11 @@
                 assert x+1 == y
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2)

-    def test_parametrize_class_scenarios(self, testdir: Testdir) -> None:
-        testdir.makepyfile(
+    def test_parametrize_class_scenarios(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
         # same as doc/en/example/parametrize scenario example
         def pytest_generate_tests(metafunc):
@@ -941,7 +1022,7 @@
                   pass
         """
         )
-        result = testdir.runpytest("-v")
+        result = pytester.runpytest("-v")
         assert result.ret == 0
         result.stdout.fnmatch_lines(
             """
@@ -978,8 +1059,8 @@


 class TestMetafuncFunctional:
-    def test_attributes(self, testdir: Testdir) -> None:
-        p = testdir.makepyfile(
+    def test_attributes(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             # assumes that generate/provide runs in the same process
             import sys, pytest
@@ -1005,11 +1086,11 @@
                     assert metafunc.cls == TestClass
         """
         )
-        result = testdir.runpytest(p, "-v")
+        result = pytester.runpytest(p, "-v")
         result.assert_outcomes(passed=2)

-    def test_two_functions(self, testdir: Testdir) -> None:
-        p = testdir.makepyfile(
+    def test_two_functions(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             def pytest_generate_tests(metafunc):
                 metafunc.parametrize('arg1', [10, 20], ids=['0', '1'])
@@ -1021,7 +1102,7 @@
                 assert arg1 in (10, 20)
         """
         )
-        result = testdir.runpytest("-v", p)
+        result = pytester.runpytest("-v", p)
         result.stdout.fnmatch_lines(
             [
                 "*test_func1*0*PASS*",
@@ -1032,8 +1113,8 @@
             ]
         )

-    def test_noself_in_method(self, testdir: Testdir) -> None:
-        p = testdir.makepyfile(
+    def test_noself_in_method(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             def pytest_generate_tests(metafunc):
                 assert 'xyz' not in metafunc.fixturenames
@@ -1043,11 +1124,11 @@
                     pass
         """
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.assert_outcomes(passed=1)

-    def test_generate_tests_in_class(self, testdir: Testdir) -> None:
-        p = testdir.makepyfile(
+    def test_generate_tests_in_class(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             class TestClass(object):
                 def pytest_generate_tests(self, metafunc):
@@ -1057,11 +1138,11 @@
                     assert hello == "world"
         """
         )
-        result = testdir.runpytest("-v", p)
+        result = pytester.runpytest("-v", p)
         result.stdout.fnmatch_lines(["*test_myfunc*hello*PASS*", "*1 passed*"])

-    def test_two_functions_not_same_instance(self, testdir: Testdir) -> None:
-        p = testdir.makepyfile(
+    def test_two_functions_not_same_instance(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             def pytest_generate_tests(metafunc):
                 metafunc.parametrize('arg1', [10, 20], ids=["0", "1"])
@@ -1072,13 +1153,13 @@
                     self.x = 1
         """
         )
-        result = testdir.runpytest("-v", p)
+        result = pytester.runpytest("-v", p)
         result.stdout.fnmatch_lines(
             ["*test_func*0*PASS*", "*test_func*1*PASS*", "*2 pass*"]
         )

-    def test_issue28_setup_method_in_generate_tests(self, testdir: Testdir) -> None:
-        p = testdir.makepyfile(
+    def test_issue28_setup_method_in_generate_tests(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             def pytest_generate_tests(metafunc):
                 metafunc.parametrize('arg1', [1])
@@ -1090,11 +1171,11 @@
                     self.val = 1
             """
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.assert_outcomes(passed=1)

-    def test_parametrize_functional2(self, testdir: Testdir) -> None:
-        testdir.makepyfile(
+    def test_parametrize_functional2(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             def pytest_generate_tests(metafunc):
                 metafunc.parametrize("arg1", [1,2])
@@ -1103,13 +1184,13 @@
                 assert 0, (arg1, arg2)
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             ["*(1, 4)*", "*(1, 5)*", "*(2, 4)*", "*(2, 5)*", "*4 failed*"]
         )

-    def test_parametrize_and_inner_getfixturevalue(self, testdir: Testdir) -> None:
-        p = testdir.makepyfile(
+    def test_parametrize_and_inner_getfixturevalue(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             def pytest_generate_tests(metafunc):
                 metafunc.parametrize("arg1", [1], indirect=True)
@@ -1129,11 +1210,11 @@
                 assert arg1 == 11
         """
         )
-        result = testdir.runpytest("-v", p)
+        result = pytester.runpytest("-v", p)
         result.stdout.fnmatch_lines(["*test_func1*1*PASS*", "*1 passed*"])

-    def test_parametrize_on_setup_arg(self, testdir: Testdir) -> None:
-        p = testdir.makepyfile(
+    def test_parametrize_on_setup_arg(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             """
             def pytest_generate_tests(metafunc):
                 assert "arg1" in metafunc.fixturenames
@@ -1152,17 +1233,17 @@
                 assert arg2 == 10
         """
         )
-        result = testdir.runpytest("-v", p)
+        result = pytester.runpytest("-v", p)
         result.stdout.fnmatch_lines(["*test_func*1*PASS*", "*1 passed*"])

-    def test_parametrize_with_ids(self, testdir: Testdir) -> None:
-        testdir.makeini(
+    def test_parametrize_with_ids(self, pytester: Pytester) -> None:
+        pytester.makeini(
             """
             [pytest]
             console_output_style=classic
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest
             def pytest_generate_tests(metafunc):
@@ -1173,14 +1254,14 @@
                 assert a == b
         """
         )
-        result = testdir.runpytest("-v")
+        result = pytester.runpytest("-v")
         assert result.ret == 1
         result.stdout.fnmatch_lines_random(
             ["*test_function*basic*PASSED", "*test_function*advanced*FAILED"]
         )

-    def test_parametrize_without_ids(self, testdir: Testdir) -> None:
-        testdir.makepyfile(
+    def test_parametrize_without_ids(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             def pytest_generate_tests(metafunc):
@@ -1191,7 +1272,7 @@
                 assert 1
         """
         )
-        result = testdir.runpytest("-v")
+        result = pytester.runpytest("-v")
         result.stdout.fnmatch_lines(
             """
             *test_function*1-b0*
@@ -1199,8 +1280,8 @@
         """
         )

-    def test_parametrize_with_None_in_ids(self, testdir: Testdir) -> None:
-        testdir.makepyfile(
+    def test_parametrize_with_None_in_ids(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             def pytest_generate_tests(metafunc):
@@ -1211,7 +1292,7 @@
                 assert a == b
         """
         )
-        result = testdir.runpytest("-v")
+        result = pytester.runpytest("-v")
         assert result.ret == 1
         result.stdout.fnmatch_lines_random(
             [
@@ -1221,9 +1302,9 @@
             ]
         )

-    def test_fixture_parametrized_empty_ids(self, testdir: Testdir) -> None:
+    def test_fixture_parametrized_empty_ids(self, pytester: Pytester) -> None:
         """Fixtures parametrized with empty ids cause an internal error (#1849)."""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -1235,12 +1316,12 @@
                  pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["* 1 skipped *"])

-    def test_parametrized_empty_ids(self, testdir: Testdir) -> None:
+    def test_parametrized_empty_ids(self, pytester: Pytester) -> None:
         """Tests parametrized with empty ids cause an internal error (#1849)."""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -1249,32 +1330,32 @@
                  pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["* 1 skipped *"])

-    def test_parametrized_ids_invalid_type(self, testdir: Testdir) -> None:
+    def test_parametrized_ids_invalid_type(self, pytester: Pytester) -> None:
         """Test error with non-strings/non-ints, without generator (#1857)."""
-        testdir.makepyfile(
-            """
-            import pytest
-
-            @pytest.mark.parametrize("x, expected", [(1, 2), (3, 4), (5, 6)], ids=(None, 2, type))
+        pytester.makepyfile(
+            """
+            import pytest
+
+            @pytest.mark.parametrize("x, expected", [(1, 2), (3, 4), (5, 6)], ids=(None, 2, OSError()))
             def test_ids_numbers(x,expected):
                 assert x * 2 == expected
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             [
-                "In test_ids_numbers: ids must be list of string/float/int/bool,"
-                " found: <class 'type'> (type: <class 'type'>) at index 2"
+                "In test_ids_numbers: ids contains unsupported value OSError() (type: <class 'OSError'>) at index 2. "
+                "Supported types are: str, bytes, int, float, complex, bool, enum, regex or anything with a __name__."
             ]
         )

     def test_parametrize_with_identical_ids_get_unique_names(
-        self, testdir: Testdir
+        self, pytester: Pytester
     ) -> None:
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest
             def pytest_generate_tests(metafunc):
@@ -1285,7 +1366,7 @@
                 assert a == b
         """
         )
-        result = testdir.runpytest("-v")
+        result = pytester.runpytest("-v")
         assert result.ret == 1
         result.stdout.fnmatch_lines_random(
             ["*test_function*a0*PASSED*", "*test_function*a1*FAILED*"]
@@ -1293,9 +1374,9 @@

     @pytest.mark.parametrize(("scope", "length"), [("module", 2), ("function", 4)])
     def test_parametrize_scope_overrides(
-        self, testdir: Testdir, scope: str, length: int
+        self, pytester: Pytester, scope: str, length: int
     ) -> None:
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest
             values = []
@@ -1316,11 +1397,11 @@
         """
             % (scope, length)
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=5)

-    def test_parametrize_issue323(self, testdir: Testdir) -> None:
-        testdir.makepyfile(
+    def test_parametrize_issue323(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -1334,11 +1415,11 @@
                 pass
         """
         )
-        reprec = testdir.inline_run("--collect-only")
+        reprec = pytester.inline_run("--collect-only")
         assert not reprec.getcalls("pytest_internalerror")

-    def test_usefixtures_seen_in_generate_tests(self, testdir: Testdir) -> None:
-        testdir.makepyfile(
+    def test_usefixtures_seen_in_generate_tests(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             def pytest_generate_tests(metafunc):
@@ -1350,13 +1431,13 @@
                 pass
         """
         )
-        reprec = testdir.runpytest()
+        reprec = pytester.runpytest()
         reprec.assert_outcomes(passed=1)

-    def test_generate_tests_only_done_in_subdir(self, testdir: Testdir) -> None:
-        sub1 = testdir.mkpydir("sub1")
-        sub2 = testdir.mkpydir("sub2")
-        sub1.join("conftest.py").write(
+    def test_generate_tests_only_done_in_subdir(self, pytester: Pytester) -> None:
+        sub1 = pytester.mkpydir("sub1")
+        sub2 = pytester.mkpydir("sub2")
+        sub1.joinpath("conftest.py").write_text(
             textwrap.dedent(
                 """\
                 def pytest_generate_tests(metafunc):
@@ -1364,7 +1445,7 @@
                 """
             )
         )
-        sub2.join("conftest.py").write(
+        sub2.joinpath("conftest.py").write_text(
             textwrap.dedent(
                 """\
                 def pytest_generate_tests(metafunc):
@@ -1372,13 +1453,13 @@
                 """
             )
         )
-        sub1.join("test_in_sub1.py").write("def test_1(): pass")
-        sub2.join("test_in_sub2.py").write("def test_2(): pass")
-        result = testdir.runpytest("--keep-duplicates", "-v", "-s", sub1, sub2, sub1)
+        sub1.joinpath("test_in_sub1.py").write_text("def test_1(): pass")
+        sub2.joinpath("test_in_sub2.py").write_text("def test_2(): pass")
+        result = pytester.runpytest("--keep-duplicates", "-v", "-s", sub1, sub2, sub1)
         result.assert_outcomes(passed=3)

-    def test_generate_same_function_names_issue403(self, testdir: Testdir) -> None:
-        testdir.makepyfile(
+    def test_generate_same_function_names_issue403(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -1392,12 +1473,12 @@
             test_y = make_tests()
         """
         )
-        reprec = testdir.runpytest()
+        reprec = pytester.runpytest()
         reprec.assert_outcomes(passed=4)

-    def test_parametrize_misspelling(self, testdir: Testdir) -> None:
+    def test_parametrize_misspelling(self, pytester: Pytester) -> None:
         """#463"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -1406,7 +1487,7 @@
                 pass
         """
         )
-        result = testdir.runpytest("--collectonly")
+        result = pytester.runpytest("--collectonly")
         result.stdout.fnmatch_lines(
             [
                 "collected 0 items / 1 error",
@@ -1417,7 +1498,7 @@
                 '    @pytest.mark.parametrise("x", range(2))',
                 "E   Failed: Unknown 'parametrise' mark, did you mean 'parametrize'?",
                 "*! Interrupted: 1 error during collection !*",
-                "*= 1 error in *",
+                "*= no tests collected, 1 error in *",
             ]
         )

@@ -1426,8 +1507,8 @@
     """Tests related to automatically find out the correct scope for
     parametrized tests (#1832)."""

-    def test_parametrize_auto_scope(self, testdir: Testdir) -> None:
-        testdir.makepyfile(
+    def test_parametrize_auto_scope(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -1445,11 +1526,11 @@

         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["* 3 passed *"])

-    def test_parametrize_auto_scope_indirect(self, testdir: Testdir) -> None:
-        testdir.makepyfile(
+    def test_parametrize_auto_scope_indirect(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -1468,11 +1549,11 @@
                 assert echo in (1, 2, 3)
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["* 3 passed *"])

-    def test_parametrize_auto_scope_override_fixture(self, testdir: Testdir) -> None:
-        testdir.makepyfile(
+    def test_parametrize_auto_scope_override_fixture(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -1485,11 +1566,11 @@
                 assert animal in ('dog', 'cat')
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["* 2 passed *"])

-    def test_parametrize_all_indirects(self, testdir: Testdir) -> None:
-        testdir.makepyfile(
+    def test_parametrize_all_indirects(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -1512,19 +1593,19 @@
                 assert echo in (1, 2, 3)
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["* 3 passed *"])

     def test_parametrize_some_arguments_auto_scope(
-        self, testdir: Testdir, monkeypatch
+        self, pytester: Pytester, monkeypatch
     ) -> None:
         """Integration test for (#3941)"""
-        class_fix_setup = []  # type: List[object]
+        class_fix_setup: List[object] = []
         monkeypatch.setattr(sys, "class_fix_setup", class_fix_setup, raising=False)
-        func_fix_setup = []  # type: List[object]
+        func_fix_setup: List[object] = []
         monkeypatch.setattr(sys, "func_fix_setup", func_fix_setup, raising=False)

-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest
             import sys
@@ -1545,13 +1626,13 @@
                     pass
             """
         )
-        result = testdir.runpytest_inprocess()
+        result = pytester.runpytest_inprocess()
         result.stdout.fnmatch_lines(["* 4 passed in *"])
         assert func_fix_setup == [True] * 4
         assert class_fix_setup == [10, 20]

-    def test_parametrize_issue634(self, testdir: Testdir) -> None:
-        testdir.makepyfile(
+    def test_parametrize_issue634(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -1579,7 +1660,7 @@
                 metafunc.parametrize('foo', params, indirect=True)
         """
         )
-        result = testdir.runpytest("-s")
+        result = pytester.runpytest("-s")
         output = result.stdout.str()
         assert output.count("preparing foo-2") == 1
         assert output.count("preparing foo-3") == 1
@@ -1588,7 +1669,7 @@
 class TestMarkersWithParametrization:
     """#308"""

-    def test_simple_mark(self, testdir: Testdir) -> None:
+    def test_simple_mark(self, pytester: Pytester) -> None:
         s = """
             import pytest

@@ -1601,7 +1682,7 @@
             def test_increment(n, expected):
                 assert n + 1 == expected
         """
-        items = testdir.getitems(s)
+        items = pytester.getitems(s)
         assert len(items) == 3
         for item in items:
             assert "foo" in item.keywords
@@ -1609,7 +1690,7 @@
         assert "bar" in items[1].keywords
         assert "bar" not in items[2].keywords

-    def test_select_based_on_mark(self, testdir: Testdir) -> None:
+    def test_select_based_on_mark(self, pytester: Pytester) -> None:
         s = """
             import pytest

@@ -1621,14 +1702,14 @@
             def test_increment(n, expected):
                 assert n + 1 == expected
         """
-        testdir.makepyfile(s)
-        rec = testdir.inline_run("-m", "foo")
+        pytester.makepyfile(s)
+        rec = pytester.inline_run("-m", "foo")
         passed, skipped, fail = rec.listoutcomes()
         assert len(passed) == 1
         assert len(skipped) == 0
         assert len(fail) == 0

-    def test_simple_xfail(self, testdir: Testdir) -> None:
+    def test_simple_xfail(self, pytester: Pytester) -> None:
         s = """
             import pytest

@@ -1640,12 +1721,12 @@
             def test_increment(n, expected):
                 assert n + 1 == expected
         """
-        testdir.makepyfile(s)
-        reprec = testdir.inline_run()
+        pytester.makepyfile(s)
+        reprec = pytester.inline_run()
         # xfail is skip??
         reprec.assertoutcome(passed=2, skipped=1)

-    def test_simple_xfail_single_argname(self, testdir: Testdir) -> None:
+    def test_simple_xfail_single_argname(self, pytester: Pytester) -> None:
         s = """
             import pytest

@@ -1657,11 +1738,11 @@
             def test_isEven(n):
                 assert n % 2 == 0
         """
-        testdir.makepyfile(s)
-        reprec = testdir.inline_run()
+        pytester.makepyfile(s)
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2, skipped=1)

-    def test_xfail_with_arg(self, testdir: Testdir) -> None:
+    def test_xfail_with_arg(self, pytester: Pytester) -> None:
         s = """
             import pytest

@@ -1673,11 +1754,11 @@
             def test_increment(n, expected):
                 assert n + 1 == expected
         """
-        testdir.makepyfile(s)
-        reprec = testdir.inline_run()
+        pytester.makepyfile(s)
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2, skipped=1)

-    def test_xfail_with_kwarg(self, testdir: Testdir) -> None:
+    def test_xfail_with_kwarg(self, pytester: Pytester) -> None:
         s = """
             import pytest

@@ -1689,11 +1770,11 @@
             def test_increment(n, expected):
                 assert n + 1 == expected
         """
-        testdir.makepyfile(s)
-        reprec = testdir.inline_run()
+        pytester.makepyfile(s)
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2, skipped=1)

-    def test_xfail_with_arg_and_kwarg(self, testdir: Testdir) -> None:
+    def test_xfail_with_arg_and_kwarg(self, pytester: Pytester) -> None:
         s = """
             import pytest

@@ -1705,12 +1786,12 @@
             def test_increment(n, expected):
                 assert n + 1 == expected
         """
-        testdir.makepyfile(s)
-        reprec = testdir.inline_run()
+        pytester.makepyfile(s)
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2, skipped=1)

     @pytest.mark.parametrize("strict", [True, False])
-    def test_xfail_passing_is_xpass(self, testdir: Testdir, strict: bool) -> None:
+    def test_xfail_passing_is_xpass(self, pytester: Pytester, strict: bool) -> None:
         s = """
             import pytest

@@ -1726,12 +1807,12 @@
         """.format(
             strict=strict
         )
-        testdir.makepyfile(s)
-        reprec = testdir.inline_run()
+        pytester.makepyfile(s)
+        reprec = pytester.inline_run()
         passed, failed = (2, 1) if strict else (3, 0)
         reprec.assertoutcome(passed=passed, failed=failed)

-    def test_parametrize_called_in_generate_tests(self, testdir: Testdir) -> None:
+    def test_parametrize_called_in_generate_tests(self, pytester: Pytester) -> None:
         s = """
             import pytest

@@ -1750,13 +1831,15 @@
             def test_increment(n, expected):
                 assert n + 1 == expected
         """
-        testdir.makepyfile(s)
-        reprec = testdir.inline_run()
+        pytester.makepyfile(s)
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2, skipped=2)

-    def test_parametrize_ID_generation_string_int_works(self, testdir: Testdir) -> None:
+    def test_parametrize_ID_generation_string_int_works(
+        self, pytester: Pytester
+    ) -> None:
         """#290"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -1769,11 +1852,11 @@
                 return
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2)

     @pytest.mark.parametrize("strict", [True, False])
-    def test_parametrize_marked_value(self, testdir: Testdir, strict: bool) -> None:
+    def test_parametrize_marked_value(self, pytester: Pytester, strict: bool) -> None:
         s = """
             import pytest

@@ -1792,19 +1875,19 @@
         """.format(
             strict=strict
         )
-        testdir.makepyfile(s)
-        reprec = testdir.inline_run()
+        pytester.makepyfile(s)
+        reprec = pytester.inline_run()
         passed, failed = (0, 2) if strict else (2, 0)
         reprec.assertoutcome(passed=passed, failed=failed)

-    def test_pytest_make_parametrize_id(self, testdir: Testdir) -> None:
-        testdir.makeconftest(
+    def test_pytest_make_parametrize_id(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             def pytest_make_parametrize_id(config, val):
                 return str(val * 2)
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
                 import pytest

@@ -1813,17 +1896,17 @@
                     pass
                 """
         )
-        result = testdir.runpytest("-v")
+        result = pytester.runpytest("-v")
         result.stdout.fnmatch_lines(["*test_func*0*PASS*", "*test_func*2*PASS*"])

-    def test_pytest_make_parametrize_id_with_argname(self, testdir: Testdir) -> None:
-        testdir.makeconftest(
+    def test_pytest_make_parametrize_id_with_argname(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             def pytest_make_parametrize_id(config, val, argname):
                 return str(val * 2 if argname == 'x' else val * 10)
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
                 import pytest

@@ -1836,13 +1919,13 @@
                     pass
                 """
         )
-        result = testdir.runpytest("-v")
+        result = pytester.runpytest("-v")
         result.stdout.fnmatch_lines(
             ["*test_func_a*0*PASS*", "*test_func_a*2*PASS*", "*test_func_b*10*PASS*"]
         )

-    def test_parametrize_positional_args(self, testdir: Testdir) -> None:
-        testdir.makepyfile(
+    def test_parametrize_positional_args(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -1851,11 +1934,11 @@
                 pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.assert_outcomes(passed=1)

-    def test_parametrize_iterator(self, testdir: Testdir) -> None:
-        testdir.makepyfile(
+    def test_parametrize_iterator(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import itertools
             import pytest
@@ -1877,7 +1960,7 @@
                 pass
         """
         )
-        result = testdir.runpytest("-vv", "-s")
+        result = pytester.runpytest("-vv", "-s")
         result.stdout.fnmatch_lines(
             [
                 "test_parametrize_iterator.py::test1[param0] PASSED",
('testing/python', 'integration.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,77 +1,8 @@
-from typing import Any
-
 import pytest
-from _pytest import runner
 from _pytest._code import getfslineno
-
-
-class TestOEJSKITSpecials:
-    def test_funcarg_non_pycollectobj(
-        self, testdir, recwarn
-    ) -> None:  # rough jstests usage
-        testdir.makeconftest(
-            """
-            import pytest
-            def pytest_pycollect_makeitem(collector, name, obj):
-                if name == "MyClass":
-                    return MyCollector.from_parent(collector, name=name)
-            class MyCollector(pytest.Collector):
-                def reportinfo(self):
-                    return self.fspath, 3, "xyz"
-        """
-        )
-        modcol = testdir.getmodulecol(
-            """
-            import pytest
-            @pytest.fixture
-            def arg1(request):
-                return 42
-            class MyClass(object):
-                pass
-        """
-        )
-        # this hook finds funcarg factories
-        rep = runner.collect_one_node(collector=modcol)
-        # TODO: Don't treat as Any.
-        clscol = rep.result[0]  # type: Any
-        clscol.obj = lambda arg1: None
-        clscol.funcargs = {}
-        pytest._fillfuncargs(clscol)
-        assert clscol.funcargs["arg1"] == 42
-
-    def test_autouse_fixture(self, testdir, recwarn) -> None:  # rough jstests usage
-        testdir.makeconftest(
-            """
-            import pytest
-            def pytest_pycollect_makeitem(collector, name, obj):
-                if name == "MyClass":
-                    return MyCollector.from_parent(collector, name=name)
-            class MyCollector(pytest.Collector):
-                def reportinfo(self):
-                    return self.fspath, 3, "xyz"
-        """
-        )
-        modcol = testdir.getmodulecol(
-            """
-            import pytest
-            @pytest.fixture(autouse=True)
-            def hello():
-                pass
-            @pytest.fixture
-            def arg1(request):
-                return 42
-            class MyClass(object):
-                pass
-        """
-        )
-        # this hook finds funcarg factories
-        rep = runner.collect_one_node(modcol)
-        # TODO: Don't treat as Any.
-        clscol = rep.result[0]  # type: Any
-        clscol.obj = lambda: None
-        clscol.funcargs = {}
-        pytest._fillfuncargs(clscol)
-        assert not clscol.funcargs
+from _pytest.fixtures import getfixturemarker
+from _pytest.pytester import Pytester
+from _pytest.python import Function


 def test_wrapped_getfslineno() -> None:
@@ -125,8 +56,8 @@
         values = getfuncargnames(f)
         assert values == ("y", "z")

-    def test_unittest_mock(self, testdir):
-        testdir.makepyfile(
+    def test_unittest_mock(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import unittest.mock
             class T(unittest.TestCase):
@@ -137,11 +68,11 @@
                     abspath.assert_any_call("hello")
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)

-    def test_unittest_mock_and_fixture(self, testdir):
-        testdir.makepyfile(
+    def test_unittest_mock_and_fixture(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import os.path
             import unittest.mock
@@ -158,12 +89,12 @@
                 os.path.abspath("hello")
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)

-    def test_unittest_mock_and_pypi_mock(self, testdir):
+    def test_unittest_mock_and_pypi_mock(self, pytester: Pytester) -> None:
         pytest.importorskip("mock", "1.0.1")
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import mock
             import unittest.mock
@@ -181,15 +112,15 @@
                     abspath.assert_any_call("hello")
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2)

-    def test_mock_sentinel_check_against_numpy_like(self, testdir):
+    def test_mock_sentinel_check_against_numpy_like(self, pytester: Pytester) -> None:
         """Ensure our function that detects mock arguments compares against sentinels using
         identity to circumvent objects which can't be compared with equality against others
         in a truth context, like with numpy arrays (#5606).
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             dummy="""
             class NumpyLike:
                 def __init__(self, value):
@@ -199,7 +130,7 @@
             FOO = NumpyLike(10)
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             from unittest.mock import patch
             import dummy
@@ -209,12 +140,12 @@
                     assert dummy.FOO.value == 50
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)

-    def test_mock(self, testdir):
+    def test_mock(self, pytester: Pytester) -> None:
         pytest.importorskip("mock", "1.0.1")
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import os
             import unittest
@@ -230,14 +161,14 @@
             @mock.patch("os.path.abspath")
             @mock.patch("os.path.normpath")
             @mock.patch("os.path.basename", new=mock_basename)
-            def test_someting(normpath, abspath, tmpdir):
+            def test_someting(normpath, abspath, tmp_path):
                 abspath.return_value = "this"
                 os.path.normpath(os.path.abspath("hello"))
                 normpath.assert_any_call("this")
                 assert os.path.basename("123") == "mock_basename"
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2)
         calls = reprec.getcalls("pytest_runtest_logreport")
         funcnames = [
@@ -245,9 +176,9 @@
         ]
         assert funcnames == ["T.test_hello", "test_someting"]

-    def test_mock_sorting(self, testdir):
+    def test_mock_sorting(self, pytester: Pytester) -> None:
         pytest.importorskip("mock", "1.0.1")
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import os
             import mock
@@ -263,15 +194,15 @@
                 pass
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         calls = reprec.getreports("pytest_runtest_logreport")
         calls = [x for x in calls if x.when == "call"]
         names = [x.nodeid.split("::")[-1] for x in calls]
         assert names == ["test_one", "test_two", "test_three"]

-    def test_mock_double_patch_issue473(self, testdir):
+    def test_mock_double_patch_issue473(self, pytester: Pytester) -> None:
         pytest.importorskip("mock", "1.0.1")
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             from mock import patch
             from pytest import mark
@@ -284,13 +215,13 @@
                     pass
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)


 class TestReRunTests:
-    def test_rerun(self, testdir):
-        testdir.makeconftest(
+    def test_rerun(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             from _pytest.runner import runtestprotocol
             def pytest_runtest_protocol(item, nextitem):
@@ -298,7 +229,7 @@
                 runtestprotocol(item, log=True, nextitem=nextitem)
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest
             count = 0
@@ -314,7 +245,7 @@
                 pass
         """
         )
-        result = testdir.runpytest("-s")
+        result = pytester.runpytest("-s")
         result.stdout.fnmatch_lines(
             """
             *fix count 0*
@@ -331,26 +262,27 @@
 def test_pytestconfig_is_session_scoped() -> None:
     from _pytest.fixtures import pytestconfig

-    marker = pytestconfig._pytestfixturefunction  # type: ignore
+    marker = getfixturemarker(pytestconfig)
+    assert marker is not None
     assert marker.scope == "session"


 class TestNoselikeTestAttribute:
-    def test_module_with_global_test(self, testdir):
-        testdir.makepyfile(
+    def test_module_with_global_test(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             __test__ = False
             def test_hello():
                 pass
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         assert not reprec.getfailedcollections()
         calls = reprec.getreports("pytest_runtest_logreport")
         assert not calls

-    def test_class_and_method(self, testdir):
-        testdir.makepyfile(
+    def test_class_and_method(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             __test__ = True
             def test_func():
@@ -363,13 +295,13 @@
                     pass
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         assert not reprec.getfailedcollections()
         calls = reprec.getreports("pytest_runtest_logreport")
         assert not calls

-    def test_unittest_class(self, testdir):
-        testdir.makepyfile(
+    def test_unittest_class(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import unittest
             class TC(unittest.TestCase):
@@ -381,20 +313,20 @@
                     pass
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         assert not reprec.getfailedcollections()
         call = reprec.getcalls("pytest_collection_modifyitems")[0]
         assert len(call.items) == 1
         assert call.items[0].cls.__name__ == "TC"

-    def test_class_with_nasty_getattr(self, testdir):
+    def test_class_with_nasty_getattr(self, pytester: Pytester) -> None:
         """Make sure we handle classes with a custom nasty __getattr__ right.

         With a custom __getattr__ which e.g. returns a function (like with a
         RPC wrapper), we shouldn't assume this meant "__test__ = True".
         """
         # https://github.com/pytest-dev/pytest/issues/1204
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             class MetaModel(type):

@@ -413,7 +345,7 @@
                     pass
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         assert not reprec.getfailedcollections()
         call = reprec.getcalls("pytest_collection_modifyitems")[0]
         assert not call.items
@@ -422,8 +354,8 @@
 class TestParameterize:
     """#351"""

-    def test_idfn_marker(self, testdir):
-        testdir.makepyfile(
+    def test_idfn_marker(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -440,11 +372,11 @@
                 pass
         """
         )
-        res = testdir.runpytest("--collect-only")
+        res = pytester.runpytest("--collect-only")
         res.stdout.fnmatch_lines(["*spam-2*", "*ham-2*"])

-    def test_idfn_fixture(self, testdir):
-        testdir.makepyfile(
+    def test_idfn_fixture(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -468,5 +400,30 @@
                 pass
         """
         )
-        res = testdir.runpytest("--collect-only")
+        res = pytester.runpytest("--collect-only")
         res.stdout.fnmatch_lines(["*spam-2*", "*ham-2*"])
+
+
+def test_function_instance(pytester: Pytester) -> None:
+    items = pytester.getitems(
+        """
+        def test_func(): pass
+        class TestIt:
+            def test_method(self): pass
+            @classmethod
+            def test_class(cls): pass
+            @staticmethod
+            def test_static(): pass
+        """
+    )
+    assert len(items) == 3
+    assert isinstance(items[0], Function)
+    assert items[0].name == "test_func"
+    assert items[0].instance is None
+    assert isinstance(items[1], Function)
+    assert items[1].name == "test_method"
+    assert items[1].instance is not None
+    assert items[1].instance.__class__.__name__ == "TestIt"
+    assert isinstance(items[2], Function)
+    assert items[2].name == "test_static"
+    assert items[2].instance is None
('testing/python', 'raises.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -3,6 +3,7 @@

 import pytest
 from _pytest.outcomes import Failed
+from _pytest.pytester import Pytester


 class TestRaises:
@@ -50,8 +51,8 @@
             pprint.pprint(excinfo)
             raise E()

-    def test_raises_as_contextmanager(self, testdir):
-        testdir.makepyfile(
+    def test_raises_as_contextmanager(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             import _pytest._code
@@ -75,11 +76,11 @@
                            1/0
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*3 passed*"])

-    def test_does_not_raise(self, testdir):
-        testdir.makepyfile(
+    def test_does_not_raise(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             from contextlib import contextmanager
             import pytest
@@ -100,11 +101,11 @@
                     assert (6 / example_input) is not None
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*4 passed*"])

-    def test_does_not_raise_does_raise(self, testdir):
-        testdir.makepyfile(
+    def test_does_not_raise_does_raise(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             from contextlib import contextmanager
             import pytest
@@ -123,7 +124,7 @@
                     assert (6 / example_input) is not None
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*2 failed*"])

     def test_noclass(self) -> None:
@@ -143,7 +144,7 @@
         try:
             pytest.raises(ValueError, int, "0")
         except pytest.fail.Exception as e:
-            assert e.msg == "DID NOT RAISE {}".format(repr(ValueError))
+            assert e.msg == f"DID NOT RAISE {repr(ValueError)}"
         else:
             assert False, "Expected pytest.raises.Exception"

@@ -151,7 +152,7 @@
             with pytest.raises(ValueError):
                 pass
         except pytest.fail.Exception as e:
-            assert e.msg == "DID NOT RAISE {}".format(repr(ValueError))
+            assert e.msg == f"DID NOT RAISE {repr(ValueError)}"
         else:
             assert False, "Expected pytest.raises.Exception"

@@ -162,11 +163,6 @@

         class T:
             def __call__(self):
-                # Early versions of Python 3.5 have some bug causing the
-                # __call__ frame to still refer to t even after everything
-                # is done. This makes the test pass for them.
-                if sys.version_info < (3, 5, 2):
-                    del self
                 raise ValueError

         t = T()
@@ -211,7 +207,7 @@
         pytest.raises(TypeError, int, match="invalid")

         def tfunc(match):
-            raise ValueError("match={}".format(match))
+            raise ValueError(f"match={match}")

         pytest.raises(ValueError, tfunc, match="asdf").match("match=asdf")
         pytest.raises(ValueError, tfunc, match="").match("match=")
('testing/python', 'fixtures.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,13 +1,17 @@
+import os
 import sys
 import textwrap
+from pathlib import Path

 import pytest
 from _pytest import fixtures
 from _pytest.compat import getfuncargnames
 from _pytest.config import ExitCode
 from _pytest.fixtures import FixtureRequest
-from _pytest.pathlib import Path
+from _pytest.monkeypatch import MonkeyPatch
 from _pytest.pytester import get_public_names
+from _pytest.pytester import Pytester
+from _pytest.python import Function


 def test_getfuncargnames_functions():
@@ -55,6 +59,20 @@
     assert getfuncargnames(A.static, cls=A) == ("arg1", "arg2")


+def test_getfuncargnames_staticmethod_inherited() -> None:
+    """Test getfuncargnames for inherited staticmethods (#8061)"""
+
+    class A:
+        @staticmethod
+        def static(arg1, arg2, x=1):
+            raise NotImplementedError()
+
+    class B(A):
+        pass
+
+    assert getfuncargnames(B.static, cls=B) == ("arg1", "arg2")
+
+
 def test_getfuncargnames_partial():
     """Check getfuncargnames for methods defined with functools.partial (#5701)"""
     import functools
@@ -85,13 +103,9 @@

 @pytest.mark.pytester_example_path("fixtures/fill_fixtures")
 class TestFillFixtures:
-    def test_fillfuncargs_exposed(self):
-        # used by oejskit, kept for compatibility
-        assert pytest._fillfuncargs == fixtures._fillfuncargs
-
-    def test_funcarg_lookupfails(self, testdir):
-        testdir.copy_example()
-        result = testdir.runpytest()  # "--collect-only")
+    def test_funcarg_lookupfails(self, pytester: Pytester) -> None:
+        pytester.copy_example()
+        result = pytester.runpytest()  # "--collect-only")
         assert result.ret != 0
         result.stdout.fnmatch_lines(
             """
@@ -101,60 +115,64 @@
             """
         )

-    def test_detect_recursive_dependency_error(self, testdir):
-        testdir.copy_example()
-        result = testdir.runpytest()
+    def test_detect_recursive_dependency_error(self, pytester: Pytester) -> None:
+        pytester.copy_example()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             ["*recursive dependency involving fixture 'fix1' detected*"]
         )

-    def test_funcarg_basic(self, testdir):
-        testdir.copy_example()
-        item = testdir.getitem(Path("test_funcarg_basic.py"))
-        item._request._fillfixtures()
+    def test_funcarg_basic(self, pytester: Pytester) -> None:
+        pytester.copy_example()
+        item = pytester.getitem(Path("test_funcarg_basic.py"))
+        assert isinstance(item, Function)
+        # Execute's item's setup, which fills fixtures.
+        item.session._setupstate.setup(item)
         del item.funcargs["request"]
         assert len(get_public_names(item.funcargs)) == 2
         assert item.funcargs["some"] == "test_func"
         assert item.funcargs["other"] == 42

-    def test_funcarg_lookup_modulelevel(self, testdir):
-        testdir.copy_example()
-        reprec = testdir.inline_run()
+    def test_funcarg_lookup_modulelevel(self, pytester: Pytester) -> None:
+        pytester.copy_example()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2)

-    def test_funcarg_lookup_classlevel(self, testdir):
-        p = testdir.copy_example()
-        result = testdir.runpytest(p)
+    def test_funcarg_lookup_classlevel(self, pytester: Pytester) -> None:
+        p = pytester.copy_example()
+        result = pytester.runpytest(p)
         result.stdout.fnmatch_lines(["*1 passed*"])

-    def test_conftest_funcargs_only_available_in_subdir(self, testdir):
-        testdir.copy_example()
-        result = testdir.runpytest("-v")
+    def test_conftest_funcargs_only_available_in_subdir(
+        self, pytester: Pytester
+    ) -> None:
+        pytester.copy_example()
+        result = pytester.runpytest("-v")
         result.assert_outcomes(passed=2)

-    def test_extend_fixture_module_class(self, testdir):
-        testfile = testdir.copy_example()
-        result = testdir.runpytest()
+    def test_extend_fixture_module_class(self, pytester: Pytester) -> None:
+        testfile = pytester.copy_example()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*1 passed*"])
-        result = testdir.runpytest(testfile)
+        result = pytester.runpytest(testfile)
         result.stdout.fnmatch_lines(["*1 passed*"])

-    def test_extend_fixture_conftest_module(self, testdir):
-        p = testdir.copy_example()
-        result = testdir.runpytest()
+    def test_extend_fixture_conftest_module(self, pytester: Pytester) -> None:
+        p = pytester.copy_example()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*1 passed*"])
-        result = testdir.runpytest(str(next(Path(str(p)).rglob("test_*.py"))))
+        result = pytester.runpytest(str(next(Path(str(p)).rglob("test_*.py"))))
         result.stdout.fnmatch_lines(["*1 passed*"])

-    def test_extend_fixture_conftest_conftest(self, testdir):
-        p = testdir.copy_example()
-        result = testdir.runpytest()
+    def test_extend_fixture_conftest_conftest(self, pytester: Pytester) -> None:
+        p = pytester.copy_example()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*1 passed*"])
-        result = testdir.runpytest(str(next(Path(str(p)).rglob("test_*.py"))))
+        result = pytester.runpytest(str(next(Path(str(p)).rglob("test_*.py"))))
         result.stdout.fnmatch_lines(["*1 passed*"])

-    def test_extend_fixture_conftest_plugin(self, testdir):
-        testdir.makepyfile(
+    def test_extend_fixture_conftest_plugin(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             testplugin="""
             import pytest

@@ -163,8 +181,8 @@
                 return 7
         """
         )
-        testdir.syspathinsert()
-        testdir.makeconftest(
+        pytester.syspathinsert()
+        pytester.makeconftest(
             """
             import pytest

@@ -175,18 +193,18 @@
                 return foo + 7
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_foo(foo):
                 assert foo == 14
         """
         )
-        result = testdir.runpytest("-s")
+        result = pytester.runpytest("-s")
         assert result.ret == 0

-    def test_extend_fixture_plugin_plugin(self, testdir):
+    def test_extend_fixture_plugin_plugin(self, pytester: Pytester) -> None:
         # Two plugins should extend each order in loading order
-        testdir.makepyfile(
+        pytester.makepyfile(
             testplugin0="""
             import pytest

@@ -195,7 +213,7 @@
                 return 7
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             testplugin1="""
             import pytest

@@ -204,8 +222,8 @@
                 return foo + 7
         """
         )
-        testdir.syspathinsert()
-        testdir.makepyfile(
+        pytester.syspathinsert()
+        pytester.makepyfile(
             """
             pytest_plugins = ['testplugin0', 'testplugin1']

@@ -213,12 +231,14 @@
                 assert foo == 14
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret == 0

-    def test_override_parametrized_fixture_conftest_module(self, testdir):
+    def test_override_parametrized_fixture_conftest_module(
+        self, pytester: Pytester
+    ) -> None:
         """Test override of the parametrized fixture with non-parametrized one on the test module level."""
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest

@@ -227,7 +247,7 @@
                 return request.param
         """
         )
-        testfile = testdir.makepyfile(
+        testfile = pytester.makepyfile(
             """
             import pytest

@@ -239,14 +259,16 @@
                 assert spam == 'spam'
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*1 passed*"])
-        result = testdir.runpytest(testfile)
+        result = pytester.runpytest(testfile)
         result.stdout.fnmatch_lines(["*1 passed*"])

-    def test_override_parametrized_fixture_conftest_conftest(self, testdir):
+    def test_override_parametrized_fixture_conftest_conftest(
+        self, pytester: Pytester
+    ) -> None:
         """Test override of the parametrized fixture with non-parametrized one on the conftest level."""
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest

@@ -255,8 +277,8 @@
                 return request.param
         """
         )
-        subdir = testdir.mkpydir("subdir")
-        subdir.join("conftest.py").write(
+        subdir = pytester.mkpydir("subdir")
+        subdir.joinpath("conftest.py").write_text(
             textwrap.dedent(
                 """\
                 import pytest
@@ -267,8 +289,8 @@
                 """
             )
         )
-        testfile = subdir.join("test_spam.py")
-        testfile.write(
+        testfile = subdir.joinpath("test_spam.py")
+        testfile.write_text(
             textwrap.dedent(
                 """\
                 def test_spam(spam):
@@ -276,14 +298,16 @@
                 """
             )
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*1 passed*"])
-        result = testdir.runpytest(testfile)
+        result = pytester.runpytest(testfile)
         result.stdout.fnmatch_lines(["*1 passed*"])

-    def test_override_non_parametrized_fixture_conftest_module(self, testdir):
+    def test_override_non_parametrized_fixture_conftest_module(
+        self, pytester: Pytester
+    ) -> None:
         """Test override of the non-parametrized fixture with parametrized one on the test module level."""
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest

@@ -292,7 +316,7 @@
                 return 'spam'
         """
         )
-        testfile = testdir.makepyfile(
+        testfile = pytester.makepyfile(
             """
             import pytest

@@ -307,14 +331,16 @@
                 params['spam'] += 1
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*3 passed*"])
-        result = testdir.runpytest(testfile)
+        result = pytester.runpytest(testfile)
         result.stdout.fnmatch_lines(["*3 passed*"])

-    def test_override_non_parametrized_fixture_conftest_conftest(self, testdir):
+    def test_override_non_parametrized_fixture_conftest_conftest(
+        self, pytester: Pytester
+    ) -> None:
         """Test override of the non-parametrized fixture with parametrized one on the conftest level."""
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest

@@ -323,8 +349,8 @@
                 return 'spam'
         """
         )
-        subdir = testdir.mkpydir("subdir")
-        subdir.join("conftest.py").write(
+        subdir = pytester.mkpydir("subdir")
+        subdir.joinpath("conftest.py").write_text(
             textwrap.dedent(
                 """\
                 import pytest
@@ -335,8 +361,8 @@
                 """
             )
         )
-        testfile = subdir.join("test_spam.py")
-        testfile.write(
+        testfile = subdir.joinpath("test_spam.py")
+        testfile.write_text(
             textwrap.dedent(
                 """\
                 params = {'spam': 1}
@@ -347,18 +373,18 @@
                 """
             )
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*3 passed*"])
-        result = testdir.runpytest(testfile)
+        result = pytester.runpytest(testfile)
         result.stdout.fnmatch_lines(["*3 passed*"])

     def test_override_autouse_fixture_with_parametrized_fixture_conftest_conftest(
-        self, testdir
-    ):
+        self, pytester: Pytester
+    ) -> None:
         """Test override of the autouse fixture with parametrized one on the conftest level.
         This test covers the issue explained in issue 1601
         """
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest

@@ -367,8 +393,8 @@
                 return 'spam'
         """
         )
-        subdir = testdir.mkpydir("subdir")
-        subdir.join("conftest.py").write(
+        subdir = pytester.mkpydir("subdir")
+        subdir.joinpath("conftest.py").write_text(
             textwrap.dedent(
                 """\
                 import pytest
@@ -379,8 +405,8 @@
                 """
             )
         )
-        testfile = subdir.join("test_spam.py")
-        testfile.write(
+        testfile = subdir.joinpath("test_spam.py")
+        testfile.write_text(
             textwrap.dedent(
                 """\
                 params = {'spam': 1}
@@ -391,16 +417,18 @@
                 """
             )
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*3 passed*"])
-        result = testdir.runpytest(testfile)
+        result = pytester.runpytest(testfile)
         result.stdout.fnmatch_lines(["*3 passed*"])

-    def test_override_fixture_reusing_super_fixture_parametrization(self, testdir):
+    def test_override_fixture_reusing_super_fixture_parametrization(
+        self, pytester: Pytester
+    ) -> None:
         """Override a fixture at a lower level, reusing the higher-level fixture that
         is parametrized (#1953).
         """
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest

@@ -409,7 +437,7 @@
                 return request.param
             """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -421,14 +449,16 @@
                 assert foo in (2, 4)
             """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*2 passed*"])

-    def test_override_parametrize_fixture_and_indirect(self, testdir):
+    def test_override_parametrize_fixture_and_indirect(
+        self, pytester: Pytester
+    ) -> None:
         """Override a fixture at a lower level, reusing the higher-level fixture that
         is parametrized, while also using indirect parametrization.
         """
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest

@@ -437,7 +467,7 @@
                 return request.param
             """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -455,14 +485,14 @@
                 assert foo in (2, 4)
             """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*2 passed*"])

     def test_override_top_level_fixture_reusing_super_fixture_parametrization(
-        self, testdir
-    ):
+        self, pytester: Pytester
+    ) -> None:
         """Same as the above test, but with another level of overwriting."""
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest

@@ -471,7 +501,7 @@
                 return request.param
             """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -489,15 +519,17 @@
                     assert foo in (2, 4)
             """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*2 passed*"])

-    def test_override_parametrized_fixture_with_new_parametrized_fixture(self, testdir):
+    def test_override_parametrized_fixture_with_new_parametrized_fixture(
+        self, pytester: Pytester
+    ) -> None:
         """Overriding a parametrized fixture, while also parametrizing the new fixture and
         simultaneously requesting the overwritten fixture as parameter, yields the same value
         as ``request.param``.
         """
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest

@@ -506,7 +538,7 @@
                 return request.param
             """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -519,13 +551,13 @@
                 assert foo in (20, 40)
             """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*2 passed*"])

-    def test_autouse_fixture_plugin(self, testdir):
+    def test_autouse_fixture_plugin(self, pytester: Pytester) -> None:
         # A fixture from a plugin has no baseid set, which screwed up
         # the autouse fixture handling.
-        testdir.makepyfile(
+        pytester.makepyfile(
             testplugin="""
             import pytest

@@ -534,8 +566,8 @@
                 request.function.foo = 7
         """
         )
-        testdir.syspathinsert()
-        testdir.makepyfile(
+        pytester.syspathinsert()
+        pytester.makepyfile(
             """
             pytest_plugins = 'testplugin'

@@ -543,11 +575,11 @@
                 assert request.function.foo == 7
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret == 0

-    def test_funcarg_lookup_error(self, testdir):
-        testdir.makeconftest(
+    def test_funcarg_lookup_error(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest

@@ -564,13 +596,13 @@
             def d_fixture(): pass
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_lookup_error(unknown):
                 pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             [
                 "*ERROR at setup of test_lookup_error*",
@@ -584,9 +616,9 @@
         )
         result.stdout.no_fnmatch_line("*INTERNAL*")

-    def test_fixture_excinfo_leak(self, testdir):
+    def test_fixture_excinfo_leak(self, pytester: Pytester) -> None:
         # on python2 sys.excinfo would leak into fixture executions
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import sys
             import traceback
@@ -605,13 +637,13 @@
                 assert sys.exc_info() == (None, None, None)
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret == 0


 class TestRequestBasic:
-    def test_request_attributes(self, testdir):
-        item = testdir.getitem(
+    def test_request_attributes(self, pytester: Pytester) -> None:
+        item = pytester.getitem(
             """
             import pytest

@@ -620,7 +652,8 @@
             def test_func(something): pass
         """
         )
-        req = fixtures.FixtureRequest(item)
+        assert isinstance(item, Function)
+        req = fixtures.FixtureRequest(item, _ispytest=True)
         assert req.function == item.obj
         assert req.keywords == item.keywords
         assert hasattr(req.module, "test_func")
@@ -629,8 +662,8 @@
         assert req.config == item.config
         assert repr(req).find(req.function.__name__) != -1

-    def test_request_attributes_method(self, testdir):
-        (item,) = testdir.getitems(
+    def test_request_attributes_method(self, pytester: Pytester) -> None:
+        (item,) = pytester.getitems(
             """
             import pytest
             class TestB(object):
@@ -642,12 +675,13 @@
                     pass
         """
         )
+        assert isinstance(item, Function)
         req = item._request
         assert req.cls.__name__ == "TestB"
         assert req.instance.__class__ == req.cls

-    def test_request_contains_funcarg_arg2fixturedefs(self, testdir):
-        modcol = testdir.getmodulecol(
+    def test_request_contains_funcarg_arg2fixturedefs(self, pytester: Pytester) -> None:
+        modcol = pytester.getmodulecol(
             """
             import pytest
             @pytest.fixture
@@ -658,9 +692,11 @@
                     pass
         """
         )
-        (item1,) = testdir.genitems([modcol])
+        (item1,) = pytester.genitems([modcol])
         assert item1.name == "test_method"
-        arg2fixturedefs = fixtures.FixtureRequest(item1)._arg2fixturedefs
+        arg2fixturedefs = fixtures.FixtureRequest(
+            item1, _ispytest=True
+        )._arg2fixturedefs
         assert len(arg2fixturedefs) == 1
         assert arg2fixturedefs["something"][0].argname == "something"

@@ -668,14 +704,14 @@
         hasattr(sys, "pypy_version_info"),
         reason="this method of test doesn't work on pypy",
     )
-    def test_request_garbage(self, testdir):
+    def test_request_garbage(self, pytester: Pytester) -> None:
         try:
             import xdist  # noqa
         except ImportError:
             pass
         else:
             pytest.xfail("this test is flaky when executed with xdist")
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import sys
             import pytest
@@ -701,11 +737,11 @@
                 pass
         """
         )
-        result = testdir.runpytest_subprocess()
+        result = pytester.runpytest_subprocess()
         result.stdout.fnmatch_lines(["* 1 passed in *"])

-    def test_getfixturevalue_recursive(self, testdir):
-        testdir.makeconftest(
+    def test_getfixturevalue_recursive(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest

@@ -714,7 +750,7 @@
                 return 1
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -725,10 +761,10 @@
                 assert something == 2
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)

-    def test_getfixturevalue_teardown(self, testdir):
+    def test_getfixturevalue_teardown(self, pytester: Pytester) -> None:
         """
         Issue #1895

@@ -739,7 +775,7 @@
         `inner` dependent on `resource` when it is used via `getfixturevalue`: `test_func`
         will then cause the `resource`'s finalizer to be called first because of this.
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -763,23 +799,31 @@
                 pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["* 2 passed in *"])

-    def test_getfixturevalue(self, testdir):
-        item = testdir.getitem(
-            """
-            import pytest
+    def test_getfixturevalue(self, pytester: Pytester) -> None:
+        item = pytester.getitem(
+            """
+            import pytest
+
+            @pytest.fixture
+            def something(request):
+                return 1
+
             values = [2]
-            @pytest.fixture
-            def something(request): return 1
             @pytest.fixture
             def other(request):
                 return values.pop()
+
             def test_func(something): pass
         """
         )
+        assert isinstance(item, Function)
         req = item._request
+
+        # Execute item's setup.
+        item.session._setupstate.setup(item)

         with pytest.raises(pytest.FixtureLookupError):
             req.getfixturevalue("notexists")
@@ -791,13 +835,12 @@
         assert val2 == 2
         val2 = req.getfixturevalue("other")  # see about caching
         assert val2 == 2
-        item._request._fillfixtures()
         assert item.funcargs["something"] == 1
         assert len(get_public_names(item.funcargs)) == 2
         assert "request" in item.funcargs

-    def test_request_addfinalizer(self, testdir):
-        item = testdir.getitem(
+    def test_request_addfinalizer(self, pytester: Pytester) -> None:
+        item = pytester.getitem(
             """
             import pytest
             teardownlist = []
@@ -807,18 +850,21 @@
             def test_func(something): pass
         """
         )
-        item.session._setupstate.prepare(item)
+        assert isinstance(item, Function)
+        item.session._setupstate.setup(item)
         item._request._fillfixtures()
         # successively check finalization calls
-        teardownlist = item.getparent(pytest.Module).obj.teardownlist
+        parent = item.getparent(pytest.Module)
+        assert parent is not None
+        teardownlist = parent.obj.teardownlist
         ss = item.session._setupstate
         assert not teardownlist
-        ss.teardown_exact(item, None)
+        ss.teardown_exact(None)
         print(ss.stack)
         assert teardownlist == [1]

-    def test_request_addfinalizer_failing_setup(self, testdir):
-        testdir.makepyfile(
+    def test_request_addfinalizer_failing_setup(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             values = [1]
@@ -832,11 +878,13 @@
                 assert not values
         """
         )
-        reprec = testdir.inline_run("-s")
+        reprec = pytester.inline_run("-s")
         reprec.assertoutcome(failed=1, passed=1)

-    def test_request_addfinalizer_failing_setup_module(self, testdir):
-        testdir.makepyfile(
+    def test_request_addfinalizer_failing_setup_module(
+        self, pytester: Pytester
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest
             values = [1, 2]
@@ -849,12 +897,14 @@
                 pass
         """
         )
-        reprec = testdir.inline_run("-s")
+        reprec = pytester.inline_run("-s")
         mod = reprec.getcalls("pytest_runtest_setup")[0].item.module
         assert not mod.values

-    def test_request_addfinalizer_partial_setup_failure(self, testdir):
-        p = testdir.makepyfile(
+    def test_request_addfinalizer_partial_setup_failure(
+        self, pytester: Pytester
+    ) -> None:
+        p = pytester.makepyfile(
             """
             import pytest
             values = []
@@ -867,17 +917,19 @@
                 assert len(values) == 1
         """
         )
-        result = testdir.runpytest(p)
+        result = pytester.runpytest(p)
         result.stdout.fnmatch_lines(
             ["*1 error*"]  # XXX the whole module collection fails
         )

-    def test_request_subrequest_addfinalizer_exceptions(self, testdir):
+    def test_request_subrequest_addfinalizer_exceptions(
+        self, pytester: Pytester
+    ) -> None:
         """
         Ensure exceptions raised during teardown by a finalizer are suppressed
         until all finalizers are called, re-raising the first exception (#2440)
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest
             values = []
@@ -901,19 +953,19 @@
                 assert values == [3, 2, 1]
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             ["*Exception: Error in excepts fixture", "* 2 passed, 1 error in *"]
         )

-    def test_request_getmodulepath(self, testdir):
-        modcol = testdir.getmodulecol("def test_somefunc(): pass")
-        (item,) = testdir.genitems([modcol])
-        req = fixtures.FixtureRequest(item)
-        assert req.fspath == modcol.fspath
-
-    def test_request_fixturenames(self, testdir):
-        testdir.makepyfile(
+    def test_request_getmodulepath(self, pytester: Pytester) -> None:
+        modcol = pytester.getmodulecol("def test_somefunc(): pass")
+        (item,) = pytester.genitems([modcol])
+        req = fixtures.FixtureRequest(item, _ispytest=True)
+        assert req.path == modcol.path
+
+    def test_request_fixturenames(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             from _pytest.pytester import get_public_names
@@ -924,25 +976,25 @@
             def farg(arg1):
                 pass
             @pytest.fixture(autouse=True)
-            def sarg(tmpdir):
+            def sarg(tmp_path):
                 pass
             def test_function(request, farg):
                 assert set(get_public_names(request.fixturenames)) == \
-                       set(["tmpdir", "sarg", "arg1", "request", "farg",
+                       set(["sarg", "arg1", "request", "farg",
                             "tmp_path", "tmp_path_factory"])
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)

-    def test_request_fixturenames_dynamic_fixture(self, testdir):
+    def test_request_fixturenames_dynamic_fixture(self, pytester: Pytester) -> None:
         """Regression test for #3057"""
-        testdir.copy_example("fixtures/test_getfixturevalue_dynamic.py")
-        result = testdir.runpytest()
+        pytester.copy_example("fixtures/test_getfixturevalue_dynamic.py")
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*1 passed*"])

-    def test_setupdecorator_and_xunit(self, testdir):
-        testdir.makepyfile(
+    def test_setupdecorator_and_xunit(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             values = []
@@ -970,13 +1022,14 @@
                              "function", "method", "function"]
         """
         )
-        reprec = testdir.inline_run("-v")
+        reprec = pytester.inline_run("-v")
         reprec.assertoutcome(passed=3)

-    def test_fixtures_sub_subdir_normalize_sep(self, testdir):
+    def test_fixtures_sub_subdir_normalize_sep(self, pytester: Pytester) -> None:
         # this tests that normalization of nodeids takes place
-        b = testdir.mkdir("tests").mkdir("unit")
-        b.join("conftest.py").write(
+        b = pytester.path.joinpath("tests", "unit")
+        b.mkdir(parents=True)
+        b.joinpath("conftest.py").write_text(
             textwrap.dedent(
                 """\
                 import pytest
@@ -986,9 +1039,9 @@
                 """
             )
         )
-        p = b.join("test_module.py")
-        p.write("def test_func(arg1): pass")
-        result = testdir.runpytest(p, "--fixtures")
+        p = b.joinpath("test_module.py")
+        p.write_text("def test_func(arg1): pass")
+        result = pytester.runpytest(p, "--fixtures")
         assert result.ret == 0
         result.stdout.fnmatch_lines(
             """
@@ -997,13 +1050,13 @@
         """
         )

-    def test_show_fixtures_color_yes(self, testdir):
-        testdir.makepyfile("def test_this(): assert 1")
-        result = testdir.runpytest("--color=yes", "--fixtures")
-        assert "\x1b[32mtmpdir" in result.stdout.str()
-
-    def test_newstyle_with_request(self, testdir):
-        testdir.makepyfile(
+    def test_show_fixtures_color_yes(self, pytester: Pytester) -> None:
+        pytester.makepyfile("def test_this(): assert 1")
+        result = pytester.runpytest("--color=yes", "--fixtures")
+        assert "\x1b[32mtmp_path" in result.stdout.str()
+
+    def test_newstyle_with_request(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture()
@@ -1013,11 +1066,11 @@
                 pass
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)

-    def test_setupcontext_no_param(self, testdir):
-        testdir.makepyfile(
+    def test_setupcontext_no_param(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture(params=[1,2])
@@ -1031,13 +1084,27 @@
                 assert arg in (1,2)
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2)


+class TestRequestSessionScoped:
+    @pytest.fixture(scope="session")
+    def session_request(self, request):
+        return request
+
+    @pytest.mark.parametrize("name", ["path", "module"])
+    def test_session_scoped_unavailable_attributes(self, session_request, name):
+        with pytest.raises(
+            AttributeError,
+            match=f"{name} not available in session-scoped context",
+        ):
+            getattr(session_request, name)
+
+
 class TestRequestMarking:
-    def test_applymarker(self, testdir):
-        item1, item2 = testdir.getitems(
+    def test_applymarker(self, pytester: Pytester) -> None:
+        item1, item2 = pytester.getitems(
             """
             import pytest

@@ -1051,7 +1118,7 @@
                     pass
         """
         )
-        req1 = fixtures.FixtureRequest(item1)
+        req1 = fixtures.FixtureRequest(item1, _ispytest=True)
         assert "xfail" not in item1.keywords
         req1.applymarker(pytest.mark.xfail)
         assert "xfail" in item1.keywords
@@ -1059,10 +1126,10 @@
         req1.applymarker(pytest.mark.skipif)
         assert "skipif" in item1.keywords
         with pytest.raises(ValueError):
-            req1.applymarker(42)
-
-    def test_accesskeywords(self, testdir):
-        testdir.makepyfile(
+            req1.applymarker(42)  # type: ignore[arg-type]
+
+    def test_accesskeywords(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture()
@@ -1074,11 +1141,11 @@
                 assert "abc" not in keywords
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)

-    def test_accessmarker_dynamic(self, testdir):
-        testdir.makeconftest(
+    def test_accessmarker_dynamic(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest
             @pytest.fixture()
@@ -1090,7 +1157,7 @@
                 request.applymarker(pytest.mark.XYZ("hello"))
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest
             def test_fun1(keywords):
@@ -1101,13 +1168,13 @@
                 assert "abc" not in keywords
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2)


 class TestFixtureUsages:
-    def test_noargfixturedec(self, testdir):
-        testdir.makepyfile(
+    def test_noargfixturedec(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture
@@ -1118,11 +1185,11 @@
                 assert arg1 == 1
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)

-    def test_receives_funcargs(self, testdir):
-        testdir.makepyfile(
+    def test_receives_funcargs(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture()
@@ -1140,11 +1207,11 @@
                 assert arg2 == 2
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2)

-    def test_receives_funcargs_scope_mismatch(self, testdir):
-        testdir.makepyfile(
+    def test_receives_funcargs_scope_mismatch(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture(scope="function")
@@ -1159,7 +1226,7 @@
                 assert arg2 == 2
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             [
                 "*ScopeMismatch*involved factories*",
@@ -1169,8 +1236,10 @@
             ]
         )

-    def test_receives_funcargs_scope_mismatch_issue660(self, testdir):
-        testdir.makepyfile(
+    def test_receives_funcargs_scope_mismatch_issue660(
+        self, pytester: Pytester
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture(scope="function")
@@ -1185,13 +1254,13 @@
                 assert arg2 == 2
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             ["*ScopeMismatch*involved factories*", "* def arg2*", "*1 error*"]
         )

-    def test_invalid_scope(self, testdir):
-        testdir.makepyfile(
+    def test_invalid_scope(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture(scope="functions")
@@ -1202,14 +1271,14 @@
                 pass
         """
         )
-        result = testdir.runpytest_inprocess()
+        result = pytester.runpytest_inprocess()
         result.stdout.fnmatch_lines(
             "*Fixture 'badscope' from test_invalid_scope.py got an unexpected scope value 'functions'"
         )

     @pytest.mark.parametrize("scope", ["function", "session"])
-    def test_parameters_without_eq_semantics(self, scope, testdir):
-        testdir.makepyfile(
+    def test_parameters_without_eq_semantics(self, scope, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             class NoEq1:  # fails on `a == b` statement
                 def __eq__(self, _):
@@ -1236,11 +1305,11 @@
                 scope=scope
             )
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*4 passed*"])

-    def test_funcarg_parametrized_and_used_twice(self, testdir):
-        testdir.makepyfile(
+    def test_funcarg_parametrized_and_used_twice(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             values = []
@@ -1258,11 +1327,13 @@
                 assert len(values) == arg1
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*2 passed*"])

-    def test_factory_uses_unknown_funcarg_as_dependency_error(self, testdir):
-        testdir.makepyfile(
+    def test_factory_uses_unknown_funcarg_as_dependency_error(
+        self, pytester: Pytester
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -1278,7 +1349,7 @@
                 pass
             """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             """
             *pytest.fixture()*
@@ -1289,8 +1360,8 @@
         """
         )

-    def test_factory_setup_as_classes_fails(self, testdir):
-        testdir.makepyfile(
+    def test_factory_setup_as_classes_fails(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             class arg1(object):
@@ -1300,12 +1371,12 @@

         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         values = reprec.getfailedcollections()
         assert len(values) == 1

-    def test_usefixtures_marker(self, testdir):
-        testdir.makepyfile(
+    def test_usefixtures_marker(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -1326,17 +1397,17 @@
             pytest.mark.usefixtures("myfix")(TestClass)
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2)

-    def test_usefixtures_ini(self, testdir):
-        testdir.makeini(
+    def test_usefixtures_ini(self, pytester: Pytester) -> None:
+        pytester.makeini(
             """
             [pytest]
             usefixtures = myfix
         """
         )
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest

@@ -1346,7 +1417,7 @@

         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             class TestClass(object):
                 def test_one(self):
@@ -1355,19 +1426,19 @@
                     assert self.hello == "world"
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2)

-    def test_usefixtures_seen_in_showmarkers(self, testdir):
-        result = testdir.runpytest("--markers")
+    def test_usefixtures_seen_in_showmarkers(self, pytester: Pytester) -> None:
+        result = pytester.runpytest("--markers")
         result.stdout.fnmatch_lines(
             """
             *usefixtures(fixturename1*mark tests*fixtures*
         """
         )

-    def test_request_instance_issue203(self, testdir):
-        testdir.makepyfile(
+    def test_request_instance_issue203(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -1380,11 +1451,11 @@
                     assert self.arg1 == 1
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)

-    def test_fixture_parametrized_with_iterator(self, testdir):
-        testdir.makepyfile(
+    def test_fixture_parametrized_with_iterator(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -1407,14 +1478,14 @@
                 values.append(arg2*10)
         """
         )
-        reprec = testdir.inline_run("-v")
+        reprec = pytester.inline_run("-v")
         reprec.assertoutcome(passed=4)
         values = reprec.getcalls("pytest_runtest_call")[0].item.module.values
         assert values == [1, 2, 10, 20]

-    def test_setup_functions_as_fixtures(self, testdir):
+    def test_setup_functions_as_fixtures(self, pytester: Pytester) -> None:
         """Ensure setup_* methods obey fixture scope rules (#517, #3094)."""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -1448,15 +1519,14 @@
                     pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["* 2 passed in *"])


 class TestFixtureManagerParseFactories:
     @pytest.fixture
-    def testdir(self, request):
-        testdir = request.getfixturevalue("testdir")
-        testdir.makeconftest(
+    def pytester(self, pytester: Pytester) -> Pytester:
+        pytester.makeconftest(
             """
             import pytest

@@ -1473,10 +1543,10 @@
                 return request._pyfuncitem
         """
         )
-        return testdir
-
-    def test_parsefactories_evil_objects_issue214(self, testdir):
-        testdir.makepyfile(
+        return pytester
+
+    def test_parsefactories_evil_objects_issue214(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             class A(object):
                 def __call__(self):
@@ -1488,11 +1558,11 @@
                 pass
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1, failed=0)

-    def test_parsefactories_conftest(self, testdir):
-        testdir.makepyfile(
+    def test_parsefactories_conftest(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             def test_hello(item, fm):
                 for name in ("fm", "hello", "item"):
@@ -1502,11 +1572,13 @@
                     assert fac.func.__name__ == name
         """
         )
-        reprec = testdir.inline_run("-s")
+        reprec = pytester.inline_run("-s")
         reprec.assertoutcome(passed=1)

-    def test_parsefactories_conftest_and_module_and_class(self, testdir):
-        testdir.makepyfile(
+    def test_parsefactories_conftest_and_module_and_class(
+        self, pytester: Pytester
+    ) -> None:
+        pytester.makepyfile(
             """\
             import pytest

@@ -1527,15 +1599,17 @@
                     assert faclist[2].func(item._request) == "class"
             """
         )
-        reprec = testdir.inline_run("-s")
+        reprec = pytester.inline_run("-s")
         reprec.assertoutcome(passed=1)

-    def test_parsefactories_relative_node_ids(self, testdir):
+    def test_parsefactories_relative_node_ids(
+        self, pytester: Pytester, monkeypatch: MonkeyPatch
+    ) -> None:
         # example mostly taken from:
         # https://mail.python.org/pipermail/pytest-dev/2014-September/002617.html
-        runner = testdir.mkdir("runner")
-        package = testdir.mkdir("package")
-        package.join("conftest.py").write(
+        runner = pytester.mkdir("runner")
+        package = pytester.mkdir("package")
+        package.joinpath("conftest.py").write_text(
             textwrap.dedent(
                 """\
             import pytest
@@ -1545,7 +1619,7 @@
             """
             )
         )
-        package.join("test_x.py").write(
+        package.joinpath("test_x.py").write_text(
             textwrap.dedent(
                 """\
                 def test_x(one):
@@ -1553,9 +1627,10 @@
                 """
             )
         )
-        sub = package.mkdir("sub")
-        sub.join("__init__.py").ensure()
-        sub.join("conftest.py").write(
+        sub = package.joinpath("sub")
+        sub.mkdir()
+        sub.joinpath("__init__.py").touch()
+        sub.joinpath("conftest.py").write_text(
             textwrap.dedent(
                 """\
                 import pytest
@@ -1565,7 +1640,7 @@
                 """
             )
         )
-        sub.join("test_y.py").write(
+        sub.joinpath("test_y.py").write_text(
             textwrap.dedent(
                 """\
                 def test_x(one):
@@ -1573,20 +1648,21 @@
                 """
             )
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2)
-        with runner.as_cwd():
-            reprec = testdir.inline_run("..")
+        with monkeypatch.context() as mp:
+            mp.chdir(runner)
+            reprec = pytester.inline_run("..")
             reprec.assertoutcome(passed=2)

-    def test_package_xunit_fixture(self, testdir):
-        testdir.makepyfile(
+    def test_package_xunit_fixture(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             __init__="""\
             values = []
         """
         )
-        package = testdir.mkdir("package")
-        package.join("__init__.py").write(
+        package = pytester.mkdir("package")
+        package.joinpath("__init__.py").write_text(
             textwrap.dedent(
                 """\
                 from .. import values
@@ -1597,7 +1673,7 @@
                 """
             )
         )
-        package.join("test_x.py").write(
+        package.joinpath("test_x.py").write_text(
             textwrap.dedent(
                 """\
                 from .. import values
@@ -1606,8 +1682,8 @@
                 """
             )
         )
-        package = testdir.mkdir("package2")
-        package.join("__init__.py").write(
+        package = pytester.mkdir("package2")
+        package.joinpath("__init__.py").write_text(
             textwrap.dedent(
                 """\
                 from .. import values
@@ -1618,7 +1694,7 @@
                 """
             )
         )
-        package.join("test_x.py").write(
+        package.joinpath("test_x.py").write_text(
             textwrap.dedent(
                 """\
                 from .. import values
@@ -1627,19 +1703,19 @@
                 """
             )
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2)

-    def test_package_fixture_complex(self, testdir):
-        testdir.makepyfile(
+    def test_package_fixture_complex(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             __init__="""\
             values = []
         """
         )
-        testdir.syspathinsert(testdir.tmpdir.dirname)
-        package = testdir.mkdir("package")
-        package.join("__init__.py").write("")
-        package.join("conftest.py").write(
+        pytester.syspathinsert(pytester.path.name)
+        package = pytester.mkdir("package")
+        package.joinpath("__init__.py").write_text("")
+        package.joinpath("conftest.py").write_text(
             textwrap.dedent(
                 """\
                 import pytest
@@ -1657,7 +1733,7 @@
                 """
             )
         )
-        package.join("test_x.py").write(
+        package.joinpath("test_x.py").write_text(
             textwrap.dedent(
                 """\
                 from .. import values
@@ -1668,27 +1744,27 @@
                 """
             )
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2)

-    def test_collect_custom_items(self, testdir):
-        testdir.copy_example("fixtures/custom_item")
-        result = testdir.runpytest("foo")
+    def test_collect_custom_items(self, pytester: Pytester) -> None:
+        pytester.copy_example("fixtures/custom_item")
+        result = pytester.runpytest("foo")
         result.stdout.fnmatch_lines(["*passed*"])


 class TestAutouseDiscovery:
     @pytest.fixture
-    def testdir(self, testdir):
-        testdir.makeconftest(
+    def pytester(self, pytester: Pytester) -> Pytester:
+        pytester.makeconftest(
             """
             import pytest
             @pytest.fixture(autouse=True)
-            def perfunction(request, tmpdir):
+            def perfunction(request, tmp_path):
                 pass

             @pytest.fixture()
-            def arg1(tmpdir):
+            def arg1(tmp_path):
                 pass
             @pytest.fixture(autouse=True)
             def perfunction2(arg1):
@@ -1703,24 +1779,24 @@
                 return request._pyfuncitem
         """
         )
-        return testdir
-
-    def test_parsefactories_conftest(self, testdir):
-        testdir.makepyfile(
+        return pytester
+
+    def test_parsefactories_conftest(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             from _pytest.pytester import get_public_names
             def test_check_setup(item, fm):
-                autousenames = fm._getautousenames(item.nodeid)
+                autousenames = list(fm._getautousenames(item.nodeid))
                 assert len(get_public_names(autousenames)) == 2
                 assert "perfunction2" in autousenames
                 assert "perfunction" in autousenames
         """
         )
-        reprec = testdir.inline_run("-s")
+        reprec = pytester.inline_run("-s")
         reprec.assertoutcome(passed=1)

-    def test_two_classes_separated_autouse(self, testdir):
-        testdir.makepyfile(
+    def test_two_classes_separated_autouse(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             class TestA(object):
@@ -1739,11 +1815,11 @@
                     assert self.values == [1]
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2)

-    def test_setup_at_classlevel(self, testdir):
-        testdir.makepyfile(
+    def test_setup_at_classlevel(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             class TestClass(object):
@@ -1756,12 +1832,12 @@
                     assert self.funcname == "test_method2"
         """
         )
-        reprec = testdir.inline_run("-s")
+        reprec = pytester.inline_run("-s")
         reprec.assertoutcome(passed=2)

     @pytest.mark.xfail(reason="'enabled' feature not implemented")
-    def test_setup_enabled_functionnode(self, testdir):
-        testdir.makepyfile(
+    def test_setup_enabled_functionnode(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -1784,13 +1860,13 @@
                 assert "db" in request.fixturenames
         """
         )
-        reprec = testdir.inline_run("-s")
+        reprec = pytester.inline_run("-s")
         reprec.assertoutcome(passed=2)

-    def test_callables_nocode(self, testdir):
+    def test_callables_nocode(self, pytester: Pytester) -> None:
         """An imported mock.call would break setup/factory discovery due to
         it being callable and __code__ not being a code object."""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
            class _call(tuple):
                def __call__(self, *k, **kw):
@@ -1801,13 +1877,13 @@
            call = _call()
         """
         )
-        reprec = testdir.inline_run("-s")
+        reprec = pytester.inline_run("-s")
         reprec.assertoutcome(failed=0, passed=0)

-    def test_autouse_in_conftests(self, testdir):
-        a = testdir.mkdir("a")
-        b = testdir.mkdir("a1")
-        conftest = testdir.makeconftest(
+    def test_autouse_in_conftests(self, pytester: Pytester) -> None:
+        a = pytester.mkdir("a")
+        b = pytester.mkdir("a1")
+        conftest = pytester.makeconftest(
             """
             import pytest
             @pytest.fixture(autouse=True)
@@ -1815,18 +1891,18 @@
                 xxx
         """
         )
-        conftest.move(a.join(conftest.basename))
-        a.join("test_something.py").write("def test_func(): pass")
-        b.join("test_otherthing.py").write("def test_func(): pass")
-        result = testdir.runpytest()
+        conftest.rename(a.joinpath(conftest.name))
+        a.joinpath("test_something.py").write_text("def test_func(): pass")
+        b.joinpath("test_otherthing.py").write_text("def test_func(): pass")
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             """
             *1 passed*1 error*
         """
         )

-    def test_autouse_in_module_and_two_classes(self, testdir):
-        testdir.makepyfile(
+    def test_autouse_in_module_and_two_classes(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             values = []
@@ -1847,14 +1923,14 @@
                     assert values == ["module", "module", "A", "module"], values
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=3)


 class TestAutouseManagement:
-    def test_autouse_conftest_mid_directory(self, testdir):
-        pkgdir = testdir.mkpydir("xyz123")
-        pkgdir.join("conftest.py").write(
+    def test_autouse_conftest_mid_directory(self, pytester: Pytester) -> None:
+        pkgdir = pytester.mkpydir("xyz123")
+        pkgdir.joinpath("conftest.py").write_text(
             textwrap.dedent(
                 """\
                 import pytest
@@ -1865,8 +1941,11 @@
                 """
             )
         )
-        t = pkgdir.ensure("tests", "test_app.py")
-        t.write(
+        sub = pkgdir.joinpath("tests")
+        sub.mkdir()
+        t = sub.joinpath("test_app.py")
+        t.touch()
+        t.write_text(
             textwrap.dedent(
                 """\
                 import sys
@@ -1875,11 +1954,11 @@
                 """
             )
         )
-        reprec = testdir.inline_run("-s")
+        reprec = pytester.inline_run("-s")
         reprec.assertoutcome(passed=1)

-    def test_funcarg_and_setup(self, testdir):
-        testdir.makepyfile(
+    def test_funcarg_and_setup(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             values = []
@@ -1902,11 +1981,11 @@
                 assert arg == 0
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2)

-    def test_uses_parametrized_resource(self, testdir):
-        testdir.makepyfile(
+    def test_uses_parametrized_resource(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             values = []
@@ -1928,11 +2007,11 @@

         """
         )
-        reprec = testdir.inline_run("-s")
+        reprec = pytester.inline_run("-s")
         reprec.assertoutcome(passed=2)

-    def test_session_parametrized_function(self, testdir):
-        testdir.makepyfile(
+    def test_session_parametrized_function(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -1955,11 +2034,13 @@
                 assert values[:arg] == [1,2][:arg]
         """
         )
-        reprec = testdir.inline_run("-v", "-s")
+        reprec = pytester.inline_run("-v", "-s")
         reprec.assertoutcome(passed=4)

-    def test_class_function_parametrization_finalization(self, testdir):
-        p = testdir.makeconftest(
+    def test_class_function_parametrization_finalization(
+        self, pytester: Pytester
+    ) -> None:
+        p = pytester.makeconftest(
             """
             import pytest
             import pprint
@@ -1981,7 +2062,7 @@
                 request.addfinalizer(fin)
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -1993,17 +2074,16 @@
                     pass
         """
         )
-        confcut = "--confcutdir={}".format(testdir.tmpdir)
-        reprec = testdir.inline_run("-v", "-s", confcut)
+        reprec = pytester.inline_run("-v", "-s", "--confcutdir", pytester.path)
         reprec.assertoutcome(passed=8)
         config = reprec.getcalls("pytest_unconfigure")[0].config
-        values = config.pluginmanager._getconftestmodules(p, importmode="prepend")[
-            0
-        ].values
+        values = config.pluginmanager._getconftestmodules(
+            p, importmode="prepend", rootpath=pytester.path
+        )[0].values
         assert values == ["fin_a1", "fin_a2", "fin_b1", "fin_b2"] * 2

-    def test_scope_ordering(self, testdir):
-        testdir.makepyfile(
+    def test_scope_ordering(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             values = []
@@ -2022,11 +2102,11 @@
                     assert values == [1,3,2]
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)

-    def test_parametrization_setup_teardown_ordering(self, testdir):
-        testdir.makepyfile(
+    def test_parametrization_setup_teardown_ordering(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             values = []
@@ -2051,11 +2131,11 @@
                              "setup-2", "step1-2", "step2-2", "teardown-2",]
         """
         )
-        reprec = testdir.inline_run("-s")
+        reprec = pytester.inline_run("-s")
         reprec.assertoutcome(passed=5)

-    def test_ordering_autouse_before_explicit(self, testdir):
-        testdir.makepyfile(
+    def test_ordering_autouse_before_explicit(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -2070,14 +2150,16 @@
                 assert values == [1,2]
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)

     @pytest.mark.parametrize("param1", ["", "params=[1]"], ids=["p00", "p01"])
     @pytest.mark.parametrize("param2", ["", "params=[1]"], ids=["p10", "p11"])
-    def test_ordering_dependencies_torndown_first(self, testdir, param1, param2):
+    def test_ordering_dependencies_torndown_first(
+        self, pytester: Pytester, param1, param2
+    ) -> None:
         """#226"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest
             values = []
@@ -2097,13 +2179,13 @@
         """
             % locals()
         )
-        reprec = testdir.inline_run("-s")
+        reprec = pytester.inline_run("-s")
         reprec.assertoutcome(passed=2)


 class TestFixtureMarker:
-    def test_parametrize(self, testdir):
-        testdir.makepyfile(
+    def test_parametrize(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture(params=["a", "b", "c"])
@@ -2116,11 +2198,11 @@
                 assert values == list("abc")
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=4)

-    def test_multiple_parametrization_issue_736(self, testdir):
-        testdir.makepyfile(
+    def test_multiple_parametrization_issue_736(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -2134,19 +2216,21 @@
                 assert foobar in [4,5,6]
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=9)

     @pytest.mark.parametrize(
         "param_args",
         ["'fixt, val'", "'fixt,val'", "['fixt', 'val']", "('fixt', 'val')"],
     )
-    def test_override_parametrized_fixture_issue_979(self, testdir, param_args):
+    def test_override_parametrized_fixture_issue_979(
+        self, pytester: Pytester, param_args
+    ) -> None:
         """Make sure a parametrized argument can override a parametrized fixture.

         This was a regression introduced in the fix for #736.
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -2160,11 +2244,11 @@
         """
             % param_args
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2)

-    def test_scope_session(self, testdir):
-        testdir.makepyfile(
+    def test_scope_session(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             values = []
@@ -2184,11 +2268,11 @@
                     assert len(values) == 1
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=3)

-    def test_scope_session_exc(self, testdir):
-        testdir.makepyfile(
+    def test_scope_session_exc(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             values = []
@@ -2205,11 +2289,11 @@
                 assert values == [1]
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(skipped=2, passed=1)

-    def test_scope_session_exc_two_fix(self, testdir):
-        testdir.makepyfile(
+    def test_scope_session_exc_two_fix(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             values = []
@@ -2231,11 +2315,11 @@
                 assert m == []
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(skipped=2, passed=1)

-    def test_scope_exc(self, testdir):
-        testdir.makepyfile(
+    def test_scope_exc(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             test_foo="""
                 def test_foo(fix):
                     pass
@@ -2260,11 +2344,11 @@
                     assert req_list == [1]
             """,
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(skipped=2, passed=1)

-    def test_scope_module_uses_session(self, testdir):
-        testdir.makepyfile(
+    def test_scope_module_uses_session(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             values = []
@@ -2284,11 +2368,11 @@
                     assert len(values) == 1
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=3)

-    def test_scope_module_and_finalizer(self, testdir):
-        testdir.makeconftest(
+    def test_scope_module_and_finalizer(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest
             finalized_list = []
@@ -2306,7 +2390,7 @@
                 return len(finalized_list)
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             test_mod1="""
                 def test_1(arg, created, finalized):
                     assert created == 1
@@ -2324,11 +2408,11 @@
                     assert finalized == 2
             """,
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=4)

-    def test_scope_mismatch_various(self, testdir):
-        testdir.makeconftest(
+    def test_scope_mismatch_various(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest
             finalized = []
@@ -2338,7 +2422,7 @@
                 pass
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             test_mod1="""
                 import pytest
                 @pytest.fixture(scope="session")
@@ -2348,14 +2432,14 @@
                     pass
             """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret != 0
         result.stdout.fnmatch_lines(
             ["*ScopeMismatch*You tried*function*session*request*"]
         )

-    def test_dynamic_scope(self, testdir):
-        testdir.makeconftest(
+    def test_dynamic_scope(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest

@@ -2378,7 +2462,7 @@
         """
         )

-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_first(dynamic_fixture):
                 assert dynamic_fixture == 1
@@ -2390,14 +2474,14 @@
         """
         )

-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2)

-        reprec = testdir.inline_run("--extend-scope")
+        reprec = pytester.inline_run("--extend-scope")
         reprec.assertoutcome(passed=1, failed=1)

-    def test_dynamic_scope_bad_return(self, testdir):
-        testdir.makepyfile(
+    def test_dynamic_scope_bad_return(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -2410,14 +2494,14 @@

         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             "Fixture 'fixture' from test_dynamic_scope_bad_return.py "
             "got an unexpected scope value 'wrong-scope'"
         )

-    def test_register_only_with_mark(self, testdir):
-        testdir.makeconftest(
+    def test_register_only_with_mark(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest
             @pytest.fixture()
@@ -2425,7 +2509,7 @@
                 return 1
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             test_mod1="""
                 import pytest
                 @pytest.fixture()
@@ -2435,11 +2519,11 @@
                     assert arg == 2
             """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)

-    def test_parametrize_and_scope(self, testdir):
-        testdir.makepyfile(
+    def test_parametrize_and_scope(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture(scope="module", params=["a", "b", "c"])
@@ -2450,7 +2534,7 @@
                 values.append(arg)
         """
         )
-        reprec = testdir.inline_run("-v")
+        reprec = pytester.inline_run("-v")
         reprec.assertoutcome(passed=3)
         values = reprec.getcalls("pytest_runtest_call")[0].item.module.values
         assert len(values) == 3
@@ -2458,8 +2542,8 @@
         assert "b" in values
         assert "c" in values

-    def test_scope_mismatch(self, testdir):
-        testdir.makeconftest(
+    def test_scope_mismatch(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest
             @pytest.fixture(scope="function")
@@ -2467,7 +2551,7 @@
                 pass
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture(scope="session")
@@ -2477,11 +2561,11 @@
                 pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(["*ScopeMismatch*", "*1 error*"])

-    def test_parametrize_separated_order(self, testdir):
-        testdir.makepyfile(
+    def test_parametrize_separated_order(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -2496,19 +2580,19 @@
                 values.append(arg)
         """
         )
-        reprec = testdir.inline_run("-v")
+        reprec = pytester.inline_run("-v")
         reprec.assertoutcome(passed=4)
         values = reprec.getcalls("pytest_runtest_call")[0].item.module.values
         assert values == [1, 1, 2, 2]

-    def test_module_parametrized_ordering(self, testdir):
-        testdir.makeini(
+    def test_module_parametrized_ordering(self, pytester: Pytester) -> None:
+        pytester.makeini(
             """
             [pytest]
             console_output_style=classic
         """
         )
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest

@@ -2520,7 +2604,7 @@
                 pass
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             test_mod1="""
             def test_func(sarg):
                 pass
@@ -2538,7 +2622,7 @@
                 pass
         """,
         )
-        result = testdir.runpytest("-v")
+        result = pytester.runpytest("-v")
         result.stdout.fnmatch_lines(
             """
             test_mod1.py::test_func[s1] PASSED
@@ -2560,14 +2644,14 @@
         """
         )

-    def test_dynamic_parametrized_ordering(self, testdir):
-        testdir.makeini(
+    def test_dynamic_parametrized_ordering(self, pytester: Pytester) -> None:
+        pytester.makeini(
             """
             [pytest]
             console_output_style=classic
         """
         )
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest

@@ -2587,7 +2671,7 @@
                 pass
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test(reprovision):
                 pass
@@ -2595,7 +2679,7 @@
                 pass
         """
         )
-        result = testdir.runpytest("-v")
+        result = pytester.runpytest("-v")
         result.stdout.fnmatch_lines(
             """
             test_dynamic_parametrized_ordering.py::test[flavor1-vxlan] PASSED
@@ -2609,14 +2693,14 @@
         """
         )

-    def test_class_ordering(self, testdir):
-        testdir.makeini(
+    def test_class_ordering(self, pytester: Pytester) -> None:
+        pytester.makeini(
             """
             [pytest]
             console_output_style=classic
         """
         )
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest

@@ -2637,7 +2721,7 @@
                 request.addfinalizer(fin)
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -2651,7 +2735,7 @@
                     pass
         """
         )
-        result = testdir.runpytest("-vs")
+        result = pytester.runpytest("-vs")
         result.stdout.re_match_lines(
             r"""
             test_class_ordering.py::TestClass2::test_1\[a-1\] PASSED
@@ -2669,8 +2753,10 @@
         """
         )

-    def test_parametrize_separated_order_higher_scope_first(self, testdir):
-        testdir.makepyfile(
+    def test_parametrize_separated_order_higher_scope_first(
+        self, pytester: Pytester
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -2699,7 +2785,7 @@
                 values.append("test4")
         """
         )
-        reprec = testdir.inline_run("-v")
+        reprec = pytester.inline_run("-v")
         reprec.assertoutcome(passed=12)
         values = reprec.getcalls("pytest_runtest_call")[0].item.module.values
         expected = [
@@ -2745,8 +2831,8 @@
         pprint.pprint(list(zip(values, expected)))
         assert values == expected

-    def test_parametrized_fixture_teardown_order(self, testdir):
-        testdir.makepyfile(
+    def test_parametrized_fixture_teardown_order(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture(params=[1,2], scope="class")
@@ -2778,7 +2864,7 @@
                 assert not values
         """
         )
-        result = testdir.runpytest("-v")
+        result = pytester.runpytest("-v")
         result.stdout.fnmatch_lines(
             """
             *3 passed*
@@ -2786,8 +2872,8 @@
         )
         result.stdout.no_fnmatch_line("*error*")

-    def test_fixture_finalizer(self, testdir):
-        testdir.makeconftest(
+    def test_fixture_finalizer(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest
             import sys
@@ -2796,13 +2882,13 @@
             def browser(request):

                 def finalize():
-                    sys.stdout.write('Finalized')
+                    sys.stdout.write_text('Finalized')
                 request.addfinalizer(finalize)
                 return {}
         """
         )
-        b = testdir.mkdir("subdir")
-        b.join("test_overridden_fixture_finalizer.py").write(
+        b = pytester.mkdir("subdir")
+        b.joinpath("test_overridden_fixture_finalizer.py").write_text(
             textwrap.dedent(
                 """\
                 import pytest
@@ -2816,12 +2902,12 @@
                 """
             )
         )
-        reprec = testdir.runpytest("-s")
+        reprec = pytester.runpytest("-s")
         for test in ["test_browser"]:
             reprec.stdout.fnmatch_lines(["*Finalized*"])

-    def test_class_scope_with_normal_tests(self, testdir):
-        testpath = testdir.makepyfile(
+    def test_class_scope_with_normal_tests(self, pytester: Pytester) -> None:
+        testpath = pytester.makepyfile(
             """
             import pytest

@@ -2844,12 +2930,12 @@
                 def test_c(self, a):
                     assert a == 3"""
         )
-        reprec = testdir.inline_run(testpath)
+        reprec = pytester.inline_run(testpath)
         for test in ["test_a", "test_b", "test_c"]:
             assert reprec.matchreport(test).passed

-    def test_request_is_clean(self, testdir):
-        testdir.makepyfile(
+    def test_request_is_clean(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             values = []
@@ -2860,12 +2946,12 @@
                 pass
         """
         )
-        reprec = testdir.inline_run("-s")
+        reprec = pytester.inline_run("-s")
         values = reprec.getcalls("pytest_runtest_call")[0].item.module.values
         assert values == [1, 2]

-    def test_parametrize_separated_lifecycle(self, testdir):
-        testdir.makepyfile(
+    def test_parametrize_separated_lifecycle(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -2881,7 +2967,7 @@
                 values.append(arg)
         """
         )
-        reprec = testdir.inline_run("-vs")
+        reprec = pytester.inline_run("-vs")
         reprec.assertoutcome(passed=4)
         values = reprec.getcalls("pytest_runtest_call")[0].item.module.values
         import pprint
@@ -2893,8 +2979,10 @@
         assert values[3] == values[4] == 2
         assert values[5] == "fin2"

-    def test_parametrize_function_scoped_finalizers_called(self, testdir):
-        testdir.makepyfile(
+    def test_parametrize_function_scoped_finalizers_called(
+        self, pytester: Pytester
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -2914,13 +3002,15 @@
                 assert values == [1, "fin1", 2, "fin2", 1, "fin1", 2, "fin2"]
         """
         )
-        reprec = testdir.inline_run("-v")
+        reprec = pytester.inline_run("-v")
         reprec.assertoutcome(passed=5)

     @pytest.mark.parametrize("scope", ["session", "function", "module"])
-    def test_finalizer_order_on_parametrization(self, scope, testdir):
+    def test_finalizer_order_on_parametrization(
+        self, scope, pytester: Pytester
+    ) -> None:
         """#246"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest
             values = []
@@ -2951,12 +3041,12 @@
         """
             % {"scope": scope}
         )
-        reprec = testdir.inline_run("-lvs")
+        reprec = pytester.inline_run("-lvs")
         reprec.assertoutcome(passed=3)

-    def test_class_scope_parametrization_ordering(self, testdir):
+    def test_class_scope_parametrization_ordering(self, pytester: Pytester) -> None:
         """#396"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest
             values = []
@@ -2977,7 +3067,7 @@
                     values.append("test_population")
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=6)
         values = reprec.getcalls("pytest_runtest_call")[0].item.module.values
         assert values == [
@@ -2993,8 +3083,8 @@
             "fin Doe",
         ]

-    def test_parametrize_setup_function(self, testdir):
-        testdir.makepyfile(
+    def test_parametrize_setup_function(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -3023,11 +3113,13 @@

         """
         )
-        reprec = testdir.inline_run("-v")
+        reprec = pytester.inline_run("-v")
         reprec.assertoutcome(passed=6)

-    def test_fixture_marked_function_not_collected_as_test(self, testdir):
-        testdir.makepyfile(
+    def test_fixture_marked_function_not_collected_as_test(
+        self, pytester: Pytester
+    ) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture
@@ -3038,11 +3130,11 @@
                 assert test_app == 1
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)

-    def test_params_and_ids(self, testdir):
-        testdir.makepyfile(
+    def test_params_and_ids(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -3055,11 +3147,11 @@
                 assert 1
         """
         )
-        res = testdir.runpytest("-v")
+        res = pytester.runpytest("-v")
         res.stdout.fnmatch_lines(["*test_foo*alpha*", "*test_foo*beta*"])

-    def test_params_and_ids_yieldfixture(self, testdir):
-        testdir.makepyfile(
+    def test_params_and_ids_yieldfixture(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -3071,12 +3163,14 @@
                 assert 1
         """
         )
-        res = testdir.runpytest("-v")
+        res = pytester.runpytest("-v")
         res.stdout.fnmatch_lines(["*test_foo*alpha*", "*test_foo*beta*"])

-    def test_deterministic_fixture_collection(self, testdir, monkeypatch):
+    def test_deterministic_fixture_collection(
+        self, pytester: Pytester, monkeypatch
+    ) -> None:
         """#920"""
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -3101,36 +3195,36 @@
             """
         )
         monkeypatch.setenv("PYTHONHASHSEED", "1")
-        out1 = testdir.runpytest_subprocess("-v")
+        out1 = pytester.runpytest_subprocess("-v")
         monkeypatch.setenv("PYTHONHASHSEED", "2")
-        out2 = testdir.runpytest_subprocess("-v")
-        out1 = [
+        out2 = pytester.runpytest_subprocess("-v")
+        output1 = [
             line
             for line in out1.outlines
             if line.startswith("test_deterministic_fixture_collection.py::test_foo")
         ]
-        out2 = [
+        output2 = [
             line
             for line in out2.outlines
             if line.startswith("test_deterministic_fixture_collection.py::test_foo")
         ]
-        assert len(out1) == 12
-        assert out1 == out2
+        assert len(output1) == 12
+        assert output1 == output2


 class TestRequestScopeAccess:
     pytestmark = pytest.mark.parametrize(
         ("scope", "ok", "error"),
         [
-            ["session", "", "fspath class function module"],
-            ["module", "module fspath", "cls function"],
-            ["class", "module fspath cls", "function"],
-            ["function", "module fspath cls function", ""],
+            ["session", "", "path class function module"],
+            ["module", "module path", "cls function"],
+            ["class", "module path cls", "function"],
+            ["function", "module path cls function", ""],
         ],
     )

-    def test_setup(self, testdir, scope, ok, error):
-        testdir.makepyfile(
+    def test_setup(self, pytester: Pytester, scope, ok, error) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture(scope=%r, autouse=True)
@@ -3147,11 +3241,11 @@
         """
             % (scope, ok.split(), error.split())
         )
-        reprec = testdir.inline_run("-l")
+        reprec = pytester.inline_run("-l")
         reprec.assertoutcome(passed=1)

-    def test_funcarg(self, testdir, scope, ok, error):
-        testdir.makepyfile(
+    def test_funcarg(self, pytester: Pytester, scope, ok, error) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture(scope=%r)
@@ -3168,13 +3262,13 @@
         """
             % (scope, ok.split(), error.split())
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)


 class TestErrors:
-    def test_subfactory_missing_funcarg(self, testdir):
-        testdir.makepyfile(
+    def test_subfactory_missing_funcarg(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture()
@@ -3184,14 +3278,14 @@
                 pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret != 0
         result.stdout.fnmatch_lines(
             ["*def gen(qwe123):*", "*fixture*qwe123*not found*", "*1 error*"]
         )

-    def test_issue498_fixture_finalizer_failing(self, testdir):
-        testdir.makepyfile(
+    def test_issue498_fixture_finalizer_failing(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture
@@ -3210,7 +3304,7 @@
                 assert values[0] != values[1]
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             """
             *ERROR*teardown*test_1*
@@ -3221,8 +3315,8 @@
         """
         )

-    def test_setupfunc_missing_funcarg(self, testdir):
-        testdir.makepyfile(
+    def test_setupfunc_missing_funcarg(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest
             @pytest.fixture(autouse=True)
@@ -3232,7 +3326,7 @@
                 pass
         """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         assert result.ret != 0
         result.stdout.fnmatch_lines(
             ["*def gen(qwe123):*", "*fixture*qwe123*not found*", "*1 error*"]
@@ -3240,34 +3334,34 @@


 class TestShowFixtures:
-    def test_funcarg_compat(self, testdir):
-        config = testdir.parseconfigure("--funcargs")
+    def test_funcarg_compat(self, pytester: Pytester) -> None:
+        config = pytester.parseconfigure("--funcargs")
         assert config.option.showfixtures

-    def test_show_fixtures(self, testdir):
-        result = testdir.runpytest("--fixtures")
+    def test_show_fixtures(self, pytester: Pytester) -> None:
+        result = pytester.runpytest("--fixtures")
         result.stdout.fnmatch_lines(
             [
-                "tmpdir_factory [[]session scope[]]",
+                "tmp_path_factory [[]session scope[]] -- .../_pytest/tmpdir.py:*",
                 "*for the test session*",
-                "tmpdir",
+                "tmp_path -- .../_pytest/tmpdir.py:*",
                 "*temporary directory*",
             ]
         )

-    def test_show_fixtures_verbose(self, testdir):
-        result = testdir.runpytest("--fixtures", "-v")
+    def test_show_fixtures_verbose(self, pytester: Pytester) -> None:
+        result = pytester.runpytest("--fixtures", "-v")
         result.stdout.fnmatch_lines(
             [
-                "tmpdir_factory [[]session scope[]] -- *tmpdir.py*",
+                "tmp_path_factory [[]session scope[]] -- .../_pytest/tmpdir.py:*",
                 "*for the test session*",
-                "tmpdir -- *tmpdir.py*",
+                "tmp_path -- .../_pytest/tmpdir.py:*",
                 "*temporary directory*",
             ]
         )

-    def test_show_fixtures_testmodule(self, testdir):
-        p = testdir.makepyfile(
+    def test_show_fixtures_testmodule(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             '''
             import pytest
             @pytest.fixture
@@ -3278,20 +3372,20 @@
                 """  hello world """
         '''
         )
-        result = testdir.runpytest("--fixtures", p)
+        result = pytester.runpytest("--fixtures", p)
         result.stdout.fnmatch_lines(
             """
-            *tmpdir
+            *tmp_path -- *
             *fixtures defined from*
-            *arg1*
+            *arg1 -- test_show_fixtures_testmodule.py:6*
             *hello world*
         """
         )
         result.stdout.no_fnmatch_line("*arg0*")

     @pytest.mark.parametrize("testmod", [True, False])
-    def test_show_fixtures_conftest(self, testdir, testmod):
-        testdir.makeconftest(
+    def test_show_fixtures_conftest(self, pytester: Pytester, testmod) -> None:
+        pytester.makeconftest(
             '''
             import pytest
             @pytest.fixture
@@ -3300,24 +3394,24 @@
         '''
         )
         if testmod:
-            testdir.makepyfile(
+            pytester.makepyfile(
                 """
                 def test_hello():
                     pass
             """
             )
-        result = testdir.runpytest("--fixtures")
+        result = pytester.runpytest("--fixtures")
         result.stdout.fnmatch_lines(
             """
-            *tmpdir*
+            *tmp_path*
             *fixtures defined from*conftest*
             *arg1*
             *hello world*
         """
         )

-    def test_show_fixtures_trimmed_doc(self, testdir):
-        p = testdir.makepyfile(
+    def test_show_fixtures_trimmed_doc(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             textwrap.dedent(
                 '''\
                 import pytest
@@ -3338,23 +3432,23 @@
                 '''
             )
         )
-        result = testdir.runpytest("--fixtures", p)
+        result = pytester.runpytest("--fixtures", p)
         result.stdout.fnmatch_lines(
             textwrap.dedent(
                 """\
                 * fixtures defined from test_show_fixtures_trimmed_doc *
-                arg2
+                arg2 -- test_show_fixtures_trimmed_doc.py:10
                     line1
                     line2
-                arg1
+                arg1 -- test_show_fixtures_trimmed_doc.py:3
                     line1
                     line2
                 """
             )
         )

-    def test_show_fixtures_indented_doc(self, testdir):
-        p = testdir.makepyfile(
+    def test_show_fixtures_indented_doc(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             textwrap.dedent(
                 '''\
                 import pytest
@@ -3367,20 +3461,22 @@
                 '''
             )
         )
-        result = testdir.runpytest("--fixtures", p)
+        result = pytester.runpytest("--fixtures", p)
         result.stdout.fnmatch_lines(
             textwrap.dedent(
                 """\
                 * fixtures defined from test_show_fixtures_indented_doc *
-                fixture1
+                fixture1 -- test_show_fixtures_indented_doc.py:3
                     line1
                         indented line
                 """
             )
         )

-    def test_show_fixtures_indented_doc_first_line_unindented(self, testdir):
-        p = testdir.makepyfile(
+    def test_show_fixtures_indented_doc_first_line_unindented(
+        self, pytester: Pytester
+    ) -> None:
+        p = pytester.makepyfile(
             textwrap.dedent(
                 '''\
                 import pytest
@@ -3393,12 +3489,12 @@
                 '''
             )
         )
-        result = testdir.runpytest("--fixtures", p)
+        result = pytester.runpytest("--fixtures", p)
         result.stdout.fnmatch_lines(
             textwrap.dedent(
                 """\
                 * fixtures defined from test_show_fixtures_indented_doc_first_line_unindented *
-                fixture1
+                fixture1 -- test_show_fixtures_indented_doc_first_line_unindented.py:3
                     line1
                     line2
                         indented line
@@ -3406,8 +3502,8 @@
             )
         )

-    def test_show_fixtures_indented_in_class(self, testdir):
-        p = testdir.makepyfile(
+    def test_show_fixtures_indented_in_class(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile(
             textwrap.dedent(
                 '''\
                 import pytest
@@ -3421,12 +3517,12 @@
                 '''
             )
         )
-        result = testdir.runpytest("--fixtures", p)
+        result = pytester.runpytest("--fixtures", p)
         result.stdout.fnmatch_lines(
             textwrap.dedent(
                 """\
                 * fixtures defined from test_show_fixtures_indented_in_class *
-                fixture1
+                fixture1 -- test_show_fixtures_indented_in_class.py:4
                     line1
                     line2
                         indented line
@@ -3434,9 +3530,9 @@
             )
         )

-    def test_show_fixtures_different_files(self, testdir):
+    def test_show_fixtures_different_files(self, pytester: Pytester) -> None:
         """`--fixtures` only shows fixtures from first file (#833)."""
-        testdir.makepyfile(
+        pytester.makepyfile(
             test_a='''
             import pytest

@@ -3449,7 +3545,7 @@
                 pass
         '''
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             test_b='''
             import pytest

@@ -3462,21 +3558,21 @@
                 pass
         '''
         )
-        result = testdir.runpytest("--fixtures")
+        result = pytester.runpytest("--fixtures")
         result.stdout.fnmatch_lines(
             """
             * fixtures defined from test_a *
-            fix_a
+            fix_a -- test_a.py:4
                 Fixture A

             * fixtures defined from test_b *
-            fix_b
+            fix_b -- test_b.py:4
                 Fixture B
         """
         )

-    def test_show_fixtures_with_same_name(self, testdir):
-        testdir.makeconftest(
+    def test_show_fixtures_with_same_name(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             '''
             import pytest
             @pytest.fixture
@@ -3485,13 +3581,13 @@
                 return "Hello World"
         '''
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             def test_foo(arg1):
                 assert arg1 == "Hello World"
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             '''
             import pytest
             @pytest.fixture
@@ -3502,15 +3598,15 @@
                 assert arg1 == "Hi"
         '''
         )
-        result = testdir.runpytest("--fixtures")
+        result = pytester.runpytest("--fixtures")
         result.stdout.fnmatch_lines(
             """
             * fixtures defined from conftest *
-            arg1
+            arg1 -- conftest.py:3
                 Hello World in conftest.py

             * fixtures defined from test_show_fixtures_with_same_name *
-            arg1
+            arg1 -- test_show_fixtures_with_same_name.py:3
                 Hi from test module
         """
         )
@@ -3526,28 +3622,11 @@


 class TestContextManagerFixtureFuncs:
-    @pytest.fixture(params=["fixture", "yield_fixture"])
-    def flavor(self, request, testdir, monkeypatch):
-        monkeypatch.setenv("PYTEST_FIXTURE_FLAVOR", request.param)
-        testdir.makepyfile(
-            test_context="""
-            import os
-            import pytest
-            import warnings
-            VAR = "PYTEST_FIXTURE_FLAVOR"
-            if VAR not in os.environ:
-                warnings.warn("PYTEST_FIXTURE_FLAVOR was not set, assuming fixture")
-                fixture = pytest.fixture
-            else:
-                fixture = getattr(pytest, os.environ[VAR])
-        """
-        )
-
-    def test_simple(self, testdir, flavor):
-        testdir.makepyfile(
-            """
-            from test_context import fixture
-            @fixture
+    def test_simple(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
+            """
+            import pytest
+            @pytest.fixture
             def arg1():
                 print("setup")
                 yield 1
@@ -3559,7 +3638,7 @@
                 assert 0
         """
         )
-        result = testdir.runpytest("-s")
+        result = pytester.runpytest("-s")
         result.stdout.fnmatch_lines(
             """
             *setup*
@@ -3571,11 +3650,11 @@
         """
         )

-    def test_scoped(self, testdir, flavor):
-        testdir.makepyfile(
-            """
-            from test_context import fixture
-            @fixture(scope="module")
+    def test_scoped(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
+            """
+            import pytest
+            @pytest.fixture(scope="module")
             def arg1():
                 print("setup")
                 yield 1
@@ -3586,7 +3665,7 @@
                 print("test2", arg1)
         """
         )
-        result = testdir.runpytest("-s")
+        result = pytester.runpytest("-s")
         result.stdout.fnmatch_lines(
             """
             *setup*
@@ -3596,11 +3675,11 @@
         """
         )

-    def test_setup_exception(self, testdir, flavor):
-        testdir.makepyfile(
-            """
-            from test_context import fixture
-            @fixture(scope="module")
+    def test_setup_exception(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
+            """
+            import pytest
+            @pytest.fixture(scope="module")
             def arg1():
                 pytest.fail("setup")
                 yield 1
@@ -3608,7 +3687,7 @@
                 pass
         """
         )
-        result = testdir.runpytest("-s")
+        result = pytester.runpytest("-s")
         result.stdout.fnmatch_lines(
             """
             *pytest.fail*setup*
@@ -3616,11 +3695,11 @@
         """
         )

-    def test_teardown_exception(self, testdir, flavor):
-        testdir.makepyfile(
-            """
-            from test_context import fixture
-            @fixture(scope="module")
+    def test_teardown_exception(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
+            """
+            import pytest
+            @pytest.fixture(scope="module")
             def arg1():
                 yield 1
                 pytest.fail("teardown")
@@ -3628,7 +3707,7 @@
                 pass
         """
         )
-        result = testdir.runpytest("-s")
+        result = pytester.runpytest("-s")
         result.stdout.fnmatch_lines(
             """
             *pytest.fail*teardown*
@@ -3636,11 +3715,11 @@
         """
         )

-    def test_yields_more_than_one(self, testdir, flavor):
-        testdir.makepyfile(
-            """
-            from test_context import fixture
-            @fixture(scope="module")
+    def test_yields_more_than_one(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
+            """
+            import pytest
+            @pytest.fixture(scope="module")
             def arg1():
                 yield 1
                 yield 2
@@ -3648,7 +3727,7 @@
                 pass
         """
         )
-        result = testdir.runpytest("-s")
+        result = pytester.runpytest("-s")
         result.stdout.fnmatch_lines(
             """
             *fixture function*
@@ -3656,24 +3735,24 @@
         """
         )

-    def test_custom_name(self, testdir, flavor):
-        testdir.makepyfile(
-            """
-            from test_context import fixture
-            @fixture(name='meow')
+    def test_custom_name(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
+            """
+            import pytest
+            @pytest.fixture(name='meow')
             def arg1():
                 return 'mew'
             def test_1(meow):
                 print(meow)
         """
         )
-        result = testdir.runpytest("-s")
+        result = pytester.runpytest("-s")
         result.stdout.fnmatch_lines(["*mew*"])


 class TestParameterizedSubRequest:
-    def test_call_from_fixture(self, testdir):
-        testdir.makepyfile(
+    def test_call_from_fixture(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             test_call_from_fixture="""
             import pytest

@@ -3689,7 +3768,7 @@
                 pass
             """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             [
                 "The requested fixture has no parameter defined for test:",
@@ -3702,8 +3781,8 @@
             ]
         )

-    def test_call_from_test(self, testdir):
-        testdir.makepyfile(
+    def test_call_from_test(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             test_call_from_test="""
             import pytest

@@ -3715,7 +3794,7 @@
                 request.getfixturevalue('fix_with_param')
             """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             [
                 "The requested fixture has no parameter defined for test:",
@@ -3728,8 +3807,8 @@
             ]
         )

-    def test_external_fixture(self, testdir):
-        testdir.makeconftest(
+    def test_external_fixture(self, pytester: Pytester) -> None:
+        pytester.makeconftest(
             """
             import pytest

@@ -3739,13 +3818,13 @@
             """
         )

-        testdir.makepyfile(
+        pytester.makepyfile(
             test_external_fixture="""
             def test_foo(request):
                 request.getfixturevalue('fix_with_param')
             """
         )
-        result = testdir.runpytest()
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             [
                 "The requested fixture has no parameter defined for test:",
@@ -3759,11 +3838,11 @@
             ]
         )

-    def test_non_relative_path(self, testdir):
-        tests_dir = testdir.mkdir("tests")
-        fixdir = testdir.mkdir("fixtures")
-        fixfile = fixdir.join("fix.py")
-        fixfile.write(
+    def test_non_relative_path(self, pytester: Pytester) -> None:
+        tests_dir = pytester.mkdir("tests")
+        fixdir = pytester.mkdir("fixtures")
+        fixfile = fixdir.joinpath("fix.py")
+        fixfile.write_text(
             textwrap.dedent(
                 """\
                 import pytest
@@ -3775,8 +3854,8 @@
             )
         )

-        testfile = tests_dir.join("test_foos.py")
-        testfile.write(
+        testfile = tests_dir.joinpath("test_foos.py")
+        testfile.write_text(
             textwrap.dedent(
                 """\
                 from fix import fix_with_param
@@ -3787,16 +3866,16 @@
             )
         )

-        tests_dir.chdir()
-        testdir.syspathinsert(fixdir)
-        result = testdir.runpytest()
+        os.chdir(tests_dir)
+        pytester.syspathinsert(fixdir)
+        result = pytester.runpytest()
         result.stdout.fnmatch_lines(
             [
                 "The requested fixture has no parameter defined for test:",
                 "    test_foos.py::test_foo",
                 "",
                 "Requested fixture 'fix_with_param' defined in:",
-                "{}:4".format(fixfile),
+                f"{fixfile}:4",
                 "Requested here:",
                 "test_foos.py:4",
                 "*1 failed*",
@@ -3804,25 +3883,25 @@
         )

         # With non-overlapping rootdir, passing tests_dir.
-        rootdir = testdir.mkdir("rootdir")
-        rootdir.chdir()
-        result = testdir.runpytest("--rootdir", rootdir, tests_dir)
+        rootdir = pytester.mkdir("rootdir")
+        os.chdir(rootdir)
+        result = pytester.runpytest("--rootdir", rootdir, tests_dir)
         result.stdout.fnmatch_lines(
             [
                 "The requested fixture has no parameter defined for test:",
                 "    test_foos.py::test_foo",
                 "",
                 "Requested fixture 'fix_with_param' defined in:",
-                "{}:4".format(fixfile),
+                f"{fixfile}:4",
                 "Requested here:",
-                "{}:4".format(testfile),
+                f"{testfile}:4",
                 "*1 failed*",
             ]
         )


-def test_pytest_fixture_setup_and_post_finalizer_hook(testdir):
-    testdir.makeconftest(
+def test_pytest_fixture_setup_and_post_finalizer_hook(pytester: Pytester) -> None:
+    pytester.makeconftest(
         """
         def pytest_fixture_setup(fixturedef, request):
             print('ROOT setup hook called for {0} from {1}'.format(fixturedef.argname, request.node.name))
@@ -3830,7 +3909,7 @@
             print('ROOT finalizer hook called for {0} from {1}'.format(fixturedef.argname, request.node.name))
     """
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         **{
             "tests/conftest.py": """
             def pytest_fixture_setup(fixturedef, request):
@@ -3851,7 +3930,7 @@
         """,
         }
     )
-    result = testdir.runpytest("-s")
+    result = pytester.runpytest("-s")
     assert result.ret == 0
     result.stdout.fnmatch_lines(
         [
@@ -3868,10 +3947,12 @@
     """Class of tests that ensure fixtures are ordered based on their scopes (#2405)"""

     @pytest.mark.parametrize("variant", ["mark", "autouse"])
-    def test_func_closure_module_auto(self, testdir, variant, monkeypatch):
+    def test_func_closure_module_auto(
+        self, pytester: Pytester, variant, monkeypatch
+    ) -> None:
         """Semantically identical to the example posted in #2405 when ``use_mark=True``"""
         monkeypatch.setenv("FIXTURE_ACTIVATION_VARIANT", variant)
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import warnings
             import os
@@ -3897,16 +3978,18 @@
                 pass
         """
         )
-        items, _ = testdir.inline_genitems()
-        request = FixtureRequest(items[0])
+        items, _ = pytester.inline_genitems()
+        request = FixtureRequest(items[0], _ispytest=True)
         assert request.fixturenames == "m1 f1".split()

-    def test_func_closure_with_native_fixtures(self, testdir, monkeypatch) -> None:
+    def test_func_closure_with_native_fixtures(
+        self, pytester: Pytester, monkeypatch: MonkeyPatch
+    ) -> None:
         """Sanity check that verifies the order returned by the closures and the actual fixture execution order:
         The execution order may differ because of fixture inter-dependencies.
         """
         monkeypatch.setattr(pytest, "FIXTURE_ORDER", [], raising=False)
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -3925,15 +4008,15 @@
                 FIXTURE_ORDER.append('m1')

             @pytest.fixture(scope='session')
-            def my_tmpdir_factory():
-                FIXTURE_ORDER.append('my_tmpdir_factory')
-
-            @pytest.fixture
-            def my_tmpdir(my_tmpdir_factory):
-                FIXTURE_ORDER.append('my_tmpdir')
-
-            @pytest.fixture
-            def f1(my_tmpdir):
+            def my_tmp_path_factory():
+                FIXTURE_ORDER.append('my_tmp_path_factory')
+
+            @pytest.fixture
+            def my_tmp_path(my_tmp_path_factory):
+                FIXTURE_ORDER.append('my_tmp_path')
+
+            @pytest.fixture
+            def f1(my_tmp_path):
                 FIXTURE_ORDER.append('f1')

             @pytest.fixture
@@ -3943,19 +4026,20 @@
             def test_foo(f1, p1, m1, f2, s1): pass
         """
         )
-        items, _ = testdir.inline_genitems()
-        request = FixtureRequest(items[0])
+        items, _ = pytester.inline_genitems()
+        request = FixtureRequest(items[0], _ispytest=True)
         # order of fixtures based on their scope and position in the parameter list
         assert (
-            request.fixturenames == "s1 my_tmpdir_factory p1 m1 f1 f2 my_tmpdir".split()
-        )
-        testdir.runpytest()
-        # actual fixture execution differs: dependent fixtures must be created first ("my_tmpdir")
+            request.fixturenames
+            == "s1 my_tmp_path_factory p1 m1 f1 f2 my_tmp_path".split()
+        )
+        pytester.runpytest()
+        # actual fixture execution differs: dependent fixtures must be created first ("my_tmp_path")
         FIXTURE_ORDER = pytest.FIXTURE_ORDER  # type: ignore[attr-defined]
-        assert FIXTURE_ORDER == "s1 my_tmpdir_factory p1 m1 my_tmpdir f1 f2".split()
-
-    def test_func_closure_module(self, testdir):
-        testdir.makepyfile(
+        assert FIXTURE_ORDER == "s1 my_tmp_path_factory p1 m1 my_tmp_path f1 f2".split()
+
+    def test_func_closure_module(self, pytester: Pytester) -> None:
+        pytester.makepyfile(
             """
             import pytest

@@ -3969,15 +4053,15 @@
                 pass
         """
         )
-        items, _ = testdir.inline_genitems()
-        request = FixtureRequest(items[0])
+        items, _ = pytester.inline_genitems()
+        request = FixtureRequest(items[0], _ispytest=True)
         assert request.fixturenames == "m1 f1".split()

-    def test_func_closure_scopes_reordered(self, testdir):
+    def test_func_closure_scopes_reordered(self, pytester: Pytester) -> None:
         """Test ensures that fixtures are ordered by scope regardless of the order of the parameters, although
         fixtures of same scope keep the declared order
         """
-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             import pytest

@@ -4002,13 +4086,15 @@
                     pass
         """
         )
-        items, _ = testdir.inline_genitems()
-        request = FixtureRequest(items[0])
+        items, _ = pytester.inline_genitems()
+        request = FixtureRequest(items[0], _ispytest=True)
         assert request.fixturenames == "s1 m1 c1 f2 f1".split()

-    def test_func_closure_same_scope_closer_root_first(self, testdir):
+    def test_func_closure_same_scope_closer_root_first(
+        self, pytester: Pytester
+    ) -> None:
         """Auto-use fixtures of same scope are ordered by closer-to-root first"""
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest

@@ -4016,7 +4102,7 @@
             def m_conf(): pass
         """
         )
-        testdir.makepyfile(
+        pytester.makepyfile(
             **{
                 "sub/conftest.py": """
                 import pytest
@@ -4042,13 +4128,13 @@
         """,
             }
         )
-        items, _ = testdir.inline_genitems()
-        request = FixtureRequest(items[0])
+        items, _ = pytester.inline_genitems()
+        request = FixtureRequest(items[0], _ispytest=True)
         assert request.fixturenames == "p_sub m_conf m_sub m_test f1".split()

-    def test_func_closure_all_scopes_complex(self, testdir):
+    def test_func_closure_all_scopes_complex(self, pytester: Pytester) -> None:
         """Complex test involving all scopes and mixing autouse with normal fixtures"""
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest

@@ -4059,8 +4145,8 @@
             def p1(): pass
         """
         )
-        testdir.makepyfile(**{"__init__.py": ""})
-        testdir.makepyfile(
+        pytester.makepyfile(**{"__init__.py": ""})
+        pytester.makepyfile(
             """
             import pytest

@@ -4086,11 +4172,11 @@
                     pass
         """
         )
-        items, _ = testdir.inline_genitems()
-        request = FixtureRequest(items[0])
+        items, _ = pytester.inline_genitems()
+        request = FixtureRequest(items[0], _ispytest=True)
         assert request.fixturenames == "s1 p1 m1 m2 c1 f2 f1".split()

-    def test_multiple_packages(self, testdir):
+    def test_multiple_packages(self, pytester: Pytester) -> None:
         """Complex test involving multiple package fixtures. Make sure teardowns
         are executed in order.
         .
@@ -4105,11 +4191,12 @@
                 ├── conftest.py
                 └── test_2.py
         """
-        root = testdir.mkdir("root")
-        root.join("__init__.py").write("values = []")
-        sub1 = root.mkdir("sub1")
-        sub1.ensure("__init__.py")
-        sub1.join("conftest.py").write(
+        root = pytester.mkdir("root")
+        root.joinpath("__init__.py").write_text("values = []")
+        sub1 = root.joinpath("sub1")
+        sub1.mkdir()
+        sub1.joinpath("__init__.py").touch()
+        sub1.joinpath("conftest.py").write_text(
             textwrap.dedent(
                 """\
             import pytest
@@ -4122,7 +4209,7 @@
         """
             )
         )
-        sub1.join("test_1.py").write(
+        sub1.joinpath("test_1.py").write_text(
             textwrap.dedent(
                 """\
             from .. import values
@@ -4131,9 +4218,10 @@
         """
             )
         )
-        sub2 = root.mkdir("sub2")
-        sub2.ensure("__init__.py")
-        sub2.join("conftest.py").write(
+        sub2 = root.joinpath("sub2")
+        sub2.mkdir()
+        sub2.joinpath("__init__.py").touch()
+        sub2.joinpath("conftest.py").write_text(
             textwrap.dedent(
                 """\
             import pytest
@@ -4146,7 +4234,7 @@
         """
             )
         )
-        sub2.join("test_2.py").write(
+        sub2.joinpath("test_2.py").write_text(
             textwrap.dedent(
                 """\
             from .. import values
@@ -4155,14 +4243,14 @@
         """
             )
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=2)

-    def test_class_fixture_self_instance(self, testdir):
+    def test_class_fixture_self_instance(self, pytester: Pytester) -> None:
         """Check that plugin classes which implement fixtures receive the plugin instance
         as self (see #2270).
         """
-        testdir.makeconftest(
+        pytester.makeconftest(
             """
             import pytest

@@ -4180,14 +4268,14 @@
         """
         )

-        testdir.makepyfile(
+        pytester.makepyfile(
             """
             class TestClass(object):
                 def test_1(self, myfix):
                     assert myfix == 1
         """
         )
-        reprec = testdir.inline_run()
+        reprec = pytester.inline_run()
         reprec.assertoutcome(passed=1)


@@ -4202,9 +4290,9 @@
         assert fix() == 1


-def test_fixture_param_shadowing(testdir):
+def test_fixture_param_shadowing(pytester: Pytester) -> None:
     """Parametrized arguments would be shadowed if a fixture with the same name also exists (#5036)"""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest

@@ -4237,7 +4325,7 @@
     """
     )
     # Only one test should have run
-    result = testdir.runpytest("-v")
+    result = pytester.runpytest("-v")
     result.assert_outcomes(passed=4)
     result.stdout.fnmatch_lines(["*::test_direct[[]1[]]*"])
     result.stdout.fnmatch_lines(["*::test_normal_fixture[[]a[]]*"])
@@ -4245,9 +4333,9 @@
     result.stdout.fnmatch_lines(["*::test_indirect[[]1[]]*"])


-def test_fixture_named_request(testdir):
-    testdir.copy_example("fixtures/test_fixture_named_request.py")
-    result = testdir.runpytest()
+def test_fixture_named_request(pytester: Pytester) -> None:
+    pytester.copy_example("fixtures/test_fixture_named_request.py")
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         [
             "*'request' is a reserved word for fixtures, use another name:",
@@ -4256,9 +4344,9 @@
     )


-def test_indirect_fixture_does_not_break_scope(testdir):
+def test_indirect_fixture_does_not_break_scope(pytester: Pytester) -> None:
     """Ensure that fixture scope is respected when using indirect fixtures (#570)"""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         instantiated  = []
@@ -4303,14 +4391,14 @@
             ]
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.assert_outcomes(passed=7)


-def test_fixture_parametrization_nparray(testdir):
+def test_fixture_parametrization_nparray(pytester: Pytester) -> None:
     pytest.importorskip("numpy")

-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         from numpy import linspace
         from pytest import fixture
@@ -4323,18 +4411,18 @@
             assert value == value
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.assert_outcomes(passed=10)


-def test_fixture_arg_ordering(testdir):
+def test_fixture_arg_ordering(pytester: Pytester) -> None:
     """
     This test describes how fixtures in the same scope but without explicit dependencies
     between them are created. While users should make dependencies explicit, often
     they rely on this order, so this test exists to catch regressions in this regard.
     See #6540 and #6492.
     """
-    p1 = testdir.makepyfile(
+    p1 = pytester.makepyfile(
         """
         import pytest

@@ -4358,12 +4446,12 @@
             assert suffixes == ["fix_1", "fix_2", "fix_3", "fix_4", "fix_5"]
         """
     )
-    result = testdir.runpytest("-vv", str(p1))
+    result = pytester.runpytest("-vv", str(p1))
     assert result.ret == 0


-def test_yield_fixture_with_no_value(testdir):
-    testdir.makepyfile(
+def test_yield_fixture_with_no_value(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import pytest
         @pytest.fixture(name='custom')
@@ -4376,7 +4464,7 @@
         """
     )
     expected = "E               ValueError: custom did not yield a value"
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.assert_outcomes(errors=1)
     result.stdout.fnmatch_lines([expected])
     assert result.ret == ExitCode.TESTS_FAILED
('testing/io', 'test_saferepr.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,5 +1,6 @@
 import pytest
 from _pytest._io.saferepr import _pformat_dispatch
+from _pytest._io.saferepr import DEFAULT_REPR_MAX_SIZE
 from _pytest._io.saferepr import saferepr


@@ -12,6 +13,13 @@
     s = saferepr("x" * 50, maxsize=25)
     assert len(s) == 25
     expected = repr("x" * 10 + "..." + "x" * 10)
+    assert s == expected
+
+
+def test_no_maxsize():
+    text = "x" * DEFAULT_REPR_MAX_SIZE * 10
+    s = saferepr(text, maxsize=None)
+    expected = repr(text)
     assert s == expected


('testing/io', 'test_terminalwriter.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -3,6 +3,7 @@
 import re
 import shutil
 import sys
+from pathlib import Path
 from typing import Generator
 from unittest import mock

@@ -55,7 +56,7 @@
     file = io.TextIOWrapper(buffer, encoding="cp1252")
     tw = terminalwriter.TerminalWriter(file)
     tw.write("hello 🌀 wôrld אבג", flush=True)
-    assert buffer.getvalue() == br"hello \U0001f300 w\xf4rld \u05d0\u05d1\u05d2"
+    assert buffer.getvalue() == rb"hello \U0001f300 w\xf4rld \u05d0\u05d1\u05d2"


 win32 = int(sys.platform == "win32")
@@ -64,10 +65,10 @@
 class TestTerminalWriter:
     @pytest.fixture(params=["path", "stringio"])
     def tw(
-        self, request, tmpdir
+        self, request, tmp_path: Path
     ) -> Generator[terminalwriter.TerminalWriter, None, None]:
         if request.param == "path":
-            p = tmpdir.join("tmpfile")
+            p = tmp_path.joinpath("tmpfile")
             f = open(str(p), "w+", encoding="utf8")
             tw = terminalwriter.TerminalWriter(f)

@@ -257,13 +258,22 @@
             id="with markup and code_highlight",
         ),
         pytest.param(
-            True, False, "assert 0\n", id="with markup but no code_highlight",
-        ),
-        pytest.param(
-            False, True, "assert 0\n", id="without markup but with code_highlight",
-        ),
-        pytest.param(
-            False, False, "assert 0\n", id="neither markup nor code_highlight",
+            True,
+            False,
+            "assert 0\n",
+            id="with markup but no code_highlight",
+        ),
+        pytest.param(
+            False,
+            True,
+            "assert 0\n",
+            id="without markup but with code_highlight",
+        ),
+        pytest.param(
+            False,
+            False,
+            "assert 0\n",
+            id="neither markup nor code_highlight",
         ),
     ],
 )
('testing/code', 'test_excinfo.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,15 +1,15 @@
+import importlib
 import io
 import operator
-import os
 import queue
 import sys
 import textwrap
+from pathlib import Path
 from typing import Any
 from typing import Dict
 from typing import Tuple
+from typing import TYPE_CHECKING
 from typing import Union
-
-import py

 import _pytest
 import pytest
@@ -17,15 +17,12 @@
 from _pytest._code.code import ExceptionInfo
 from _pytest._code.code import FormattedExcinfo
 from _pytest._io import TerminalWriter
-from _pytest.compat import TYPE_CHECKING
+from _pytest.monkeypatch import MonkeyPatch
+from _pytest.pathlib import bestrelpath
+from _pytest.pathlib import import_path
 from _pytest.pytester import LineMatcher
-
-try:
-    import importlib
-except ImportError:
-    invalidate_import_caches = None
-else:
-    invalidate_import_caches = getattr(importlib, "invalidate_caches", None)
+from _pytest.pytester import Pytester
+

 if TYPE_CHECKING:
     from _pytest._code.code import _TracebackStyle
@@ -152,24 +149,25 @@
             "    except somenoname:  # type: ignore[name-defined] # noqa: F821",
         ]

-    def test_traceback_cut(self):
-        co = _pytest._code.Code(f)
+    def test_traceback_cut(self) -> None:
+        co = _pytest._code.Code.from_function(f)
         path, firstlineno = co.path, co.firstlineno
+        assert isinstance(path, Path)
         traceback = self.excinfo.traceback
         newtraceback = traceback.cut(path=path, firstlineno=firstlineno)
         assert len(newtraceback) == 1
         newtraceback = traceback.cut(path=path, lineno=firstlineno + 2)
         assert len(newtraceback) == 1

-    def test_traceback_cut_excludepath(self, testdir):
-        p = testdir.makepyfile("def f(): raise ValueError")
+    def test_traceback_cut_excludepath(self, pytester: Pytester) -> None:
+        p = pytester.makepyfile("def f(): raise ValueError")
         with pytest.raises(ValueError) as excinfo:
-            p.pyimport().f()
-        basedir = py.path.local(pytest.__file__).dirpath()
+            import_path(p, root=pytester.path).f()  # type: ignore[attr-defined]
+        basedir = Path(pytest.__file__).parent
         newtraceback = excinfo.traceback.cut(excludepath=basedir)
         for x in newtraceback:
-            if hasattr(x, "path"):
-                assert not py.path.local(x.path).relto(basedir)
+            assert isinstance(x.path, Path)
+            assert basedir not in x.path.parents
         assert newtraceback[-1].frame.code.path == p

     def test_traceback_filter(self):
@@ -206,8 +204,8 @@
         excinfo = pytest.raises(ValueError, h)
         traceback = excinfo.traceback
         ntraceback = traceback.filter()
-        print("old: {!r}".format(traceback))
-        print("new: {!r}".format(ntraceback))
+        print(f"old: {traceback!r}")
+        print(f"new: {ntraceback!r}")

         if matching:
             assert len(ntraceback) == len(traceback) - 2
@@ -265,7 +263,7 @@
         decorator = pytest.importorskip("decorator").decorator

         def log(f, *k, **kw):
-            print("{} {}".format(k, kw))
+            print(f"{k} {kw}")
             f(*k, **kw)

         log = decorator(log)
@@ -296,7 +294,7 @@
         excinfo = pytest.raises(ValueError, f)
         tb = excinfo.traceback
         entry = tb.getcrashentry()
-        co = _pytest._code.Code(h)
+        co = _pytest._code.Code.from_function(h)
         assert entry.frame.code.path == co.path
         assert entry.lineno == co.firstlineno + 1
         assert entry.frame.code.name == "h"
@@ -313,7 +311,7 @@
         excinfo = pytest.raises(ValueError, f)
         tb = excinfo.traceback
         entry = tb.getcrashentry()
-        co = _pytest._code.Code(g)
+        co = _pytest._code.Code.from_function(g)
         assert entry.frame.code.path == co.path
         assert entry.lineno == co.firstlineno + 2
         assert entry.frame.code.name == "g"
@@ -366,19 +364,19 @@
     assert s == "  File '<string>':1 in <module>\n  ???\n"


-def test_excinfo_no_python_sourcecode(tmpdir):
+def test_excinfo_no_python_sourcecode(tmp_path: Path) -> None:
     # XXX: simplified locally testable version
-    tmpdir.join("test.txt").write("{{ h()}}:")
+    tmp_path.joinpath("test.txt").write_text("{{ h()}}:")

     jinja2 = pytest.importorskip("jinja2")
-    loader = jinja2.FileSystemLoader(str(tmpdir))
+    loader = jinja2.FileSystemLoader(str(tmp_path))
     env = jinja2.Environment(loader=loader)
     template = env.get_template("test.txt")
     excinfo = pytest.raises(ValueError, template.render, h=h)
     for item in excinfo.traceback:
         print(item)  # XXX: for some reason jinja.Template.render is printed in full
         item.source  # shouldn't fail
-        if isinstance(item.path, py.path.local) and item.path.basename == "test.txt":
+        if isinstance(item.path, Path) and item.path.name == "test.txt":
             assert str(item.source) == "{{ h()}}:"


@@ -394,16 +392,16 @@
     assert s.startswith("def get")


-def test_codepath_Queue_example():
+def test_codepath_Queue_example() -> None:
     try:
         queue.Queue().get(timeout=0.001)
     except queue.Empty:
         excinfo = _pytest._code.ExceptionInfo.from_current()
     entry = excinfo.traceback[-1]
     path = entry.path
-    assert isinstance(path, py.path.local)
-    assert path.basename.lower() == "queue.py"
-    assert path.check()
+    assert isinstance(path, Path)
+    assert path.name.lower() == "queue.py"
+    assert path.exists()


 def test_match_succeeds():
@@ -412,8 +410,8 @@
     excinfo.match(r".*zero.*")


-def test_match_raises_error(testdir):
-    testdir.makepyfile(
+def test_match_raises_error(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import pytest
         def test_division_zero():
@@ -422,32 +420,30 @@
             excinfo.match(r'[123]+')
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert result.ret != 0

     exc_msg = "Regex pattern '[[]123[]]+' does not match 'division by zero'."
-    result.stdout.fnmatch_lines(["E * AssertionError: {}".format(exc_msg)])
+    result.stdout.fnmatch_lines([f"E * AssertionError: {exc_msg}"])
     result.stdout.no_fnmatch_line("*__tracebackhide__ = True*")

-    result = testdir.runpytest("--fulltrace")
+    result = pytester.runpytest("--fulltrace")
     assert result.ret != 0
     result.stdout.fnmatch_lines(
-        ["*__tracebackhide__ = True*", "E * AssertionError: {}".format(exc_msg)]
+        ["*__tracebackhide__ = True*", f"E * AssertionError: {exc_msg}"]
     )


 class TestFormattedExcinfo:
     @pytest.fixture
-    def importasmod(self, request, _sys_snapshot):
+    def importasmod(self, tmp_path: Path, _sys_snapshot):
         def importasmod(source):
             source = textwrap.dedent(source)
-            tmpdir = request.getfixturevalue("tmpdir")
-            modpath = tmpdir.join("mod.py")
-            tmpdir.ensure("__init__.py")
-            modpath.write(source)
-            if invalidate_import_caches is not None:
-                invalidate_import_caches()
-            return modpath.pyimport()
+            modpath = tmp_path.joinpath("mod.py")
+            tmp_path.joinpath("__init__.py").touch()
+            modpath.write_text(source)
+            importlib.invalidate_caches()
+            return import_path(modpath, root=tmp_path)

         return importasmod

@@ -459,7 +455,7 @@
                 pass
             """
         ).strip()
-        pr.flow_marker = "|"
+        pr.flow_marker = "|"  # type: ignore[misc]
         lines = pr.get_source(source, 0)
         assert len(lines) == 2
         assert lines[0] == "|   def f(x):"
@@ -689,7 +685,7 @@
         p = FormattedExcinfo(style="short")
         reprtb = p.repr_traceback_entry(excinfo.traceback[-2])
         lines = reprtb.lines
-        basename = py.path.local(mod.__file__).basename
+        basename = Path(mod.__file__).name
         assert lines[0] == "    func1()"
         assert reprtb.reprfileloc is not None
         assert basename in str(reprtb.reprfileloc.path)
@@ -754,7 +750,6 @@
         from _pytest._code.code import Code

         monkeypatch.setattr(Code, "path", "bogus")
-        excinfo.traceback[0].frame.code.path = "bogus"  # type: ignore[misc]
         p = FormattedExcinfo(style="short")
         reprtb = p.repr_traceback_entry(excinfo.traceback[-2])
         lines = reprtb.lines
@@ -778,7 +773,7 @@
         )
         excinfo = pytest.raises(ValueError, mod.entry)

-        styles = ("long", "short")  # type: Tuple[_TracebackStyle, ...]
+        styles: Tuple[_TracebackStyle, ...] = ("long", "short")
         for style in styles:
             p = FormattedExcinfo(style=style)
             reprtb = p.repr_traceback(excinfo)
@@ -810,21 +805,21 @@

         raised = 0

-        orig_getcwd = os.getcwd
+        orig_path_cwd = Path.cwd

         def raiseos():
             nonlocal raised
             upframe = sys._getframe().f_back
             assert upframe is not None
-            if upframe.f_code.co_name == "checked_call":
+            if upframe.f_code.co_name == "_makepath":
                 # Only raise with expected calls, but not via e.g. inspect for
                 # py38-windows.
                 raised += 1
                 raise OSError(2, "custom_oserror")
-            return orig_getcwd()
-
-        monkeypatch.setattr(os, "getcwd", raiseos)
-        assert p._makepath(__file__) == __file__
+            return orig_path_cwd()
+
+        monkeypatch.setattr(Path, "cwd", raiseos)
+        assert p._makepath(Path(__file__)) == __file__
         assert raised == 1
         repr_tb = p.repr_traceback(excinfo)

@@ -834,14 +829,14 @@
                 "def entry():",
                 ">       f(0)",
                 "",
-                "{}:5: ".format(mod.__file__),
+                f"{mod.__file__}:5: ",
                 "_ _ *",
                 "",
                 "    def f(x):",
                 ">       raise ValueError(x)",
                 "E       ValueError: 0",
                 "",
-                "{}:3: ValueError".format(mod.__file__),
+                f"{mod.__file__}:3: ValueError",
             ]
         )
         assert raised == 3
@@ -905,7 +900,7 @@
         )
         excinfo = pytest.raises(ValueError, mod.entry)

-        styles = ("short", "long", "no")  # type: Tuple[_TracebackStyle, ...]
+        styles: Tuple[_TracebackStyle, ...] = ("short", "long", "no")
         for style in styles:
             for showlocals in (True, False):
                 repr = excinfo.getrepr(style=style, showlocals=showlocals)
@@ -956,7 +951,9 @@
         assert line.endswith("mod.py")
         assert tw_mock.lines[12] == ":3: ValueError"

-    def test_toterminal_long_missing_source(self, importasmod, tmpdir, tw_mock):
+    def test_toterminal_long_missing_source(
+        self, importasmod, tmp_path: Path, tw_mock
+    ) -> None:
         mod = importasmod(
             """
             def g(x):
@@ -966,7 +963,7 @@
         """
         )
         excinfo = pytest.raises(ValueError, mod.f)
-        tmpdir.join("mod.py").remove()
+        tmp_path.joinpath("mod.py").unlink()
         excinfo.traceback = excinfo.traceback.filter()
         repr = excinfo.getrepr()
         repr.toterminal(tw_mock)
@@ -986,7 +983,9 @@
         assert line.endswith("mod.py")
         assert tw_mock.lines[10] == ":3: ValueError"

-    def test_toterminal_long_incomplete_source(self, importasmod, tmpdir, tw_mock):
+    def test_toterminal_long_incomplete_source(
+        self, importasmod, tmp_path: Path, tw_mock
+    ) -> None:
         mod = importasmod(
             """
             def g(x):
@@ -996,7 +995,7 @@
         """
         )
         excinfo = pytest.raises(ValueError, mod.f)
-        tmpdir.join("mod.py").write("asdf")
+        tmp_path.joinpath("mod.py").write_text("asdf")
         excinfo.traceback = excinfo.traceback.filter()
         repr = excinfo.getrepr()
         repr.toterminal(tw_mock)
@@ -1016,7 +1015,9 @@
         assert line.endswith("mod.py")
         assert tw_mock.lines[10] == ":3: ValueError"

-    def test_toterminal_long_filenames(self, importasmod, tw_mock):
+    def test_toterminal_long_filenames(
+        self, importasmod, tw_mock, monkeypatch: MonkeyPatch
+    ) -> None:
         mod = importasmod(
             """
             def f():
@@ -1024,25 +1025,22 @@
         """
         )
         excinfo = pytest.raises(ValueError, mod.f)
-        path = py.path.local(mod.__file__)
-        old = path.dirpath().chdir()
-        try:
-            repr = excinfo.getrepr(abspath=False)
-            repr.toterminal(tw_mock)
-            x = py.path.local().bestrelpath(path)
-            if len(x) < len(str(path)):
-                msg = tw_mock.get_write_msg(-2)
-                assert msg == "mod.py"
-                assert tw_mock.lines[-1] == ":3: ValueError"
-
-            repr = excinfo.getrepr(abspath=True)
-            repr.toterminal(tw_mock)
+        path = Path(mod.__file__)
+        monkeypatch.chdir(path.parent)
+        repr = excinfo.getrepr(abspath=False)
+        repr.toterminal(tw_mock)
+        x = bestrelpath(Path.cwd(), path)
+        if len(x) < len(str(path)):
             msg = tw_mock.get_write_msg(-2)
-            assert msg == path
-            line = tw_mock.lines[-1]
-            assert line == ":3: ValueError"
-        finally:
-            old.chdir()
+            assert msg == "mod.py"
+            assert tw_mock.lines[-1] == ":3: ValueError"
+
+        repr = excinfo.getrepr(abspath=True)
+        repr.toterminal(tw_mock)
+        msg = tw_mock.get_write_msg(-2)
+        assert msg == str(path)
+        line = tw_mock.lines[-1]
+        assert line == ":3: ValueError"

     @pytest.mark.parametrize(
         "reproptions",
@@ -1370,7 +1368,7 @@
 @pytest.mark.parametrize("encoding", [None, "utf8", "utf16"])
 def test_repr_traceback_with_unicode(style, encoding):
     if encoding is None:
-        msg = "☹"  # type: Union[str, bytes]
+        msg: Union[str, bytes] = "☹"
     else:
         msg = "☹".encode(encoding)
     try:
@@ -1382,16 +1380,41 @@
     assert repr_traceback is not None


-def test_cwd_deleted(testdir):
-    testdir.makepyfile(
-        """
-        def test(tmpdir):
-            tmpdir.chdir()
-            tmpdir.remove()
+def test_cwd_deleted(pytester: Pytester) -> None:
+    pytester.makepyfile(
+        """
+        import os
+
+        def test(tmp_path):
+            os.chdir(tmp_path)
+            tmp_path.unlink()
             assert False
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
+    result.stdout.fnmatch_lines(["* 1 failed in *"])
+    result.stdout.no_fnmatch_line("*INTERNALERROR*")
+    result.stderr.no_fnmatch_line("*INTERNALERROR*")
+
+
+def test_regression_nagative_line_index(pytester: Pytester) -> None:
+    """
+    With Python 3.10 alphas, there was an INTERNALERROR reported in
+    https://github.com/pytest-dev/pytest/pull/8227
+    This test ensures it does not regress.
+    """
+    pytester.makepyfile(
+        """
+        import ast
+        import pytest
+
+
+        def test_literal_eval():
+            with pytest.raises(ValueError, match="^$"):
+                ast.literal_eval("pytest")
+    """
+    )
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["* 1 failed in *"])
     result.stdout.no_fnmatch_line("*INTERNALERROR*")
     result.stderr.no_fnmatch_line("*INTERNALERROR*")
('testing/code', 'test_code.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -28,11 +28,12 @@
     assert code.fullsource is None


-def test_code_with_class() -> None:
+def test_code_from_function_with_class() -> None:
     class A:
         pass

-    pytest.raises(TypeError, Code, A)
+    with pytest.raises(TypeError):
+        Code.from_function(A)


 def x() -> None:
@@ -40,13 +41,13 @@


 def test_code_fullsource() -> None:
-    code = Code(x)
+    code = Code.from_function(x)
     full = code.fullsource
     assert "test_code_fullsource()" in str(full)


 def test_code_source() -> None:
-    code = Code(x)
+    code = Code.from_function(x)
     src = code.source()
     expected = """def x() -> None:
     raise NotImplementedError()"""
@@ -73,7 +74,7 @@


 def test_code_from_func() -> None:
-    co = Code(test_frame_getsourcelineno_myself)
+    co = Code.from_function(test_frame_getsourcelineno_myself)
     assert co.firstlineno
     assert co.path

@@ -92,25 +93,25 @@
     def f1(x):
         raise NotImplementedError()

-    c1 = Code(f1)
+    c1 = Code.from_function(f1)
     assert c1.getargs(var=True) == ("x",)

     def f2(x, *y):
         raise NotImplementedError()

-    c2 = Code(f2)
+    c2 = Code.from_function(f2)
     assert c2.getargs(var=True) == ("x", "y")

     def f3(x, **z):
         raise NotImplementedError()

-    c3 = Code(f3)
+    c3 = Code.from_function(f3)
     assert c3.getargs(var=True) == ("x", "z")

     def f4(x, *y, **z):
         raise NotImplementedError()

-    c4 = Code(f4)
+    c4 = Code.from_function(f4)
     assert c4.getargs(var=True) == ("x", "y", "z")


('testing/code', 'test_source.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,22 +1,20 @@
 # flake8: noqa
 # disable flake check on this file because some constructs are strange
 # or redundant on purpose and can't be disable on a line-by-line basis
-import ast
 import inspect
 import linecache
 import sys
 import textwrap
-from types import CodeType
+from pathlib import Path
 from typing import Any
 from typing import Dict
-from typing import Optional
-
-import py.path
-
-import _pytest._code
+
 import pytest
+from _pytest._code import Code
+from _pytest._code import Frame
 from _pytest._code import getfslineno
 from _pytest._code import Source
+from _pytest.pathlib import import_path


 def test_source_str_function() -> None:
@@ -35,7 +33,7 @@


 def test_source_from_function() -> None:
-    source = _pytest._code.Source(test_source_str_function)
+    source = Source(test_source_str_function)
     assert str(source).startswith("def test_source_str_function() -> None:")


@@ -44,13 +42,13 @@
         def test_method(self):
             pass

-    source = _pytest._code.Source(TestClass().test_method)
+    source = Source(TestClass().test_method)
     assert source.lines == ["def test_method(self):", "    pass"]


 def test_source_from_lines() -> None:
     lines = ["a \n", "b\n", "c"]
-    source = _pytest._code.Source(lines)
+    source = Source(lines)
     assert source.lines == ["a ", "b", "c"]


@@ -58,7 +56,7 @@
     def f():
         raise NotImplementedError()

-    source = _pytest._code.Source(f)
+    source = Source(f)
     assert str(source).startswith("def f():")


@@ -220,7 +218,7 @@
     class A:
         def __init__(self, *args) -> None:
             frame = sys._getframe(1)
-            self.source = _pytest._code.Frame(frame).statement
+            self.source = Frame(frame).statement

     x = A("x", "y")

@@ -250,8 +248,8 @@
     def g():
         pass  # pragma: no cover

-    f_source = _pytest._code.Source(f)
-    g_source = _pytest._code.Source(g)
+    f_source = Source(f)
+    g_source = Source(g)
     assert str(f_source).strip() == "def f():\n    raise NotImplementedError()"
     assert str(g_source).strip() == "def g():\n    pass  # pragma: no cover"

@@ -268,7 +266,7 @@
     pass
 """
 '''
-    assert str(_pytest._code.Source(f)) == expected.rstrip()
+    assert str(Source(f)) == expected.rstrip()


 def test_deindent() -> None:
@@ -285,19 +283,20 @@
     assert lines == ["def f():", "    def g():", "        pass"]


-def test_source_of_class_at_eof_without_newline(tmpdir, _sys_snapshot) -> None:
+def test_source_of_class_at_eof_without_newline(_sys_snapshot, tmp_path: Path) -> None:
     # this test fails because the implicit inspect.getsource(A) below
     # does not return the "x = 1" last line.
-    source = _pytest._code.Source(
-        """
-        class A(object):
+    source = Source(
+        """
+        class A:
             def method(self):
                 x = 1
     """
     )
-    path = tmpdir.join("a.py")
-    path.write(source)
-    s2 = _pytest._code.Source(tmpdir.join("a.py").pyimport().A)
+    path = tmp_path.joinpath("a.py")
+    path.write_text(str(source))
+    mod: Any = import_path(path, root=tmp_path)
+    s2 = Source(mod.A)
     assert str(source).strip() == str(s2).strip()


@@ -330,14 +329,13 @@
     lines = ["if 1:\n", "    def x():\n", "          pass\n"]
     co = compile("".join(lines), filename, "exec")

-    # Type ignored because linecache.cache is private.
-    monkeypatch.setitem(linecache.cache, filename, (1, None, lines, filename))  # type: ignore[attr-defined]
+    monkeypatch.setitem(linecache.cache, filename, (1, None, lines, filename))

     src, lineno = findsource(co)
     assert src is not None
     assert "if 1:" in str(src)

-    d = {}  # type: Dict[str, Any]
+    d: Dict[str, Any] = {}
     eval(co, d)
     src, lineno = findsource(d["x"])
     assert src is not None
@@ -351,8 +349,8 @@

     fspath, lineno = getfslineno(f)

-    assert isinstance(fspath, py.path.local)
-    assert fspath.basename == "test_source.py"
+    assert isinstance(fspath, Path)
+    assert fspath.name == "test_source.py"
     assert lineno == f.__code__.co_firstlineno - 1  # see findsource

     class A:
@@ -361,8 +359,8 @@
     fspath, lineno = getfslineno(A)

     _, A_lineno = inspect.findsource(A)
-    assert isinstance(fspath, py.path.local)
-    assert fspath.basename == "test_source.py"
+    assert isinstance(fspath, Path)
+    assert fspath.name == "test_source.py"
     assert lineno == A_lineno

     assert getfslineno(3) == ("", -1)
@@ -372,40 +370,32 @@

     B.__name__ = B.__qualname__ = "B2"
     assert getfslineno(B)[1] == -1
-
-    co = compile("...", "", "eval")
-    assert co.co_filename == ""
-
-    if hasattr(sys, "pypy_version_info"):
-        assert getfslineno(co) == ("", -1)
-    else:
-        assert getfslineno(co) == ("", 0)


 def test_code_of_object_instance_with_call() -> None:
     class A:
         pass

-    pytest.raises(TypeError, lambda: _pytest._code.Source(A()))
+    pytest.raises(TypeError, lambda: Source(A()))

     class WithCall:
         def __call__(self) -> None:
             pass

-    code = _pytest._code.Code(WithCall())
+    code = Code.from_function(WithCall())
     assert "pass" in str(code.source())

     class Hello:
         def __call__(self) -> None:
             pass

-    pytest.raises(TypeError, lambda: _pytest._code.Code(Hello))
+    pytest.raises(TypeError, lambda: Code.from_function(Hello))


 def getstatement(lineno: int, source) -> Source:
     from _pytest._code.source import getstatementrange_ast

-    src = _pytest._code.Source(source)
+    src = Source(source)
     ast, start, end = getstatementrange_ast(lineno, src)
     return src[start:end]

@@ -490,7 +480,7 @@

     src = inspect.getsource(deco_fixture)
     assert src == "    @pytest.fixture\n    def deco_fixture():\n        assert False\n"
-    # currenly Source does not unwrap decorators, testing the
+    # currently Source does not unwrap decorators, testing the
     # existing behavior here for explicitness, but perhaps we should revisit/change this
     # in the future
     assert str(Source(deco_fixture)).startswith("@functools.wraps(function)")
@@ -624,6 +614,19 @@
     assert str(source) == "def func(): raise ValueError(42)"


+def test_decorator() -> None:
+    s = """\
+def foo(f):
+    pass
+
+@foo
+def bar():
+    pass
+    """
+    source = getstatement(3, s)
+    assert "@foo" in str(source)
+
+
 def XXX_test_expression_multiline() -> None:
     source = """\
 something
@@ -637,7 +640,7 @@
     class A:
         def __init__(self, *args):
             frame = sys._getframe(1)
-            self.source = _pytest._code.Frame(frame).statement
+            self.source = Frame(frame).statement

     # fmt: off
     x = A('x',
('testing/logging', 'test_fixture.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -2,14 +2,14 @@

 import pytest
 from _pytest.logging import caplog_records_key
-from _pytest.pytester import Testdir
+from _pytest.pytester import Pytester

 logger = logging.getLogger(__name__)
 sublogger = logging.getLogger(__name__ + ".baz")


-def test_fixture_help(testdir):
-    result = testdir.runpytest("--fixtures")
+def test_fixture_help(pytester: Pytester) -> None:
+    result = pytester.runpytest("--fixtures")
     result.stdout.fnmatch_lines(["*caplog*"])


@@ -28,12 +28,12 @@
     assert "CRITICAL" in caplog.text


-def test_change_level_undo(testdir: Testdir) -> None:
+def test_change_level_undo(pytester: Pytester) -> None:
     """Ensure that 'set_level' is undone after the end of the test.

     Tests the logging output themselves (affacted both by logger and handler levels).
     """
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import logging

@@ -49,17 +49,17 @@
             assert 0
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*log from test1*", "*2 failed in *"])
     result.stdout.no_fnmatch_line("*log from test2*")


-def test_change_level_undos_handler_level(testdir: Testdir) -> None:
+def test_change_level_undos_handler_level(pytester: Pytester) -> None:
     """Ensure that 'set_level' is undone after the end of the test (handler).

     Issue #7569. Tests the handler level specifically.
     """
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import logging

@@ -78,7 +78,7 @@
             assert caplog.handler.level == 43
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.assert_outcomes(passed=3)


@@ -169,11 +169,11 @@
     assert [x.message for x in caplog.get_records("setup")] == ["a_setup_log"]

     # This reaches into private API, don't use this type of thing in real tests!
-    assert set(caplog._item._store[caplog_records_key]) == {"setup", "call"}
-
-
-def test_ini_controls_global_log_level(testdir):
-    testdir.makepyfile(
+    assert set(caplog._item.stash[caplog_records_key]) == {"setup", "call"}
+
+
+def test_ini_controls_global_log_level(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import pytest
         import logging
@@ -187,20 +187,20 @@
             assert 'ERROR' in caplog.text
     """
     )
-    testdir.makeini(
+    pytester.makeini(
         """
         [pytest]
         log_level=ERROR
     """
     )

-    result = testdir.runpytest()
+    result = pytester.runpytest()
     # make sure that that we get a '0' exit code for the testsuite
     assert result.ret == 0


-def test_caplog_can_override_global_log_level(testdir):
-    testdir.makepyfile(
+def test_caplog_can_override_global_log_level(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import pytest
         import logging
@@ -227,19 +227,19 @@
             assert "message won't be shown" not in caplog.text
     """
     )
-    testdir.makeini(
+    pytester.makeini(
         """
         [pytest]
         log_level=WARNING
     """
     )

-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert result.ret == 0


-def test_caplog_captures_despite_exception(testdir):
-    testdir.makepyfile(
+def test_caplog_captures_despite_exception(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import pytest
         import logging
@@ -255,26 +255,28 @@
                 raise Exception()
     """
     )
-    testdir.makeini(
+    pytester.makeini(
         """
         [pytest]
         log_level=WARNING
     """
     )

-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*ERROR message will be shown*"])
     result.stdout.no_fnmatch_line("*DEBUG message won't be shown*")
     assert result.ret == 1


-def test_log_report_captures_according_to_config_option_upon_failure(testdir):
+def test_log_report_captures_according_to_config_option_upon_failure(
+    pytester: Pytester,
+) -> None:
     """Test that upon failure:
     (1) `caplog` succeeded to capture the DEBUG message and assert on it => No `Exception` is raised.
     (2) The `DEBUG` message does NOT appear in the `Captured log call` report.
     (3) The stdout, `INFO`, and `WARNING` messages DO appear in the test reports due to `--log-level=INFO`.
     """
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         import logging
@@ -299,7 +301,7 @@
     """
     )

-    result = testdir.runpytest("--log-level=INFO")
+    result = pytester.runpytest("--log-level=INFO")
     result.stdout.no_fnmatch_line("*Exception: caplog failed to capture DEBUG*")
     result.stdout.no_fnmatch_line("*DEBUG log message*")
     result.stdout.fnmatch_lines(
('testing/logging', 'test_reporting.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -6,12 +6,13 @@
 import pytest
 from _pytest.capture import CaptureManager
 from _pytest.config import ExitCode
-from _pytest.pytester import Testdir
+from _pytest.fixtures import FixtureRequest
+from _pytest.pytester import Pytester
 from _pytest.terminal import TerminalReporter


-def test_nothing_logged(testdir):
-    testdir.makepyfile(
+def test_nothing_logged(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import sys

@@ -21,7 +22,7 @@
             assert False
         """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     assert result.ret == 1
     result.stdout.fnmatch_lines(["*- Captured stdout call -*", "text going to stdout"])
     result.stdout.fnmatch_lines(["*- Captured stderr call -*", "text going to stderr"])
@@ -29,8 +30,8 @@
         result.stdout.fnmatch_lines(["*- Captured *log call -*"])


-def test_messages_logged(testdir):
-    testdir.makepyfile(
+def test_messages_logged(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import sys
         import logging
@@ -44,15 +45,15 @@
             assert False
         """
     )
-    result = testdir.runpytest("--log-level=INFO")
+    result = pytester.runpytest("--log-level=INFO")
     assert result.ret == 1
     result.stdout.fnmatch_lines(["*- Captured *log call -*", "*text going to logger*"])
     result.stdout.fnmatch_lines(["*- Captured stdout call -*", "text going to stdout"])
     result.stdout.fnmatch_lines(["*- Captured stderr call -*", "text going to stderr"])


-def test_root_logger_affected(testdir):
-    testdir.makepyfile(
+def test_root_logger_affected(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import logging
         logger = logging.getLogger()
@@ -65,8 +66,8 @@
             assert 0
     """
     )
-    log_file = testdir.tmpdir.join("pytest.log").strpath
-    result = testdir.runpytest("--log-level=ERROR", "--log-file=pytest.log")
+    log_file = str(pytester.path.joinpath("pytest.log"))
+    result = pytester.runpytest("--log-level=ERROR", "--log-file=pytest.log")
     assert result.ret == 1

     # The capture log calls in the stdout section only contain the
@@ -87,8 +88,8 @@
         assert "error text going to logger" in contents


-def test_log_cli_level_log_level_interaction(testdir):
-    testdir.makepyfile(
+def test_log_cli_level_log_level_interaction(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import logging
         logger = logging.getLogger()
@@ -102,7 +103,7 @@
     """
     )

-    result = testdir.runpytest("--log-cli-level=INFO", "--log-level=ERROR")
+    result = pytester.runpytest("--log-cli-level=INFO", "--log-level=ERROR")
     assert result.ret == 1

     result.stdout.fnmatch_lines(
@@ -117,8 +118,8 @@
     result.stdout.no_re_match_line("DEBUG")


-def test_setup_logging(testdir):
-    testdir.makepyfile(
+def test_setup_logging(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import logging

@@ -132,7 +133,7 @@
             assert False
     """
     )
-    result = testdir.runpytest("--log-level=INFO")
+    result = pytester.runpytest("--log-level=INFO")
     assert result.ret == 1
     result.stdout.fnmatch_lines(
         [
@@ -144,8 +145,8 @@
     )


-def test_teardown_logging(testdir):
-    testdir.makepyfile(
+def test_teardown_logging(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import logging

@@ -159,7 +160,7 @@
             assert False
         """
     )
-    result = testdir.runpytest("--log-level=INFO")
+    result = pytester.runpytest("--log-level=INFO")
     assert result.ret == 1
     result.stdout.fnmatch_lines(
         [
@@ -172,9 +173,9 @@


 @pytest.mark.parametrize("enabled", [True, False])
-def test_log_cli_enabled_disabled(testdir, enabled):
+def test_log_cli_enabled_disabled(pytester: Pytester, enabled: bool) -> None:
     msg = "critical message logged by test"
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import logging
         def test_log_cli():
@@ -184,13 +185,13 @@
         )
     )
     if enabled:
-        testdir.makeini(
+        pytester.makeini(
             """
             [pytest]
             log_cli=true
         """
         )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     if enabled:
         result.stdout.fnmatch_lines(
             [
@@ -204,9 +205,9 @@
         assert msg not in result.stdout.str()


-def test_log_cli_default_level(testdir):
+def test_log_cli_default_level(pytester: Pytester) -> None:
     # Default log file level
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         import logging
@@ -217,14 +218,14 @@
             logging.getLogger('catchlog').warning("WARNING message will be shown")
     """
     )
-    testdir.makeini(
+    pytester.makeini(
         """
         [pytest]
         log_cli=true
     """
     )

-    result = testdir.runpytest()
+    result = pytester.runpytest()

     # fnmatch_lines does an assertion internally
     result.stdout.fnmatch_lines(
@@ -234,14 +235,16 @@
         ]
     )
     result.stdout.no_fnmatch_line("*INFO message won't be shown*")
-    # make sure that that we get a '0' exit code for the testsuite
+    # make sure that we get a '0' exit code for the testsuite
     assert result.ret == 0


-def test_log_cli_default_level_multiple_tests(testdir, request):
+def test_log_cli_default_level_multiple_tests(
+    pytester: Pytester, request: FixtureRequest
+) -> None:
     """Ensure we reset the first newline added by the live logger between tests"""
     filename = request.node.name + ".py"
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import logging

@@ -252,20 +255,20 @@
             logging.warning("log message from test_log_2")
     """
     )
-    testdir.makeini(
+    pytester.makeini(
         """
         [pytest]
         log_cli=true
     """
     )

-    result = testdir.runpytest()
-    result.stdout.fnmatch_lines(
-        [
-            "{}::test_log_1 ".format(filename),
+    result = pytester.runpytest()
+    result.stdout.fnmatch_lines(
+        [
+            f"{filename}::test_log_1 ",
             "*WARNING*log message from test_log_1*",
             "PASSED *50%*",
-            "{}::test_log_2 ".format(filename),
+            f"{filename}::test_log_2 ",
             "*WARNING*log message from test_log_2*",
             "PASSED *100%*",
             "=* 2 passed in *=",
@@ -273,11 +276,13 @@
     )


-def test_log_cli_default_level_sections(testdir, request):
+def test_log_cli_default_level_sections(
+    pytester: Pytester, request: FixtureRequest
+) -> None:
     """Check that with live logging enable we are printing the correct headers during
     start/setup/call/teardown/finish."""
     filename = request.node.name + ".py"
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         import pytest
         import logging
@@ -290,7 +295,7 @@
     """
     )

-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         import logging
@@ -308,17 +313,17 @@
             logging.warning("log message from test_log_2")
     """
     )
-    testdir.makeini(
+    pytester.makeini(
         """
         [pytest]
         log_cli=true
     """
     )

-    result = testdir.runpytest()
-    result.stdout.fnmatch_lines(
-        [
-            "{}::test_log_1 ".format(filename),
+    result = pytester.runpytest()
+    result.stdout.fnmatch_lines(
+        [
+            f"{filename}::test_log_1 ",
             "*-- live log start --*",
             "*WARNING* >>>>> START >>>>>*",
             "*-- live log setup --*",
@@ -330,7 +335,7 @@
             "*WARNING*log message from teardown of test_log_1*",
             "*-- live log finish --*",
             "*WARNING* <<<<< END <<<<<<<*",
-            "{}::test_log_2 ".format(filename),
+            f"{filename}::test_log_2 ",
             "*-- live log start --*",
             "*WARNING* >>>>> START >>>>>*",
             "*-- live log setup --*",
@@ -347,11 +352,13 @@
     )


-def test_live_logs_unknown_sections(testdir, request):
+def test_live_logs_unknown_sections(
+    pytester: Pytester, request: FixtureRequest
+) -> None:
     """Check that with live logging enable we are printing the correct headers during
     start/setup/call/teardown/finish."""
     filename = request.node.name + ".py"
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         import pytest
         import logging
@@ -367,7 +374,7 @@
     """
     )

-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         import logging
@@ -383,18 +390,18 @@

     """
     )
-    testdir.makeini(
+    pytester.makeini(
         """
         [pytest]
         log_cli=true
     """
     )

-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(
         [
             "*WARNING*Unknown Section*",
-            "{}::test_log_1 ".format(filename),
+            f"{filename}::test_log_1 ",
             "*WARNING* >>>>> START >>>>>*",
             "*-- live log setup --*",
             "*WARNING*log message from setup of test_log_1*",
@@ -409,11 +416,13 @@
     )


-def test_sections_single_new_line_after_test_outcome(testdir, request):
+def test_sections_single_new_line_after_test_outcome(
+    pytester: Pytester, request: FixtureRequest
+) -> None:
     """Check that only a single new line is written between log messages during
     teardown/finish."""
     filename = request.node.name + ".py"
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         import pytest
         import logging
@@ -427,7 +436,7 @@
     """
     )

-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         import logging
@@ -443,17 +452,17 @@
             logging.warning("log message from test_log_1")
     """
     )
-    testdir.makeini(
+    pytester.makeini(
         """
         [pytest]
         log_cli=true
     """
     )

-    result = testdir.runpytest()
-    result.stdout.fnmatch_lines(
-        [
-            "{}::test_log_1 ".format(filename),
+    result = pytester.runpytest()
+    result.stdout.fnmatch_lines(
+        [
+            f"{filename}::test_log_1 ",
             "*-- live log start --*",
             "*WARNING* >>>>> START >>>>>*",
             "*-- live log setup --*",
@@ -487,9 +496,9 @@
     )


-def test_log_cli_level(testdir):
+def test_log_cli_level(pytester: Pytester) -> None:
     # Default log file level
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         import logging
@@ -501,14 +510,14 @@
             print('PASSED')
     """
     )
-    testdir.makeini(
+    pytester.makeini(
         """
         [pytest]
         log_cli=true
     """
     )

-    result = testdir.runpytest("-s", "--log-cli-level=INFO")
+    result = pytester.runpytest("-s", "--log-cli-level=INFO")

     # fnmatch_lines does an assertion internally
     result.stdout.fnmatch_lines(
@@ -519,10 +528,10 @@
     )
     result.stdout.no_fnmatch_line("*This log message won't be shown*")

-    # make sure that that we get a '0' exit code for the testsuite
+    # make sure that we get a '0' exit code for the testsuite
     assert result.ret == 0

-    result = testdir.runpytest("-s", "--log-level=INFO")
+    result = pytester.runpytest("-s", "--log-level=INFO")

     # fnmatch_lines does an assertion internally
     result.stdout.fnmatch_lines(
@@ -533,19 +542,19 @@
     )
     result.stdout.no_fnmatch_line("*This log message won't be shown*")

-    # make sure that that we get a '0' exit code for the testsuite
+    # make sure that we get a '0' exit code for the testsuite
     assert result.ret == 0


-def test_log_cli_ini_level(testdir):
-    testdir.makeini(
+def test_log_cli_ini_level(pytester: Pytester) -> None:
+    pytester.makeini(
         """
         [pytest]
         log_cli=true
         log_cli_level = INFO
         """
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         import logging
@@ -558,7 +567,7 @@
     """
     )

-    result = testdir.runpytest("-s")
+    result = pytester.runpytest("-s")

     # fnmatch_lines does an assertion internally
     result.stdout.fnmatch_lines(
@@ -569,7 +578,7 @@
     )
     result.stdout.no_fnmatch_line("*This log message won't be shown*")

-    # make sure that that we get a '0' exit code for the testsuite
+    # make sure that we get a '0' exit code for the testsuite
     assert result.ret == 0


@@ -577,11 +586,11 @@
     "cli_args",
     ["", "--log-level=WARNING", "--log-file-level=WARNING", "--log-cli-level=WARNING"],
 )
-def test_log_cli_auto_enable(testdir, cli_args):
+def test_log_cli_auto_enable(pytester: Pytester, cli_args: str) -> None:
     """Check that live logs are enabled if --log-level or --log-cli-level is passed on the CLI.
     It should not be auto enabled if the same configs are set on the INI file.
     """
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import logging

@@ -591,7 +600,7 @@

     """
     )
-    testdir.makeini(
+    pytester.makeini(
         """
         [pytest]
         log_level=INFO
@@ -599,7 +608,7 @@
     """
     )

-    result = testdir.runpytest(cli_args)
+    result = pytester.runpytest(cli_args)
     stdout = result.stdout.str()
     if cli_args == "--log-cli-level=WARNING":
         result.stdout.fnmatch_lines(
@@ -620,9 +629,9 @@
         assert "WARNING" not in stdout


-def test_log_file_cli(testdir):
+def test_log_file_cli(pytester: Pytester) -> None:
     # Default log file level
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         import logging
@@ -635,16 +644,16 @@
     """
     )

-    log_file = testdir.tmpdir.join("pytest.log").strpath
-
-    result = testdir.runpytest(
-        "-s", "--log-file={}".format(log_file), "--log-file-level=WARNING"
+    log_file = str(pytester.path.joinpath("pytest.log"))
+
+    result = pytester.runpytest(
+        "-s", f"--log-file={log_file}", "--log-file-level=WARNING"
     )

     # fnmatch_lines does an assertion internally
     result.stdout.fnmatch_lines(["test_log_file_cli.py PASSED"])

-    # make sure that that we get a '0' exit code for the testsuite
+    # make sure that we get a '0' exit code for the testsuite
     assert result.ret == 0
     assert os.path.isfile(log_file)
     with open(log_file) as rfh:
@@ -653,9 +662,9 @@
         assert "This log message won't be shown" not in contents


-def test_log_file_cli_level(testdir):
+def test_log_file_cli_level(pytester: Pytester) -> None:
     # Default log file level
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         import logging
@@ -668,16 +677,14 @@
     """
     )

-    log_file = testdir.tmpdir.join("pytest.log").strpath
-
-    result = testdir.runpytest(
-        "-s", "--log-file={}".format(log_file), "--log-file-level=INFO"
-    )
+    log_file = str(pytester.path.joinpath("pytest.log"))
+
+    result = pytester.runpytest("-s", f"--log-file={log_file}", "--log-file-level=INFO")

     # fnmatch_lines does an assertion internally
     result.stdout.fnmatch_lines(["test_log_file_cli_level.py PASSED"])

-    # make sure that that we get a '0' exit code for the testsuite
+    # make sure that we get a '0' exit code for the testsuite
     assert result.ret == 0
     assert os.path.isfile(log_file)
     with open(log_file) as rfh:
@@ -686,22 +693,22 @@
         assert "This log message won't be shown" not in contents


-def test_log_level_not_changed_by_default(testdir):
-    testdir.makepyfile(
+def test_log_level_not_changed_by_default(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import logging
         def test_log_file():
             assert logging.getLogger().level == logging.WARNING
     """
     )
-    result = testdir.runpytest("-s")
+    result = pytester.runpytest("-s")
     result.stdout.fnmatch_lines(["* 1 passed in *"])


-def test_log_file_ini(testdir):
-    log_file = testdir.tmpdir.join("pytest.log").strpath
-
-    testdir.makeini(
+def test_log_file_ini(pytester: Pytester) -> None:
+    log_file = str(pytester.path.joinpath("pytest.log"))
+
+    pytester.makeini(
         """
         [pytest]
         log_file={}
@@ -710,7 +717,7 @@
             log_file
         )
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         import logging
@@ -723,12 +730,12 @@
     """
     )

-    result = testdir.runpytest("-s")
+    result = pytester.runpytest("-s")

     # fnmatch_lines does an assertion internally
     result.stdout.fnmatch_lines(["test_log_file_ini.py PASSED"])

-    # make sure that that we get a '0' exit code for the testsuite
+    # make sure that we get a '0' exit code for the testsuite
     assert result.ret == 0
     assert os.path.isfile(log_file)
     with open(log_file) as rfh:
@@ -737,10 +744,10 @@
         assert "This log message won't be shown" not in contents


-def test_log_file_ini_level(testdir):
-    log_file = testdir.tmpdir.join("pytest.log").strpath
-
-    testdir.makeini(
+def test_log_file_ini_level(pytester: Pytester) -> None:
+    log_file = str(pytester.path.joinpath("pytest.log"))
+
+    pytester.makeini(
         """
         [pytest]
         log_file={}
@@ -749,7 +756,7 @@
             log_file
         )
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import pytest
         import logging
@@ -762,12 +769,12 @@
     """
     )

-    result = testdir.runpytest("-s")
+    result = pytester.runpytest("-s")

     # fnmatch_lines does an assertion internally
     result.stdout.fnmatch_lines(["test_log_file_ini_level.py PASSED"])

-    # make sure that that we get a '0' exit code for the testsuite
+    # make sure that we get a '0' exit code for the testsuite
     assert result.ret == 0
     assert os.path.isfile(log_file)
     with open(log_file) as rfh:
@@ -776,10 +783,10 @@
         assert "This log message won't be shown" not in contents


-def test_log_file_unicode(testdir):
-    log_file = testdir.tmpdir.join("pytest.log").strpath
-
-    testdir.makeini(
+def test_log_file_unicode(pytester: Pytester) -> None:
+    log_file = str(pytester.path.joinpath("pytest.log"))
+
+    pytester.makeini(
         """
         [pytest]
         log_file={}
@@ -788,7 +795,7 @@
             log_file
         )
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """\
         import logging

@@ -799,9 +806,9 @@
         """
     )

-    result = testdir.runpytest()
-
-    # make sure that that we get a '0' exit code for the testsuite
+    result = pytester.runpytest()
+
+    # make sure that we get a '0' exit code for the testsuite
     assert result.ret == 0
     assert os.path.isfile(log_file)
     with open(log_file, encoding="utf-8") as rfh:
@@ -812,11 +819,13 @@


 @pytest.mark.parametrize("has_capture_manager", [True, False])
-def test_live_logging_suspends_capture(has_capture_manager: bool, request) -> None:
+def test_live_logging_suspends_capture(
+    has_capture_manager: bool, request: FixtureRequest
+) -> None:
     """Test that capture manager is suspended when we emitting messages for live logging.

     This tests the implementation calls instead of behavior because it is difficult/impossible to do it using
-    ``testdir`` facilities because they do their own capturing.
+    ``pytester`` facilities because they do their own capturing.

     We parametrize the test to also make sure _LiveLoggingStreamHandler works correctly if no capture manager plugin
     is installed.
@@ -858,8 +867,8 @@
     assert cast(io.StringIO, out_file).getvalue() == "\nsome message\n"


-def test_collection_live_logging(testdir):
-    testdir.makepyfile(
+def test_collection_live_logging(pytester: Pytester) -> None:
+    pytester.makepyfile(
         """
         import logging

@@ -867,22 +876,22 @@
     """
     )

-    result = testdir.runpytest("--log-cli-level=INFO")
+    result = pytester.runpytest("--log-cli-level=INFO")
     result.stdout.fnmatch_lines(
         ["*--- live log collection ---*", "*Normal message*", "collected 0 items"]
     )


 @pytest.mark.parametrize("verbose", ["", "-q", "-qq"])
-def test_collection_collect_only_live_logging(testdir, verbose):
-    testdir.makepyfile(
+def test_collection_collect_only_live_logging(pytester: Pytester, verbose: str) -> None:
+    pytester.makepyfile(
         """
         def test_simple():
             pass
     """
     )

-    result = testdir.runpytest("--collect-only", "--log-cli-level=INFO", verbose)
+    result = pytester.runpytest("--collect-only", "--log-cli-level=INFO", verbose)

     expected_lines = []

@@ -891,7 +900,7 @@
             [
                 "*collected 1 item*",
                 "*<Module test_collection_collect_only_live_logging.py>*",
-                "*no tests ran*",
+                "*1 test collected*",
             ]
         )
     elif verbose == "-q":
@@ -899,7 +908,7 @@
         expected_lines.extend(
             [
                 "*test_collection_collect_only_live_logging.py::test_simple*",
-                "no tests ran in [0-9].[0-9][0-9]s",
+                "1 test collected in [0-9].[0-9][0-9]s",
             ]
         )
     elif verbose == "-qq":
@@ -909,10 +918,10 @@
     result.stdout.fnmatch_lines(expected_lines)


-def test_collection_logging_to_file(testdir):
-    log_file = testdir.tmpdir.join("pytest.log").strpath
-
-    testdir.makeini(
+def test_collection_logging_to_file(pytester: Pytester) -> None:
+    log_file = str(pytester.path.joinpath("pytest.log"))
+
+    pytester.makeini(
         """
         [pytest]
         log_file={}
@@ -922,7 +931,7 @@
         )
     )

-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import logging

@@ -934,7 +943,7 @@
     """
     )

-    result = testdir.runpytest()
+    result = pytester.runpytest()

     result.stdout.no_fnmatch_line("*--- live log collection ---*")

@@ -947,10 +956,10 @@
         assert "info message in test_simple" in contents


-def test_log_in_hooks(testdir):
-    log_file = testdir.tmpdir.join("pytest.log").strpath
-
-    testdir.makeini(
+def test_log_in_hooks(pytester: Pytester) -> None:
+    log_file = str(pytester.path.joinpath("pytest.log"))
+
+    pytester.makeini(
         """
         [pytest]
         log_file={}
@@ -960,7 +969,7 @@
             log_file
         )
     )
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         import logging

@@ -974,7 +983,7 @@
             logging.info('sessionfinish')
     """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.stdout.fnmatch_lines(["*sessionstart*", "*runtestloop*", "*sessionfinish*"])
     with open(log_file) as rfh:
         contents = rfh.read()
@@ -983,10 +992,10 @@
         assert "sessionfinish" in contents


-def test_log_in_runtest_logreport(testdir):
-    log_file = testdir.tmpdir.join("pytest.log").strpath
-
-    testdir.makeini(
+def test_log_in_runtest_logreport(pytester: Pytester) -> None:
+    log_file = str(pytester.path.joinpath("pytest.log"))
+
+    pytester.makeini(
         """
         [pytest]
         log_file={}
@@ -996,7 +1005,7 @@
             log_file
         )
     )
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
         import logging
         logger = logging.getLogger(__name__)
@@ -1005,29 +1014,29 @@
             logger.info("logreport")
     """
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
             def test_first():
                 assert True
         """
     )
-    testdir.runpytest()
+    pytester.runpytest()
     with open(log_file) as rfh:
         contents = rfh.read()
         assert contents.count("logreport") == 3


-def test_log_set_path(testdir):
-    report_dir_base = testdir.tmpdir.strpath
-
-    testdir.makeini(
+def test_log_set_path(pytester: Pytester) -> None:
+    report_dir_base = str(pytester.path)
+
+    pytester.makeini(
         """
         [pytest]
         log_file_level = DEBUG
         log_cli=true
         """
     )
-    testdir.makeconftest(
+    pytester.makeconftest(
         """
             import os
             import pytest
@@ -1042,7 +1051,7 @@
             repr(report_dir_base)
         )
     )
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
             import logging
             logger = logging.getLogger("testcase-logger")
@@ -1055,7 +1064,7 @@
                 assert True
         """
     )
-    testdir.runpytest()
+    pytester.runpytest()
     with open(os.path.join(report_dir_base, "test_first")) as rfh:
         content = rfh.read()
         assert "message from test 1" in content
@@ -1065,10 +1074,10 @@
         assert "message from test 2" in content


-def test_colored_captured_log(testdir):
+def test_colored_captured_log(pytester: Pytester) -> None:
     """Test that the level names of captured log messages of a failing test
     are colored."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import logging

@@ -1079,7 +1088,7 @@
             assert False
         """
     )
-    result = testdir.runpytest("--log-level=INFO", "--color=yes")
+    result = pytester.runpytest("--log-level=INFO", "--color=yes")
     assert result.ret == 1
     result.stdout.fnmatch_lines(
         [
@@ -1089,9 +1098,9 @@
     )


-def test_colored_ansi_esc_caplogtext(testdir):
+def test_colored_ansi_esc_caplogtext(pytester: Pytester) -> None:
     """Make sure that caplog.text does not contain ANSI escape sequences."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import logging

@@ -1102,11 +1111,11 @@
             assert '\x1b' not in caplog.text
         """
     )
-    result = testdir.runpytest("--log-level=INFO", "--color=yes")
+    result = pytester.runpytest("--log-level=INFO", "--color=yes")
     assert result.ret == 0


-def test_logging_emit_error(testdir: Testdir) -> None:
+def test_logging_emit_error(pytester: Pytester) -> None:
     """An exception raised during emit() should fail the test.

     The default behavior of logging is to print "Logging error"
@@ -1114,7 +1123,7 @@

     pytest overrides this behavior to propagate the exception.
     """
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import logging

@@ -1122,7 +1131,7 @@
             logging.warning('oops', 'first', 2)
         """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.assert_outcomes(failed=1)
     result.stdout.fnmatch_lines(
         [
@@ -1132,10 +1141,10 @@
     )


-def test_logging_emit_error_supressed(testdir: Testdir) -> None:
+def test_logging_emit_error_supressed(pytester: Pytester) -> None:
     """If logging is configured to silently ignore errors, pytest
     doesn't propagate errors either."""
-    testdir.makepyfile(
+    pytester.makepyfile(
         """
         import logging

@@ -1144,13 +1153,15 @@
             logging.warning('oops', 'first', 2)
         """
     )
-    result = testdir.runpytest()
+    result = pytester.runpytest()
     result.assert_outcomes(passed=1)


-def test_log_file_cli_subdirectories_are_successfully_created(testdir):
-    path = testdir.makepyfile(""" def test_logger(): pass """)
+def test_log_file_cli_subdirectories_are_successfully_created(
+    pytester: Pytester,
+) -> None:
+    path = pytester.makepyfile(""" def test_logger(): pass """)
     expected = os.path.join(os.path.dirname(str(path)), "foo", "bar")
-    result = testdir.runpytest("--log-file=foo/bar/logf.log")
+    result = pytester.runpytest("--log-file=foo/bar/logf.log")
     assert "logf.log" in os.listdir(expected)
     assert result.ret == ExitCode.OK
('testing/logging', 'test_formatter.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -18,9 +18,32 @@
         exc_info=None,
     )

-    class ColorConfig:
-        class option:
-            pass
+    tw = TerminalWriter()
+    tw.hasmarkup = True
+    formatter = ColoredLevelFormatter(tw, logfmt)
+    output = formatter.format(record)
+    assert output == (
+        "dummypath                   10 \x1b[32mINFO    \x1b[0m Test Message"
+    )
+
+    tw.hasmarkup = False
+    formatter = ColoredLevelFormatter(tw, logfmt)
+    output = formatter.format(record)
+    assert output == ("dummypath                   10 INFO     Test Message")
+
+
+def test_coloredlogformatter_with_width_precision() -> None:
+    logfmt = "%(filename)-25s %(lineno)4d %(levelname)-8.8s %(message)s"
+
+    record = logging.LogRecord(
+        name="dummy",
+        level=logging.INFO,
+        pathname="dummypath",
+        lineno=10,
+        msg="Test Message",
+        args=(),
+        exc_info=None,
+    )

     tw = TerminalWriter()
     tw.hasmarkup = True
@@ -41,7 +64,7 @@

     logfmt = "%(filename)-25s %(lineno)4d %(levelname)-8s %(message)s"

-    record = logging.LogRecord(
+    record: Any = logging.LogRecord(
         name="dummy",
         level=logging.INFO,
         pathname="dummypath",
@@ -49,7 +72,7 @@
         msg="Test Message line1\nline2",
         args=(),
         exc_info=None,
-    )  # type: Any
+    )
     # this is called by logging.Formatter.format
     record.message = record.getMessage()

('extra/setup-py.test', 'setup.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,4 +1,5 @@
 import sys
+
 from distutils.core import setup

 if __name__ == "__main__":
('scripts', 'release.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -10,35 +10,32 @@
 from colorama import init


-def announce(version):
+def announce(version, template_name, doc_version):
     """Generates a new release announcement entry in the docs."""
     # Get our list of authors
     stdout = check_output(["git", "describe", "--abbrev=0", "--tags"])
     stdout = stdout.decode("utf-8")
     last_version = stdout.strip()

-    stdout = check_output(
-        ["git", "log", "{}..HEAD".format(last_version), "--format=%aN"]
-    )
+    stdout = check_output(["git", "log", f"{last_version}..HEAD", "--format=%aN"])
     stdout = stdout.decode("utf-8")

-    contributors = set(stdout.splitlines())
+    contributors = {
+        name
+        for name in stdout.splitlines()
+        if not name.endswith("[bot]") and name != "pytest bot"
+    }

-    template_name = (
-        "release.minor.rst" if version.endswith(".0") else "release.patch.rst"
-    )
     template_text = (
         Path(__file__).parent.joinpath(template_name).read_text(encoding="UTF-8")
     )

-    contributors_text = (
-        "\n".join("* {}".format(name) for name in sorted(contributors)) + "\n"
+    contributors_text = "\n".join(f"* {name}" for name in sorted(contributors)) + "\n"
+    text = template_text.format(
+        version=version, contributors=contributors_text, doc_version=doc_version
     )
-    text = template_text.format(version=version, contributors=contributors_text)

-    target = Path(__file__).parent.joinpath(
-        "../doc/en/announce/release-{}.rst".format(version)
-    )
+    target = Path(__file__).parent.joinpath(f"../doc/en/announce/release-{version}.rst")
     target.write_text(text, encoding="UTF-8")
     print(f"{Fore.CYAN}[generate.announce] {Fore.RESET}Generated {target.name}")

@@ -47,7 +44,7 @@
     lines = index_path.read_text(encoding="UTF-8").splitlines()
     indent = "   "
     for index, line in enumerate(lines):
-        if line.startswith("{}release-".format(indent)):
+        if line.startswith(f"{indent}release-"):
             new_line = indent + target.stem
             if line != new_line:
                 lines.insert(index, new_line)
@@ -69,7 +66,7 @@
     print(f"{Fore.CYAN}[generate.regen] {Fore.RESET}Updating docs")
     check_call(
         ["tox", "-e", "regen"],
-        env={**os.environ, "SETUPTOOLS_SCM_PRETEND_VERSION": version},
+        env={**os.environ, "SETUPTOOLS_SCM_PRETEND_VERSION_FOR_PYTEST": version},
     )


@@ -87,16 +84,16 @@
     check_call(["tox", "-e", "docs-checklinks"])


-def pre_release(version, *, skip_check_links):
+def pre_release(version, template_name, doc_version, *, skip_check_links):
     """Generates new docs, release announcements and creates a local tag."""
-    announce(version)
+    announce(version, template_name, doc_version)
     regen(version)
     changelog(version, write_out=True)
     fix_formatting()
     if not skip_check_links:
         check_links()

-    msg = "Prepare release version {}".format(version)
+    msg = f"Prepare release version {version}"
     check_call(["git", "commit", "-a", "-m", msg])

     print()
@@ -106,10 +103,7 @@


 def changelog(version, write_out=False):
-    if write_out:
-        addopts = []
-    else:
-        addopts = ["--draft"]
+    addopts = [] if write_out else ["--draft"]
     check_call(["towncrier", "--yes", "--version", version] + addopts)


@@ -117,9 +111,20 @@
     init(autoreset=True)
     parser = argparse.ArgumentParser()
     parser.add_argument("version", help="Release version")
+    parser.add_argument(
+        "template_name", help="Name of template file to use for release announcement"
+    )
+    parser.add_argument(
+        "doc_version", help="For prereleases, the version to link to in the docs"
+    )
     parser.add_argument("--skip-check-links", action="store_true", default=False)
     options = parser.parse_args()
-    pre_release(options.version, skip_check_links=options.skip_check_links)
+    pre_release(
+        options.version,
+        options.template_name,
+        options.doc_version,
+        skip_check_links=options.skip_check_links,
+    )


 if __name__ == "__main__":
('scripts', 'publish-gh-release-notes.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,7 +1,7 @@
 """
 Script used to publish GitHub release notes extracted from CHANGELOG.rst.

-This script is meant to be executed after a successful deployment in Travis.
+This script is meant to be executed after a successful deployment in GitHub actions.

 Uses the following environment variables:

@@ -12,11 +12,8 @@

     https://github.com/settings/tokens

-  It should be encrypted using:
-
-    $travis encrypt GH_RELEASE_NOTES_TOKEN=<token> -r pytest-dev/pytest
-
-  And the contents pasted in the ``deploy.env.secure`` section in the ``travis.yml`` file.
+  This token should be set in a secret in the repository, which is exposed as an
+  environment variable in the main.yml workflow file.

 The script also requires ``pandoc`` to be previously installed in the system.

('src/pytest', '__init__.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,24 +1,38 @@
 # PYTHON_ARGCOMPLETE_OK
 """pytest: unit and functional testing with Python."""
-from . import collect
 from _pytest import __version__
+from _pytest import version_tuple
+from _pytest._code import ExceptionInfo
 from _pytest.assertion import register_assert_rewrite
+from _pytest.cacheprovider import Cache
+from _pytest.capture import CaptureFixture
 from _pytest.config import cmdline
+from _pytest.config import Config
 from _pytest.config import console_main
 from _pytest.config import ExitCode
 from _pytest.config import hookimpl
 from _pytest.config import hookspec
 from _pytest.config import main
+from _pytest.config import PytestPluginManager
 from _pytest.config import UsageError
+from _pytest.config.argparsing import OptionGroup
+from _pytest.config.argparsing import Parser
 from _pytest.debugging import pytestPDB as __pytestPDB
-from _pytest.fixtures import _fillfuncargs
 from _pytest.fixtures import fixture
 from _pytest.fixtures import FixtureLookupError
+from _pytest.fixtures import FixtureRequest
 from _pytest.fixtures import yield_fixture
 from _pytest.freeze_support import freeze_includes
+from _pytest.legacypath import TempdirFactory
+from _pytest.legacypath import Testdir
+from _pytest.logging import LogCaptureFixture
 from _pytest.main import Session
+from _pytest.mark import Mark
 from _pytest.mark import MARK_GEN as mark
+from _pytest.mark import MarkDecorator
+from _pytest.mark import MarkGenerator
 from _pytest.mark import param
+from _pytest.monkeypatch import MonkeyPatch
 from _pytest.nodes import Collector
 from _pytest.nodes import File
 from _pytest.nodes import Item
@@ -27,71 +41,125 @@
 from _pytest.outcomes import importorskip
 from _pytest.outcomes import skip
 from _pytest.outcomes import xfail
+from _pytest.pytester import HookRecorder
+from _pytest.pytester import LineMatcher
+from _pytest.pytester import Pytester
+from _pytest.pytester import RecordedHookCall
+from _pytest.pytester import RunResult
 from _pytest.python import Class
 from _pytest.python import Function
-from _pytest.python import Instance
+from _pytest.python import Metafunc
 from _pytest.python import Module
 from _pytest.python import Package
 from _pytest.python_api import approx
 from _pytest.python_api import raises
 from _pytest.recwarn import deprecated_call
+from _pytest.recwarn import WarningsRecorder
 from _pytest.recwarn import warns
+from _pytest.reports import CollectReport
+from _pytest.reports import TestReport
+from _pytest.runner import CallInfo
+from _pytest.stash import Stash
+from _pytest.stash import StashKey
+from _pytest.tmpdir import TempPathFactory
 from _pytest.warning_types import PytestAssertRewriteWarning
 from _pytest.warning_types import PytestCacheWarning
 from _pytest.warning_types import PytestCollectionWarning
 from _pytest.warning_types import PytestConfigWarning
 from _pytest.warning_types import PytestDeprecationWarning
 from _pytest.warning_types import PytestExperimentalApiWarning
+from _pytest.warning_types import PytestRemovedIn8Warning
 from _pytest.warning_types import PytestUnhandledCoroutineWarning
+from _pytest.warning_types import PytestUnhandledThreadExceptionWarning
 from _pytest.warning_types import PytestUnknownMarkWarning
+from _pytest.warning_types import PytestUnraisableExceptionWarning
 from _pytest.warning_types import PytestWarning

 set_trace = __pytestPDB.set_trace

+
 __all__ = [
     "__version__",
-    "_fillfuncargs",
     "approx",
+    "Cache",
+    "CallInfo",
+    "CaptureFixture",
     "Class",
     "cmdline",
-    "collect",
     "Collector",
+    "CollectReport",
+    "Config",
     "console_main",
     "deprecated_call",
     "exit",
+    "ExceptionInfo",
     "ExitCode",
     "fail",
     "File",
     "fixture",
     "FixtureLookupError",
+    "FixtureRequest",
     "freeze_includes",
     "Function",
     "hookimpl",
+    "HookRecorder",
     "hookspec",
     "importorskip",
-    "Instance",
     "Item",
+    "LineMatcher",
+    "LogCaptureFixture",
     "main",
     "mark",
+    "Mark",
+    "MarkDecorator",
+    "MarkGenerator",
+    "Metafunc",
     "Module",
+    "MonkeyPatch",
+    "OptionGroup",
     "Package",
     "param",
+    "Parser",
     "PytestAssertRewriteWarning",
     "PytestCacheWarning",
     "PytestCollectionWarning",
     "PytestConfigWarning",
     "PytestDeprecationWarning",
     "PytestExperimentalApiWarning",
+    "PytestRemovedIn8Warning",
+    "Pytester",
+    "PytestPluginManager",
     "PytestUnhandledCoroutineWarning",
+    "PytestUnhandledThreadExceptionWarning",
     "PytestUnknownMarkWarning",
+    "PytestUnraisableExceptionWarning",
     "PytestWarning",
     "raises",
+    "RecordedHookCall",
     "register_assert_rewrite",
+    "RunResult",
     "Session",
     "set_trace",
     "skip",
+    "Stash",
+    "StashKey",
+    "version_tuple",
+    "TempdirFactory",
+    "TempPathFactory",
+    "Testdir",
+    "TestReport",
     "UsageError",
+    "WarningsRecorder",
     "warns",
     "xfail",
     "yield_fixture",
 ]
+
+
+def __getattr__(name: str) -> object:
+    if name == "Instance":
+        # The import emits a deprecation warning.
+        from _pytest.python import Instance
+
+        return Instance
+    raise AttributeError(f"module {__name__} has no attribute {name}")
('src/_pytest', 'skipping.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -3,13 +3,14 @@
 import platform
 import sys
 import traceback
+from collections.abc import Mapping
 from typing import Generator
 from typing import Optional
 from typing import Tuple
+from typing import Type

 import attr

-from _pytest.compat import TYPE_CHECKING
 from _pytest.config import Config
 from _pytest.config import hookimpl
 from _pytest.config.argparsing import Parser
@@ -20,10 +21,7 @@
 from _pytest.outcomes import xfail
 from _pytest.reports import BaseReport
 from _pytest.runner import CallInfo
-from _pytest.store import StoreKey
-
-if TYPE_CHECKING:
-    from typing import Type
+from _pytest.stash import StashKey


 def pytest_addoption(parser: Parser) -> None:
@@ -51,7 +49,7 @@
         import pytest

         old = pytest.xfail
-        config._cleanup.append(lambda: setattr(pytest, "xfail", old))
+        config.add_cleanup(lambda: setattr(pytest, "xfail", old))

         def nop(*args, **kwargs):
             pass
@@ -70,7 +68,7 @@
         "skipif(condition, ..., *, reason=...): "
         "skip the given test function if any of the conditions evaluate to True. "
         "Example: skipif(sys.platform == 'win32') skips the test if we are on the win32 platform. "
-        "See https://docs.pytest.org/en/stable/reference.html#pytest-mark-skipif",
+        "See https://docs.pytest.org/en/stable/reference/reference.html#pytest-mark-skipif",
     )
     config.addinivalue_line(
         "markers",
@@ -80,7 +78,7 @@
         "and run=False if you don't even want to execute the test function. "
         "If only specific exception(s) are expected, you can list them in "
         "raises, and if the test fails in other ways, it will be reported as "
-        "a true failure. See https://docs.pytest.org/en/stable/reference.html#pytest-mark-xfail",
+        "a true failure. See https://docs.pytest.org/en/stable/reference/reference.html#pytest-mark-xfail",
     )


@@ -101,10 +99,20 @@
             "platform": platform,
             "config": item.config,
         }
+        for dictionary in reversed(
+            item.ihook.pytest_markeval_namespace(config=item.config)
+        ):
+            if not isinstance(dictionary, Mapping):
+                raise ValueError(
+                    "pytest_markeval_namespace() needs to return a dict, got {!r}".format(
+                        dictionary
+                    )
+                )
+            globals_.update(dictionary)
         if hasattr(item, "obj"):
             globals_.update(item.obj.__globals__)  # type: ignore[attr-defined]
         try:
-            filename = "<{} condition>".format(mark.name)
+            filename = f"<{mark.name} condition>"
             condition_code = compile(condition, filename, "eval")
             result = eval(condition_code, globals_)
         except SyntaxError as exc:
@@ -149,11 +157,11 @@
     return result, reason


-@attr.s(slots=True, frozen=True)
+@attr.s(slots=True, frozen=True, auto_attribs=True)
 class Skip:
     """The result of evaluate_skip_marks()."""

-    reason = attr.ib(type=str)
+    reason: str = "unconditional skip"


 def evaluate_skip_marks(item: Item) -> Optional[Skip]:
@@ -176,25 +184,22 @@
                 return Skip(reason)

     for mark in item.iter_markers(name="skip"):
-        if "reason" in mark.kwargs:
-            reason = mark.kwargs["reason"]
-        elif mark.args:
-            reason = mark.args[0]
-        else:
-            reason = "unconditional skip"
-        return Skip(reason)
+        try:
+            return Skip(*mark.args, **mark.kwargs)
+        except TypeError as e:
+            raise TypeError(str(e) + " - maybe you meant pytest.mark.skipif?") from None

     return None


-@attr.s(slots=True, frozen=True)
+@attr.s(slots=True, frozen=True, auto_attribs=True)
 class Xfail:
     """The result of evaluate_xfail_marks()."""

-    reason = attr.ib(type=str)
-    run = attr.ib(type=bool)
-    strict = attr.ib(type=bool)
-    raises = attr.ib(type=Optional[Tuple["Type[BaseException]", ...]])
+    reason: str
+    run: bool
+    strict: bool
+    raises: Optional[Tuple[Type[BaseException], ...]]


 def evaluate_xfail_marks(item: Item) -> Optional[Xfail]:
@@ -222,30 +227,26 @@
     return None


-# Whether skipped due to skip or skipif marks.
-skipped_by_mark_key = StoreKey[bool]()
 # Saves the xfail mark evaluation. Can be refreshed during call if None.
-xfailed_key = StoreKey[Optional[Xfail]]()
-unexpectedsuccess_key = StoreKey[str]()
+xfailed_key = StashKey[Optional[Xfail]]()


 @hookimpl(tryfirst=True)
 def pytest_runtest_setup(item: Item) -> None:
     skipped = evaluate_skip_marks(item)
-    item._store[skipped_by_mark_key] = skipped is not None
     if skipped:
-        skip(skipped.reason)
-
-    item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)
+        raise skip.Exception(skipped.reason, _use_item_location=True)
+
+    item.stash[xfailed_key] = xfailed = evaluate_xfail_marks(item)
     if xfailed and not item.config.option.runxfail and not xfailed.run:
         xfail("[NOTRUN] " + xfailed.reason)


 @hookimpl(hookwrapper=True)
 def pytest_runtest_call(item: Item) -> Generator[None, None, None]:
-    xfailed = item._store.get(xfailed_key, None)
+    xfailed = item.stash.get(xfailed_key, None)
     if xfailed is None:
-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)
+        item.stash[xfailed_key] = xfailed = evaluate_xfail_marks(item)

     if xfailed and not item.config.option.runxfail and not xfailed.run:
         xfail("[NOTRUN] " + xfailed.reason)
@@ -253,25 +254,17 @@
     yield

     # The test run may have added an xfail mark dynamically.
-    xfailed = item._store.get(xfailed_key, None)
+    xfailed = item.stash.get(xfailed_key, None)
     if xfailed is None:
-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)
+        item.stash[xfailed_key] = xfailed = evaluate_xfail_marks(item)


 @hookimpl(hookwrapper=True)
 def pytest_runtest_makereport(item: Item, call: CallInfo[None]):
     outcome = yield
     rep = outcome.get_result()
-    xfailed = item._store.get(xfailed_key, None)
-    # unittest special case, see setting of unexpectedsuccess_key
-    if unexpectedsuccess_key in item._store and rep.when == "call":
-        reason = item._store[unexpectedsuccess_key]
-        if reason:
-            rep.longrepr = "Unexpected success: {}".format(reason)
-        else:
-            rep.longrepr = "Unexpected success"
-        rep.outcome = "failed"
-    elif item.config.option.runxfail:
+    xfailed = item.stash.get(xfailed_key, None)
+    if item.config.option.runxfail:
         pass  # don't interfere
     elif call.excinfo and isinstance(call.excinfo.value, xfail.Exception):
         assert call.excinfo.value.msg is not None
@@ -293,19 +286,6 @@
                 rep.outcome = "passed"
                 rep.wasxfail = xfailed.reason

-    if (
-        item._store.get(skipped_by_mark_key, True)
-        and rep.skipped
-        and type(rep.longrepr) is tuple
-    ):
-        # Skipped by mark.skipif; change the location of the failure
-        # to point to the item definition, otherwise it will display
-        # the location of where the skip exception was raised within pytest.
-        _, _, reason = rep.longrepr
-        filename, line = item.reportinfo()[:2]
-        assert line is not None
-        rep.longrepr = str(filename), line + 1, reason
-

 def pytest_report_teststatus(report: BaseReport) -> Optional[Tuple[str, str, str]]:
     if hasattr(report, "wasxfail"):
('src/_pytest', 'logging.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,10 +1,12 @@
 """Access and control log capturing."""
+import io
 import logging
 import os
 import re
-import sys
 from contextlib import contextmanager
+from contextlib import nullcontext
 from io import StringIO
+from pathlib import Path
 from typing import AbstractSet
 from typing import Dict
 from typing import Generator
@@ -12,31 +14,38 @@
 from typing import Mapping
 from typing import Optional
 from typing import Tuple
+from typing import TYPE_CHECKING
 from typing import TypeVar
 from typing import Union

-import pytest
 from _pytest import nodes
 from _pytest._io import TerminalWriter
 from _pytest.capture import CaptureManager
 from _pytest.compat import final
-from _pytest.compat import nullcontext
 from _pytest.config import _strtobool
 from _pytest.config import Config
 from _pytest.config import create_terminal_writer
+from _pytest.config import hookimpl
+from _pytest.config import UsageError
 from _pytest.config.argparsing import Parser
+from _pytest.deprecated import check_ispytest
+from _pytest.fixtures import fixture
 from _pytest.fixtures import FixtureRequest
 from _pytest.main import Session
-from _pytest.pathlib import Path
-from _pytest.store import StoreKey
+from _pytest.stash import StashKey
 from _pytest.terminal import TerminalReporter
+
+if TYPE_CHECKING:
+    logging_StreamHandler = logging.StreamHandler[StringIO]
+else:
+    logging_StreamHandler = logging.StreamHandler


 DEFAULT_LOG_FORMAT = "%(levelname)-8s %(name)s:%(filename)s:%(lineno)d %(message)s"
 DEFAULT_LOG_DATE_FORMAT = "%H:%M:%S"
 _ANSI_ESCAPE_SEQ = re.compile(r"\x1b\[[\d;]+m")
-caplog_handler_key = StoreKey["LogCaptureHandler"]()
-caplog_records_key = StoreKey[Dict[str, List[logging.LogRecord]]]()
+caplog_handler_key = StashKey["LogCaptureHandler"]()
+caplog_records_key = StashKey[Dict[str, List[logging.LogRecord]]]()


 def _remove_ansi_escape_sequences(text: str) -> str:
@@ -47,7 +56,7 @@
     """A logging formatter which colorizes the %(levelname)..s part of the
     log format passed to __init__."""

-    LOGLEVEL_COLOROPTS = {
+    LOGLEVEL_COLOROPTS: Mapping[int, AbstractSet[str]] = {
         logging.CRITICAL: {"red"},
         logging.ERROR: {"red", "bold"},
         logging.WARNING: {"yellow"},
@@ -55,13 +64,31 @@
         logging.INFO: {"green"},
         logging.DEBUG: {"purple"},
         logging.NOTSET: set(),
-    }  # type: Mapping[int, AbstractSet[str]]
-    LEVELNAME_FMT_REGEX = re.compile(r"%\(levelname\)([+-.]?\d*s)")
+    }
+    LEVELNAME_FMT_REGEX = re.compile(r"%\(levelname\)([+-.]?\d*(?:\.\d+)?s)")

     def __init__(self, terminalwriter: TerminalWriter, *args, **kwargs) -> None:
         super().__init__(*args, **kwargs)
+        self._terminalwriter = terminalwriter
         self._original_fmt = self._style._fmt
-        self._level_to_fmt_mapping = {}  # type: Dict[int, str]
+        self._level_to_fmt_mapping: Dict[int, str] = {}
+
+        for level, color_opts in self.LOGLEVEL_COLOROPTS.items():
+            self.add_color_level(level, *color_opts)
+
+    def add_color_level(self, level: int, *color_opts: str) -> None:
+        """Add or update color opts for a log level.
+
+        :param level:
+            Log level to apply a style to, e.g. ``logging.INFO``.
+        :param color_opts:
+            ANSI escape sequence color options. Capitalized colors indicates
+            background color, i.e. ``'green', 'Yellow', 'bold'`` will give bold
+            green text on yellow background.
+
+        .. warning::
+            This is an experimental API.
+        """

         assert self._fmt is not None
         levelname_fmt_match = self.LEVELNAME_FMT_REGEX.search(self._fmt)
@@ -69,19 +96,16 @@
             return
         levelname_fmt = levelname_fmt_match.group()

-        for level, color_opts in self.LOGLEVEL_COLOROPTS.items():
-            formatted_levelname = levelname_fmt % {
-                "levelname": logging.getLevelName(level)
-            }
-
-            # add ANSI escape sequences around the formatted levelname
-            color_kwargs = {name: True for name in color_opts}
-            colorized_formatted_levelname = terminalwriter.markup(
-                formatted_levelname, **color_kwargs
-            )
-            self._level_to_fmt_mapping[level] = self.LEVELNAME_FMT_REGEX.sub(
-                colorized_formatted_levelname, self._fmt
-            )
+        formatted_levelname = levelname_fmt % {"levelname": logging.getLevelName(level)}
+
+        # add ANSI escape sequences around the formatted levelname
+        color_kwargs = {name: True for name in color_opts}
+        colorized_formatted_levelname = self._terminalwriter.markup(
+            formatted_levelname, **color_kwargs
+        )
+        self._level_to_fmt_mapping[level] = self.LEVELNAME_FMT_REGEX.sub(
+            colorized_formatted_levelname, self._fmt
+        )

     def format(self, record: logging.LogRecord) -> str:
         fmt = self._level_to_fmt_mapping.get(record.levelno, self._original_fmt)
@@ -99,14 +123,6 @@
     def __init__(self, fmt: str, auto_indent: Union[int, str, bool, None]) -> None:
         super().__init__(fmt)
         self._auto_indent = self._get_auto_indent(auto_indent)
-
-    @staticmethod
-    def _update_message(
-        record_dict: Dict[str, object], message: str
-    ) -> Dict[str, object]:
-        tmp = record_dict.copy()
-        tmp["message"] = message
-        return tmp

     @staticmethod
     def _get_auto_indent(auto_indent_option: Union[int, str, bool, None]) -> int:
@@ -173,7 +189,7 @@

             if auto_indent:
                 lines = record.message.splitlines()
-                formatted = self._fmt % self._update_message(record.__dict__, lines[0])
+                formatted = self._fmt % {**record.__dict__, "message": lines[0]}

                 if auto_indent < 0:
                     indentation = _remove_ansi_escape_sequences(formatted).find(
@@ -312,15 +328,13 @@
         root_logger.removeHandler(self.handler)


-class LogCaptureHandler(logging.StreamHandler):
+class LogCaptureHandler(logging_StreamHandler):
     """A logging handler that stores log records and the log text."""
-
-    stream = None  # type: StringIO

     def __init__(self) -> None:
         """Create a new log handler."""
         super().__init__(StringIO())
-        self.records = []  # type: List[logging.LogRecord]
+        self.records: List[logging.LogRecord] = []

     def emit(self, record: logging.LogRecord) -> None:
         """Keep the log records in a list in addition to the log text."""
@@ -344,11 +358,12 @@
 class LogCaptureFixture:
     """Provides access and control of log capturing."""

-    def __init__(self, item: nodes.Node) -> None:
+    def __init__(self, item: nodes.Node, *, _ispytest: bool = False) -> None:
+        check_ispytest(_ispytest)
         self._item = item
-        self._initial_handler_level = None  # type: Optional[int]
+        self._initial_handler_level: Optional[int] = None
         # Dict of log name -> log level.
-        self._initial_logger_levels = {}  # type: Dict[Optional[str], int]
+        self._initial_logger_levels: Dict[Optional[str], int] = {}

     def _finalize(self) -> None:
         """Finalize the fixture.
@@ -368,7 +383,7 @@

         :rtype: LogCaptureHandler
         """
-        return self._item._store[caplog_handler_key]
+        return self._item.stash[caplog_handler_key]

     def get_records(self, when: str) -> List[logging.LogRecord]:
         """Get the logging records for one of the possible test phases.
@@ -381,7 +396,7 @@

         .. versionadded:: 3.4
         """
-        return self._item._store[caplog_records_key].get(when, [])
+        return self._item.stash[caplog_records_key].get(when, [])

     @property
     def text(self) -> str:
@@ -447,7 +462,7 @@

     @contextmanager
     def at_level(
-        self, level: int, logger: Optional[str] = None
+        self, level: Union[int, str], logger: Optional[str] = None
     ) -> Generator[None, None, None]:
         """Context manager that sets the level for capturing of logs. After
         the end of the 'with' statement the level is restored to its original
@@ -468,7 +483,7 @@
             self.handler.setLevel(handler_orig_level)


-@pytest.fixture
+@fixture
 def caplog(request: FixtureRequest) -> Generator[LogCaptureFixture, None, None]:
     """Access and control log capturing.

@@ -480,7 +495,7 @@
     * caplog.record_tuples   -> list of (logger_name, level, message) tuples
     * caplog.clear()         -> clear captured records and formatted log output string
     """
-    result = LogCaptureFixture(request.node)
+    result = LogCaptureFixture(request.node, _ispytest=True)
     yield result
     result._finalize()

@@ -501,7 +516,7 @@
         return int(getattr(logging, log_level, log_level))
     except ValueError as e:
         # Python logging does not recognise this as a logging level
-        raise pytest.UsageError(
+        raise UsageError(
             "'{}' is not recognized as a logging level name for "
             "'{}'. Please consider passing the "
             "logging level num instead.".format(log_level, setting_name)
@@ -509,7 +524,7 @@


 # run after terminalreporter/capturemanager are configured
-@pytest.hookimpl(trylast=True)
+@hookimpl(trylast=True)
 def pytest_configure(config: Config) -> None:
     config.pluginmanager.register(LoggingPlugin(config), "logging-plugin")

@@ -564,9 +579,9 @@
             terminal_reporter = config.pluginmanager.get_plugin("terminalreporter")
             capture_manager = config.pluginmanager.get_plugin("capturemanager")
             # if capturemanager plugin is disabled, live logging still works.
-            self.log_cli_handler = _LiveLoggingStreamHandler(
-                terminal_reporter, capture_manager
-            )  # type: Union[_LiveLoggingStreamHandler, _LiveLoggingNullHandler]
+            self.log_cli_handler: Union[
+                _LiveLoggingStreamHandler, _LiveLoggingNullHandler
+            ] = _LiveLoggingStreamHandler(terminal_reporter, capture_manager)
         else:
             self.log_cli_handler = _LiveLoggingNullHandler()
         log_cli_formatter = self._create_formatter(
@@ -582,9 +597,9 @@
         if color != "no" and ColoredLevelFormatter.LEVELNAME_FMT_REGEX.search(
             log_format
         ):
-            formatter = ColoredLevelFormatter(
+            formatter: logging.Formatter = ColoredLevelFormatter(
                 create_terminal_writer(self._config), log_format, log_date_format
-            )  # type: logging.Formatter
+            )
         else:
             formatter = logging.Formatter(log_format, log_date_format)

@@ -610,17 +625,9 @@
         if not fpath.parent.exists():
             fpath.parent.mkdir(exist_ok=True, parents=True)

-        stream = fpath.open(mode="w", encoding="UTF-8")
-        if sys.version_info >= (3, 7):
-            old_stream = self.log_file_handler.setStream(stream)
-        else:
-            old_stream = self.log_file_handler.stream
-            self.log_file_handler.acquire()
-            try:
-                self.log_file_handler.flush()
-                self.log_file_handler.stream = stream
-            finally:
-                self.log_file_handler.release()
+        # https://github.com/python/mypy/issues/11193
+        stream: io.TextIOWrapper = fpath.open(mode="w", encoding="UTF-8")  # type: ignore[assignment]
+        old_stream = self.log_file_handler.setStream(stream)
         if old_stream:
             old_stream.close()

@@ -639,7 +646,7 @@

         return True

-    @pytest.hookimpl(hookwrapper=True, tryfirst=True)
+    @hookimpl(hookwrapper=True, tryfirst=True)
     def pytest_sessionstart(self) -> Generator[None, None, None]:
         self.log_cli_handler.set_when("sessionstart")

@@ -647,7 +654,7 @@
             with catching_logs(self.log_file_handler, level=self.log_file_level):
                 yield

-    @pytest.hookimpl(hookwrapper=True, tryfirst=True)
+    @hookimpl(hookwrapper=True, tryfirst=True)
     def pytest_collection(self) -> Generator[None, None, None]:
         self.log_cli_handler.set_when("collection")

@@ -655,7 +662,7 @@
             with catching_logs(self.log_file_handler, level=self.log_file_level):
                 yield

-    @pytest.hookimpl(hookwrapper=True)
+    @hookimpl(hookwrapper=True)
     def pytest_runtestloop(self, session: Session) -> Generator[None, None, None]:
         if session.config.option.collectonly:
             yield
@@ -669,59 +676,61 @@
             with catching_logs(self.log_file_handler, level=self.log_file_level):
                 yield  # Run all the tests.

-    @pytest.hookimpl
+    @hookimpl
     def pytest_runtest_logstart(self) -> None:
         self.log_cli_handler.reset()
         self.log_cli_handler.set_when("start")

-    @pytest.hookimpl
+    @hookimpl
     def pytest_runtest_logreport(self) -> None:
         self.log_cli_handler.set_when("logreport")

     def _runtest_for(self, item: nodes.Item, when: str) -> Generator[None, None, None]:
         """Implement the internals of the pytest_runtest_xxx() hooks."""
         with catching_logs(
-            self.caplog_handler, level=self.log_level,
+            self.caplog_handler,
+            level=self.log_level,
         ) as caplog_handler, catching_logs(
-            self.report_handler, level=self.log_level,
+            self.report_handler,
+            level=self.log_level,
         ) as report_handler:
             caplog_handler.reset()
             report_handler.reset()
-            item._store[caplog_records_key][when] = caplog_handler.records
-            item._store[caplog_handler_key] = caplog_handler
+            item.stash[caplog_records_key][when] = caplog_handler.records
+            item.stash[caplog_handler_key] = caplog_handler

             yield

             log = report_handler.stream.getvalue().strip()
             item.add_report_section(when, "log", log)

-    @pytest.hookimpl(hookwrapper=True)
+    @hookimpl(hookwrapper=True)
     def pytest_runtest_setup(self, item: nodes.Item) -> Generator[None, None, None]:
         self.log_cli_handler.set_when("setup")

-        empty = {}  # type: Dict[str, List[logging.LogRecord]]
-        item._store[caplog_records_key] = empty
+        empty: Dict[str, List[logging.LogRecord]] = {}
+        item.stash[caplog_records_key] = empty
         yield from self._runtest_for(item, "setup")

-    @pytest.hookimpl(hookwrapper=True)
+    @hookimpl(hookwrapper=True)
     def pytest_runtest_call(self, item: nodes.Item) -> Generator[None, None, None]:
         self.log_cli_handler.set_when("call")

         yield from self._runtest_for(item, "call")

-    @pytest.hookimpl(hookwrapper=True)
+    @hookimpl(hookwrapper=True)
     def pytest_runtest_teardown(self, item: nodes.Item) -> Generator[None, None, None]:
         self.log_cli_handler.set_when("teardown")

         yield from self._runtest_for(item, "teardown")
-        del item._store[caplog_records_key]
-        del item._store[caplog_handler_key]
-
-    @pytest.hookimpl
+        del item.stash[caplog_records_key]
+        del item.stash[caplog_handler_key]
+
+    @hookimpl
     def pytest_runtest_logfinish(self) -> None:
         self.log_cli_handler.set_when("finish")

-    @pytest.hookimpl(hookwrapper=True, tryfirst=True)
+    @hookimpl(hookwrapper=True, tryfirst=True)
     def pytest_sessionfinish(self) -> Generator[None, None, None]:
         self.log_cli_handler.set_when("sessionfinish")

@@ -729,7 +738,7 @@
             with catching_logs(self.log_file_handler, level=self.log_file_level):
                 yield

-    @pytest.hookimpl
+    @hookimpl
     def pytest_unconfigure(self) -> None:
         # Close the FileHandler explicitly.
         # (logging.shutdown might have lost the weakref?!)
@@ -744,7 +753,7 @@
         pass


-class _LiveLoggingStreamHandler(logging.StreamHandler):
+class _LiveLoggingStreamHandler(logging_StreamHandler):
     """A logging StreamHandler used by the live logging feature: it will
     write a newline before the first log message in each test.

@@ -755,14 +764,14 @@

     # Officially stream needs to be a IO[str], but TerminalReporter
     # isn't. So force it.
-    stream = None  # type: TerminalReporter # type: ignore
+    stream: TerminalReporter = None  # type: ignore

     def __init__(
         self,
         terminal_reporter: TerminalReporter,
         capture_manager: Optional[CaptureManager],
     ) -> None:
-        logging.StreamHandler.__init__(self, stream=terminal_reporter)  # type: ignore[arg-type]
+        super().__init__(stream=terminal_reporter)  # type: ignore[arg-type]
         self.capture_manager = capture_manager
         self.reset()
         self.set_when(None)
('src/_pytest', 'unittest.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -9,13 +9,14 @@
 from typing import List
 from typing import Optional
 from typing import Tuple
+from typing import Type
+from typing import TYPE_CHECKING
 from typing import Union

 import _pytest._code
 import pytest
 from _pytest.compat import getimfunc
 from _pytest.compat import is_async_function
-from _pytest.compat import TYPE_CHECKING
 from _pytest.config import hookimpl
 from _pytest.fixtures import FixtureRequest
 from _pytest.nodes import Collector
@@ -26,16 +27,13 @@
 from _pytest.outcomes import xfail
 from _pytest.python import Class
 from _pytest.python import Function
-from _pytest.python import PyCollector
+from _pytest.python import Module
 from _pytest.runner import CallInfo
-from _pytest.skipping import skipped_by_mark_key
-from _pytest.skipping import unexpectedsuccess_key
+from _pytest.scope import Scope

 if TYPE_CHECKING:
     import unittest
-    from typing import Type
-
-    from _pytest.fixtures import _Scope
+    import twisted.trial.unittest

     _SysExcInfoType = Union[
         Tuple[Type[BaseException], BaseException, types.TracebackType],
@@ -44,7 +42,7 @@


 def pytest_pycollect_makeitem(
-    collector: PyCollector, name: str, obj: object
+    collector: Union[Module, Class], name: str, obj: object
 ) -> Optional["UnitTestCase"]:
     # Has unittest been imported and is obj a subclass of its TestCase?
     try:
@@ -55,7 +53,7 @@
     except Exception:
         return None
     # Yes, so let's collect it.
-    item = UnitTestCase.from_parent(collector, name=name, obj=obj)  # type: UnitTestCase
+    item: UnitTestCase = UnitTestCase.from_parent(collector, name=name, obj=obj)
     return item


@@ -99,54 +97,106 @@
         """Injects a hidden auto-use fixture to invoke setUpClass/setup_method and corresponding
         teardown functions (#517)."""
         class_fixture = _make_xunit_fixture(
-            cls, "setUpClass", "tearDownClass", scope="class", pass_self=False
+            cls,
+            "setUpClass",
+            "tearDownClass",
+            "doClassCleanups",
+            scope=Scope.Class,
+            pass_self=False,
         )
         if class_fixture:
             cls.__pytest_class_setup = class_fixture  # type: ignore[attr-defined]

         method_fixture = _make_xunit_fixture(
-            cls, "setup_method", "teardown_method", scope="function", pass_self=True
+            cls,
+            "setup_method",
+            "teardown_method",
+            None,
+            scope=Scope.Function,
+            pass_self=True,
         )
         if method_fixture:
             cls.__pytest_method_setup = method_fixture  # type: ignore[attr-defined]


 def _make_xunit_fixture(
-    obj: type, setup_name: str, teardown_name: str, scope: "_Scope", pass_self: bool
+    obj: type,
+    setup_name: str,
+    teardown_name: str,
+    cleanup_name: Optional[str],
+    scope: Scope,
+    pass_self: bool,
 ):
     setup = getattr(obj, setup_name, None)
     teardown = getattr(obj, teardown_name, None)
     if setup is None and teardown is None:
         return None

-    @pytest.fixture(scope=scope, autouse=True)
+    if cleanup_name:
+        cleanup = getattr(obj, cleanup_name, lambda *args: None)
+    else:
+
+        def cleanup(*args):
+            pass
+
+    @pytest.fixture(
+        scope=scope.value,
+        autouse=True,
+        # Use a unique name to speed up lookup.
+        name=f"_unittest_{setup_name}_fixture_{obj.__qualname__}",
+    )
     def fixture(self, request: FixtureRequest) -> Generator[None, None, None]:
         if _is_skipped(self):
             reason = self.__unittest_skip_why__
-            pytest.skip(reason)
+            raise pytest.skip.Exception(reason, _use_item_location=True)
         if setup is not None:
+            try:
+                if pass_self:
+                    setup(self, request.function)
+                else:
+                    setup()
+            # unittest does not call the cleanup function for every BaseException, so we
+            # follow this here.
+            except Exception:
+                if pass_self:
+                    cleanup(self)
+                else:
+                    cleanup()
+
+                raise
+        yield
+        try:
+            if teardown is not None:
+                if pass_self:
+                    teardown(self, request.function)
+                else:
+                    teardown()
+        finally:
             if pass_self:
-                setup(self, request.function)
+                cleanup(self)
             else:
-                setup()
-        yield
-        if teardown is not None:
-            if pass_self:
-                teardown(self, request.function)
-            else:
-                teardown()
+                cleanup()

     return fixture


 class TestCaseFunction(Function):
     nofuncargs = True
-    _excinfo = None  # type: Optional[List[_pytest._code.ExceptionInfo[BaseException]]]
-    _testcase = None  # type: Optional[unittest.TestCase]
+    _excinfo: Optional[List[_pytest._code.ExceptionInfo[BaseException]]] = None
+    _testcase: Optional["unittest.TestCase"] = None
+
+    def _getobj(self):
+        assert self.parent is not None
+        # Unlike a regular Function in a Class, where `item.obj` returns
+        # a *bound* method (attached to an instance), TestCaseFunction's
+        # `obj` returns an *unbound* method (not attached to an instance).
+        # This inconsistency is probably not desirable, but needs some
+        # consideration before changing.
+        return getattr(self.parent.obj, self.originalname)  # type: ignore[attr-defined]

     def setup(self) -> None:
         # A bound method to be called during teardown() if set (see 'runtest()').
-        self._explicit_tearDown = None  # type: Optional[Callable[[], None]]
+        self._explicit_tearDown: Optional[Callable[[], None]] = None
         assert self.parent is not None
         self._testcase = self.parent.obj(self.name)  # type: ignore[attr-defined]
         self._obj = getattr(self._testcase, self.name)
@@ -167,7 +217,7 @@
         # Unwrap potential exception info (see twisted trial support below).
         rawexcinfo = getattr(rawexcinfo, "_rawexcinfo", rawexcinfo)
         try:
-            excinfo = _pytest._code.ExceptionInfo(rawexcinfo)  # type: ignore[arg-type]
+            excinfo = _pytest._code.ExceptionInfo[BaseException].from_exc_info(rawexcinfo)  # type: ignore[arg-type]
             # Invoke the attributes to trigger storing the traceback
             # trial causes some issue there.
             excinfo.value
@@ -213,9 +263,8 @@

     def addSkip(self, testcase: "unittest.TestCase", reason: str) -> None:
         try:
-            skip(reason)
+            raise pytest.skip.Exception(reason, _use_item_location=True)
         except skip.Exception:
-            self._store[skipped_by_mark_key] = True
             self._addexcinfo(sys.exc_info())

     def addExpectedFailure(
@@ -230,24 +279,24 @@
             self._addexcinfo(sys.exc_info())

     def addUnexpectedSuccess(
-        self, testcase: "unittest.TestCase", reason: str = ""
+        self,
+        testcase: "unittest.TestCase",
+        reason: Optional["twisted.trial.unittest.Todo"] = None,
     ) -> None:
-        self._store[unexpectedsuccess_key] = reason
+        msg = "Unexpected success"
+        if reason:
+            msg += f": {reason.reason}"
+        # Preserve unittest behaviour - fail the test. Explicitly not an XPASS.
+        try:
+            fail(msg, pytrace=False)
+        except fail.Exception:
+            self._addexcinfo(sys.exc_info())

     def addSuccess(self, testcase: "unittest.TestCase") -> None:
         pass

     def stopTest(self, testcase: "unittest.TestCase") -> None:
         pass
-
-    def _expecting_failure(self, test_method) -> bool:
-        """Return True if the given unittest method (or the entire class) is marked
-        with @expectedFailure."""
-        expecting_failure_method = getattr(
-            test_method, "__unittest_expecting_failure__", False
-        )
-        expecting_failure_class = getattr(self, "__unittest_expecting_failure__", False)
-        return bool(expecting_failure_class or expecting_failure_method)

     def runtest(self) -> None:
         from _pytest.debugging import maybe_wrap_pytest_function_for_tracing
@@ -282,7 +331,7 @@
     def _prunetraceback(
         self, excinfo: _pytest._code.ExceptionInfo[BaseException]
     ) -> None:
-        Function._prunetraceback(self, excinfo)
+        super()._prunetraceback(excinfo)
         traceback = excinfo.traceback.filter(
             lambda x: not x.frame.f_globals.get("__unittest")
         )
@@ -300,6 +349,10 @@
             except AttributeError:
                 pass

+    # Convert unittest.SkipTest to pytest.skip.
+    # This is actually only needed for nose, which reuses unittest.SkipTest for
+    # its own nose.SkipTest. For unittest TestCases, SkipTest is already
+    # handled internally, and doesn't reach here.
     unittest = sys.modules.get("unittest")
     if (
         unittest
@@ -307,7 +360,6 @@
         and isinstance(call.excinfo.value, unittest.SkipTest)  # type: ignore[attr-defined]
     ):
         excinfo = call.excinfo
-        # Let's substitute the excinfo with a pytest.skip one.
         call2 = CallInfo[None].from_call(
             lambda: pytest.skip(str(excinfo.value)), call.when
         )
@@ -320,7 +372,7 @@
 @hookimpl(hookwrapper=True)
 def pytest_runtest_protocol(item: Item) -> Generator[None, None, None]:
     if isinstance(item, TestCaseFunction) and "twisted.trial.unittest" in sys.modules:
-        ut = sys.modules["twisted.python.failure"]  # type: Any
+        ut: Any = sys.modules["twisted.python.failure"]
         Failure__init__ = ut.Failure.__init__
         check_testcase_implements_trial_reporter()

('src/_pytest', 'runner.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -9,6 +9,8 @@
 from typing import List
 from typing import Optional
 from typing import Tuple
+from typing import Type
+from typing import TYPE_CHECKING
 from typing import TypeVar
 from typing import Union

@@ -23,17 +25,17 @@
 from _pytest._code.code import ExceptionInfo
 from _pytest._code.code import TerminalRepr
 from _pytest.compat import final
-from _pytest.compat import TYPE_CHECKING
 from _pytest.config.argparsing import Parser
+from _pytest.deprecated import check_ispytest
 from _pytest.nodes import Collector
 from _pytest.nodes import Item
 from _pytest.nodes import Node
 from _pytest.outcomes import Exit
+from _pytest.outcomes import OutcomeException
 from _pytest.outcomes import Skipped
 from _pytest.outcomes import TEST_OUTCOME

 if TYPE_CHECKING:
-    from typing import Type
     from typing_extensions import Literal

     from _pytest.main import Session
@@ -77,8 +79,7 @@
                 dlist.append(rep)
     if not dlist:
         return
-    dlist.sort(key=lambda x: x.duration)
-    dlist.reverse()
+    dlist.sort(key=lambda x: x.duration, reverse=True)  # type: ignore[no-any-return]
     if not durations:
         tr.write_sep("=", "slowest durations")
     else:
@@ -93,7 +94,7 @@
                 % (len(dlist) - i, durations_min)
             )
             break
-        tr.write_line("{:02.2f}s {:<8} {}".format(rep.duration, rep.when, rep.nodeid))
+        tr.write_line(f"{rep.duration:02.2f}s {rep.when:<8} {rep.nodeid}")


 def pytest_sessionstart(session: "Session") -> None:
@@ -101,7 +102,7 @@


 def pytest_sessionfinish(session: "Session") -> None:
-    session._setupstate.teardown_all()
+    session._setupstate.teardown_exact(None)


 def pytest_runtest_protocol(item: Item, nextitem: Optional[Item]) -> bool:
@@ -117,6 +118,8 @@
 ) -> List[TestReport]:
     hasrequest = hasattr(item, "_request")
     if hasrequest and not item._request:  # type: ignore[attr-defined]
+        # This only happens if the item is re-run, as is done by
+        # pytest-rerunfailures.
         item._initrequest()  # type: ignore[attr-defined]
     rep = call_and_report(item, "setup", log)
     reports = [rep]
@@ -148,7 +151,7 @@

 def pytest_runtest_setup(item: Item) -> None:
     _update_current_test_var(item, "setup")
-    item.session._setupstate.prepare(item)
+    item.session._setupstate.setup(item)


 def pytest_runtest_call(item: Item) -> None:
@@ -173,7 +176,7 @@

 def pytest_runtest_teardown(item: Item, nextitem: Optional[Item]) -> None:
     _update_current_test_var(item, "teardown")
-    item.session._setupstate.teardown_exact(item, nextitem)
+    item.session._setupstate.teardown_exact(nextitem)
     _update_current_test_var(item, None)


@@ -186,7 +189,7 @@
     """
     var_name = "PYTEST_CURRENT_TEST"
     if when:
-        value = "{} ({})".format(item.nodeid, when)
+        value = f"{item.nodeid} ({when})"
         # don't allow null bytes on environment variables (see #2644, #2957)
         value = value.replace("\x00", "(null)")
         os.environ[var_name] = value
@@ -215,7 +218,7 @@
 ) -> TestReport:
     call = call_runtest_hook(item, when, **kwds)
     hook = item.ihook
-    report = hook.pytest_runtest_makereport(item=item, call=call)  # type: TestReport
+    report: TestReport = hook.pytest_runtest_makereport(item=item, call=call)
     if log:
         hook.pytest_runtest_logreport(report=report)
     if check_interactive_exception(call, report):
@@ -242,14 +245,14 @@
     item: Item, when: "Literal['setup', 'call', 'teardown']", **kwds
 ) -> "CallInfo[None]":
     if when == "setup":
-        ihook = item.ihook.pytest_runtest_setup  # type: Callable[..., None]
+        ihook: Callable[..., None] = item.ihook.pytest_runtest_setup
     elif when == "call":
         ihook = item.ihook.pytest_runtest_call
     elif when == "teardown":
         ihook = item.ihook.pytest_runtest_teardown
     else:
-        assert False, "Unhandled runtest hook case: {}".format(when)
-    reraise = (Exit,)  # type: Tuple[Type[BaseException], ...]
+        assert False, f"Unhandled runtest hook case: {when}"
+    reraise: Tuple[Type[BaseException], ...] = (Exit,)
     if not item.config.getoption("usepdb", False):
         reraise += (KeyboardInterrupt,)
     return CallInfo.from_call(
@@ -261,36 +264,49 @@


 @final
-@attr.s(repr=False)
+@attr.s(repr=False, init=False, auto_attribs=True)
 class CallInfo(Generic[TResult]):
-    """Result/Exception info a function invocation.
-
-    :param T result:
-        The return value of the call, if it didn't raise. Can only be
-        accessed if excinfo is None.
-    :param Optional[ExceptionInfo] excinfo:
-        The captured exception of the call, if it raised.
-    :param float start:
-        The system time when the call started, in seconds since the epoch.
-    :param float stop:
-        The system time when the call ended, in seconds since the epoch.
-    :param float duration:
-        The call duration, in seconds.
-    :param str when:
-        The context of invocation: "setup", "call", "teardown", ...
-    """
-
-    _result = attr.ib(type="Optional[TResult]")
-    excinfo = attr.ib(type=Optional[ExceptionInfo[BaseException]])
-    start = attr.ib(type=float)
-    stop = attr.ib(type=float)
-    duration = attr.ib(type=float)
-    when = attr.ib(type="Literal['collect', 'setup', 'call', 'teardown']")
+    """Result/Exception info of a function invocation."""
+
+    _result: Optional[TResult]
+    #: The captured exception of the call, if it raised.
+    excinfo: Optional[ExceptionInfo[BaseException]]
+    #: The system time when the call started, in seconds since the epoch.
+    start: float
+    #: The system time when the call ended, in seconds since the epoch.
+    stop: float
+    #: The call duration, in seconds.
+    duration: float
+    #: The context of invocation: "collect", "setup", "call" or "teardown".
+    when: "Literal['collect', 'setup', 'call', 'teardown']"
+
+    def __init__(
+        self,
+        result: Optional[TResult],
+        excinfo: Optional[ExceptionInfo[BaseException]],
+        start: float,
+        stop: float,
+        duration: float,
+        when: "Literal['collect', 'setup', 'call', 'teardown']",
+        *,
+        _ispytest: bool = False,
+    ) -> None:
+        check_ispytest(_ispytest)
+        self._result = result
+        self.excinfo = excinfo
+        self.start = start
+        self.stop = stop
+        self.duration = duration
+        self.when = when

     @property
     def result(self) -> TResult:
+        """The return value of the call, if it didn't raise.
+
+        Can only be accessed if excinfo is None.
+        """
         if self.excinfo is not None:
-            raise AttributeError("{!r} has no valid result".format(self))
+            raise AttributeError(f"{self!r} has no valid result")
         # The cast is safe because an exception wasn't raised, hence
         # _result has the expected function return type (which may be
         #  None, that's why a cast and not an assert).
@@ -301,13 +317,25 @@
         cls,
         func: "Callable[[], TResult]",
         when: "Literal['collect', 'setup', 'call', 'teardown']",
-        reraise: "Optional[Union[Type[BaseException], Tuple[Type[BaseException], ...]]]" = None,
+        reraise: Optional[
+            Union[Type[BaseException], Tuple[Type[BaseException], ...]]
+        ] = None,
     ) -> "CallInfo[TResult]":
+        """Call func, wrapping the result in a CallInfo.
+
+        :param func:
+            The function to call. Called without arguments.
+        :param when:
+            The phase in which the function is called.
+        :param reraise:
+            Exception or exceptions that shall propagate if raised by the
+            function, instead of being wrapped in the CallInfo.
+        """
         excinfo = None
         start = timing.time()
         precise_start = timing.perf_counter()
         try:
-            result = func()  # type: Optional[TResult]
+            result: Optional[TResult] = func()
         except BaseException:
             excinfo = ExceptionInfo.from_current()
             if reraise is not None and isinstance(excinfo.value, reraise):
@@ -324,12 +352,13 @@
             when=when,
             result=result,
             excinfo=excinfo,
+            _ispytest=True,
         )

     def __repr__(self) -> str:
         if self.excinfo is None:
-            return "<CallInfo when={!r} result: {!r}>".format(self.when, self._result)
-        return "<CallInfo when={!r} excinfo={!r}>".format(self.when, self.excinfo)
+            return f"<CallInfo when={self.when!r} result: {self._result!r}>"
+        return f"<CallInfo when={self.when!r} excinfo={self.excinfo!r}>"


 def pytest_runtest_makereport(item: Item, call: CallInfo[None]) -> TestReport:
@@ -338,9 +367,9 @@

 def pytest_make_collect_report(collector: Collector) -> CollectReport:
     call = CallInfo.from_call(lambda: list(collector.collect()), "collect")
-    longrepr = None  # type: Union[None, Tuple[str, int, str], str, TerminalRepr]
+    longrepr: Union[None, Tuple[str, int, str], str, TerminalRepr] = None
     if not call.excinfo:
-        outcome = "passed"  # type: Literal["passed", "skipped", "failed"]
+        outcome: Literal["passed", "skipped", "failed"] = "passed"
     else:
         skip_exceptions = [Skipped]
         unittest = sys.modules.get("unittest")
@@ -368,93 +397,144 @@


 class SetupState:
-    """Shared state for setting up/tearing down test items or collectors."""
-
-    def __init__(self):
-        self.stack = []  # type: List[Node]
-        self._finalizers = {}  # type: Dict[Node, List[Callable[[], object]]]
-
-    def addfinalizer(self, finalizer: Callable[[], object], colitem) -> None:
-        """Attach a finalizer to the given colitem."""
-        assert colitem and not isinstance(colitem, tuple)
+    """Shared state for setting up/tearing down test items or collectors
+    in a session.
+
+    Suppose we have a collection tree as follows:
+
+    <Session session>
+        <Module mod1>
+            <Function item1>
+        <Module mod2>
+            <Function item2>
+
+    The SetupState maintains a stack. The stack starts out empty:
+
+        []
+
+    During the setup phase of item1, setup(item1) is called. What it does
+    is:
+
+        push session to stack, run session.setup()
+        push mod1 to stack, run mod1.setup()
+        push item1 to stack, run item1.setup()
+
+    The stack is:
+
+        [session, mod1, item1]
+
+    While the stack is in this shape, it is allowed to add finalizers to
+    each of session, mod1, item1 using addfinalizer().
+
+    During the teardown phase of item1, teardown_exact(item2) is called,
+    where item2 is the next item to item1. What it does is:
+
+        pop item1 from stack, run its teardowns
+        pop mod1 from stack, run its teardowns
+
+    mod1 was popped because it ended its purpose with item1. The stack is:
+
+        [session]
+
+    During the setup phase of item2, setup(item2) is called. What it does
+    is:
+
+        push mod2 to stack, run mod2.setup()
+        push item2 to stack, run item2.setup()
+
+    Stack:
+
+        [session, mod2, item2]
+
+    During the teardown phase of item2, teardown_exact(None) is called,
+    because item2 is the last item. What it does is:
+
+        pop item2 from stack, run its teardowns
+        pop mod2 from stack, run its teardowns
+        pop session from stack, run its teardowns
+
+    Stack:
+
+        []
+
+    The end!
+    """
+
+    def __init__(self) -> None:
+        # The stack is in the dict insertion order.
+        self.stack: Dict[
+            Node,
+            Tuple[
+                # Node's finalizers.
+                List[Callable[[], object]],
+                # Node's exception, if its setup raised.
+                Optional[Union[OutcomeException, Exception]],
+            ],
+        ] = {}
+
+    def setup(self, item: Item) -> None:
+        """Setup objects along the collector chain to the item."""
+        needed_collectors = item.listchain()
+
+        # If a collector fails its setup, fail its entire subtree of items.
+        # The setup is not retried for each item - the same exception is used.
+        for col, (finalizers, exc) in self.stack.items():
+            assert col in needed_collectors, "previous item was not torn down properly"
+            if exc:
+                raise exc
+
+        for col in needed_collectors[len(self.stack) :]:
+            assert col not in self.stack
+            # Push onto the stack.
+            self.stack[col] = ([col.teardown], None)
+            try:
+                col.setup()
+            except TEST_OUTCOME as exc:
+                self.stack[col] = (self.stack[col][0], exc)
+                raise exc
+
+    def addfinalizer(self, finalizer: Callable[[], object], node: Node) -> None:
+        """Attach a finalizer to the given node.
+
+        The node must be currently active in the stack.
+        """
+        assert node and not isinstance(node, tuple)
         assert callable(finalizer)
-        # assert colitem in self.stack  # some unit tests don't setup stack :/
-        self._finalizers.setdefault(colitem, []).append(finalizer)
-
-    def _pop_and_teardown(self):
-        colitem = self.stack.pop()
-        self._teardown_with_finalization(colitem)
-
-    def _callfinalizers(self, colitem) -> None:
-        finalizers = self._finalizers.pop(colitem, None)
+        assert node in self.stack, (node, self.stack)
+        self.stack[node][0].append(finalizer)
+
+    def teardown_exact(self, nextitem: Optional[Item]) -> None:
+        """Teardown the current stack up until reaching nodes that nextitem
+        also descends from.
+
+        When nextitem is None (meaning we're at the last item), the entire
+        stack is torn down.
+        """
+        needed_collectors = nextitem and nextitem.listchain() or []
         exc = None
-        while finalizers:
-            fin = finalizers.pop()
-            try:
-                fin()
-            except TEST_OUTCOME as e:
-                # XXX Only first exception will be seen by user,
-                #     ideally all should be reported.
-                if exc is None:
-                    exc = e
+        while self.stack:
+            if list(self.stack.keys()) == needed_collectors[: len(self.stack)]:
+                break
+            node, (finalizers, _) = self.stack.popitem()
+            while finalizers:
+                fin = finalizers.pop()
+                try:
+                    fin()
+                except TEST_OUTCOME as e:
+                    # XXX Only first exception will be seen by user,
+                    #     ideally all should be reported.
+                    if exc is None:
+                        exc = e
         if exc:
             raise exc
-
-    def _teardown_with_finalization(self, colitem) -> None:
-        self._callfinalizers(colitem)
-        colitem.teardown()
-        for colitem in self._finalizers:
-            assert colitem in self.stack
-
-    def teardown_all(self) -> None:
-        while self.stack:
-            self._pop_and_teardown()
-        for key in list(self._finalizers):
-            self._teardown_with_finalization(key)
-        assert not self._finalizers
-
-    def teardown_exact(self, item, nextitem) -> None:
-        needed_collectors = nextitem and nextitem.listchain() or []
-        self._teardown_towards(needed_collectors)
-
-    def _teardown_towards(self, needed_collectors) -> None:
-        exc = None
-        while self.stack:
-            if self.stack == needed_collectors[: len(self.stack)]:
-                break
-            try:
-                self._pop_and_teardown()
-            except TEST_OUTCOME as e:
-                # XXX Only first exception will be seen by user,
-                #     ideally all should be reported.
-                if exc is None:
-                    exc = e
-        if exc:
-            raise exc
-
-    def prepare(self, colitem) -> None:
-        """Setup objects along the collector chain to the test-method."""
-
-        # Check if the last collection node has raised an error.
-        for col in self.stack:
-            if hasattr(col, "_prepare_exc"):
-                exc = col._prepare_exc  # type: ignore[attr-defined]
-                raise exc
-
-        needed_collectors = colitem.listchain()
-        for col in needed_collectors[len(self.stack) :]:
-            self.stack.append(col)
-            try:
-                col.setup()
-            except TEST_OUTCOME as e:
-                col._prepare_exc = e  # type: ignore[attr-defined]
-                raise e
+        if nextitem is None:
+            assert not self.stack


 def collect_one_node(collector: Collector) -> CollectReport:
     ihook = collector.ihook
     ihook.pytest_collectstart(collector=collector)
-    rep = ihook.pytest_make_collect_report(collector=collector)  # type: CollectReport
+    rep: CollectReport = ihook.pytest_make_collect_report(collector=collector)
     call = rep.__dict__.pop("call", None)
     if call and check_interactive_exception(call, rep):
         ihook.pytest_exception_interact(node=collector, call=call, report=rep)
('src/_pytest', 'helpconfig.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -5,8 +5,6 @@
 from typing import List
 from typing import Optional
 from typing import Union
-
-import py

 import pytest
 from _pytest.config import Config
@@ -51,7 +49,7 @@
         action="count",
         default=0,
         dest="version",
-        help="display pytest version and information about plugins."
+        help="display pytest version and information about plugins. "
         "When given twice, also display information about plugins.",
     )
     group._addoption(
@@ -80,10 +78,14 @@
     )
     group.addoption(
         "--debug",
-        action="store_true",
+        action="store",
+        nargs="?",
+        const="pytestdebug.log",
         dest="debug",
-        default=False,
-        help="store internal tracing debug information in 'pytestdebug.log'.",
+        metavar="DEBUG_FILE_NAME",
+        help="store internal tracing debug information in this log file.\n"
+        "This file is opened with 'w' and truncated as a result, care advised.\n"
+        "Defaults to 'pytestdebug.log'.",
     )
     group._addoption(
         "-o",
@@ -97,16 +99,17 @@
 @pytest.hookimpl(hookwrapper=True)
 def pytest_cmdline_parse():
     outcome = yield
-    config = outcome.get_result()  # type: Config
+    config: Config = outcome.get_result()
+
     if config.option.debug:
-        path = os.path.abspath("pytestdebug.log")
+        # --debug | --debug <file.log> was provided.
+        path = config.option.debug
         debugfile = open(path, "w")
         debugfile.write(
-            "versions pytest-%s, py-%s, "
+            "versions pytest-%s, "
             "python-%s\ncwd=%s\nargs=%s\n\n"
             % (
                 pytest.__version__,
-                py.__version__,
                 ".".join(map(str, sys.version_info)),
                 os.getcwd(),
                 config.invocation_params.args,
@@ -114,11 +117,11 @@
         )
         config.trace.root.setwriter(debugfile.write)
         undo_tracing = config.pluginmanager.enable_tracing()
-        sys.stderr.write("writing pytestdebug information to %s\n" % path)
+        sys.stderr.write("writing pytest debug information to %s\n" % path)

         def unset_tracing() -> None:
             debugfile.close()
-            sys.stderr.write("wrote pytestdebug information to %s\n" % debugfile.name)
+            sys.stderr.write("wrote pytest debug information to %s\n" % debugfile.name)
             config.trace.root.setwriter(None)
             undo_tracing()

@@ -127,7 +130,7 @@

 def showversion(config: Config) -> None:
     if config.option.version > 1:
-        sys.stderr.write(
+        sys.stdout.write(
             "This is pytest version {}, imported from {}\n".format(
                 pytest.__version__, pytest.__file__
             )
@@ -135,9 +138,9 @@
         plugininfo = getpluginversioninfo(config)
         if plugininfo:
             for line in plugininfo:
-                sys.stderr.write(line + "\n")
+                sys.stdout.write(line + "\n")
     else:
-        sys.stderr.write("pytest {}\n".format(pytest.__version__))
+        sys.stdout.write(f"pytest {pytest.__version__}\n")


 def pytest_cmdline_main(config: Config) -> Optional[Union[int, ExitCode]]:
@@ -172,8 +175,8 @@
         if type is None:
             type = "string"
         if help is None:
-            raise TypeError("help argument cannot be None for {}".format(name))
-        spec = "{} ({}):".format(name, type)
+            raise TypeError(f"help argument cannot be None for {name}")
+        spec = f"{name} ({type}):"
         tw.write("  %s" % spec)
         spec_len = len(spec)
         if spec_len > (indent_len - 3):
@@ -208,7 +211,7 @@
         ("PYTEST_DEBUG", "set to enable debug tracing of pytest's internals"),
     ]
     for name, help in vars:
-        tw.line("  {:<24} {}".format(name, help))
+        tw.line(f"  {name:<24} {help}")
     tw.line()
     tw.line()

@@ -235,7 +238,7 @@
         lines.append("setuptools registered plugins:")
         for plugin, dist in plugininfo:
             loc = getattr(plugin, "__file__", repr(plugin))
-            content = "{}-{} at {}".format(dist.project_name, dist.version, loc)
+            content = f"{dist.project_name}-{dist.version} at {loc}"
             lines.append("  " + content)
     return lines

@@ -243,9 +246,7 @@
 def pytest_report_header(config: Config) -> List[str]:
     lines = []
     if config.option.debug or config.option.traceconfig:
-        lines.append(
-            "using: pytest-{} pylib-{}".format(pytest.__version__, py.__version__)
-        )
+        lines.append(f"using: pytest-{pytest.__version__}")

         verinfo = getpluginversioninfo(config)
         if verinfo:
@@ -259,5 +260,5 @@
                 r = plugin.__file__
             else:
                 r = repr(plugin)
-            lines.append("    {:<20}: {}".format(name, r))
+            lines.append(f"    {name:<20}: {r}")
     return lines
('src/_pytest', 'pastebin.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -8,11 +8,11 @@
 from _pytest.config import Config
 from _pytest.config import create_terminal_writer
 from _pytest.config.argparsing import Parser
-from _pytest.store import StoreKey
+from _pytest.stash import StashKey
 from _pytest.terminal import TerminalReporter


-pastebinfile_key = StoreKey[IO[bytes]]()
+pastebinfile_key = StashKey[IO[bytes]]()


 def pytest_addoption(parser: Parser) -> None:
@@ -37,26 +37,26 @@
         # when using pytest-xdist, for example.
         if tr is not None:
             # pastebin file will be UTF-8 encoded binary file.
-            config._store[pastebinfile_key] = tempfile.TemporaryFile("w+b")
+            config.stash[pastebinfile_key] = tempfile.TemporaryFile("w+b")
             oldwrite = tr._tw.write

             def tee_write(s, **kwargs):
                 oldwrite(s, **kwargs)
                 if isinstance(s, str):
                     s = s.encode("utf-8")
-                config._store[pastebinfile_key].write(s)
+                config.stash[pastebinfile_key].write(s)

             tr._tw.write = tee_write


 def pytest_unconfigure(config: Config) -> None:
-    if pastebinfile_key in config._store:
-        pastebinfile = config._store[pastebinfile_key]
+    if pastebinfile_key in config.stash:
+        pastebinfile = config.stash[pastebinfile_key]
         # Get terminal contents and delete file.
         pastebinfile.seek(0)
         sessionlog = pastebinfile.read()
         pastebinfile.close()
-        del config._store[pastebinfile_key]
+        del config.stash[pastebinfile_key]
         # Undo our patching in the terminal reporter.
         tr = config.pluginmanager.getplugin("terminalreporter")
         del tr._tw.__dict__["write"]
@@ -77,16 +77,16 @@
     from urllib.parse import urlencode

     params = {"code": contents, "lexer": "text", "expiry": "1week"}
-    url = "https://bpaste.net"
+    url = "https://bpa.st"
     try:
-        response = (
+        response: str = (
             urlopen(url, data=urlencode(params).encode("ascii")).read().decode("utf-8")
-        )  # type: str
+        )
     except OSError as exc_info:  # urllib errors
         return "bad response: %s" % exc_info
     m = re.search(r'href="/raw/(\w+)"', response)
     if m:
-        return "{}/show/{}".format(url, m.group(1))
+        return f"{url}/show/{m.group(1)}"
     else:
         return "bad response: invalid format ('" + response + "')"

@@ -107,4 +107,4 @@
             s = file.getvalue()
             assert len(s)
             pastebinurl = create_new_paste(s)
-            terminalreporter.write_line("{} --> {}".format(msg, pastebinurl))
+            terminalreporter.write_line(f"{msg} --> {pastebinurl}")
('src/_pytest', 'compat.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -3,39 +3,42 @@
 import functools
 import inspect
 import os
-import re
 import sys
-from contextlib import contextmanager
 from inspect import Parameter
 from inspect import signature
+from pathlib import Path
 from typing import Any
 from typing import Callable
 from typing import Generic
 from typing import Optional
-from typing import overload as overload
 from typing import Tuple
+from typing import TYPE_CHECKING
 from typing import TypeVar
 from typing import Union

 import attr
-
-from _pytest.outcomes import fail
-from _pytest.outcomes import TEST_OUTCOME
-
-if sys.version_info < (3, 5, 2):
-    TYPE_CHECKING = False  # type: bool
-else:
-    from typing import TYPE_CHECKING
-
+import py

 if TYPE_CHECKING:
     from typing import NoReturn
-    from typing import Type
     from typing_extensions import Final


 _T = TypeVar("_T")
 _S = TypeVar("_S")
+
+#: constant to prepare valuing pylib path replacements/lazy proxies later on
+#  intended for removal in pytest 8.0 or 9.0
+
+# fmt: off
+# intentional space to create a fake difference for the verification
+LEGACY_PATH = py.path. local
+# fmt: on
+
+
+def legacy_path(path: Union[str, "os.PathLike[str]"]) -> LEGACY_PATH:
+    """Internal wrapper to prepare lazy proxies for legacy_path instances"""
+    return LEGACY_PATH(path)


 # fmt: off
@@ -43,13 +46,8 @@
 # https://www.python.org/dev/peps/pep-0484/#support-for-singleton-types-in-unions
 class NotSetType(enum.Enum):
     token = 0
-NOTSET = NotSetType.token  # type: Final # noqa: E305
+NOTSET: "Final" = NotSetType.token  # noqa: E305
 # fmt: on
-
-MODULE_NOT_FOUND_ERROR = (
-    "ModuleNotFoundError" if sys.version_info[:2] >= (3, 6) else "ImportError"
-)
-

 if sys.version_info >= (3, 8):
     from importlib import metadata as importlib_metadata
@@ -59,22 +57,6 @@

 def _format_args(func: Callable[..., Any]) -> str:
     return str(signature(func))
-
-
-# The type of re.compile objects is not exposed in Python.
-REGEX_TYPE = type(re.compile(""))
-
-
-if sys.version_info < (3, 6):
-
-    def fspath(p):
-        """os.fspath replacement, useful to point out when we should replace it by the
-        real function once we drop py35."""
-        return str(p)
-
-
-else:
-    fspath = os.fspath


 def is_generator(func: object) -> bool:
@@ -97,14 +79,10 @@
 def is_async_function(func: object) -> bool:
     """Return True if the given function seems to be an async function or
     an async generator."""
-    return iscoroutinefunction(func) or (
-        sys.version_info >= (3, 6) and inspect.isasyncgenfunction(func)
-    )
+    return iscoroutinefunction(func) or inspect.isasyncgenfunction(func)


 def getlocation(function, curdir: Optional[str] = None) -> str:
-    from _pytest.pathlib import Path
-
     function = get_real_func(function)
     fn = Path(inspect.getfile(function))
     lineno = function.__code__.co_firstlineno
@@ -142,7 +120,7 @@
     *,
     name: str = "",
     is_method: bool = False,
-    cls: Optional[type] = None
+    cls: Optional[type] = None,
 ) -> Tuple[str, ...]:
     """Return the names of a function's mandatory arguments.

@@ -170,8 +148,10 @@
     try:
         parameters = signature(function).parameters
     except (ValueError, TypeError) as e:
+        from _pytest.outcomes import fail
+
         fail(
-            "Could not determine arguments of {!r}: {}".format(function, e),
+            f"Could not determine arguments of {function!r}: {e}",
             pytrace=False,
         )

@@ -179,9 +159,8 @@
         p.name
         for p in parameters.values()
         if (
-            # TODO: Remove type ignore after https://github.com/python/typeshed/pull/4383
-            p.kind is Parameter.POSITIONAL_OR_KEYWORD  # type: ignore[unreachable]
-            or p.kind is Parameter.KEYWORD_ONLY  # type: ignore[unreachable]
+            p.kind is Parameter.POSITIONAL_OR_KEYWORD
+            or p.kind is Parameter.KEYWORD_ONLY
         )
         and p.default is Parameter.empty
     )
@@ -192,24 +171,18 @@
     # it's passed as an unbound method or function, remove the first
     # parameter name.
     if is_method or (
-        cls and not isinstance(cls.__dict__.get(name, None), staticmethod)
+        # Not using `getattr` because we don't want to resolve the staticmethod.
+        # Not using `cls.__dict__` because we want to check the entire MRO.
+        cls
+        and not isinstance(
+            inspect.getattr_static(cls, name, default=None), staticmethod
+        )
     ):
         arg_names = arg_names[1:]
     # Remove any names that will be replaced with mocks.
     if hasattr(function, "__wrapped__"):
         arg_names = arg_names[num_mock_patch_args(function) :]
     return arg_names
-
-
-if sys.version_info < (3, 7):
-
-    @contextmanager
-    def nullcontext():
-        yield
-
-
-else:
-    from contextlib import nullcontext as nullcontext  # noqa: F401


 def get_default_arg_names(function: Callable[..., Any]) -> Tuple[str, ...]:
@@ -225,7 +198,7 @@


 _non_printable_ascii_translate_table = {
-    i: "\\x{:02x}".format(i) for i in range(128) if i not in range(32, 127)
+    i: f"\\x{i:02x}" for i in range(128) if i not in range(32, 127)
 }
 _non_printable_ascii_translate_table.update(
     {ord("\t"): "\\t", ord("\r"): "\\r", ord("\n"): "\\n"}
@@ -338,6 +311,8 @@
     are derived from BaseException instead of Exception (for more details
     check #2707).
     """
+    from _pytest.outcomes import TEST_OUTCOME
+
     try:
         return getattr(object, name, default)
     except TEST_OUTCOME:
@@ -350,12 +325,6 @@
         return inspect.isclass(obj)
     except Exception:
         return False
-
-
-if sys.version_info < (3, 5, 2):
-
-    def overload(f):  # noqa: F811
-        return f


 if TYPE_CHECKING:
@@ -367,19 +336,15 @@
     from typing import final as final
 else:

-    def final(f):  # noqa: F811
+    def final(f):
         return f
-
-
-if getattr(attr, "__version_info__", ()) >= (19, 2):
-    ATTRS_EQ_FIELD = "eq"
-else:
-    ATTRS_EQ_FIELD = "cmp"


 if sys.version_info >= (3, 8):
     from functools import cached_property as cached_property
 else:
+    from typing import overload
+    from typing import Type

     class cached_property(Generic[_S, _T]):
         __slots__ = ("func", "__doc__")
@@ -390,33 +355,19 @@

         @overload
         def __get__(
-            self, instance: None, owner: Optional["Type[_S]"] = ...
+            self, instance: None, owner: Optional[Type[_S]] = ...
         ) -> "cached_property[_S, _T]":
             ...

-        @overload  # noqa: F811
-        def __get__(  # noqa: F811
-            self, instance: _S, owner: Optional["Type[_S]"] = ...
-        ) -> _T:
+        @overload
+        def __get__(self, instance: _S, owner: Optional[Type[_S]] = ...) -> _T:
             ...

-        def __get__(self, instance, owner=None):  # noqa: F811
+        def __get__(self, instance, owner=None):
             if instance is None:
                 return self
             value = instance.__dict__[self.func.__name__] = self.func(instance)
             return value
-
-
-# Sometimes an algorithm needs a dict which yields items in the order in which
-# they were inserted when iterated. Since Python 3.7, `dict` preserves
-# insertion order. Since `dict` is faster and uses less memory than
-# `OrderedDict`, prefer to use it if possible.
-if sys.version_info >= (3, 7):
-    order_preserving_dict = dict
-else:
-    from collections import OrderedDict
-
-    order_preserving_dict = OrderedDict


 # Perform exhaustiveness checking.
@@ -451,4 +402,4 @@
 #
 # This also work for Enums (if you use `is` to compare) and Literals.
 def assert_never(value: "NoReturn") -> "NoReturn":
-    assert False, "Unhandled value: {} ({})".format(value, type(value).__name__)
+    assert False, f"Unhandled value: {value} ({type(value).__name__})"
('src/_pytest', 'terminal.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -8,9 +8,13 @@
 import platform
 import sys
 import warnings
+from collections import Counter
 from functools import partial
+from pathlib import Path
 from typing import Any
 from typing import Callable
+from typing import cast
+from typing import ClassVar
 from typing import Dict
 from typing import Generator
 from typing import List
@@ -20,30 +24,28 @@
 from typing import Set
 from typing import TextIO
 from typing import Tuple
+from typing import TYPE_CHECKING
 from typing import Union

 import attr
 import pluggy
-import py
-
-import pytest
+
+import _pytest._version
 from _pytest import nodes
 from _pytest import timing
 from _pytest._code import ExceptionInfo
 from _pytest._code.code import ExceptionRepr
 from _pytest._io.wcwidth import wcswidth
 from _pytest.compat import final
-from _pytest.compat import order_preserving_dict
-from _pytest.compat import TYPE_CHECKING
 from _pytest.config import _PluggyPlugin
 from _pytest.config import Config
 from _pytest.config import ExitCode
+from _pytest.config import hookimpl
 from _pytest.config.argparsing import Parser
 from _pytest.nodes import Item
 from _pytest.nodes import Node
 from _pytest.pathlib import absolutepath
 from _pytest.pathlib import bestrelpath
-from _pytest.pathlib import Path
 from _pytest.reports import BaseReport
 from _pytest.reports import CollectReport
 from _pytest.reports import TestReport
@@ -235,7 +237,7 @@


 def getreportopt(config: Config) -> str:
-    reportchars = config.option.reportchars  # type: str
+    reportchars: str = config.option.reportchars

     old_aliases = {"F", "S"}
     reportopts = ""
@@ -259,7 +261,7 @@
     return reportopts


-@pytest.hookimpl(trylast=True)  # after _pytest.runner
+@hookimpl(trylast=True)  # after _pytest.runner
 def pytest_report_teststatus(report: BaseReport) -> Tuple[str, str, str]:
     letter = "F"
     if report.passed:
@@ -267,7 +269,7 @@
     elif report.skipped:
         letter = "s"

-    outcome = report.outcome  # type: str
+    outcome: str = report.outcome
     if report.when in ("collect", "setup", "teardown") and outcome == "failed":
         outcome = "error"
         letter = "E"
@@ -275,7 +277,7 @@
     return outcome, letter, outcome.upper()


-@attr.s
+@attr.s(auto_attribs=True)
 class WarningReport:
     """Simple structure to hold warnings information captured by ``pytest_warning_recorded``.

@@ -283,30 +285,24 @@
         User friendly message about the warning.
     :ivar str|None nodeid:
         nodeid that generated the warning (see ``get_location``).
-    :ivar tuple|py.path.local fslocation:
+    :ivar tuple fslocation:
         File system location of the source of the warning (see ``get_location``).
     """

-    message = attr.ib(type=str)
-    nodeid = attr.ib(type=Optional[str], default=None)
-    fslocation = attr.ib(
-        type=Optional[Union[Tuple[str, int], py.path.local]], default=None
-    )
-    count_towards_summary = True
+    message: str
+    nodeid: Optional[str] = None
+    fslocation: Optional[Tuple[str, int]] = None
+
+    count_towards_summary: ClassVar = True

     def get_location(self, config: Config) -> Optional[str]:
         """Return the more user-friendly information about the location of a warning, or None."""
         if self.nodeid:
             return self.nodeid
         if self.fslocation:
-            if isinstance(self.fslocation, tuple) and len(self.fslocation) >= 2:
-                filename, linenum = self.fslocation[:2]
-                relpath = bestrelpath(
-                    config.invocation_params.dir, absolutepath(filename)
-                )
-                return "{}:{}".format(relpath, linenum)
-            else:
-                return str(self.fslocation)
+            filename, linenum = self.fslocation
+            relpath = bestrelpath(config.invocation_params.dir, absolutepath(filename))
+            return f"{relpath}:{linenum}"
         return None


@@ -317,27 +313,26 @@

         self.config = config
         self._numcollected = 0
-        self._session = None  # type: Optional[Session]
-        self._showfspath = None  # type: Optional[bool]
-
-        self.stats = {}  # type: Dict[str, List[Any]]
-        self._main_color = None  # type: Optional[str]
-        self._known_types = None  # type: Optional[List[str]]
-        self.startdir = config.invocation_dir
+        self._session: Optional[Session] = None
+        self._showfspath: Optional[bool] = None
+
+        self.stats: Dict[str, List[Any]] = {}
+        self._main_color: Optional[str] = None
+        self._known_types: Optional[List[str]] = None
         self.startpath = config.invocation_params.dir
         if file is None:
             file = sys.stdout
         self._tw = _pytest.config.create_terminal_writer(config, file)
         self._screen_width = self._tw.fullwidth
-        self.currentfspath = None  # type: Union[None, Path, str, int]
+        self.currentfspath: Union[None, Path, str, int] = None
         self.reportchars = getreportopt(config)
         self.hasmarkup = self._tw.hasmarkup
         self.isatty = file.isatty()
-        self._progress_nodeids_reported = set()  # type: Set[str]
+        self._progress_nodeids_reported: Set[str] = set()
         self._show_progress_info = self._determine_show_progress_info()
-        self._collect_report_last_write = None  # type: Optional[float]
-        self._already_displayed_warnings = None  # type: Optional[int]
-        self._keyboardinterrupt_memo = None  # type: Optional[ExceptionRepr]
+        self._collect_report_last_write: Optional[float] = None
+        self._already_displayed_warnings: Optional[int] = None
+        self._keyboardinterrupt_memo: Optional[ExceptionRepr] = None

     def _determine_show_progress_info(self) -> "Literal['progress', 'count', False]":
         """Return whether we should display progress information based on the current config."""
@@ -347,7 +342,7 @@
         # do not show progress if we are showing fixture setup/teardown
         if self.config.getoption("setupshow", False):
             return False
-        cfg = self.config.getini("console_output_style")  # type: str
+        cfg: str = self.config.getini("console_output_style")
         if cfg == "progress":
             return "progress"
         elif cfg == "count":
@@ -357,7 +352,7 @@

     @property
     def verbosity(self) -> int:
-        verbosity = self.config.option.verbose  # type: int
+        verbosity: int = self.config.option.verbose
         return verbosity

     @property
@@ -450,7 +445,7 @@
         sep: str,
         title: Optional[str] = None,
         fullwidth: Optional[int] = None,
-        **markup: bool
+        **markup: bool,
     ) -> None:
         self.ensure_newline()
         self._tw.sep(sep, title, fullwidth, **markup)
@@ -473,7 +468,9 @@
         return True

     def pytest_warning_recorded(
-        self, warning_message: warnings.WarningMessage, nodeid: str,
+        self,
+        warning_message: warnings.WarningMessage,
+        nodeid: str,
     ) -> None:
         from _pytest.warnings import warning_record_to_str

@@ -487,7 +484,7 @@

     def pytest_plugin_registered(self, plugin: _PluggyPlugin) -> None:
         if self.config.option.traceconfig:
-            msg = "PLUGIN registered: {}".format(plugin)
+            msg = f"PLUGIN registered: {plugin}"
             # XXX This event may happen during setup/teardown time
             #     which unfortunately captures our output here
             #     which garbles our output if we use self.write_line.
@@ -512,9 +509,9 @@
     def pytest_runtest_logreport(self, report: TestReport) -> None:
         self._tests_ran = True
         rep = report
-        res = self.config.hook.pytest_report_teststatus(
-            report=rep, config=self.config
-        )  # type: Tuple[str, str, Union[str, Tuple[str, Mapping[str, bool]]]]
+        res: Tuple[
+            str, str, Union[str, Tuple[str, Mapping[str, bool]]]
+        ] = self.config.hook.pytest_report_teststatus(report=rep, config=self.config)
         category, letter, word = res
         if not isinstance(word, tuple):
             markup = None
@@ -544,6 +541,22 @@
             line = self._locationline(rep.nodeid, *rep.location)
             if not running_xdist:
                 self.write_ensure_prefix(line, word, **markup)
+                if rep.skipped or hasattr(report, "wasxfail"):
+                    reason = _get_raw_skip_reason(rep)
+                    if self.config.option.verbose < 2:
+                        available_width = (
+                            (self._tw.fullwidth - self._tw.width_of_current_line)
+                            - len(" [100%]")
+                            - 1
+                        )
+                        formatted_reason = _format_trimmed(
+                            " ({})", reason, available_width
+                        )
+                    else:
+                        formatted_reason = f" ({reason})"
+
+                    if reason and formatted_reason is not None:
+                        self._tw.write(formatted_reason)
                 if self._show_progress_info:
                     self._write_progress_information_filling_space()
             else:
@@ -570,7 +583,7 @@
         if self.verbosity <= 0 and self._show_progress_info:
             if self._show_progress_info == "count":
                 num_tests = self._session.testscollected
-                progress_length = len(" [{}/{}]".format(str(num_tests), str(num_tests)))
+                progress_length = len(f" [{num_tests}/{num_tests}]")
             else:
                 progress_length = len(" [100%]")

@@ -592,10 +605,10 @@
         if self._show_progress_info == "count":
             if collected:
                 progress = self._progress_nodeids_reported
-                counter_format = "{{:{}d}}".format(len(str(collected)))
-                format_string = " [{}/{{}}]".format(counter_format)
+                counter_format = f"{{:{len(str(collected))}d}}"
+                format_string = f" [{counter_format}/{{}}]"
                 return format_string.format(len(progress), collected)
-            return " [ {} / {} ]".format(collected, collected)
+            return f" [ {collected} / {collected} ]"
         else:
             if collected:
                 return " [{:3d}%]".format(
@@ -628,7 +641,7 @@
             self._add_stats("error", [report])
         elif report.skipped:
             self._add_stats("skipped", [report])
-        items = [x for x in report.result if isinstance(x, pytest.Item)]
+        items = [x for x in report.result if isinstance(x, Item)]
         self._numcollected += len(items)
         if self.isatty:
             self.report_collect()
@@ -650,11 +663,8 @@
         errors = len(self.stats.get("error", []))
         skipped = len(self.stats.get("skipped", []))
         deselected = len(self.stats.get("deselected", []))
-        selected = self._numcollected - errors - skipped - deselected
-        if final:
-            line = "collected "
-        else:
-            line = "collecting "
+        selected = self._numcollected - deselected
+        line = "collected " if final else "collecting "
         line += (
             str(self._numcollected) + " item" + ("" if self._numcollected == 1 else "s")
         )
@@ -664,7 +674,7 @@
             line += " / %d deselected" % deselected
         if skipped:
             line += " / %d skipped" % skipped
-        if self._numcollected > selected > 0:
+        if self._numcollected > selected:
             line += " / %d selected" % selected
         if self.isatty:
             self.rewrite(line, bold=True, erase=True)
@@ -673,7 +683,7 @@
         else:
             self.write_line(line)

-    @pytest.hookimpl(trylast=True)
+    @hookimpl(trylast=True)
     def pytest_sessionstart(self, session: "Session") -> None:
         self._session = session
         self._sessionstarttime = timing.time()
@@ -682,13 +692,13 @@
         self.write_sep("=", "test session starts", bold=True)
         verinfo = platform.python_version()
         if not self.no_header:
-            msg = "platform {} -- Python {}".format(sys.platform, verinfo)
+            msg = f"platform {sys.platform} -- Python {verinfo}"
             pypy_version_info = getattr(sys, "pypy_version_info", None)
             if pypy_version_info:
                 verinfo = ".".join(map(str, pypy_version_info[:3]))
-                msg += "[pypy-{}-{}]".format(verinfo, pypy_version_info[3])
-            msg += ", pytest-{}, py-{}, pluggy-{}".format(
-                pytest.__version__, py.__version__, pluggy.__version__
+                msg += f"[pypy-{verinfo}-{pypy_version_info[3]}]"
+            msg += ", pytest-{}, pluggy-{}".format(
+                _pytest._version.version, pluggy.__version__
             )
             if (
                 self.verbosity > 0
@@ -698,7 +708,7 @@
                 msg += " -- " + str(sys.executable)
             self.write_line(msg)
             lines = self.config.hook.pytest_report_header(
-                config=self.config, startdir=self.startdir
+                config=self.config, start_path=self.startpath
             )
             self._write_report_lines_from_hooks(lines)

@@ -718,8 +728,8 @@
         if config.inipath:
             line += ", configfile: " + bestrelpath(config.rootpath, config.inipath)

-        testpaths = config.getini("testpaths")  # type: List[str]
-        if testpaths and config.args == testpaths:
+        testpaths: List[str] = config.getini("testpaths")
+        if config.invocation_params.dir == config.rootpath and config.args == testpaths:
             line += ", testpaths: {}".format(", ".join(testpaths))

         result = [line]
@@ -733,7 +743,9 @@
         self.report_collect(True)

         lines = self.config.hook.pytest_report_collectionfinish(
-            config=self.config, startdir=self.startdir, items=session.items
+            config=self.config,
+            start_path=self.startpath,
+            items=session.items,
         )
         self._write_report_lines_from_hooks(lines)

@@ -750,22 +762,16 @@
                     rep.toterminal(self._tw)

     def _printcollecteditems(self, items: Sequence[Item]) -> None:
-        # To print out items and their parent collectors
-        # we take care to leave out Instances aka ()
-        # because later versions are going to get rid of them anyway.
         if self.config.option.verbose < 0:
             if self.config.option.verbose < -1:
-                counts = {}  # type: Dict[str, int]
-                for item in items:
-                    name = item.nodeid.split("::", 1)[0]
-                    counts[name] = counts.get(name, 0) + 1
+                counts = Counter(item.nodeid.split("::", 1)[0] for item in items)
                 for name, count in sorted(counts.items()):
                     self._tw.line("%s: %d" % (name, count))
             else:
                 for item in items:
                     self._tw.line(item.nodeid)
             return
-        stack = []  # type: List[Node]
+        stack: List[Node] = []
         indent = ""
         for item in items:
             needed_collectors = item.listchain()[1:]  # strip root node
@@ -775,10 +781,8 @@
                 stack.pop()
             for col in needed_collectors[len(stack) :]:
                 stack.append(col)
-                if col.name == "()":  # Skip Instances.
-                    continue
                 indent = (len(stack) - 1) * "  "
-                self._tw.line("{}{}".format(indent, col))
+                self._tw.line(f"{indent}{col}")
                 if self.config.option.verbose >= 1:
                     obj = getattr(col, "obj", None)
                     doc = inspect.getdoc(obj) if obj else None
@@ -786,7 +790,7 @@
                         for line in doc.splitlines():
                             self._tw.line("{}{}".format(indent + "  ", line))

-    @pytest.hookimpl(hookwrapper=True)
+    @hookimpl(hookwrapper=True)
     def pytest_sessionfinish(
         self, session: "Session", exitstatus: Union[int, ExitCode]
     ):
@@ -813,7 +817,7 @@
             self.write_sep("!", str(session.shouldstop), red=True)
         self.summary_stats()

-    @pytest.hookimpl(hookwrapper=True)
+    @hookimpl(hookwrapper=True)
     def pytest_terminal_summary(self) -> Generator[None, None, None]:
         self.summary_errors()
         self.summary_failures()
@@ -847,8 +851,10 @@
                     yellow=True,
                 )

-    def _locationline(self, nodeid, fspath, lineno, domain):
-        def mkrel(nodeid):
+    def _locationline(
+        self, nodeid: str, fspath: str, lineno: Optional[int], domain: str
+    ) -> str:
+        def mkrel(nodeid: str) -> str:
             line = self.config.cwd_relative_nodeid(nodeid)
             if domain and line.endswith(domain):
                 line = line[: -len(domain)]
@@ -858,13 +864,12 @@
             return line

         # collect_fspath comes from testid which has a "/"-normalized path.
-
         if fspath:
             res = mkrel(nodeid)
             if self.verbosity >= 2 and nodeid.split("::")[0] != fspath.replace(
                 "\\", nodes.SEP
             ):
-                res += " <- " + bestrelpath(self.startpath, fspath)
+                res += " <- " + bestrelpath(self.startpath, Path(fspath))
         else:
             res = "[location]"
         return res + " "
@@ -888,17 +893,11 @@
     # Summaries for sessionfinish.
     #
     def getreports(self, name: str):
-        values = []
-        for x in self.stats.get(name, []):
-            if not hasattr(x, "_pdbshown"):
-                values.append(x)
-        return values
+        return [x for x in self.stats.get(name, ()) if not hasattr(x, "_pdbshown")]

     def summary_warnings(self) -> None:
         if self.hasopt("w"):
-            all_warnings = self.stats.get(
-                "warnings"
-            )  # type: Optional[List[WarningReport]]
+            all_warnings: Optional[List[WarningReport]] = self.stats.get("warnings")
             if not all_warnings:
                 return

@@ -911,9 +910,7 @@
             if not warning_reports:
                 return

-            reports_grouped_by_message = (
-                order_preserving_dict()
-            )  # type: Dict[str, List[WarningReport]]
+            reports_grouped_by_message: Dict[str, List[WarningReport]] = {}
             for wr in warning_reports:
                 reports_grouped_by_message.setdefault(wr.message, []).append(wr)

@@ -927,10 +924,9 @@
                 if len(locations) < 10:
                     return "\n".join(map(str, locations))

-                counts_by_filename = order_preserving_dict()  # type: Dict[str, int]
-                for loc in locations:
-                    key = str(loc).split("::", 1)[0]
-                    counts_by_filename[key] = counts_by_filename.get(key, 0) + 1
+                counts_by_filename = Counter(
+                    str(loc).split("::", 1)[0] for loc in locations
+                )
                 return "\n".join(
                     "{}: {} warning{}".format(k, v, "s" if v > 1 else "")
                     for k, v in counts_by_filename.items()
@@ -949,12 +945,14 @@
                     message = message.rstrip()
                 self._tw.line(message)
                 self._tw.line()
-            self._tw.line("-- Docs: https://docs.pytest.org/en/stable/warnings.html")
+            self._tw.line(
+                "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html"
+            )

     def summary_passes(self) -> None:
         if self.config.option.tbstyle != "no":
             if self.hasopt("P"):
-                reports = self.getreports("passed")  # type: List[TestReport]
+                reports: List[TestReport] = self.getreports("passed")
                 if not reports:
                     return
                 self.write_sep("=", "PASSES")
@@ -992,7 +990,7 @@

     def summary_failures(self) -> None:
         if self.config.option.tbstyle != "no":
-            reports = self.getreports("failed")  # type: List[BaseReport]
+            reports: List[BaseReport] = self.getreports("failed")
             if not reports:
                 return
             self.write_sep("=", "FAILURES")
@@ -1009,7 +1007,7 @@

     def summary_errors(self) -> None:
         if self.config.option.tbstyle != "no":
-            reports = self.getreports("error")  # type: List[BaseReport]
+            reports: List[BaseReport] = self.getreports("error")
             if not reports:
                 return
             self.write_sep("=", "ERRORS")
@@ -1018,7 +1016,7 @@
                 if rep.when == "collect":
                     msg = "ERROR collecting " + msg
                 else:
-                    msg = "ERROR at {} of {}".format(rep.when, msg)
+                    msg = f"ERROR at {rep.when} of {msg}"
                 self.write_sep("_", msg, red=True, bold=True)
                 self._outrep_summary(rep)

@@ -1054,7 +1052,7 @@
         msg = ", ".join(line_parts)

         main_markup = {main_color: True}
-        duration = " in {}".format(format_session_duration(session_duration))
+        duration = f" in {format_session_duration(session_duration)}"
         duration_with_markup = self._tw.markup(duration, **main_markup)
         if display_sep:
             fullwidth += len(duration_with_markup) - len(duration)
@@ -1091,7 +1089,7 @@
             for rep in xfailed:
                 verbose_word = rep._get_verbose_word(self.config)
                 pos = _get_pos(self.config, rep)
-                lines.append("{} {}".format(verbose_word, pos))
+                lines.append(f"{verbose_word} {pos}")
                 reason = rep.wasxfail
                 if reason:
                     lines.append("  " + str(reason))
@@ -1102,10 +1100,10 @@
                 verbose_word = rep._get_verbose_word(self.config)
                 pos = _get_pos(self.config, rep)
                 reason = rep.wasxfail
-                lines.append("{} {} {}".format(verbose_word, pos, reason))
+                lines.append(f"{verbose_word} {pos} {reason}")

         def show_skipped(lines: List[str]) -> None:
-            skipped = self.stats.get("skipped", [])  # type: List[CollectReport]
+            skipped: List[CollectReport] = self.stats.get("skipped", [])
             fskips = _folded_skips(self.startpath, skipped) if skipped else []
             if not fskips:
                 return
@@ -1121,16 +1119,16 @@
                 else:
                     lines.append("%s [%d] %s: %s" % (verbose_word, num, fspath, reason))

-        REPORTCHAR_ACTIONS = {
+        REPORTCHAR_ACTIONS: Mapping[str, Callable[[List[str]], None]] = {
             "x": show_xfailed,
             "X": show_xpassed,
             "f": partial(show_simple, "failed"),
             "s": show_skipped,
             "p": partial(show_simple, "passed"),
             "E": partial(show_simple, "error"),
-        }  # type: Mapping[str, Callable[[List[str]], None]]
-
-        lines = []  # type: List[str]
+        }
+
+        lines: List[str] = []
         for char in self.reportchars:
             action = REPORTCHAR_ACTIONS.get(char)
             if action:  # skipping e.g. "P" (passed with output) here.
@@ -1161,7 +1159,7 @@
         return main_color

     def _set_main_color(self) -> None:
-        unknown_types = []  # type: List[str]
+        unknown_types: List[str] = []
         for found_type in self.stats.keys():
             if found_type:  # setup/teardown reports have an empty key, ignore them
                 if found_type not in KNOWN_TYPES and found_type not in unknown_types:
@@ -1170,21 +1168,83 @@
         self._main_color = self._determine_main_color(bool(unknown_types))

     def build_summary_stats_line(self) -> Tuple[List[Tuple[str, Dict[str, bool]]], str]:
+        """
+        Build the parts used in the last summary stats line.
+
+        The summary stats line is the line shown at the end, "=== 12 passed, 2 errors in Xs===".
+
+        This function builds a list of the "parts" that make up for the text in that line, in
+        the example above it would be:
+
+            [
+                ("12 passed", {"green": True}),
+                ("2 errors", {"red": True}
+            ]
+
+        That last dict for each line is a "markup dictionary", used by TerminalWriter to
+        color output.
+
+        The final color of the line is also determined by this function, and is the second
+        element of the returned tuple.
+        """
+        if self.config.getoption("collectonly"):
+            return self._build_collect_only_summary_stats_line()
+        else:
+            return self._build_normal_summary_stats_line()
+
+    def _get_reports_to_display(self, key: str) -> List[Any]:
+        """Get test/collection reports for the given status key, such as `passed` or `error`."""
+        reports = self.stats.get(key, [])
+        return [x for x in reports if getattr(x, "count_towards_summary", True)]
+
+    def _build_normal_summary_stats_line(
+        self,
+    ) -> Tuple[List[Tuple[str, Dict[str, bool]]], str]:
         main_color, known_types = self._get_main_color()
-
         parts = []
+
         for key in known_types:
-            reports = self.stats.get(key, None)
+            reports = self._get_reports_to_display(key)
             if reports:
-                count = sum(
-                    1 for rep in reports if getattr(rep, "count_towards_summary", True)
-                )
+                count = len(reports)
                 color = _color_for_type.get(key, _color_for_type_default)
                 markup = {color: True, "bold": color == main_color}
-                parts.append(("%d %s" % _make_plural(count, key), markup))
+                parts.append(("%d %s" % pluralize(count, key), markup))

         if not parts:
             parts = [("no tests ran", {_color_for_type_default: True})]
+
+        return parts, main_color
+
+    def _build_collect_only_summary_stats_line(
+        self,
+    ) -> Tuple[List[Tuple[str, Dict[str, bool]]], str]:
+        deselected = len(self._get_reports_to_display("deselected"))
+        errors = len(self._get_reports_to_display("error"))
+
+        if self._numcollected == 0:
+            parts = [("no tests collected", {"yellow": True})]
+            main_color = "yellow"
+
+        elif deselected == 0:
+            main_color = "green"
+            collected_output = "%d %s collected" % pluralize(self._numcollected, "test")
+            parts = [(collected_output, {main_color: True})]
+        else:
+            all_tests_were_deselected = self._numcollected == deselected
+            if all_tests_were_deselected:
+                main_color = "yellow"
+                collected_output = f"no tests collected ({deselected} deselected)"
+            else:
+                main_color = "green"
+                selected = self._numcollected - deselected
+                collected_output = f"{selected}/{self._numcollected} tests collected ({deselected} deselected)"
+
+            parts = [(collected_output, {main_color: True})]
+
+        if errors:
+            main_color = _color_for_type["error"]
+            parts += [("%d %s" % pluralize(errors, "error"), {main_color: True})]

         return parts, main_color

@@ -1192,6 +1252,31 @@
 def _get_pos(config: Config, rep: BaseReport):
     nodeid = config.cwd_relative_nodeid(rep.nodeid)
     return nodeid
+
+
+def _format_trimmed(format: str, msg: str, available_width: int) -> Optional[str]:
+    """Format msg into format, ellipsizing it if doesn't fit in available_width.
+
+    Returns None if even the ellipsis can't fit.
+    """
+    # Only use the first line.
+    i = msg.find("\n")
+    if i != -1:
+        msg = msg[:i]
+
+    ellipsis = "..."
+    format_width = wcswidth(format.format(""))
+    if format_width + len(ellipsis) > available_width:
+        return None
+
+    if format_width + wcswidth(msg) > available_width:
+        available_width -= len(ellipsis)
+        msg = msg[:available_width]
+        while format_width + wcswidth(msg) > available_width:
+            msg = msg[:-1]
+        msg += ellipsis
+
+    return format.format(msg)


 def _get_line_with_reprcrash_message(
@@ -1201,12 +1286,8 @@
     verbose_word = rep._get_verbose_word(config)
     pos = _get_pos(config, rep)

-    line = "{} {}".format(verbose_word, pos)
-    len_line = wcswidth(line)
-    ellipsis, len_ellipsis = "...", 3
-    if len_line > termwidth - len_ellipsis:
-        # No space for an additional message.
-        return line
+    line = f"{verbose_word} {pos}"
+    line_width = wcswidth(line)

     try:
         # Type ignored intentionally -- possible AttributeError expected.
@@ -1214,29 +1295,19 @@
     except AttributeError:
         pass
     else:
-        # Only use the first line.
-        i = msg.find("\n")
-        if i != -1:
-            msg = msg[:i]
-        len_msg = wcswidth(msg)
-
-        sep, len_sep = " - ", 3
-        max_len_msg = termwidth - len_line - len_sep
-        if max_len_msg >= len_ellipsis:
-            if len_msg > max_len_msg:
-                max_len_msg -= len_ellipsis
-                msg = msg[:max_len_msg]
-                while wcswidth(msg) > max_len_msg:
-                    msg = msg[:-1]
-                msg += ellipsis
-            line += sep + msg
+        available_width = termwidth - line_width
+        msg = _format_trimmed(" - {}", msg, available_width)
+        if msg is not None:
+            line += msg
+
     return line


 def _folded_skips(
-    startpath: Path, skipped: Sequence[CollectReport],
+    startpath: Path,
+    skipped: Sequence[CollectReport],
 ) -> List[Tuple[int, str, Optional[int], str]]:
-    d = {}  # type: Dict[Tuple[str, Optional[int], str], List[CollectReport]]
+    d: Dict[Tuple[str, Optional[int], str], List[CollectReport]] = {}
     for event in skipped:
         assert event.longrepr is not None
         assert isinstance(event.longrepr, tuple), (event, event.longrepr)
@@ -1253,11 +1324,11 @@
             and "skip" in keywords
             and "pytestmark" not in keywords
         ):
-            key = (fspath, None, reason)  # type: Tuple[str, Optional[int], str]
+            key: Tuple[str, Optional[int], str] = (fspath, None, reason)
         else:
             key = (fspath, lineno, reason)
         d.setdefault(key, []).append(event)
-    values = []  # type: List[Tuple[int, str, Optional[int], str]]
+    values: List[Tuple[int, str, Optional[int], str]] = []
     for key, events in d.items():
         values.append((len(events), *key))
     return values
@@ -1272,9 +1343,9 @@
 _color_for_type_default = "yellow"


-def _make_plural(count: int, noun: str) -> Tuple[int, str]:
+def pluralize(count: int, noun: str) -> Tuple[int, str]:
     # No need to pluralize words such as `failed` or `passed`.
-    if noun not in ["error", "warnings"]:
+    if noun not in ["error", "warnings", "test"]:
         return count, noun

     # The `warnings` key is plural. To avoid API breakage, we keep it that way but
@@ -1286,7 +1357,7 @@


 def _plugin_nameversions(plugininfo) -> List[str]:
-    values = []  # type: List[str]
+    values: List[str] = []
     for plugin, dist in plugininfo:
         # Gets us name and version!
         name = "{dist.project_name}-{dist.version}".format(dist=dist)
@@ -1302,7 +1373,28 @@
 def format_session_duration(seconds: float) -> str:
     """Format the given seconds in a human readable manner to show in the final summary."""
     if seconds < 60:
-        return "{:.2f}s".format(seconds)
+        return f"{seconds:.2f}s"
     else:
         dt = datetime.timedelta(seconds=int(seconds))
-        return "{:.2f}s ({})".format(seconds, dt)
+        return f"{seconds:.2f}s ({dt})"
+
+
+def _get_raw_skip_reason(report: TestReport) -> str:
+    """Get the reason string of a skip/xfail/xpass test report.
+
+    The string is just the part given by the user.
+    """
+    if hasattr(report, "wasxfail"):
+        reason = cast(str, report.wasxfail)
+        if reason.startswith("reason: "):
+            reason = reason[len("reason: ") :]
+        return reason
+    else:
+        assert report.skipped
+        assert isinstance(report.longrepr, tuple)
+        _, _, reason = report.longrepr
+        if reason.startswith("Skipped: "):
+            reason = reason[len("Skipped: ") :]
+        elif reason == "Skipped":
+            reason = ""
+        return reason
('src/_pytest', 'warnings.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -3,9 +3,9 @@
 from contextlib import contextmanager
 from typing import Generator
 from typing import Optional
+from typing import TYPE_CHECKING

 import pytest
-from _pytest.compat import TYPE_CHECKING
 from _pytest.config import apply_warning_filters
 from _pytest.config import Config
 from _pytest.config import parse_warning_filter
@@ -21,7 +21,7 @@
     config.addinivalue_line(
         "markers",
         "filterwarnings(warning): add a warning filter to the given test. "
-        "see https://docs.pytest.org/en/stable/warnings.html#pytest-mark-filterwarnings ",
+        "see https://docs.pytest.org/en/stable/how-to/capture-warnings.html#pytest-mark-filterwarnings ",
     )


@@ -61,14 +61,6 @@
         yield

         for warning_message in log:
-            ihook.pytest_warning_captured.call_historic(
-                kwargs=dict(
-                    warning_message=warning_message,
-                    when=when,
-                    item=item,
-                    location=None,
-                )
-            )
             ihook.pytest_warning_recorded.call_historic(
                 kwargs=dict(
                     warning_message=warning_message,
@@ -89,6 +81,23 @@
         warning_message.lineno,
         warning_message.line,
     )
+    if warning_message.source is not None:
+        try:
+            import tracemalloc
+        except ImportError:
+            pass
+        else:
+            tb = tracemalloc.get_object_traceback(warning_message.source)
+            if tb is not None:
+                formatted_tb = "\n".join(tb.format())
+                # Use a leading new line to better separate the (large) output
+                # from the traceback to the previous warning text.
+                msg += f"\nObject allocated at:\n{formatted_tb}"
+            else:
+                # No need for a leading new line.
+                url = "https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings"
+                msg += "Enable tracemalloc to get traceback where the object was allocated.\n"
+                msg += f"See {url} for more info."
     return msg


('src/_pytest', 'deprecated.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -8,7 +8,10 @@
 :class:`PytestWarning`, or :class:`UnformattedWarning`
 in case of warnings which need to format their messages.
 """
+from warnings import warn
+
 from _pytest.warning_types import PytestDeprecationWarning
+from _pytest.warning_types import PytestRemovedIn8Warning
 from _pytest.warning_types import UnformattedWarning

 # set of plugins which have been integrated into the core; we use this list to ignore
@@ -20,34 +23,101 @@
 }


-FILLFUNCARGS = UnformattedWarning(
-    PytestDeprecationWarning,
-    "{name} is deprecated, use "
-    "function._request._fillfixtures() instead if you cannot avoid reaching into internals.",
+# This can be* removed pytest 8, but it's harmless and common, so no rush to remove.
+# * If you're in the future: "could have been".
+YIELD_FIXTURE = PytestDeprecationWarning(
+    "@pytest.yield_fixture is deprecated.\n"
+    "Use @pytest.fixture instead; they are the same."
 )

-PYTEST_COLLECT_MODULE = UnformattedWarning(
-    PytestDeprecationWarning,
-    "pytest.collect.{name} was moved to pytest.{name}\n"
-    "Please update to the new name.",
+WARNING_CMDLINE_PREPARSE_HOOK = PytestRemovedIn8Warning(
+    "The pytest_cmdline_preparse hook is deprecated and will be removed in a future release. \n"
+    "Please use pytest_load_initial_conftests hook instead."
+)
+
+FSCOLLECTOR_GETHOOKPROXY_ISINITPATH = PytestRemovedIn8Warning(
+    "The gethookproxy() and isinitpath() methods of FSCollector and Package are deprecated; "
+    "use self.session.gethookproxy() and self.session.isinitpath() instead. "
+)
+
+STRICT_OPTION = PytestRemovedIn8Warning(
+    "The --strict option is deprecated, use --strict-markers instead."
+)
+
+# This deprecation is never really meant to be removed.
+PRIVATE = PytestDeprecationWarning("A private pytest class or function was used.")
+
+ARGUMENT_PERCENT_DEFAULT = PytestRemovedIn8Warning(
+    'pytest now uses argparse. "%default" should be changed to "%(default)s"',
+)
+
+ARGUMENT_TYPE_STR_CHOICE = UnformattedWarning(
+    PytestRemovedIn8Warning,
+    "`type` argument to addoption() is the string {typ!r}."
+    " For choices this is optional and can be omitted, "
+    " but when supplied should be a type (for example `str` or `int`)."
+    " (options: {names})",
+)
+
+ARGUMENT_TYPE_STR = UnformattedWarning(
+    PytestRemovedIn8Warning,
+    "`type` argument to addoption() is the string {typ!r}, "
+    " but when supplied should be a type (for example `str` or `int`)."
+    " (options: {names})",
 )


-MINUS_K_DASH = PytestDeprecationWarning(
-    "The `-k '-expr'` syntax to -k is deprecated.\nUse `-k 'not expr'` instead."
+HOOK_LEGACY_PATH_ARG = UnformattedWarning(
+    PytestRemovedIn8Warning,
+    "The ({pylib_path_arg}: py.path.local) argument is deprecated, please use ({pathlib_path_arg}: pathlib.Path)\n"
+    "see https://docs.pytest.org/en/latest/deprecations.html"
+    "#py-path-local-arguments-for-hooks-replaced-with-pathlib-path",
 )

-MINUS_K_COLON = PytestDeprecationWarning(
-    "The `-k 'expr:'` syntax to -k is deprecated.\n"
-    "Please open an issue if you use this and want a replacement."
+NODE_CTOR_FSPATH_ARG = UnformattedWarning(
+    PytestRemovedIn8Warning,
+    "The (fspath: py.path.local) argument to {node_type_name} is deprecated. "
+    "Please use the (path: pathlib.Path) argument instead.\n"
+    "See https://docs.pytest.org/en/latest/deprecations.html"
+    "#fspath-argument-for-node-constructors-replaced-with-pathlib-path",
 )

-WARNING_CAPTURED_HOOK = PytestDeprecationWarning(
-    "The pytest_warning_captured is deprecated and will be removed in a future release.\n"
-    "Please use pytest_warning_recorded instead."
+WARNS_NONE_ARG = PytestRemovedIn8Warning(
+    "Passing None has been deprecated.\n"
+    "See https://docs.pytest.org/en/latest/how-to/capture-warnings.html"
+    "#additional-use-cases-of-warnings-in-tests"
+    " for alternatives in common use cases."
 )

-FSCOLLECTOR_GETHOOKPROXY_ISINITPATH = PytestDeprecationWarning(
-    "The gethookproxy() and isinitpath() methods of FSCollector and Package are deprecated; "
-    "use self.session.gethookproxy() and self.session.isinitpath() instead. "
+KEYWORD_MSG_ARG = UnformattedWarning(
+    PytestRemovedIn8Warning,
+    "pytest.{func}(msg=...) is now deprecated, use pytest.{func}(reason=...) instead",
 )
+
+INSTANCE_COLLECTOR = PytestRemovedIn8Warning(
+    "The pytest.Instance collector type is deprecated and is no longer used. "
+    "See https://docs.pytest.org/en/latest/deprecations.html#the-pytest-instance-collector",
+)
+
+# You want to make some `__init__` or function "private".
+#
+#   def my_private_function(some, args):
+#       ...
+#
+# Do this:
+#
+#   def my_private_function(some, args, *, _ispytest: bool = False):
+#       check_ispytest(_ispytest)
+#       ...
+#
+# Change all internal/allowed calls to
+#
+#   my_private_function(some, args, _ispytest=True)
+#
+# All other calls will get the default _ispytest=False and trigger
+# the warning (possibly error in the future).
+
+
+def check_ispytest(ispytest: bool) -> None:
+    if not ispytest:
+        warn(PRIVATE, stacklevel=3)
('src/_pytest', 'recwarn.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -8,19 +8,18 @@
 from typing import Iterator
 from typing import List
 from typing import Optional
+from typing import overload
 from typing import Pattern
 from typing import Tuple
+from typing import Type
 from typing import TypeVar
 from typing import Union

 from _pytest.compat import final
-from _pytest.compat import overload
-from _pytest.compat import TYPE_CHECKING
+from _pytest.deprecated import check_ispytest
+from _pytest.deprecated import WARNS_NONE_ARG
 from _pytest.fixtures import fixture
 from _pytest.outcomes import fail
-
-if TYPE_CHECKING:
-    from typing import Type


 T = TypeVar("T")
@@ -30,10 +29,10 @@
 def recwarn() -> Generator["WarningsRecorder", None, None]:
     """Return a :class:`WarningsRecorder` instance that records all warnings emitted by test functions.

-    See http://docs.python.org/library/warnings.html for information
+    See https://docs.python.org/library/how-to/capture-warnings.html for information
     on warning categories.
     """
-    wrec = WarningsRecorder()
+    wrec = WarningsRecorder(_ispytest=True)
     with wrec:
         warnings.simplefilter("default")
         yield wrec
@@ -41,19 +40,17 @@

 @overload
 def deprecated_call(
-    *, match: Optional[Union[str, "Pattern[str]"]] = ...
+    *, match: Optional[Union[str, Pattern[str]]] = ...
 ) -> "WarningsRecorder":
     ...


-@overload  # noqa: F811
-def deprecated_call(  # noqa: F811
-    func: Callable[..., T], *args: Any, **kwargs: Any
-) -> T:
-    ...
-
-
-def deprecated_call(  # noqa: F811
+@overload
+def deprecated_call(func: Callable[..., T], *args: Any, **kwargs: Any) -> T:
+    ...
+
+
+def deprecated_call(
     func: Optional[Callable[..., Any]] = None, *args: Any, **kwargs: Any
 ) -> Union["WarningsRecorder", Any]:
     """Assert that code produces a ``DeprecationWarning`` or ``PendingDeprecationWarning``.
@@ -65,7 +62,8 @@
         ...     warnings.warn('use v3 of this api', DeprecationWarning)
         ...     return 200

-        >>> with deprecated_call():
+        >>> import pytest
+        >>> with pytest.deprecated_call():
         ...    assert api_call_v2() == 200

     It can also be used by passing a function and ``*args`` and ``**kwargs``,
@@ -86,28 +84,28 @@

 @overload
 def warns(
-    expected_warning: Optional[Union["Type[Warning]", Tuple["Type[Warning]", ...]]],
+    expected_warning: Union[Type[Warning], Tuple[Type[Warning], ...]] = ...,
     *,
-    match: "Optional[Union[str, Pattern[str]]]" = ...
+    match: Optional[Union[str, Pattern[str]]] = ...,
 ) -> "WarningsChecker":
     ...


-@overload  # noqa: F811
-def warns(  # noqa: F811
-    expected_warning: Optional[Union["Type[Warning]", Tuple["Type[Warning]", ...]]],
+@overload
+def warns(
+    expected_warning: Union[Type[Warning], Tuple[Type[Warning], ...]],
     func: Callable[..., T],
     *args: Any,
-    **kwargs: Any
+    **kwargs: Any,
 ) -> T:
     ...


-def warns(  # noqa: F811
-    expected_warning: Optional[Union["Type[Warning]", Tuple["Type[Warning]", ...]]],
+def warns(
+    expected_warning: Union[Type[Warning], Tuple[Type[Warning], ...]] = Warning,
     *args: Any,
-    match: Optional[Union[str, "Pattern[str]"]] = None,
-    **kwargs: Any
+    match: Optional[Union[str, Pattern[str]]] = None,
+    **kwargs: Any,
 ) -> Union["WarningsChecker", Any]:
     r"""Assert that code raises a particular class of warning.

@@ -119,25 +117,26 @@
     one for each warning raised.

     This function can be used as a context manager, or any of the other ways
-    ``pytest.raises`` can be used::
-
-        >>> with warns(RuntimeWarning):
+    :func:`pytest.raises` can be used::
+
+        >>> import pytest
+        >>> with pytest.warns(RuntimeWarning):
         ...    warnings.warn("my warning", RuntimeWarning)

     In the context manager form you may use the keyword argument ``match`` to assert
     that the warning matches a text or regex::

-        >>> with warns(UserWarning, match='must be 0 or None'):
+        >>> with pytest.warns(UserWarning, match='must be 0 or None'):
         ...     warnings.warn("value must be 0 or None", UserWarning)

-        >>> with warns(UserWarning, match=r'must be \d+$'):
+        >>> with pytest.warns(UserWarning, match=r'must be \d+$'):
         ...     warnings.warn("value must be 42", UserWarning)

-        >>> with warns(UserWarning, match=r'must be \d+$'):
+        >>> with pytest.warns(UserWarning, match=r'must be \d+$'):
         ...     warnings.warn("this is not here", UserWarning)
         Traceback (most recent call last):
           ...
-        Failed: DID NOT WARN. No warnings of type ...UserWarning... was emitted...
+        Failed: DID NOT WARN. No warnings of type ...UserWarning... were emitted...

     """
     __tracebackhide__ = True
@@ -147,14 +146,12 @@
             msg += ", ".join(sorted(kwargs))
             msg += "\nUse context-manager form instead?"
             raise TypeError(msg)
-        return WarningsChecker(expected_warning, match_expr=match)
+        return WarningsChecker(expected_warning, match_expr=match, _ispytest=True)
     else:
         func = args[0]
         if not callable(func):
-            raise TypeError(
-                "{!r} object (type: {}) must be callable".format(func, type(func))
-            )
-        with WarningsChecker(expected_warning):
+            raise TypeError(f"{func!r} object (type: {type(func)}) must be callable")
+        with WarningsChecker(expected_warning, _ispytest=True):
             return func(*args[1:], **kwargs)


@@ -164,11 +161,12 @@
     Adapted from `warnings.catch_warnings`.
     """

-    def __init__(self) -> None:
+    def __init__(self, *, _ispytest: bool = False) -> None:
+        check_ispytest(_ispytest)
         # Type ignored due to the way typeshed handles warnings.catch_warnings.
         super().__init__(record=True)  # type: ignore[call-arg]
         self._entered = False
-        self._list = []  # type: List[warnings.WarningMessage]
+        self._list: List[warnings.WarningMessage] = []

     @property
     def list(self) -> List["warnings.WarningMessage"]:
@@ -187,7 +185,7 @@
         """The number of recorded warnings."""
         return len(self._list)

-    def pop(self, cls: "Type[Warning]" = Warning) -> "warnings.WarningMessage":
+    def pop(self, cls: Type[Warning] = Warning) -> "warnings.WarningMessage":
         """Pop the first recorded warning, raise exception if not exists."""
         for i, w in enumerate(self._list):
             if issubclass(w.category, cls):
@@ -214,7 +212,7 @@

     def __exit__(
         self,
-        exc_type: Optional["Type[BaseException]"],
+        exc_type: Optional[Type[BaseException]],
         exc_val: Optional[BaseException],
         exc_tb: Optional[TracebackType],
     ) -> None:
@@ -234,14 +232,18 @@
     def __init__(
         self,
         expected_warning: Optional[
-            Union["Type[Warning]", Tuple["Type[Warning]", ...]]
-        ] = None,
-        match_expr: Optional[Union[str, "Pattern[str]"]] = None,
+            Union[Type[Warning], Tuple[Type[Warning], ...]]
+        ] = Warning,
+        match_expr: Optional[Union[str, Pattern[str]]] = None,
+        *,
+        _ispytest: bool = False,
     ) -> None:
-        super().__init__()
+        check_ispytest(_ispytest)
+        super().__init__(_ispytest=True)

         msg = "exceptions must be derived from Warning, not %s"
         if expected_warning is None:
+            warnings.warn(WARNS_NONE_ARG, stacklevel=4)
             expected_warning_tup = None
         elif isinstance(expected_warning, tuple):
             for exc in expected_warning:
@@ -258,7 +260,7 @@

     def __exit__(
         self,
-        exc_type: Optional["Type[BaseException]"],
+        exc_type: Optional[Type[BaseException]],
         exc_val: Optional[BaseException],
         exc_tb: Optional[TracebackType],
     ) -> None:
@@ -272,7 +274,7 @@
                 if not any(issubclass(r.category, self.expected_warning) for r in self):
                     __tracebackhide__ = True
                     fail(
-                        "DID NOT WARN. No warnings of type {} was emitted. "
+                        "DID NOT WARN. No warnings of type {} were emitted. "
                         "The list of emitted warnings is: {}.".format(
                             self.expected_warning, [each.message for each in self]
                         )
@@ -285,7 +287,7 @@
                     else:
                         fail(
                             "DID NOT WARN. No warnings of type {} matching"
-                            " ('{}') was emitted. The list of emitted warnings"
+                            " ('{}') were emitted. The list of emitted warnings"
                             " is: {}.".format(
                                 self.expected_warning,
                                 self.match_expr,
('src/_pytest', 'tmpdir.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,58 +1,78 @@
 """Support for providing temporary directories to test functions."""
 import os
 import re
+import sys
 import tempfile
+from pathlib import Path
 from typing import Optional

 import attr
-import py
-
-import pytest
-from .pathlib import ensure_reset_dir
+
 from .pathlib import LOCK_TIMEOUT
 from .pathlib import make_numbered_dir
 from .pathlib import make_numbered_dir_with_cleanup
-from .pathlib import Path
+from .pathlib import rm_rf
 from _pytest.compat import final
 from _pytest.config import Config
+from _pytest.deprecated import check_ispytest
+from _pytest.fixtures import fixture
 from _pytest.fixtures import FixtureRequest
 from _pytest.monkeypatch import MonkeyPatch


 @final
-@attr.s
+@attr.s(init=False)
 class TempPathFactory:
     """Factory for temporary directories under the common base temp directory.

     The base directory can be configured using the ``--basetemp`` option.
     """

-    _given_basetemp = attr.ib(
-        type=Optional[Path],
-        # Use os.path.abspath() to get absolute path instead of resolve() as it
-        # does not work the same in all platforms (see #4427).
-        # Path.absolute() exists, but it is not public (see https://bugs.python.org/issue25012).
-        # Ignore type because of https://github.com/python/mypy/issues/6172.
-        converter=attr.converters.optional(
-            lambda p: Path(os.path.abspath(str(p)))  # type: ignore
-        ),
-    )
+    _given_basetemp = attr.ib(type=Optional[Path])
     _trace = attr.ib()
-    _basetemp = attr.ib(type=Optional[Path], default=None)
+    _basetemp = attr.ib(type=Optional[Path])
+
+    def __init__(
+        self,
+        given_basetemp: Optional[Path],
+        trace,
+        basetemp: Optional[Path] = None,
+        *,
+        _ispytest: bool = False,
+    ) -> None:
+        check_ispytest(_ispytest)
+        if given_basetemp is None:
+            self._given_basetemp = None
+        else:
+            # Use os.path.abspath() to get absolute path instead of resolve() as it
+            # does not work the same in all platforms (see #4427).
+            # Path.absolute() exists, but it is not public (see https://bugs.python.org/issue25012).
+            self._given_basetemp = Path(os.path.abspath(str(given_basetemp)))
+        self._trace = trace
+        self._basetemp = basetemp

     @classmethod
-    def from_config(cls, config: Config) -> "TempPathFactory":
-        """Create a factory according to pytest configuration."""
+    def from_config(
+        cls,
+        config: Config,
+        *,
+        _ispytest: bool = False,
+    ) -> "TempPathFactory":
+        """Create a factory according to pytest configuration.
+
+        :meta private:
+        """
+        check_ispytest(_ispytest)
         return cls(
-            given_basetemp=config.option.basetemp, trace=config.trace.get("tmpdir")
+            given_basetemp=config.option.basetemp,
+            trace=config.trace.get("tmpdir"),
+            _ispytest=True,
         )

     def _ensure_relative_to_basetemp(self, basename: str) -> str:
         basename = os.path.normpath(basename)
         if (self.getbasetemp() / basename).resolve().parent != self.getbasetemp():
-            raise ValueError(
-                "{} is not a normalized and relative path".format(basename)
-            )
+            raise ValueError(f"{basename} is not a normalized and relative path")
         return basename

     def mktemp(self, basename: str, numbered: bool = True) -> Path:
@@ -73,20 +93,22 @@
         basename = self._ensure_relative_to_basetemp(basename)
         if not numbered:
             p = self.getbasetemp().joinpath(basename)
-            p.mkdir()
+            p.mkdir(mode=0o700)
         else:
-            p = make_numbered_dir(root=self.getbasetemp(), prefix=basename)
+            p = make_numbered_dir(root=self.getbasetemp(), prefix=basename, mode=0o700)
             self._trace("mktemp", p)
         return p

     def getbasetemp(self) -> Path:
-        """Return base temporary directory."""
+        """Return the base temporary directory, creating it if needed."""
         if self._basetemp is not None:
             return self._basetemp

         if self._given_basetemp is not None:
             basetemp = self._given_basetemp
-            ensure_reset_dir(basetemp)
+            if basetemp.exists():
+                rm_rf(basetemp)
+            basetemp.mkdir(mode=0o700)
             basetemp = basetemp.resolve()
         else:
             from_env = os.environ.get("PYTEST_DEBUG_TEMPROOT")
@@ -94,70 +116,73 @@
             user = get_user() or "unknown"
             # use a sub-directory in the temproot to speed-up
             # make_numbered_dir() call
-            rootdir = temproot.joinpath("pytest-of-{}".format(user))
-            rootdir.mkdir(exist_ok=True)
+            rootdir = temproot.joinpath(f"pytest-of-{user}")
+            try:
+                rootdir.mkdir(mode=0o700, exist_ok=True)
+            except OSError:
+                # getuser() likely returned illegal characters for the platform, use unknown back off mechanism
+                rootdir = temproot.joinpath("pytest-of-unknown")
+                rootdir.mkdir(mode=0o700, exist_ok=True)
+            # Because we use exist_ok=True with a predictable name, make sure
+            # we are the owners, to prevent any funny business (on unix, where
+            # temproot is usually shared).
+            # Also, to keep things private, fixup any world-readable temp
+            # rootdir's permissions. Historically 0o755 was used, so we can't
+            # just error out on this, at least for a while.
+            if sys.platform != "win32":
+                uid = os.getuid()
+                rootdir_stat = rootdir.stat()
+                # getuid shouldn't fail, but cpython defines such a case.
+                # Let's hope for the best.
+                if uid != -1:
+                    if rootdir_stat.st_uid != uid:
+                        raise OSError(
+                            f"The temporary directory {rootdir} is not owned by the current user. "
+                            "Fix this and try again."
+                        )
+                    if (rootdir_stat.st_mode & 0o077) != 0:
+                        os.chmod(rootdir, rootdir_stat.st_mode & ~0o077)
             basetemp = make_numbered_dir_with_cleanup(
-                prefix="pytest-", root=rootdir, keep=3, lock_timeout=LOCK_TIMEOUT
+                prefix="pytest-",
+                root=rootdir,
+                keep=3,
+                lock_timeout=LOCK_TIMEOUT,
+                mode=0o700,
             )
         assert basetemp is not None, basetemp
-        self._basetemp = t = basetemp
-        self._trace("new basetemp", t)
-        return t
-
-
-@final
-@attr.s
-class TempdirFactory:
-    """Backward comptibility wrapper that implements :class:``py.path.local``
-    for :class:``TempPathFactory``."""
-
-    _tmppath_factory = attr.ib(type=TempPathFactory)
-
-    def mktemp(self, basename: str, numbered: bool = True) -> py.path.local:
-        """Same as :meth:`TempPathFactory.mktemp`, but returns a ``py.path.local`` object."""
-        return py.path.local(self._tmppath_factory.mktemp(basename, numbered).resolve())
-
-    def getbasetemp(self) -> py.path.local:
-        """Backward compat wrapper for ``_tmppath_factory.getbasetemp``."""
-        return py.path.local(self._tmppath_factory.getbasetemp().resolve())
+        self._basetemp = basetemp
+        self._trace("new basetemp", basetemp)
+        return basetemp


 def get_user() -> Optional[str]:
     """Return the current user name, or None if getuser() does not work
     in the current environment (see #1010)."""
-    import getpass
-
     try:
+        # In some exotic environments, getpass may not be importable.
+        import getpass
+
         return getpass.getuser()
     except (ImportError, KeyError):
         return None


 def pytest_configure(config: Config) -> None:
-    """Create a TempdirFactory and attach it to the config object.
+    """Create a TempPathFactory and attach it to the config object.

     This is to comply with existing plugins which expect the handler to be
     available at pytest_configure time, but ideally should be moved entirely
-    to the tmpdir_factory session fixture.
+    to the tmp_path_factory session fixture.
     """
     mp = MonkeyPatch()
-    tmppath_handler = TempPathFactory.from_config(config)
-    t = TempdirFactory(tmppath_handler)
-    config._cleanup.append(mp.undo)
-    mp.setattr(config, "_tmp_path_factory", tmppath_handler, raising=False)
-    mp.setattr(config, "_tmpdirhandler", t, raising=False)
-
-
-@pytest.fixture(scope="session")
-def tmpdir_factory(request: FixtureRequest) -> TempdirFactory:
-    """Return a :class:`_pytest.tmpdir.TempdirFactory` instance for the test session."""
-    # Set dynamically by pytest_configure() above.
-    return request.config._tmpdirhandler  # type: ignore
-
-
-@pytest.fixture(scope="session")
+    config.add_cleanup(mp.undo)
+    _tmp_path_factory = TempPathFactory.from_config(config, _ispytest=True)
+    mp.setattr(config, "_tmp_path_factory", _tmp_path_factory, raising=False)
+
+
+@fixture(scope="session")
 def tmp_path_factory(request: FixtureRequest) -> TempPathFactory:
-    """Return a :class:`_pytest.tmpdir.TempPathFactory` instance for the test session."""
+    """Return a :class:`pytest.TempPathFactory` instance for the test session."""
     # Set dynamically by pytest_configure() above.
     return request.config._tmp_path_factory  # type: ignore

@@ -170,30 +195,18 @@
     return factory.mktemp(name, numbered=True)


-@pytest.fixture
-def tmpdir(tmp_path: Path) -> py.path.local:
-    """Return a temporary directory path object which is unique to each test
-    function invocation, created as a sub directory of the base temporary
-    directory.
-
-    The returned object is a `py.path.local`_ path object.
-
-    .. _`py.path.local`: https://py.readthedocs.io/en/latest/path.html
-    """
-    return py.path.local(tmp_path)
-
-
-@pytest.fixture
+@fixture
 def tmp_path(request: FixtureRequest, tmp_path_factory: TempPathFactory) -> Path:
     """Return a temporary directory path object which is unique to each test
     function invocation, created as a sub directory of the base temporary
     directory.

+    By default, a new base temporary directory is created each test session,
+    and old bases are removed after 3 sessions, to aid in debugging. If
+    ``--basetemp`` is used then it is cleared each session. See :ref:`base
+    temporary directory`.
+
     The returned object is a :class:`pathlib.Path` object.
-
-    .. note::
-
-        In python < 3.6 this is a pathlib2.Path.
     """

     return _mk_tmp(request, tmp_path_factory)
('src/_pytest', '__init__.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,8 +1,9 @@
-__all__ = ["__version__"]
+__all__ = ["__version__", "version_tuple"]

 try:
-    from ._version import version as __version__
-except ImportError:
+    from ._version import version as __version__, version_tuple
+except ImportError:  # pragma: no cover
     # broken installation, we don't even try
     # unknown only works because we do poor mans version compare
     __version__ = "unknown"
+    version_tuple = (0, 0, "unknown")  # type:ignore[assignment]
('src/_pytest', 'debugging.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -9,11 +9,12 @@
 from typing import List
 from typing import Optional
 from typing import Tuple
+from typing import Type
+from typing import TYPE_CHECKING
 from typing import Union

 from _pytest import outcomes
 from _pytest._code import ExceptionInfo
-from _pytest.compat import TYPE_CHECKING
 from _pytest.config import Config
 from _pytest.config import ConftestImportFailure
 from _pytest.config import hookimpl
@@ -24,8 +25,6 @@
 from _pytest.reports import BaseReport

 if TYPE_CHECKING:
-    from typing import Type
-
     from _pytest.capture import CaptureManager
     from _pytest.runner import CallInfo

@@ -36,7 +35,7 @@
         modname, classname = value.split(":")
     except ValueError as e:
         raise argparse.ArgumentTypeError(
-            "{!r} is not in the format 'modname:classname'".format(value)
+            f"{value!r} is not in the format 'modname:classname'"
         ) from e
     return (modname, classname)

@@ -54,7 +53,7 @@
         dest="usepdb_cls",
         metavar="modulename:classname",
         type=_validate_usepdb_cls,
-        help="start a custom interactive Python debugger on errors. "
+        help="specify a custom interactive Python debugger for use with --pdb."
         "For example: --pdbcls=IPython.terminal.debugger:TerminalPdb",
     )
     group._addoption(
@@ -89,19 +88,19 @@
             pytestPDB._config,
         ) = pytestPDB._saved.pop()

-    config._cleanup.append(fin)
+    config.add_cleanup(fin)


 class pytestPDB:
     """Pseudo PDB that defers to the real pdb."""

-    _pluginmanager = None  # type: Optional[PytestPluginManager]
-    _config = None  # type: Config
-    _saved = (
-        []
-    )  # type: List[Tuple[Callable[..., None], Optional[PytestPluginManager], Config]]
+    _pluginmanager: Optional[PytestPluginManager] = None
+    _config: Optional[Config] = None
+    _saved: List[
+        Tuple[Callable[..., None], Optional[PytestPluginManager], Optional[Config]]
+    ] = []
     _recursive_debug = 0
-    _wrapped_pdb_cls = None  # type: Optional[Tuple[Type[Any], Type[Any]]]
+    _wrapped_pdb_cls: Optional[Tuple[Type[Any], Type[Any]]] = None

     @classmethod
     def _is_capturing(cls, capman: Optional["CaptureManager"]) -> Union[str, bool]:
@@ -137,7 +136,7 @@
             except Exception as exc:
                 value = ":".join((modname, classname))
                 raise UsageError(
-                    "--pdbcls: could not import {!r}: {}".format(value, exc)
+                    f"--pdbcls: could not import {value!r}: {exc}"
                 ) from exc
         else:
             import pdb
@@ -167,6 +166,7 @@
             def do_continue(self, arg):
                 ret = super().do_continue(arg)
                 if cls._recursive_debug == 0:
+                    assert cls._config is not None
                     tw = _pytest.config.create_terminal_writer(cls._config)
                     tw.line()

@@ -240,7 +240,7 @@
         import _pytest.config

         if cls._pluginmanager is None:
-            capman = None  # type: Optional[CaptureManager]
+            capman: Optional[CaptureManager] = None
         else:
             capman = cls._pluginmanager.getplugin("capturemanager")
         if capman:
@@ -258,7 +258,7 @@
                 else:
                     capturing = cls._is_capturing(capman)
                     if capturing == "global":
-                        tw.sep(">", "PDB {} (IO-capturing turned off)".format(method))
+                        tw.sep(">", f"PDB {method} (IO-capturing turned off)")
                     elif capturing:
                         tw.sep(
                             ">",
@@ -266,7 +266,7 @@
                             % (method, capturing),
                         )
                     else:
-                        tw.sep(">", "PDB {}".format(method))
+                        tw.sep(">", f"PDB {method}")

         _pdb = cls._import_pdb_cls(capman)(**kwargs)

('src/_pytest', 'python_api.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,39 +1,69 @@
 import math
 import pprint
-from collections.abc import Iterable
-from collections.abc import Mapping
+from collections.abc import Collection
 from collections.abc import Sized
 from decimal import Decimal
-from numbers import Number
+from numbers import Complex
 from types import TracebackType
 from typing import Any
 from typing import Callable
 from typing import cast
 from typing import Generic
+from typing import List
+from typing import Mapping
 from typing import Optional
+from typing import overload
 from typing import Pattern
+from typing import Sequence
 from typing import Tuple
+from typing import Type
+from typing import TYPE_CHECKING
 from typing import TypeVar
 from typing import Union

+if TYPE_CHECKING:
+    from numpy import ndarray
+
+
 import _pytest._code
 from _pytest.compat import final
-from _pytest.compat import overload
 from _pytest.compat import STRING_TYPES
-from _pytest.compat import TYPE_CHECKING
 from _pytest.outcomes import fail

-if TYPE_CHECKING:
-    from typing import Type
-

 def _non_numeric_type_error(value, at: Optional[str]) -> TypeError:
-    at_str = " at {}".format(at) if at else ""
+    at_str = f" at {at}" if at else ""
     return TypeError(
         "cannot make approximate comparisons to non-numeric values: {!r} {}".format(
             value, at_str
         )
     )
+
+
+def _compare_approx(
+    full_object: object,
+    message_data: Sequence[Tuple[str, str, str]],
+    number_of_elements: int,
+    different_ids: Sequence[object],
+    max_abs_diff: float,
+    max_rel_diff: float,
+) -> List[str]:
+    message_list = list(message_data)
+    message_list.insert(0, ("Index", "Obtained", "Expected"))
+    max_sizes = [0, 0, 0]
+    for index, obtained, expected in message_list:
+        max_sizes[0] = max(max_sizes[0], len(index))
+        max_sizes[1] = max(max_sizes[1], len(obtained))
+        max_sizes[2] = max(max_sizes[2], len(expected))
+    explanation = [
+        f"comparison failed. Mismatched elements: {len(different_ids)} / {number_of_elements}:",
+        f"Max absolute difference: {max_abs_diff}",
+        f"Max relative difference: {max_rel_diff}",
+    ] + [
+        f"{indexes:<{max_sizes[0]}} | {obtained:<{max_sizes[1]}} | {expected:<{max_sizes[2]}}"
+        for indexes, obtained, expected in message_list
+    ]
+    return explanation


 # builtin pytest.approx helper
@@ -58,11 +88,24 @@
     def __repr__(self) -> str:
         raise NotImplementedError

+    def _repr_compare(self, other_side: Any) -> List[str]:
+        return [
+            "comparison failed",
+            f"Obtained: {other_side}",
+            f"Expected: {self}",
+        ]
+
     def __eq__(self, actual) -> bool:
         return all(
             a == self._approx_scalar(x) for a, x in self._yield_comparisons(actual)
         )

+    def __bool__(self):
+        __tracebackhide__ = True
+        raise AssertionError(
+            "approx() is not supported in a boolean context.\nDid you mean: `assert a == approx(b)`?"
+        )
+
     # Ignore type because of https://github.com/python/mypy/issues/4266.
     __hash__ = None  # type: ignore

@@ -70,6 +113,8 @@
         return not (actual == self)

     def _approx_scalar(self, x) -> "ApproxScalar":
+        if isinstance(x, Decimal):
+            return ApproxDecimal(x, rel=self.rel, abs=self.abs, nan_ok=self.nan_ok)
         return ApproxScalar(x, rel=self.rel, abs=self.abs, nan_ok=self.nan_ok)

     def _yield_comparisons(self, actual):
@@ -86,12 +131,11 @@
         # a numeric type.  For this reason, the default is to do nothing.  The
         # classes that deal with sequences should reimplement this method to
         # raise if there are any non-numeric elements in the sequence.
-        pass


 def _recursive_list_map(f, x):
     if isinstance(x, list):
-        return list(_recursive_list_map(f, xi) for xi in x)
+        return [_recursive_list_map(f, xi) for xi in x]
     else:
         return f(x)

@@ -101,7 +145,67 @@

     def __repr__(self) -> str:
         list_scalars = _recursive_list_map(self._approx_scalar, self.expected.tolist())
-        return "approx({!r})".format(list_scalars)
+        return f"approx({list_scalars!r})"
+
+    def _repr_compare(self, other_side: "ndarray") -> List[str]:
+        import itertools
+        import math
+
+        def get_value_from_nested_list(
+            nested_list: List[Any], nd_index: Tuple[Any, ...]
+        ) -> Any:
+            """
+            Helper function to get the value out of a nested list, given an n-dimensional index.
+            This mimics numpy's indexing, but for raw nested python lists.
+            """
+            value: Any = nested_list
+            for i in nd_index:
+                value = value[i]
+            return value
+
+        np_array_shape = self.expected.shape
+        approx_side_as_list = _recursive_list_map(
+            self._approx_scalar, self.expected.tolist()
+        )
+
+        if np_array_shape != other_side.shape:
+            return [
+                "Impossible to compare arrays with different shapes.",
+                f"Shapes: {np_array_shape} and {other_side.shape}",
+            ]
+
+        number_of_elements = self.expected.size
+        max_abs_diff = -math.inf
+        max_rel_diff = -math.inf
+        different_ids = []
+        for index in itertools.product(*(range(i) for i in np_array_shape)):
+            approx_value = get_value_from_nested_list(approx_side_as_list, index)
+            other_value = get_value_from_nested_list(other_side, index)
+            if approx_value != other_value:
+                abs_diff = abs(approx_value.expected - other_value)
+                max_abs_diff = max(max_abs_diff, abs_diff)
+                if other_value == 0.0:
+                    max_rel_diff = math.inf
+                else:
+                    max_rel_diff = max(max_rel_diff, abs_diff / abs(other_value))
+                different_ids.append(index)
+
+        message_data = [
+            (
+                str(index),
+                str(get_value_from_nested_list(other_side, index)),
+                str(get_value_from_nested_list(approx_side_as_list, index)),
+            )
+            for index in different_ids
+        ]
+        return _compare_approx(
+            self.expected,
+            message_data,
+            number_of_elements,
+            different_ids,
+            max_abs_diff,
+            max_rel_diff,
+        )

     def __eq__(self, actual) -> bool:
         import numpy as np
@@ -112,14 +216,12 @@
             try:
                 actual = np.asarray(actual)
             except Exception as e:
-                raise TypeError(
-                    "cannot compare '{}' to numpy.ndarray".format(actual)
-                ) from e
+                raise TypeError(f"cannot compare '{actual}' to numpy.ndarray") from e

         if not np.isscalar(actual) and actual.shape != self.expected.shape:
             return False

-        return ApproxBase.__eq__(self, actual)
+        return super().__eq__(actual)

     def _yield_comparisons(self, actual):
         import numpy as np
@@ -145,11 +247,52 @@
             {k: self._approx_scalar(v) for k, v in self.expected.items()}
         )

+    def _repr_compare(self, other_side: Mapping[object, float]) -> List[str]:
+        import math
+
+        approx_side_as_map = {
+            k: self._approx_scalar(v) for k, v in self.expected.items()
+        }
+
+        number_of_elements = len(approx_side_as_map)
+        max_abs_diff = -math.inf
+        max_rel_diff = -math.inf
+        different_ids = []
+        for (approx_key, approx_value), other_value in zip(
+            approx_side_as_map.items(), other_side.values()
+        ):
+            if approx_value != other_value:
+                max_abs_diff = max(
+                    max_abs_diff, abs(approx_value.expected - other_value)
+                )
+                max_rel_diff = max(
+                    max_rel_diff,
+                    abs((approx_value.expected - other_value) / approx_value.expected),
+                )
+                different_ids.append(approx_key)
+
+        message_data = [
+            (str(key), str(other_side[key]), str(approx_side_as_map[key]))
+            for key in different_ids
+        ]
+
+        return _compare_approx(
+            self.expected,
+            message_data,
+            number_of_elements,
+            different_ids,
+            max_abs_diff,
+            max_rel_diff,
+        )
+
     def __eq__(self, actual) -> bool:
-        if set(actual.keys()) != set(self.expected.keys()):
+        try:
+            if set(actual.keys()) != set(self.expected.keys()):
+                return False
+        except AttributeError:
             return False

-        return ApproxBase.__eq__(self, actual)
+        return super().__eq__(actual)

     def _yield_comparisons(self, actual):
         for k in self.expected.keys():
@@ -161,25 +304,67 @@
             if isinstance(value, type(self.expected)):
                 msg = "pytest.approx() does not support nested dictionaries: key={!r} value={!r}\n  full mapping={}"
                 raise TypeError(msg.format(key, value, pprint.pformat(self.expected)))
-            elif not isinstance(value, Number):
-                raise _non_numeric_type_error(self.expected, at="key={!r}".format(key))
-
-
-class ApproxSequencelike(ApproxBase):
+
+
+class ApproxSequenceLike(ApproxBase):
     """Perform approximate comparisons where the expected value is a sequence of numbers."""

     def __repr__(self) -> str:
         seq_type = type(self.expected)
-        if seq_type not in (tuple, list, set):
+        if seq_type not in (tuple, list):
             seq_type = list
         return "approx({!r})".format(
             seq_type(self._approx_scalar(x) for x in self.expected)
         )

+    def _repr_compare(self, other_side: Sequence[float]) -> List[str]:
+        import math
+
+        if len(self.expected) != len(other_side):
+            return [
+                "Impossible to compare lists with different sizes.",
+                f"Lengths: {len(self.expected)} and {len(other_side)}",
+            ]
+
+        approx_side_as_map = _recursive_list_map(self._approx_scalar, self.expected)
+
+        number_of_elements = len(approx_side_as_map)
+        max_abs_diff = -math.inf
+        max_rel_diff = -math.inf
+        different_ids = []
+        for i, (approx_value, other_value) in enumerate(
+            zip(approx_side_as_map, other_side)
+        ):
+            if approx_value != other_value:
+                abs_diff = abs(approx_value.expected - other_value)
+                max_abs_diff = max(max_abs_diff, abs_diff)
+                if other_value == 0.0:
+                    max_rel_diff = math.inf
+                else:
+                    max_rel_diff = max(max_rel_diff, abs_diff / abs(other_value))
+                different_ids.append(i)
+
+        message_data = [
+            (str(i), str(other_side[i]), str(approx_side_as_map[i]))
+            for i in different_ids
+        ]
+
+        return _compare_approx(
+            self.expected,
+            message_data,
+            number_of_elements,
+            different_ids,
+            max_abs_diff,
+            max_rel_diff,
+        )
+
     def __eq__(self, actual) -> bool:
-        if len(actual) != len(self.expected):
+        try:
+            if len(actual) != len(self.expected):
+                return False
+        except TypeError:
             return False
-        return ApproxBase.__eq__(self, actual)
+        return super().__eq__(actual)

     def _yield_comparisons(self, actual):
         return zip(actual, self.expected)
@@ -190,10 +375,6 @@
             if isinstance(x, type(self.expected)):
                 msg = "pytest.approx() does not support nested data structures: {!r} at index {}\n  full sequence: {}"
                 raise TypeError(msg.format(x, index, pprint.pformat(self.expected)))
-            elif not isinstance(x, Number):
-                raise _non_numeric_type_error(
-                    self.expected, at="index {}".format(index)
-                )


 class ApproxScalar(ApproxBase):
@@ -201,8 +382,8 @@

     # Using Real should be better than this Union, but not possible yet:
     # https://github.com/python/typeshed/pull/3108
-    DEFAULT_ABSOLUTE_TOLERANCE = 1e-12  # type: Union[float, Decimal]
-    DEFAULT_RELATIVE_TOLERANCE = 1e-6  # type: Union[float, Decimal]
+    DEFAULT_ABSOLUTE_TOLERANCE: Union[float, Decimal] = 1e-12
+    DEFAULT_RELATIVE_TOLERANCE: Union[float, Decimal] = 1e-6

     def __repr__(self) -> str:
         """Return a string communicating both the expected value and the
@@ -210,40 +391,56 @@

         For example, ``1.0 ± 1e-6``, ``(3+4j) ± 5e-6 ∠ ±180°``.
         """
-
-        # Infinities aren't compared using tolerances, so don't show a
-        # tolerance. Need to call abs to handle complex numbers, e.g. (inf + 1j).
-        if math.isinf(abs(self.expected)):
+        # Don't show a tolerance for values that aren't compared using
+        # tolerances, i.e. non-numerics and infinities. Need to call abs to
+        # handle complex numbers, e.g. (inf + 1j).
+        if (not isinstance(self.expected, (Complex, Decimal))) or math.isinf(
+            abs(self.expected)  # type: ignore[arg-type]
+        ):
             return str(self.expected)

         # If a sensible tolerance can't be calculated, self.tolerance will
         # raise a ValueError.  In this case, display '???'.
         try:
-            vetted_tolerance = "{:.1e}".format(self.tolerance)
-            if isinstance(self.expected, complex) and not math.isinf(self.tolerance):
+            vetted_tolerance = f"{self.tolerance:.1e}"
+            if (
+                isinstance(self.expected, Complex)
+                and self.expected.imag
+                and not math.isinf(self.tolerance)
+            ):
                 vetted_tolerance += " ∠ ±180°"
         except ValueError:
             vetted_tolerance = "???"

-        return "{} ± {}".format(self.expected, vetted_tolerance)
+        return f"{self.expected} ± {vetted_tolerance}"

     def __eq__(self, actual) -> bool:
         """Return whether the given value is equal to the expected value
         within the pre-specified tolerance."""
-        if _is_numpy_array(actual):
+        asarray = _as_numpy_array(actual)
+        if asarray is not None:
             # Call ``__eq__()`` manually to prevent infinite-recursion with
             # numpy<1.13.  See #3748.
-            return all(self.__eq__(a) for a in actual.flat)
+            return all(self.__eq__(a) for a in asarray.flat)

         # Short-circuit exact equality.
         if actual == self.expected:
             return True

+        # If either type is non-numeric, fall back to strict equality.
+        # NB: we need Complex, rather than just Number, to ensure that __abs__,
+        # __sub__, and __float__ are defined.
+        if not (
+            isinstance(self.expected, (Complex, Decimal))
+            and isinstance(actual, (Complex, Decimal))
+        ):
+            return False
+
         # Allow the user to control whether NaNs are considered equal to each
         # other or not.  The abs() calls are for compatibility with complex
         # numbers.
-        if math.isnan(abs(self.expected)):
-            return self.nan_ok and math.isnan(abs(actual))
+        if math.isnan(abs(self.expected)):  # type: ignore[arg-type]
+            return self.nan_ok and math.isnan(abs(actual))  # type: ignore[arg-type]

         # Infinity shouldn't be approximately equal to anything but itself, but
         # if there's a relative tolerance, it will be infinite and infinity
@@ -251,11 +448,11 @@
         # case would have been short circuited above, so here we can just
         # return false if the expected value is infinite.  The abs() call is
         # for compatibility with complex numbers.
-        if math.isinf(abs(self.expected)):
+        if math.isinf(abs(self.expected)):  # type: ignore[arg-type]
             return False

         # Return true if the two numbers are within the tolerance.
-        result = abs(self.expected - actual) <= self.tolerance  # type: bool
+        result: bool = abs(self.expected - actual) <= self.tolerance
         return result

     # Ignore type because of https://github.com/python/mypy/issues/4266.
@@ -278,7 +475,7 @@

         if absolute_tolerance < 0:
             raise ValueError(
-                "absolute tolerance can't be negative: {}".format(absolute_tolerance)
+                f"absolute tolerance can't be negative: {absolute_tolerance}"
             )
         if math.isnan(absolute_tolerance):
             raise ValueError("absolute tolerance can't be NaN.")
@@ -300,7 +497,7 @@

         if relative_tolerance < 0:
             raise ValueError(
-                "relative tolerance can't be negative: {}".format(absolute_tolerance)
+                f"relative tolerance can't be negative: {relative_tolerance}"
             )
         if math.isnan(relative_tolerance):
             raise ValueError("relative tolerance can't be NaN.")
@@ -317,16 +514,14 @@


 def approx(expected, rel=None, abs=None, nan_ok: bool = False) -> ApproxBase:
-    """Assert that two numbers (or two sets of numbers) are equal to each other
+    """Assert that two numbers (or two ordered sequences of numbers) are equal to each other
     within some tolerance.

-    Due to the `intricacies of floating-point arithmetic`__, numbers that we
+    Due to the :std:doc:`tutorial/floatingpoint`, numbers that we
     would intuitively expect to be equal are not always so::

         >>> 0.1 + 0.2 == 0.3
         False
-
-    __ https://docs.python.org/3/tutorial/floatingpoint.html

     This problem is commonly encountered when writing tests, e.g. when making
     sure that floating-point values are what you expect them to be.  One way to
@@ -351,14 +546,9 @@
         >>> 0.1 + 0.2 == approx(0.3)
         True

-    The same syntax also works for sequences of numbers::
+    The same syntax also works for ordered sequences of numbers::

         >>> (0.1 + 0.2, 0.2 + 0.4) == approx((0.3, 0.6))
-        True
-
-    Dictionary *values*::
-
-        >>> {'a': 0.1 + 0.2, 'b': 0.2 + 0.4} == approx({'a': 0.3, 'b': 0.6})
         True

     ``numpy`` arrays::
@@ -372,6 +562,20 @@
         >>> import numpy as np                                         # doctest: +SKIP
         >>> np.array([0.1, 0.2]) + np.array([0.2, 0.1]) == approx(0.3) # doctest: +SKIP
         True
+
+    Only ordered sequences are supported, because ``approx`` needs
+    to infer the relative position of the sequences without ambiguity. This means
+    ``sets`` and other unordered sequences are not supported.
+
+    Finally, dictionary *values* can also be compared::
+
+        >>> {'a': 0.1 + 0.2, 'b': 0.2 + 0.4} == approx({'a': 0.3, 'b': 0.6})
+        True
+
+    The comparison will be true if both mappings have the same keys and their
+    respective values match the expected tolerances.
+
+    **Tolerances**

     By default, ``approx`` considers numbers within a relative tolerance of
     ``1e-6`` (i.e. one part in a million) of its expected value to be equal.
@@ -409,6 +613,18 @@
         >>> 1 + 1e-8 == approx(1, rel=1e-6, abs=1e-12)
         True

+    You can also use ``approx`` to compare nonnumeric types, or dicts and
+    sequences containing nonnumeric types, in which case it falls back to
+    strict equality. This can be useful for comparing dicts and sequences that
+    can contain optional values::
+
+        >>> {"required": 1.0000005, "optional": None} == approx({"required": 1, "optional": None})
+        True
+        >>> [None, 1.0000005] == approx([None,1])
+        True
+        >>> ["foo", 1.0000005] == approx([None,1])
+        False
+
     If you're thinking about using ``approx``, then you might want to know how
     it compares to other good ways of comparing floating-point numbers.  All of
     these algorithms are based on relative and absolute tolerances and should
@@ -420,27 +636,22 @@
       both ``a`` and ``b``, this test is symmetric (i.e.  neither ``a`` nor
       ``b`` is a "reference value").  You have to specify an absolute tolerance
       if you want to compare to ``0.0`` because there is no tolerance by
-      default.  Only available in python>=3.5.  `More information...`__
-
-      __ https://docs.python.org/3/library/math.html#math.isclose
+      default.  More information: :py:func:`math.isclose`.

     - ``numpy.isclose(a, b, rtol=1e-5, atol=1e-8)``: True if the difference
       between ``a`` and ``b`` is less that the sum of the relative tolerance
       w.r.t. ``b`` and the absolute tolerance.  Because the relative tolerance
       is only calculated w.r.t. ``b``, this test is asymmetric and you can
       think of ``b`` as the reference value.  Support for comparing sequences
-      is provided by ``numpy.allclose``.  `More information...`__
-
-      __ http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.isclose.html
+      is provided by :py:func:`numpy.allclose`.  More information:
+      :std:doc:`numpy:reference/generated/numpy.isclose`.

     - ``unittest.TestCase.assertAlmostEqual(a, b)``: True if ``a`` and ``b``
       are within an absolute tolerance of ``1e-7``.  No relative tolerance is
-      considered and the absolute tolerance cannot be changed, so this function
-      is not appropriate for very large or very small numbers.  Also, it's only
-      available in subclasses of ``unittest.TestCase`` and it's ugly because it
-      doesn't follow PEP8.  `More information...`__
-
-      __ https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertAlmostEqual
+      considered , so this function is not appropriate for very large or very
+      small numbers.  Also, it's only available in subclasses of ``unittest.TestCase``
+      and it's ugly because it doesn't follow PEP8.  More information:
+      :py:meth:`unittest.TestCase.assertAlmostEqual`.

     - ``a == pytest.approx(b, rel=1e-6, abs=1e-12)``: True if the relative
       tolerance is met w.r.t. ``b`` or if the absolute tolerance is met.
@@ -449,11 +660,17 @@
       special case that you explicitly specify an absolute tolerance but not a
       relative tolerance, only the absolute tolerance is considered.

+    .. note::
+
+        ``approx`` can handle numpy arrays, but we recommend the
+        specialised test helpers in :std:doc:`numpy:reference/routines.testing`
+        if you need support for comparisons, NaNs, or ULP-based tolerances.
+
     .. warning::

        .. versionchanged:: 3.2

-       In order to avoid inconsistent behavior, ``TypeError`` is
+       In order to avoid inconsistent behavior, :py:exc:`TypeError` is
        raised for ``>``, ``>=``, ``<`` and ``<=`` comparisons.
        The example below illustrates the problem::

@@ -463,9 +680,15 @@
        In the second example one expects ``approx(0.1).__le__(0.1 + 1e-10)``
        to be called. But instead, ``approx(0.1).__lt__(0.1 + 1e-10)`` is used to
        comparison. This is because the call hierarchy of rich comparisons
-       follows a fixed behavior. `More information...`__
-
-       __ https://docs.python.org/3/reference/datamodel.html#object.__ge__
+       follows a fixed behavior. More information: :py:meth:`object.__ge__`
+
+    .. versionchanged:: 3.7.1
+       ``approx`` raises ``TypeError`` when it encounters a dict value or
+       sequence element of nonnumeric type.
+
+    .. versionchanged:: 6.1.0
+       ``approx`` falls back to strict equality for nonnumeric types instead
+       of raising ``TypeError``.
     """

     # Delegate the comparison to a class that knows how to deal with the type
@@ -486,91 +709,108 @@
     __tracebackhide__ = True

     if isinstance(expected, Decimal):
-        cls = ApproxDecimal  # type: Type[ApproxBase]
-    elif isinstance(expected, Number):
-        cls = ApproxScalar
+        cls: Type[ApproxBase] = ApproxDecimal
     elif isinstance(expected, Mapping):
         cls = ApproxMapping
     elif _is_numpy_array(expected):
+        expected = _as_numpy_array(expected)
         cls = ApproxNumpy
     elif (
-        isinstance(expected, Iterable)
+        hasattr(expected, "__getitem__")
         and isinstance(expected, Sized)
         # Type ignored because the error is wrong -- not unreachable.
         and not isinstance(expected, STRING_TYPES)  # type: ignore[unreachable]
     ):
-        cls = ApproxSequencelike
+        cls = ApproxSequenceLike
+    elif (
+        isinstance(expected, Collection)
+        # Type ignored because the error is wrong -- not unreachable.
+        and not isinstance(expected, STRING_TYPES)  # type: ignore[unreachable]
+    ):
+        msg = f"pytest.approx() only supports ordered sequences, but got: {repr(expected)}"
+        raise TypeError(msg)
     else:
-        raise _non_numeric_type_error(expected, at=None)
+        cls = ApproxScalar

     return cls(expected, rel, abs, nan_ok)


 def _is_numpy_array(obj: object) -> bool:
-    """Return true if the given object is a numpy array.
-
-    A special effort is made to avoid importing numpy unless it's really necessary.
+    """
+    Return true if the given object is implicitly convertible to ndarray,
+    and numpy is already imported.
+    """
+    return _as_numpy_array(obj) is not None
+
+
+def _as_numpy_array(obj: object) -> Optional["ndarray"]:
+    """
+    Return an ndarray if the given object is implicitly convertible to ndarray,
+    and numpy is already imported, otherwise None.
     """
     import sys

-    np = sys.modules.get("numpy")  # type: Any
+    np: Any = sys.modules.get("numpy")
     if np is not None:
-        return isinstance(obj, np.ndarray)
-    return False
+        # avoid infinite recursion on numpy scalars, which have __array__
+        if np.isscalar(obj):
+            return None
+        elif isinstance(obj, np.ndarray):
+            return obj
+        elif hasattr(obj, "__array__") or hasattr("obj", "__array_interface__"):
+            return np.asarray(obj)
+    return None


 # builtin pytest.raises helper

-_E = TypeVar("_E", bound=BaseException)
+E = TypeVar("E", bound=BaseException)


 @overload
 def raises(
-    expected_exception: Union["Type[_E]", Tuple["Type[_E]", ...]],
+    expected_exception: Union[Type[E], Tuple[Type[E], ...]],
     *,
-    match: "Optional[Union[str, Pattern[str]]]" = ...
-) -> "RaisesContext[_E]":
+    match: Optional[Union[str, Pattern[str]]] = ...,
+) -> "RaisesContext[E]":
     ...


-@overload  # noqa: F811
-def raises(  # noqa: F811
-    expected_exception: Union["Type[_E]", Tuple["Type[_E]", ...]],
+@overload
+def raises(
+    expected_exception: Union[Type[E], Tuple[Type[E], ...]],
     func: Callable[..., Any],
     *args: Any,
-    **kwargs: Any
-) -> _pytest._code.ExceptionInfo[_E]:
+    **kwargs: Any,
+) -> _pytest._code.ExceptionInfo[E]:
     ...


-def raises(  # noqa: F811
-    expected_exception: Union["Type[_E]", Tuple["Type[_E]", ...]],
-    *args: Any,
-    **kwargs: Any
-) -> Union["RaisesContext[_E]", _pytest._code.ExceptionInfo[_E]]:
+def raises(
+    expected_exception: Union[Type[E], Tuple[Type[E], ...]], *args: Any, **kwargs: Any
+) -> Union["RaisesContext[E]", _pytest._code.ExceptionInfo[E]]:
     r"""Assert that a code block/function call raises ``expected_exception``
     or raise a failure exception otherwise.

     :kwparam match:
         If specified, a string containing a regular expression,
         or a regular expression object, that is tested against the string
-        representation of the exception using ``re.search``. To match a literal
-        string that may contain `special characters`__, the pattern can
-        first be escaped with ``re.escape``.
-
-        (This is only used when ``pytest.raises`` is used as a context manager,
+        representation of the exception using :py:func:`re.search`. To match a literal
+        string that may contain :std:ref:`special characters <re-syntax>`, the pattern can
+        first be escaped with :py:func:`re.escape`.
+
+        (This is only used when :py:func:`pytest.raises` is used as a context manager,
         and passed through to the function otherwise.
-        When using ``pytest.raises`` as a function, you can use:
+        When using :py:func:`pytest.raises` as a function, you can use:
         ``pytest.raises(Exc, func, match="passed on").match("my pattern")``.)
-
-        __ https://docs.python.org/3/library/re.html#regular-expression-syntax

     .. currentmodule:: _pytest._code

     Use ``pytest.raises`` as a context manager, which will capture the exception of the given
     type::

-        >>> with raises(ZeroDivisionError):
+        >>> import pytest
+        >>> with pytest.raises(ZeroDivisionError):
         ...    1/0

     If the code block does not raise the expected exception (``ZeroDivisionError`` in the example
@@ -579,16 +819,16 @@
     You can also use the keyword argument ``match`` to assert that the
     exception matches a text or regex::

-        >>> with raises(ValueError, match='must be 0 or None'):
+        >>> with pytest.raises(ValueError, match='must be 0 or None'):
         ...     raise ValueError("value must be 0 or None")

-        >>> with raises(ValueError, match=r'must be \d+$'):
+        >>> with pytest.raises(ValueError, match=r'must be \d+$'):
         ...     raise ValueError("value must be 42")

     The context manager produces an :class:`ExceptionInfo` object which can be used to inspect the
     details of the captured exception::

-        >>> with raises(ValueError) as exc_info:
+        >>> with pytest.raises(ValueError) as exc_info:
         ...     raise ValueError("value must be 42")
         >>> assert exc_info.type is ValueError
         >>> assert exc_info.value.args[0] == "value must be 42"
@@ -602,7 +842,7 @@
        not be executed. For example::

            >>> value = 15
-           >>> with raises(ValueError) as exc_info:
+           >>> with pytest.raises(ValueError) as exc_info:
            ...     if value > 10:
            ...         raise ValueError("value must be <= 10")
            ...     assert exc_info.type is ValueError  # this will not execute
@@ -610,7 +850,7 @@
        Instead, the following approach must be taken (note the difference in
        scope)::

-           >>> with raises(ValueError) as exc_info:
+           >>> with pytest.raises(ValueError) as exc_info:
            ...     if value > 10:
            ...         raise ValueError("value must be <= 10")
            ...
@@ -660,19 +900,19 @@
     __tracebackhide__ = True

     if isinstance(expected_exception, type):
-        excepted_exceptions = (expected_exception,)  # type: Tuple[Type[_E], ...]
+        excepted_exceptions: Tuple[Type[E], ...] = (expected_exception,)
     else:
         excepted_exceptions = expected_exception
     for exc in excepted_exceptions:
-        if not isinstance(exc, type) or not issubclass(exc, BaseException):  # type: ignore[unreachable]
+        if not isinstance(exc, type) or not issubclass(exc, BaseException):
             msg = "expected exception must be a BaseException type, not {}"  # type: ignore[unreachable]
             not_a = exc.__name__ if isinstance(exc, type) else type(exc).__name__
             raise TypeError(msg.format(not_a))

-    message = "DID NOT RAISE {}".format(expected_exception)
+    message = f"DID NOT RAISE {expected_exception}"

     if not args:
-        match = kwargs.pop("match", None)  # type: Optional[Union[str, Pattern[str]]]
+        match: Optional[Union[str, Pattern[str]]] = kwargs.pop("match", None)
         if kwargs:
             msg = "Unexpected keyword arguments passed to pytest.raises: "
             msg += ", ".join(sorted(kwargs))
@@ -682,9 +922,7 @@
     else:
         func = args[0]
         if not callable(func):
-            raise TypeError(
-                "{!r} object (type: {}) must be callable".format(func, type(func))
-            )
+            raise TypeError(f"{func!r} object (type: {type(func)}) must be callable")
         try:
             func(*args[1:], **kwargs)
         except expected_exception as e:
@@ -701,25 +939,25 @@


 @final
-class RaisesContext(Generic[_E]):
+class RaisesContext(Generic[E]):
     def __init__(
         self,
-        expected_exception: Union["Type[_E]", Tuple["Type[_E]", ...]],
+        expected_exception: Union[Type[E], Tuple[Type[E], ...]],
         message: str,
-        match_expr: Optional[Union[str, "Pattern[str]"]] = None,
+        match_expr: Optional[Union[str, Pattern[str]]] = None,
     ) -> None:
         self.expected_exception = expected_exception
         self.message = message
         self.match_expr = match_expr
-        self.excinfo = None  # type: Optional[_pytest._code.ExceptionInfo[_E]]
-
-    def __enter__(self) -> _pytest._code.ExceptionInfo[_E]:
+        self.excinfo: Optional[_pytest._code.ExceptionInfo[E]] = None
+
+    def __enter__(self) -> _pytest._code.ExceptionInfo[E]:
         self.excinfo = _pytest._code.ExceptionInfo.for_later()
         return self.excinfo

     def __exit__(
         self,
-        exc_type: Optional["Type[BaseException]"],
+        exc_type: Optional[Type[BaseException]],
         exc_val: Optional[BaseException],
         exc_tb: Optional[TracebackType],
     ) -> bool:
@@ -730,9 +968,7 @@
         if not issubclass(exc_type, self.expected_exception):
             return False
         # Cast to narrow the exception type now that it's verified.
-        exc_info = cast(
-            Tuple["Type[_E]", _E, TracebackType], (exc_type, exc_val, exc_tb)
-        )
+        exc_info = cast(Tuple[Type[E], E, TracebackType], (exc_type, exc_val, exc_tb))
         self.excinfo.fill_unfilled(exc_info)
         if self.match_expr is not None:
             self.excinfo.match(self.match_expr)
('src/_pytest', '_argcomplete.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -26,7 +26,7 @@
 uses a python program to determine startup script generated by pip.
 You can speed up completion somewhat by changing this script to include
   # PYTHON_ARGCOMPLETE_OK
-so the the python-argcomplete-check-easy-install-script does not
+so the python-argcomplete-check-easy-install-script does not
 need to be called to find the entry point of the code and see if that is
 marked  with PYTHON_ARGCOMPLETE_OK.

@@ -103,11 +103,10 @@
         import argcomplete.completers
     except ImportError:
         sys.exit(-1)
-    filescompleter = FastFilesCompleter()  # type: Optional[FastFilesCompleter]
+    filescompleter: Optional[FastFilesCompleter] = FastFilesCompleter()

     def try_argcomplete(parser: argparse.ArgumentParser) -> None:
         argcomplete.autocomplete(parser, always_complete_options=False)
-

 else:

('src/_pytest', 'capture.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -14,15 +14,18 @@
 from typing import Optional
 from typing import TextIO
 from typing import Tuple
+from typing import TYPE_CHECKING
 from typing import Union

-import pytest
 from _pytest.compat import final
-from _pytest.compat import TYPE_CHECKING
 from _pytest.config import Config
+from _pytest.config import hookimpl
 from _pytest.config.argparsing import Parser
+from _pytest.deprecated import check_ispytest
+from _pytest.fixtures import fixture
 from _pytest.fixtures import SubRequest
 from _pytest.nodes import Collector
+from _pytest.nodes import File
 from _pytest.nodes import Item

 if TYPE_CHECKING:
@@ -65,32 +68,8 @@
             pass


-def _readline_workaround() -> None:
-    """Ensure readline is imported so that it attaches to the correct stdio
-    handles on Windows.
-
-    Pdb uses readline support where available--when not running from the Python
-    prompt, the readline module is not imported until running the pdb REPL.  If
-    running pytest with the --pdb option this means the readline module is not
-    imported until after I/O capture has been started.
-
-    This is a problem for pyreadline, which is often used to implement readline
-    support on Windows, as it does not attach to the correct handles for stdout
-    and/or stdin if they have been redirected by the FDCapture mechanism.  This
-    workaround ensures that readline is imported before I/O capture is setup so
-    that it can attach to the actual stdin/out for the console.
-
-    See https://github.com/pytest-dev/pytest/pull/1281.
-    """
-    if sys.platform.startswith("win32"):
-        try:
-            import readline  # noqa: F401
-        except ImportError:
-            pass
-
-
-def _py36_windowsconsoleio_workaround(stream: TextIO) -> None:
-    """Workaround for Windows Unicode console handling on Python>=3.6.
+def _windowsconsoleio_workaround(stream: TextIO) -> None:
+    """Workaround for Windows Unicode console handling.

     Python 3.6 implemented Unicode console handling for Windows. This works
     by reading/writing to the raw console handle using
@@ -113,11 +92,7 @@

     See https://github.com/pytest-dev/py/issues/103.
     """
-    if (
-        not sys.platform.startswith("win32")
-        or sys.version_info[:2] < (3, 6)
-        or hasattr(sys, "pypy_version_info")
-    ):
+    if not sys.platform.startswith("win32") or hasattr(sys, "pypy_version_info"):
         return

     # Bail out if ``stream`` doesn't seem like a proper ``io`` stream (#2666).
@@ -137,7 +112,7 @@
             buffering = -1

         return io.TextIOWrapper(
-            open(os.dup(f.fileno()), mode, buffering),  # type: ignore[arg-type]
+            open(os.dup(f.fileno()), mode, buffering),
             f.encoding,
             f.errors,
             f.newlines,
@@ -149,13 +124,12 @@
     sys.stderr = _reopen_stdio(sys.stderr, "wb")


-@pytest.hookimpl(hookwrapper=True)
+@hookimpl(hookwrapper=True)
 def pytest_load_initial_conftests(early_config: Config):
     ns = early_config.known_args_namespace
     if ns.capture == "fd":
-        _py36_windowsconsoleio_workaround(sys.stdout)
+        _windowsconsoleio_workaround(sys.stdout)
     _colorama_workaround()
-    _readline_workaround()
     pluginmanager = early_config.pluginmanager
     capman = CaptureManager(ns.capture)
     pluginmanager.register(capman, "capturemanager")
@@ -364,7 +338,7 @@
         except OSError:
             # FD capturing is conceptually simple -- create a temporary file,
             # redirect the FD to it, redirect back when done. But when the
-            # target FD is invalid it throws a wrench into this loveley scheme.
+            # target FD is invalid it throws a wrench into this lovely scheme.
             #
             # Tests themselves shouldn't care if the FD is valid, FD capturing
             # should work regardless of external circumstances. So falling back
@@ -373,9 +347,7 @@
             # Further complications are the need to support suspend() and the
             # possibility of FD reuse (e.g. the tmpfile getting the very same
             # target FD). The following approach is robust, I believe.
-            self.targetfd_invalid = os.open(
-                os.devnull, os.O_RDWR
-            )  # type: Optional[int]
+            self.targetfd_invalid: Optional[int] = os.open(os.devnull, os.O_RDWR)
             os.dup2(self.targetfd_invalid, targetfd)
         else:
             self.targetfd_invalid = None
@@ -386,8 +358,7 @@
             self.syscapture = SysCapture(targetfd)
         else:
             self.tmpfile = EncodedFile(
-                # TODO: Remove type ignore, fixed in next mypy release.
-                TemporaryFile(buffering=0),  # type: ignore[arg-type]
+                TemporaryFile(buffering=0),
                 encoding="utf-8",
                 errors="replace",
                 newline="",
@@ -504,13 +475,11 @@
 class CaptureResult(Generic[AnyStr]):
     """The result of :method:`CaptureFixture.readouterr`."""

-    # Can't use slots in Python<3.5.3 due to https://bugs.python.org/issue31272
-    if sys.version_info >= (3, 5, 3):
-        __slots__ = ("out", "err")
+    __slots__ = ("out", "err")

     def __init__(self, out: AnyStr, err: AnyStr) -> None:
-        self.out = out  # type: AnyStr
-        self.err = err  # type: AnyStr
+        self.out: AnyStr = out
+        self.err: AnyStr = err

     def __len__(self) -> int:
         return 2
@@ -548,7 +517,7 @@
         return tuple(self) < tuple(other)

     def __repr__(self) -> str:
-        return "CaptureResult(out={!r}, err={!r})".format(self.out, self.err)
+        return f"CaptureResult(out={self.out!r}, err={self.err!r})"


 class MultiCapture(Generic[AnyStr]):
@@ -562,7 +531,11 @@

     def __repr__(self) -> str:
         return "<MultiCapture out={!r} err={!r} in_={!r} _state={!r} _in_suspended={!r}>".format(
-            self.out, self.err, self.in_, self._state, self._in_suspended,
+            self.out,
+            self.err,
+            self.in_,
+            self._state,
+            self._in_suspended,
         )

     def start_capturing(self) -> None:
@@ -620,14 +593,8 @@
         return self._state == "started"

     def readouterr(self) -> CaptureResult[AnyStr]:
-        if self.out:
-            out = self.out.snap()
-        else:
-            out = ""
-        if self.err:
-            err = self.err.snap()
-        else:
-            err = ""
+        out = self.out.snap() if self.out else ""
+        err = self.err.snap() if self.err else ""
         return CaptureResult(out, err)


@@ -642,7 +609,7 @@
         return MultiCapture(
             in_=None, out=SysCapture(1, tee=True), err=SysCapture(2, tee=True)
         )
-    raise ValueError("unknown capturing method: {!r}".format(method))
+    raise ValueError(f"unknown capturing method: {method!r}")


 # CaptureManager and CaptureFixture
@@ -669,8 +636,8 @@

     def __init__(self, method: "_CaptureMethod") -> None:
         self._method = method
-        self._global_capturing = None  # type: Optional[MultiCapture[str]]
-        self._capture_fixture = None  # type: Optional[CaptureFixture[Any]]
+        self._global_capturing: Optional[MultiCapture[str]] = None
+        self._capture_fixture: Optional[CaptureFixture[Any]] = None

     def __repr__(self) -> str:
         return "<CaptureManager _method={!r} _global_capturing={!r} _capture_fixture={!r}>".format(
@@ -793,9 +760,9 @@

     # Hooks

-    @pytest.hookimpl(hookwrapper=True)
+    @hookimpl(hookwrapper=True)
     def pytest_make_collect_report(self, collector: Collector):
-        if isinstance(collector, pytest.File):
+        if isinstance(collector, File):
             self.resume_global_capture()
             outcome = yield
             self.suspend_global_capture()
@@ -808,45 +775,50 @@
         else:
             yield

-    @pytest.hookimpl(hookwrapper=True)
+    @hookimpl(hookwrapper=True)
     def pytest_runtest_setup(self, item: Item) -> Generator[None, None, None]:
         with self.item_capture("setup", item):
             yield

-    @pytest.hookimpl(hookwrapper=True)
+    @hookimpl(hookwrapper=True)
     def pytest_runtest_call(self, item: Item) -> Generator[None, None, None]:
         with self.item_capture("call", item):
             yield

-    @pytest.hookimpl(hookwrapper=True)
+    @hookimpl(hookwrapper=True)
     def pytest_runtest_teardown(self, item: Item) -> Generator[None, None, None]:
         with self.item_capture("teardown", item):
             yield

-    @pytest.hookimpl(tryfirst=True)
+    @hookimpl(tryfirst=True)
     def pytest_keyboard_interrupt(self) -> None:
         self.stop_global_capturing()

-    @pytest.hookimpl(tryfirst=True)
+    @hookimpl(tryfirst=True)
     def pytest_internalerror(self) -> None:
         self.stop_global_capturing()


 class CaptureFixture(Generic[AnyStr]):
-    """Object returned by the :py:func:`capsys`, :py:func:`capsysbinary`,
-    :py:func:`capfd` and :py:func:`capfdbinary` fixtures."""
-
-    def __init__(self, captureclass, request: SubRequest) -> None:
+    """Object returned by the :fixture:`capsys`, :fixture:`capsysbinary`,
+    :fixture:`capfd` and :fixture:`capfdbinary` fixtures."""
+
+    def __init__(
+        self, captureclass, request: SubRequest, *, _ispytest: bool = False
+    ) -> None:
+        check_ispytest(_ispytest)
         self.captureclass = captureclass
         self.request = request
-        self._capture = None  # type: Optional[MultiCapture[AnyStr]]
+        self._capture: Optional[MultiCapture[AnyStr]] = None
         self._captured_out = self.captureclass.EMPTY_BUFFER
         self._captured_err = self.captureclass.EMPTY_BUFFER

     def _start(self) -> None:
         if self._capture is None:
             self._capture = MultiCapture(
-                in_=None, out=self.captureclass(1), err=self.captureclass(2),
+                in_=None,
+                out=self.captureclass(1),
+                err=self.captureclass(2),
             )
             self._capture.start_capturing()

@@ -902,7 +874,7 @@
 # The fixtures.


-@pytest.fixture
+@fixture
 def capsys(request: SubRequest) -> Generator[CaptureFixture[str], None, None]:
     """Enable text capturing of writes to ``sys.stdout`` and ``sys.stderr``.

@@ -911,7 +883,7 @@
     ``out`` and ``err`` will be ``text`` objects.
     """
     capman = request.config.pluginmanager.getplugin("capturemanager")
-    capture_fixture = CaptureFixture[str](SysCapture, request)
+    capture_fixture = CaptureFixture[str](SysCapture, request, _ispytest=True)
     capman.set_fixture(capture_fixture)
     capture_fixture._start()
     yield capture_fixture
@@ -919,7 +891,7 @@
     capman.unset_fixture()


-@pytest.fixture
+@fixture
 def capsysbinary(request: SubRequest) -> Generator[CaptureFixture[bytes], None, None]:
     """Enable bytes capturing of writes to ``sys.stdout`` and ``sys.stderr``.

@@ -928,7 +900,7 @@
     ``out`` and ``err`` will be ``bytes`` objects.
     """
     capman = request.config.pluginmanager.getplugin("capturemanager")
-    capture_fixture = CaptureFixture[bytes](SysCaptureBinary, request)
+    capture_fixture = CaptureFixture[bytes](SysCaptureBinary, request, _ispytest=True)
     capman.set_fixture(capture_fixture)
     capture_fixture._start()
     yield capture_fixture
@@ -936,7 +908,7 @@
     capman.unset_fixture()


-@pytest.fixture
+@fixture
 def capfd(request: SubRequest) -> Generator[CaptureFixture[str], None, None]:
     """Enable text capturing of writes to file descriptors ``1`` and ``2``.

@@ -945,7 +917,7 @@
     ``out`` and ``err`` will be ``text`` objects.
     """
     capman = request.config.pluginmanager.getplugin("capturemanager")
-    capture_fixture = CaptureFixture[str](FDCapture, request)
+    capture_fixture = CaptureFixture[str](FDCapture, request, _ispytest=True)
     capman.set_fixture(capture_fixture)
     capture_fixture._start()
     yield capture_fixture
@@ -953,7 +925,7 @@
     capman.unset_fixture()


-@pytest.fixture
+@fixture
 def capfdbinary(request: SubRequest) -> Generator[CaptureFixture[bytes], None, None]:
     """Enable bytes capturing of writes to file descriptors ``1`` and ``2``.

@@ -962,7 +934,7 @@
     ``out`` and ``err`` will be ``byte`` objects.
     """
     capman = request.config.pluginmanager.getplugin("capturemanager")
-    capture_fixture = CaptureFixture[bytes](FDCaptureBinary, request)
+    capture_fixture = CaptureFixture[bytes](FDCaptureBinary, request, _ispytest=True)
     capman.set_fixture(capture_fixture)
     capture_fixture._start()
     yield capture_fixture
('src/_pytest', 'hookspec.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,5 +1,6 @@
 """Hook specifications for pytest plugins which are invoked by pytest itself
 and by builtin plugins."""
+from pathlib import Path
 from typing import Any
 from typing import Dict
 from typing import List
@@ -7,13 +8,12 @@
 from typing import Optional
 from typing import Sequence
 from typing import Tuple
+from typing import TYPE_CHECKING
 from typing import Union

-import py.path
 from pluggy import HookspecMarker

-from _pytest.compat import TYPE_CHECKING
-from _pytest.deprecated import WARNING_CAPTURED_HOOK
+from _pytest.deprecated import WARNING_CMDLINE_PREPARSE_HOOK

 if TYPE_CHECKING:
     import pdb
@@ -33,14 +33,15 @@
     from _pytest.nodes import Collector
     from _pytest.nodes import Item
     from _pytest.outcomes import Exit
+    from _pytest.python import Class
     from _pytest.python import Function
     from _pytest.python import Metafunc
     from _pytest.python import Module
-    from _pytest.python import PyCollector
     from _pytest.reports import CollectReport
     from _pytest.reports import TestReport
     from _pytest.runner import CallInfo
     from _pytest.terminal import TerminalReporter
+    from _pytest.compat import LEGACY_PATH


 hookspec = HookspecMarker("pytest")
@@ -55,7 +56,7 @@
     """Called at plugin registration time to allow adding new hooks via a call to
     ``pluginmanager.add_hookspecs(module_or_class, prefix)``.

-    :param _pytest.config.PytestPluginManager pluginmanager: pytest plugin manager.
+    :param pytest.PytestPluginManager pluginmanager: The pytest plugin manager.

     .. note::
         This hook is incompatible with ``hookwrapper=True``.
@@ -69,7 +70,7 @@
     """A new pytest plugin got registered.

     :param plugin: The plugin module or instance.
-    :param _pytest.config.PytestPluginManager manager: pytest plugin manager.
+    :param pytest.PytestPluginManager manager: pytest plugin manager.

     .. note::
         This hook is incompatible with ``hookwrapper=True``.
@@ -87,24 +88,24 @@
         files situated at the tests root directory due to how pytest
         :ref:`discovers plugins during startup <pluginorder>`.

-    :param _pytest.config.argparsing.Parser parser:
+    :param pytest.Parser parser:
         To add command line options, call
-        :py:func:`parser.addoption(...) <_pytest.config.argparsing.Parser.addoption>`.
+        :py:func:`parser.addoption(...) <pytest.Parser.addoption>`.
         To add ini-file values call :py:func:`parser.addini(...)
-        <_pytest.config.argparsing.Parser.addini>`.
-
-    :param _pytest.config.PytestPluginManager pluginmanager:
-        pytest plugin manager, which can be used to install :py:func:`hookspec`'s
+        <pytest.Parser.addini>`.
+
+    :param pytest.PytestPluginManager pluginmanager:
+        The pytest plugin manager, which can be used to install :py:func:`hookspec`'s
         or :py:func:`hookimpl`'s and allow one plugin to call another plugin's hooks
         to change how command line options are added.

     Options can later be accessed through the
-    :py:class:`config <_pytest.config.Config>` object, respectively:
-
-    - :py:func:`config.getoption(name) <_pytest.config.Config.getoption>` to
+    :py:class:`config <pytest.Config>` object, respectively:
+
+    - :py:func:`config.getoption(name) <pytest.Config.getoption>` to
       retrieve the value of a command line option.

-    - :py:func:`config.getini(name) <_pytest.config.Config.getini>` to retrieve
+    - :py:func:`config.getini(name) <pytest.Config.getini>` to retrieve
       a value read from an ini-style file.

     The config object is passed around on many internal objects via the ``.config``
@@ -128,7 +129,7 @@
     .. note::
         This hook is incompatible with ``hookwrapper=True``.

-    :param _pytest.config.Config config: The pytest config object.
+    :param pytest.Config config: The pytest config object.
     """


@@ -151,21 +152,22 @@
         ``plugins`` arg when using `pytest.main`_ to perform an in-process
         test run.

-    :param _pytest.config.PytestPluginManager pluginmanager: Pytest plugin manager.
+    :param pytest.PytestPluginManager pluginmanager: The pytest plugin manager.
     :param List[str] args: List of arguments passed on the command line.
     """


+@hookspec(warn_on_impl=WARNING_CMDLINE_PREPARSE_HOOK)
 def pytest_cmdline_preparse(config: "Config", args: List[str]) -> None:
     """(**Deprecated**) modify command line arguments before option parsing.

     This hook is considered deprecated and will be removed in a future pytest version. Consider
-    using :func:`pytest_load_initial_conftests` instead.
+    using :hook:`pytest_load_initial_conftests` instead.

     .. note::
         This hook will not be called for ``conftest.py`` files, only for setuptools plugins.

-    :param _pytest.config.Config config: The pytest config object.
+    :param pytest.Config config: The pytest config object.
     :param List[str] args: Arguments passed on the command line.
     """

@@ -175,12 +177,9 @@
     """Called for performing the main command line action. The default
     implementation will invoke the configure hooks and runtest_mainloop.

-    .. note::
-        This hook will not be called for ``conftest.py`` files, only for setuptools plugins.
-
-    Stops at first non-None result, see :ref:`firstresult`.
-
-    :param _pytest.config.Config config: The pytest config object.
+    Stops at first non-None result, see :ref:`firstresult`.
+
+    :param pytest.Config config: The pytest config object.
     """


@@ -193,9 +192,9 @@
     .. note::
         This hook will not be called for ``conftest.py`` files, only for setuptools plugins.

-    :param _pytest.config.Config early_config: The pytest config object.
+    :param pytest.Config early_config: The pytest config object.
     :param List[str] args: Arguments passed on the command line.
-    :param _pytest.config.argparsing.Parser parser: To add command line options.
+    :param pytest.Parser parser: To add command line options.
     """


@@ -248,7 +247,7 @@
     the items in-place.

     :param pytest.Session session: The pytest session object.
-    :param _pytest.config.Config config: The pytest config object.
+    :param pytest.Config config: The pytest config object.
     :param List[pytest.Item] items: List of item objects.
     """

@@ -261,7 +260,9 @@


 @hookspec(firstresult=True)
-def pytest_ignore_collect(path: py.path.local, config: "Config") -> Optional[bool]:
+def pytest_ignore_collect(
+    collection_path: Path, path: "LEGACY_PATH", config: "Config"
+) -> Optional[bool]:
     """Return True to prevent considering this path for collection.

     This hook is consulted for all files and directories prior to calling
@@ -269,19 +270,31 @@

     Stops at first non-None result, see :ref:`firstresult`.

-    :param py.path.local path: The path to analyze.
-    :param _pytest.config.Config config: The pytest config object.
+    :param pathlib.Path collection_path : The path to analyze.
+    :param LEGACY_PATH path: The path to analyze (deprecated).
+    :param pytest.Config config: The pytest config object.
+
+    .. versionchanged:: 7.0.0
+        The ``collection_path`` parameter was added as a :class:`pathlib.Path`
+        equivalent of the ``path`` parameter. The ``path`` parameter
+        has been deprecated.
     """


 def pytest_collect_file(
-    path: py.path.local, parent: "Collector"
+    file_path: Path, path: "LEGACY_PATH", parent: "Collector"
 ) -> "Optional[Collector]":
     """Create a Collector for the given path, or None if not relevant.

     The new node needs to have the specified ``parent`` as a parent.

-    :param py.path.local path: The path to collect.
+    :param pathlib.Path file_path: The path to analyze.
+    :param LEGACY_PATH path: The path to collect (deprecated).
+
+    .. versionchanged:: 7.0.0
+        The ``file_path`` parameter was added as a :class:`pathlib.Path`
+        equivalent of the ``path`` parameter. The ``path`` parameter
+        has been deprecated.
     """


@@ -309,7 +322,8 @@

 @hookspec(firstresult=True)
 def pytest_make_collect_report(collector: "Collector") -> "Optional[CollectReport]":
-    """Perform ``collector.collect()`` and return a CollectReport.
+    """Perform :func:`collector.collect() <pytest.Collector.collect>` and return
+    a :class:`~pytest.CollectReport`.

     Stops at first non-None result, see :ref:`firstresult`.
     """
@@ -321,7 +335,9 @@


 @hookspec(firstresult=True)
-def pytest_pycollect_makemodule(path: py.path.local, parent) -> Optional["Module"]:
+def pytest_pycollect_makemodule(
+    module_path: Path, path: "LEGACY_PATH", parent
+) -> Optional["Module"]:
     """Return a Module collector or None for the given path.

     This hook will be called for each matching test module path.
@@ -330,13 +346,20 @@

     Stops at first non-None result, see :ref:`firstresult`.

-    :param py.path.local path: The path of module to collect.
+    :param pathlib.Path module_path: The path of the module to collect.
+    :param LEGACY_PATH path: The path of the module to collect (deprecated).
+
+    .. versionchanged:: 7.0.0
+        The ``module_path`` parameter was added as a :class:`pathlib.Path`
+        equivalent of the ``path`` parameter.
+
+        The ``path`` parameter has been deprecated in favor of ``fspath``.
     """


 @hookspec(firstresult=True)
 def pytest_pycollect_makeitem(
-    collector: "PyCollector", name: str, obj: object
+    collector: Union["Module", "Class"], name: str, obj: object
 ) -> Union[None, "Item", "Collector", List[Union["Item", "Collector"]]]:
     """Return a custom item/collector for a Python object in a module, or None.

@@ -368,7 +391,7 @@

     Stops at first non-None result, see :ref:`firstresult`.

-    :param _pytest.config.Config config: The pytest config object.
+    :param pytest.Config config: The pytest config object.
     :param val: The parametrized value.
     :param str argname: The automatic parameter name produced by pytest.
     """
@@ -443,10 +466,10 @@
 ) -> None:
     """Called at the start of running the runtest protocol for a single item.

-    See :func:`pytest_runtest_protocol` for a description of the runtest protocol.
+    See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.

     :param str nodeid: Full node ID of the item.
-    :param location: A triple of ``(filename, lineno, testname)``.
+    :param location: A tuple of ``(filename, lineno, testname)``.
     """


@@ -455,10 +478,10 @@
 ) -> None:
     """Called at the end of running the runtest protocol for a single item.

-    See :func:`pytest_runtest_protocol` for a description of the runtest protocol.
+    See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.

     :param str nodeid: Full node ID of the item.
-    :param location: A triple of ``(filename, lineno, testname)``.
+    :param location: A tuple of ``(filename, lineno, testname)``.
     """


@@ -489,9 +512,9 @@

     :param nextitem:
         The scheduled-to-be-next test item (None if no further test item is
-        scheduled). This argument can be used to perform exact teardowns,
-        i.e. calling just enough finalizers so that nextitem only needs to
-        call setup-functions.
+        scheduled). This argument is used to perform exact teardowns, i.e.
+        calling just enough finalizers so that nextitem only needs to call
+        setup functions.
     """


@@ -499,28 +522,29 @@
 def pytest_runtest_makereport(
     item: "Item", call: "CallInfo[None]"
 ) -> Optional["TestReport"]:
-    """Called to create a :py:class:`_pytest.reports.TestReport` for each of
+    """Called to create a :class:`~pytest.TestReport` for each of
     the setup, call and teardown runtest phases of a test item.

-    See :func:`pytest_runtest_protocol` for a description of the runtest protocol.
-
-    :param CallInfo[None] call: The ``CallInfo`` for the phase.
+    See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.
+
+    :param call: The :class:`~pytest.CallInfo` for the phase.

     Stops at first non-None result, see :ref:`firstresult`.
     """


 def pytest_runtest_logreport(report: "TestReport") -> None:
-    """Process the :py:class:`_pytest.reports.TestReport` produced for each
+    """Process the :class:`~pytest.TestReport` produced for each
     of the setup, call and teardown runtest phases of an item.

-    See :func:`pytest_runtest_protocol` for a description of the runtest protocol.
+    See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.
     """


 @hookspec(firstresult=True)
 def pytest_report_to_serializable(
-    config: "Config", report: Union["CollectReport", "TestReport"],
+    config: "Config",
+    report: Union["CollectReport", "TestReport"],
 ) -> Optional[Dict[str, Any]]:
     """Serialize the given report object into a data structure suitable for
     sending over the wire, e.g. converted to JSON."""
@@ -528,9 +552,11 @@

 @hookspec(firstresult=True)
 def pytest_report_from_serializable(
-    config: "Config", data: Dict[str, Any],
+    config: "Config",
+    data: Dict[str, Any],
 ) -> Optional[Union["CollectReport", "TestReport"]]:
-    """Restore a report object previously serialized with pytest_report_to_serializable()."""
+    """Restore a report object previously serialized with
+    :hook:`pytest_report_to_serializable`."""


 # -------------------------------------------------------------------------
@@ -577,7 +603,8 @@


 def pytest_sessionfinish(
-    session: "Session", exitstatus: Union[int, "ExitCode"],
+    session: "Session",
+    exitstatus: Union[int, "ExitCode"],
 ) -> None:
     """Called after whole test run finished, right before returning the exit status to the system.

@@ -589,7 +616,7 @@
 def pytest_unconfigure(config: "Config") -> None:
     """Called before test process is exited.

-    :param _pytest.config.Config config: The pytest config object.
+    :param pytest.Config config: The pytest config object.
     """


@@ -608,12 +635,12 @@
     *in* a string will be escaped. Note that all but the first line will
     be indented slightly, the intention is for the first line to be a summary.

-    :param _pytest.config.Config config: The pytest config object.
+    :param pytest.Config config: The pytest config object.
     """


 def pytest_assertion_pass(item: "Item", lineno: int, orig: str, expl: str) -> None:
-    """**(Experimental)** Called whenever an assertion passes.
+    """Called whenever an assertion passes.

     .. versionadded:: 5.0

@@ -637,13 +664,6 @@
     :param int lineno: Line number of the assert statement.
     :param str orig: String with the original assertion.
     :param str expl: String with the assert explanation.
-
-    .. note::
-
-        This hook is **experimental**, so its parameters or even the hook itself might
-        be changed/removed without warning in any future pytest release.
-
-        If you find this hook useful, please share your feedback in an issue.
     """


@@ -653,12 +673,13 @@


 def pytest_report_header(
-    config: "Config", startdir: py.path.local
+    config: "Config", start_path: Path, startdir: "LEGACY_PATH"
 ) -> Union[str, List[str]]:
     """Return a string or list of strings to be displayed as header info for terminal reporting.

-    :param _pytest.config.Config config: The pytest config object.
-    :param py.path.local startdir: The starting dir.
+    :param pytest.Config config: The pytest config object.
+    :param Path start_path: The starting dir.
+    :param LEGACY_PATH startdir: The starting dir (deprecated).

     .. note::

@@ -672,11 +693,19 @@
         This function should be implemented only in plugins or ``conftest.py``
         files situated at the tests root directory due to how pytest
         :ref:`discovers plugins during startup <pluginorder>`.
+
+    .. versionchanged:: 7.0.0
+        The ``start_path`` parameter was added as a :class:`pathlib.Path`
+        equivalent of the ``startdir`` parameter. The ``startdir`` parameter
+        has been deprecated.
     """


 def pytest_report_collectionfinish(
-    config: "Config", startdir: py.path.local, items: Sequence["Item"],
+    config: "Config",
+    start_path: Path,
+    startdir: "LEGACY_PATH",
+    items: Sequence["Item"],
 ) -> Union[str, List[str]]:
     """Return a string or list of strings to be displayed after collection
     has finished successfully.
@@ -685,8 +714,9 @@

     .. versionadded:: 3.2

-    :param _pytest.config.Config config: The pytest config object.
-    :param py.path.local startdir: The starting dir.
+    :param pytest.Config config: The pytest config object.
+    :param Path start_path: The starting dir.
+    :param LEGACY_PATH startdir: The starting dir (deprecated).
     :param items: List of pytest items that are going to be executed; this list should not be modified.

     .. note::
@@ -695,15 +725,18 @@
         ran before it.
         If you want to have your line(s) displayed first, use
         :ref:`trylast=True <plugin-hookorder>`.
+
+    .. versionchanged:: 7.0.0
+        The ``start_path`` parameter was added as a :class:`pathlib.Path`
+        equivalent of the ``startdir`` parameter. The ``startdir`` parameter
+        has been deprecated.
     """


 @hookspec(firstresult=True)
 def pytest_report_teststatus(
     report: Union["CollectReport", "TestReport"], config: "Config"
-) -> Tuple[
-    str, str, Union[str, Mapping[str, bool]],
-]:
+) -> Tuple[str, str, Union[str, Mapping[str, bool]]]:
     """Return result-category, shortletter and verbose word for status
     reporting.

@@ -721,58 +754,25 @@
     for example ``"rerun", "R", ("RERUN", {"yellow": True})``.

     :param report: The report object whose status is to be returned.
-    :param _pytest.config.Config config: The pytest config object.
+    :param config: The pytest config object.

     Stops at first non-None result, see :ref:`firstresult`.
     """


 def pytest_terminal_summary(
-    terminalreporter: "TerminalReporter", exitstatus: "ExitCode", config: "Config",
+    terminalreporter: "TerminalReporter",
+    exitstatus: "ExitCode",
+    config: "Config",
 ) -> None:
     """Add a section to terminal summary reporting.

     :param _pytest.terminal.TerminalReporter terminalreporter: The internal terminal reporter object.
     :param int exitstatus: The exit status that will be reported back to the OS.
-    :param _pytest.config.Config config: The pytest config object.
+    :param pytest.Config config: The pytest config object.

     .. versionadded:: 4.2
         The ``config`` parameter.
-    """
-
-
-@hookspec(historic=True, warn_on_impl=WARNING_CAPTURED_HOOK)
-def pytest_warning_captured(
-    warning_message: "warnings.WarningMessage",
-    when: "Literal['config', 'collect', 'runtest']",
-    item: Optional["Item"],
-    location: Optional[Tuple[str, int, str]],
-) -> None:
-    """(**Deprecated**) Process a warning captured by the internal pytest warnings plugin.
-
-    .. deprecated:: 6.0
-
-    This hook is considered deprecated and will be removed in a future pytest version.
-    Use :func:`pytest_warning_recorded` instead.
-
-    :param warnings.WarningMessage warning_message:
-        The captured warning. This is the same object produced by :py:func:`warnings.catch_warnings`, and contains
-        the same attributes as the parameters of :py:func:`warnings.showwarning`.
-
-    :param str when:
-        Indicates when the warning was captured. Possible values:
-
-        * ``"config"``: during pytest configuration/initialization stage.
-        * ``"collect"``: during test collection.
-        * ``"runtest"``: during test execution.
-
-    :param pytest.Item|None item:
-        The item being executed if ``when`` is ``"runtest"``, otherwise ``None``.
-
-    :param tuple location:
-        When available, holds information about the execution context of the captured
-        warning (filename, linenumber, function). ``function`` evaluates to <module>
-        when the execution context is at the module level.
     """


@@ -809,12 +809,34 @@


 # -------------------------------------------------------------------------
+# Hooks for influencing skipping
+# -------------------------------------------------------------------------
+
+
+def pytest_markeval_namespace(config: "Config") -> Dict[str, Any]:
+    """Called when constructing the globals dictionary used for
+    evaluating string conditions in xfail/skipif markers.
+
+    This is useful when the condition for a marker requires
+    objects that are expensive or impossible to obtain during
+    collection time, which is required by normal boolean
+    conditions.
+
+    .. versionadded:: 6.2
+
+    :param pytest.Config config: The pytest config object.
+    :returns: A dictionary of additional globals to add.
+    """
+
+
+# -------------------------------------------------------------------------
 # error handling and internal debugging hooks
 # -------------------------------------------------------------------------


 def pytest_internalerror(
-    excrepr: "ExceptionRepr", excinfo: "ExceptionInfo[BaseException]",
+    excrepr: "ExceptionRepr",
+    excinfo: "ExceptionInfo[BaseException]",
 ) -> Optional[bool]:
     """Called for internal errors.

@@ -837,11 +859,11 @@
     """Called when an exception was raised which can potentially be
     interactively handled.

-    May be called during collection (see :py:func:`pytest_make_collect_report`),
-    in which case ``report`` is a :py:class:`_pytest.reports.CollectReport`.
-
-    May be called during runtest of an item (see :py:func:`pytest_runtest_protocol`),
-    in which case ``report`` is a :py:class:`_pytest.reports.TestReport`.
+    May be called during collection (see :hook:`pytest_make_collect_report`),
+    in which case ``report`` is a :class:`CollectReport`.
+
+    May be called during runtest of an item (see :hook:`pytest_runtest_protocol`),
+    in which case ``report`` is a :class:`TestReport`.

     This hook is not called if the exception that was raised is an internal
     exception like ``skip.Exception``.
@@ -854,7 +876,7 @@
     Can be used by plugins to take special action just before the python
     debugger enters interactive mode.

-    :param _pytest.config.Config config: The pytest config object.
+    :param pytest.Config config: The pytest config object.
     :param pdb.Pdb pdb: The Pdb instance.
     """

@@ -865,6 +887,6 @@
     Can be used by plugins to take special action just after the python
     debugger leaves interactive mode.

-    :param _pytest.config.Config config: The pytest config object.
+    :param pytest.Config config: The pytest config object.
     :param pdb.Pdb pdb: The Pdb instance.
     """
('src/_pytest', 'timing.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -3,7 +3,7 @@
 We intentionally grab some "time" functions internally to avoid tests mocking "time" to affect
 pytest runtime information (issue #185).

-Fixture "mock_timinig" also interacts with this module for pytest's own tests.
+Fixture "mock_timing" also interacts with this module for pytest's own tests.
 """
 from time import perf_counter
 from time import sleep
('src/_pytest', 'pytester.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,58 +1,81 @@
-"""(Disabled by default) support for testing pytest and pytest plugins."""
+"""(Disabled by default) support for testing pytest and pytest plugins.
+
+PYTEST_DONT_REWRITE
+"""
 import collections.abc
+import contextlib
 import gc
 import importlib
 import os
 import platform
 import re
+import shutil
 import subprocess
 import sys
 import traceback
 from fnmatch import fnmatch
 from io import StringIO
+from pathlib import Path
+from typing import Any
 from typing import Callable
 from typing import Dict
 from typing import Generator
+from typing import IO
 from typing import Iterable
 from typing import List
 from typing import Optional
+from typing import overload
 from typing import Sequence
+from typing import TextIO
 from typing import Tuple
+from typing import Type
+from typing import TYPE_CHECKING
 from typing import Union
 from weakref import WeakKeyDictionary

-import py
 from iniconfig import IniConfig
-
-import pytest
+from iniconfig import SectionWrapper
+
 from _pytest import timing
 from _pytest._code import Source
 from _pytest.capture import _get_multicapture
 from _pytest.compat import final
-from _pytest.compat import overload
-from _pytest.compat import TYPE_CHECKING
+from _pytest.compat import NOTSET
+from _pytest.compat import NotSetType
 from _pytest.config import _PluggyPlugin
 from _pytest.config import Config
 from _pytest.config import ExitCode
+from _pytest.config import hookimpl
+from _pytest.config import main
 from _pytest.config import PytestPluginManager
 from _pytest.config.argparsing import Parser
+from _pytest.deprecated import check_ispytest
+from _pytest.fixtures import fixture
 from _pytest.fixtures import FixtureRequest
 from _pytest.main import Session
 from _pytest.monkeypatch import MonkeyPatch
 from _pytest.nodes import Collector
 from _pytest.nodes import Item
+from _pytest.outcomes import fail
+from _pytest.outcomes import importorskip
+from _pytest.outcomes import skip
+from _pytest.pathlib import bestrelpath
+from _pytest.pathlib import copytree
 from _pytest.pathlib import make_numbered_dir
-from _pytest.pathlib import Path
-from _pytest.python import Module
 from _pytest.reports import CollectReport
 from _pytest.reports import TestReport
-from _pytest.tmpdir import TempdirFactory
+from _pytest.tmpdir import TempPathFactory
+from _pytest.warning_types import PytestWarning
+

 if TYPE_CHECKING:
-    from typing import Type
+    from typing_extensions import Final
     from typing_extensions import Literal

     import pexpect
+
+
+pytest_plugins = ["pytester_assertions"]


 IGNORE_PAM = [  # filenames added when obtaining details about the current user
@@ -105,7 +128,7 @@
             stdout=subprocess.PIPE,
             stderr=subprocess.DEVNULL,
             check=True,
-            universal_newlines=True,
+            text=True,
         ).stdout

         def isopen(line: str) -> bool:
@@ -138,7 +161,7 @@
         else:
             return True

-    @pytest.hookimpl(hookwrapper=True, tryfirst=True)
+    @hookimpl(hookwrapper=True, tryfirst=True)
     def pytest_runtest_protocol(self, item: Item) -> Generator[None, None, None]:
         lines1 = self.get_open_files()
         yield
@@ -160,13 +183,13 @@
                 "*** function %s:%s: %s " % item.location,
                 "See issue #2366",
             ]
-            item.warn(pytest.PytestWarning("\n".join(error)))
+            item.warn(PytestWarning("\n".join(error)))


 # used at least by pytest-xdist plugin


-@pytest.fixture
+@fixture
 def _pytest(request: FixtureRequest) -> "PytestArg":
     """Return a helper which offers a gethookrecorder(hook) method which
     returns a HookRecorder instance which helps to make assertions about called
@@ -176,11 +199,11 @@

 class PytestArg:
     def __init__(self, request: FixtureRequest) -> None:
-        self.request = request
+        self._request = request

     def gethookrecorder(self, hook) -> "HookRecorder":
         hookrecorder = HookRecorder(hook._pm)
-        self.request.addfinalizer(hookrecorder.finish_recording)
+        self._request.addfinalizer(hookrecorder.finish_recording)
         return hookrecorder


@@ -189,7 +212,20 @@
     return [x for x in values if x[0] != "_"]


-class ParsedCall:
+@final
+class RecordedHookCall:
+    """A recorded call to a hook.
+
+    The arguments to the hook call are set as attributes.
+    For example:
+
+    .. code-block:: python
+
+        calls = hook_recorder.getcalls("pytest_runtest_setup")
+        # Suppose pytest_runtest_setup was called once with `item=an_item`.
+        assert calls[0].item is an_item
+    """
+
     def __init__(self, name: str, kwargs) -> None:
         self.__dict__.update(kwargs)
         self._name = name
@@ -197,7 +233,7 @@
     def __repr__(self) -> str:
         d = self.__dict__.copy()
         del d["_name"]
-        return "<ParsedCall {!r}(**{!r})>".format(self._name, d)
+        return f"<RecordedHookCall {self._name!r}(**{d!r})>"

     if TYPE_CHECKING:
         # The class has undetermined attributes, this tells mypy about it.
@@ -205,20 +241,27 @@
             ...


+@final
 class HookRecorder:
     """Record all hooks called in a plugin manager.
+
+    Hook recorders are created by :class:`Pytester`.

     This wraps all the hook calls in the plugin manager, recording each call
     before propagating the normal calls.
     """

-    def __init__(self, pluginmanager: PytestPluginManager) -> None:
+    def __init__(
+        self, pluginmanager: PytestPluginManager, *, _ispytest: bool = False
+    ) -> None:
+        check_ispytest(_ispytest)
+
         self._pluginmanager = pluginmanager
-        self.calls = []  # type: List[ParsedCall]
-        self.ret = None  # type: Optional[Union[int, ExitCode]]
+        self.calls: List[RecordedHookCall] = []
+        self.ret: Optional[Union[int, ExitCode]] = None

         def before(hook_name: str, hook_impls, kwargs) -> None:
-            self.calls.append(ParsedCall(hook_name, kwargs))
+            self.calls.append(RecordedHookCall(hook_name, kwargs))

         def after(outcome, hook_name: str, hook_impls, kwargs) -> None:
             pass
@@ -228,7 +271,8 @@
     def finish_recording(self) -> None:
         self._undo_wrapping()

-    def getcalls(self, names: Union[str, Iterable[str]]) -> List[ParsedCall]:
+    def getcalls(self, names: Union[str, Iterable[str]]) -> List[RecordedHookCall]:
+        """Get all recorded calls to hooks with the given names (or name)."""
         if isinstance(names, str):
             names = names.split()
         return [call for call in self.calls if call._name in names]
@@ -252,19 +296,19 @@
                     break
                 print("NONAMEMATCH", name, "with", call)
             else:
-                pytest.fail("could not find {!r} check {!r}".format(name, check))
-
-    def popcall(self, name: str) -> ParsedCall:
+                fail(f"could not find {name!r} check {check!r}")
+
+    def popcall(self, name: str) -> RecordedHookCall:
         __tracebackhide__ = True
         for i, call in enumerate(self.calls):
             if call._name == name:
                 del self.calls[i]
                 return call
-        lines = ["could not find call {!r}, in:".format(name)]
+        lines = [f"could not find call {name!r}, in:"]
         lines.extend(["  %s" % x for x in self.calls])
-        pytest.fail("\n".join(lines))
-
-    def getcall(self, name: str) -> ParsedCall:
+        fail("\n".join(lines))
+
+    def getcall(self, name: str) -> RecordedHookCall:
         values = self.getcalls(name)
         assert len(values) == 1, (name, values)
         return values[0]
@@ -273,18 +317,20 @@

     @overload
     def getreports(
-        self, names: "Literal['pytest_collectreport']",
+        self,
+        names: "Literal['pytest_collectreport']",
     ) -> Sequence[CollectReport]:
         ...

-    @overload  # noqa: F811
-    def getreports(  # noqa: F811
-        self, names: "Literal['pytest_runtest_logreport']",
+    @overload
+    def getreports(
+        self,
+        names: "Literal['pytest_runtest_logreport']",
     ) -> Sequence[TestReport]:
         ...

-    @overload  # noqa: F811
-    def getreports(  # noqa: F811
+    @overload
+    def getreports(
         self,
         names: Union[str, Iterable[str]] = (
             "pytest_collectreport",
@@ -293,7 +339,7 @@
     ) -> Sequence[Union[CollectReport, TestReport]]:
         ...

-    def getreports(  # noqa: F811
+    def getreports(
         self,
         names: Union[str, Iterable[str]] = (
             "pytest_collectreport",
@@ -336,18 +382,20 @@

     @overload
     def getfailures(
-        self, names: "Literal['pytest_collectreport']",
+        self,
+        names: "Literal['pytest_collectreport']",
     ) -> Sequence[CollectReport]:
         ...

-    @overload  # noqa: F811
-    def getfailures(  # noqa: F811
-        self, names: "Literal['pytest_runtest_logreport']",
+    @overload
+    def getfailures(
+        self,
+        names: "Literal['pytest_runtest_logreport']",
     ) -> Sequence[TestReport]:
         ...

-    @overload  # noqa: F811
-    def getfailures(  # noqa: F811
+    @overload
+    def getfailures(
         self,
         names: Union[str, Iterable[str]] = (
             "pytest_collectreport",
@@ -356,7 +404,7 @@
     ) -> Sequence[Union[CollectReport, TestReport]]:
         ...

-    def getfailures(  # noqa: F811
+    def getfailures(
         self,
         names: Union[str, Iterable[str]] = (
             "pytest_collectreport",
@@ -388,7 +436,7 @@
             elif rep.skipped:
                 skipped.append(rep)
             else:
-                assert rep.failed, "Unexpected outcome: {!r}".format(rep)
+                assert rep.failed, f"Unexpected outcome: {rep!r}"
                 failed.append(rep)
         return passed, skipped, failed

@@ -397,30 +445,29 @@

     def assertoutcome(self, passed: int = 0, skipped: int = 0, failed: int = 0) -> None:
         __tracebackhide__ = True
+        from _pytest.pytester_assertions import assertoutcome

         outcomes = self.listoutcomes()
-        realpassed, realskipped, realfailed = outcomes
-        obtained = {
-            "passed": len(realpassed),
-            "skipped": len(realskipped),
-            "failed": len(realfailed),
-        }
-        expected = {"passed": passed, "skipped": skipped, "failed": failed}
-        assert obtained == expected, outcomes
+        assertoutcome(
+            outcomes,
+            passed=passed,
+            skipped=skipped,
+            failed=failed,
+        )

     def clear(self) -> None:
         self.calls[:] = []


-@pytest.fixture
+@fixture
 def linecomp() -> "LineComp":
     """A :class: `LineComp` instance for checking that an input linearly
     contains a sequence of strings."""
     return LineComp()


-@pytest.fixture(name="LineMatcher")
-def LineMatcher_fixture(request: FixtureRequest) -> "Type[LineMatcher]":
+@fixture(name="LineMatcher")
+def LineMatcher_fixture(request: FixtureRequest) -> Type["LineMatcher"]:
     """A reference to the :class: `LineMatcher`.

     This is instantiable with a list of lines (without their trailing newlines).
@@ -429,17 +476,24 @@
     return LineMatcher


-@pytest.fixture
-def testdir(request: FixtureRequest, tmpdir_factory: TempdirFactory) -> "Testdir":
-    """A :class: `TestDir` instance, that can be used to run and test pytest itself.
-
-    It is particularly useful for testing plugins. It is similar to the `tmpdir` fixture
-    but provides methods which aid in testing pytest itself.
+@fixture
+def pytester(
+    request: FixtureRequest, tmp_path_factory: TempPathFactory, monkeypatch: MonkeyPatch
+) -> "Pytester":
     """
-    return Testdir(request, tmpdir_factory)
-
-
-@pytest.fixture
+    Facilities to write tests/configuration files, execute pytest in isolation, and match
+    against expected output, perfect for black-box testing of pytest plugins.
+
+    It attempts to isolate the test run from external factors as much as possible, modifying
+    the current working directory to ``path`` and environment variables during initialization.
+
+    It is particularly useful for testing plugins. It is similar to the :fixture:`tmp_path`
+    fixture but provides methods which aid in testing pytest itself.
+    """
+    return Pytester(request, tmp_path_factory, monkeypatch, _ispytest=True)
+
+
+@fixture
 def _sys_snapshot() -> Generator[None, None, None]:
     snappaths = SysPathsSnapshot()
     snapmods = SysModulesSnapshot()
@@ -448,7 +502,7 @@
     snappaths.restore()


-@pytest.fixture
+@fixture
 def _config_for_test() -> Generator[Config, None, None]:
     from _pytest.config import get_config

@@ -463,8 +517,9 @@
 rex_outcome = re.compile(r"(\d+) (\w+)")


+@final
 class RunResult:
-    """The result of running a command."""
+    """The result of running a command from :class:`~pytest.Pytester`."""

     def __init__(
         self,
@@ -474,7 +529,7 @@
         duration: float,
     ) -> None:
         try:
-            self.ret = pytest.ExitCode(ret)  # type: Union[int, ExitCode]
+            self.ret: Union[int, ExitCode] = ExitCode(ret)
             """The return value."""
         except ValueError:
             self.ret = ret
@@ -483,13 +538,13 @@
         self.errlines = errlines
         """List of lines captured from stderr."""
         self.stdout = LineMatcher(outlines)
-        """:class:`LineMatcher` of stdout.
-
-        Use e.g. :func:`stdout.str() <LineMatcher.str()>` to reconstruct stdout, or the commonly used
-        :func:`stdout.fnmatch_lines() <LineMatcher.fnmatch_lines()>` method.
+        """:class:`~pytest.LineMatcher` of stdout.
+
+        Use e.g. :func:`str(stdout) <pytest.LineMatcher.__str__()>` to reconstruct stdout, or the commonly used
+        :func:`stdout.fnmatch_lines() <pytest.LineMatcher.fnmatch_lines()>` method.
         """
         self.stderr = LineMatcher(errlines)
-        """:class:`LineMatcher` of stderr."""
+        """:class:`~pytest.LineMatcher` of stderr."""
         self.duration = duration
         """Duration in seconds."""

@@ -543,29 +598,30 @@
         errors: int = 0,
         xpassed: int = 0,
         xfailed: int = 0,
+        warnings: Optional[int] = None,
+        deselected: Optional[int] = None,
     ) -> None:
-        """Assert that the specified outcomes appear with the respective
-        numbers (0 means it didn't occur) in the text output from a test run."""
+        """
+        Assert that the specified outcomes appear with the respective
+        numbers (0 means it didn't occur) in the text output from a test run.
+
+        ``warnings`` and ``deselected`` are only checked if not None.
+        """
         __tracebackhide__ = True
-
-        d = self.parseoutcomes()
-        obtained = {
-            "passed": d.get("passed", 0),
-            "skipped": d.get("skipped", 0),
-            "failed": d.get("failed", 0),
-            "errors": d.get("errors", 0),
-            "xpassed": d.get("xpassed", 0),
-            "xfailed": d.get("xfailed", 0),
-        }
-        expected = {
-            "passed": passed,
-            "skipped": skipped,
-            "failed": failed,
-            "errors": errors,
-            "xpassed": xpassed,
-            "xfailed": xfailed,
-        }
-        assert obtained == expected
+        from _pytest.pytester_assertions import assert_outcomes
+
+        outcomes = self.parseoutcomes()
+        assert_outcomes(
+            outcomes,
+            passed=passed,
+            skipped=skipped,
+            failed=failed,
+            errors=errors,
+            xpassed=xpassed,
+            xfailed=xfailed,
+            warnings=warnings,
+            deselected=deselected,
+        )


 class CwdSnapshot:
@@ -599,16 +655,17 @@


 @final
-class Testdir:
-    """Temporary test directory with tools to test/run pytest itself.
-
-    This is based on the :fixture:`tmpdir` fixture but provides a number of methods
-    which aid with testing pytest itself.  Unless :py:meth:`chdir` is used all
-    methods will use :py:attr:`tmpdir` as their current working directory.
+class Pytester:
+    """
+    Facilities to write tests/configuration files, execute pytest in isolation, and match
+    against expected output, perfect for black-box testing of pytest plugins.
+
+    It attempts to isolate the test run from external factors as much as possible, modifying
+    the current working directory to ``path`` and environment variables during initialization.

     Attributes:

-    :ivar tmpdir: The :py:class:`py.path.local` instance of the temporary directory.
+    :ivar Path path: temporary directory path used to create files/run tests from, etc.

     :ivar plugins:
        A list of plugins to use with :py:meth:`parseconfig` and
@@ -619,75 +676,88 @@

     __test__ = False

-    CLOSE_STDIN = object
+    CLOSE_STDIN: "Final" = NOTSET

     class TimeoutExpired(Exception):
         pass

-    def __init__(self, request: FixtureRequest, tmpdir_factory: TempdirFactory) -> None:
-        self.request = request
-        self._mod_collections = (
-            WeakKeyDictionary()
-        )  # type: WeakKeyDictionary[Module, List[Union[Item, Collector]]]
+    def __init__(
+        self,
+        request: FixtureRequest,
+        tmp_path_factory: TempPathFactory,
+        monkeypatch: MonkeyPatch,
+        *,
+        _ispytest: bool = False,
+    ) -> None:
+        check_ispytest(_ispytest)
+        self._request = request
+        self._mod_collections: WeakKeyDictionary[
+            Collector, List[Union[Item, Collector]]
+        ] = WeakKeyDictionary()
         if request.function:
-            name = request.function.__name__  # type: str
+            name: str = request.function.__name__
         else:
             name = request.node.name
         self._name = name
-        self.tmpdir = tmpdir_factory.mktemp(name, numbered=True)
-        self.test_tmproot = tmpdir_factory.mktemp("tmp-" + name, numbered=True)
-        self.plugins = []  # type: List[Union[str, _PluggyPlugin]]
+        self._path: Path = tmp_path_factory.mktemp(name, numbered=True)
+        self.plugins: List[Union[str, _PluggyPlugin]] = []
         self._cwd_snapshot = CwdSnapshot()
         self._sys_path_snapshot = SysPathsSnapshot()
         self._sys_modules_snapshot = self.__take_sys_modules_snapshot()
         self.chdir()
-        self.request.addfinalizer(self.finalize)
-        self._method = self.request.config.getoption("--runpytest")
-
-        mp = self.monkeypatch = MonkeyPatch()
-        mp.setenv("PYTEST_DEBUG_TEMPROOT", str(self.test_tmproot))
+        self._request.addfinalizer(self._finalize)
+        self._method = self._request.config.getoption("--runpytest")
+        self._test_tmproot = tmp_path_factory.mktemp(f"tmp-{name}", numbered=True)
+
+        self._monkeypatch = mp = monkeypatch
+        mp.setenv("PYTEST_DEBUG_TEMPROOT", str(self._test_tmproot))
         # Ensure no unexpected caching via tox.
         mp.delenv("TOX_ENV_DIR", raising=False)
         # Discard outer pytest options.
         mp.delenv("PYTEST_ADDOPTS", raising=False)
         # Ensure no user config is used.
-        tmphome = str(self.tmpdir)
+        tmphome = str(self.path)
         mp.setenv("HOME", tmphome)
         mp.setenv("USERPROFILE", tmphome)
         # Do not use colors for inner runs by default.
         mp.setenv("PY_COLORS", "0")

+    @property
+    def path(self) -> Path:
+        """Temporary directory where files are created and pytest is executed."""
+        return self._path
+
     def __repr__(self) -> str:
-        return "<Testdir {!r}>".format(self.tmpdir)
-
-    def __str__(self) -> str:
-        return str(self.tmpdir)
-
-    def finalize(self) -> None:
-        """Clean up global state artifacts.
+        return f"<Pytester {self.path!r}>"
+
+    def _finalize(self) -> None:
+        """
+        Clean up global state artifacts.

         Some methods modify the global interpreter state and this tries to
-        clean this up.  It does not remove the temporary directory however so
+        clean this up. It does not remove the temporary directory however so
         it can be looked at after the test run has finished.
         """
         self._sys_modules_snapshot.restore()
         self._sys_path_snapshot.restore()
         self._cwd_snapshot.restore()
-        self.monkeypatch.undo()

     def __take_sys_modules_snapshot(self) -> SysModulesSnapshot:
         # Some zope modules used by twisted-related tests keep internal state
         # and can't be deleted; we had some trouble in the past with
         # `zope.interface` for example.
+        #
+        # Preserve readline due to https://bugs.python.org/issue41033.
+        # pexpect issues a SIGWINCH.
         def preserve_module(name):
-            return name.startswith("zope")
+            return name.startswith(("zope", "readline"))

         return SysModulesSnapshot(preserve=preserve_module)

     def make_hook_recorder(self, pluginmanager: PytestPluginManager) -> HookRecorder:
         """Create a new :py:class:`HookRecorder` for a PluginManager."""
-        pluginmanager.reprec = reprec = HookRecorder(pluginmanager)
-        self.request.addfinalizer(reprec.finish_recording)
+        pluginmanager.reprec = reprec = HookRecorder(pluginmanager, _ispytest=True)
+        self._request.addfinalizer(reprec.finish_recording)
         return reprec

     def chdir(self) -> None:
@@ -695,12 +765,23 @@

         This is done automatically upon instantiation.
         """
-        self.tmpdir.chdir()
-
-    def _makefile(self, ext: str, lines, files, encoding: str = "utf-8"):
+        os.chdir(self.path)
+
+    def _makefile(
+        self,
+        ext: str,
+        lines: Sequence[Union[Any, bytes]],
+        files: Dict[str, str],
+        encoding: str = "utf-8",
+    ) -> Path:
         items = list(files.items())

-        def to_text(s):
+        if ext and not ext.startswith("."):
+            raise ValueError(
+                f"pytester.makefile expects a file extension, try .{ext} instead of {ext}"
+            )
+
+        def to_text(s: Union[Any, bytes]) -> str:
             return s.decode(encoding) if isinstance(s, bytes) else str(s)

         if lines:
@@ -710,17 +791,18 @@

         ret = None
         for basename, value in items:
-            p = self.tmpdir.join(basename).new(ext=ext)
-            p.dirpath().ensure_dir()
+            p = self.path.joinpath(basename).with_suffix(ext)
+            p.parent.mkdir(parents=True, exist_ok=True)
             source_ = Source(value)
             source = "\n".join(to_text(line) for line in source_.lines)
-            p.write(source.strip().encode(encoding), "wb")
+            p.write_text(source.strip(), encoding=encoding)
             if ret is None:
                 ret = p
+        assert ret is not None
         return ret

-    def makefile(self, ext: str, *args: str, **kwargs):
-        r"""Create new file(s) in the testdir.
+    def makefile(self, ext: str, *args: str, **kwargs: str) -> Path:
+        r"""Create new text file(s) in the test directory.

         :param str ext:
             The extension the file(s) should use, including the dot, e.g. `.py`.
@@ -736,34 +818,40 @@

         .. code-block:: python

-            testdir.makefile(".txt", "line1", "line2")
-
-            testdir.makefile(".ini", pytest="[pytest]\naddopts=-rs\n")
-
+            pytester.makefile(".txt", "line1", "line2")
+
+            pytester.makefile(".ini", pytest="[pytest]\naddopts=-rs\n")
+
+        To create binary files, use :meth:`pathlib.Path.write_bytes` directly:
+
+        .. code-block:: python
+
+            filename = pytester.path.joinpath("foo.bin")
+            filename.write_bytes(b"...")
         """
         return self._makefile(ext, args, kwargs)

-    def makeconftest(self, source):
+    def makeconftest(self, source: str) -> Path:
         """Write a contest.py file with 'source' as contents."""
         return self.makepyfile(conftest=source)

-    def makeini(self, source):
+    def makeini(self, source: str) -> Path:
         """Write a tox.ini file with 'source' as contents."""
         return self.makefile(".ini", tox=source)

-    def getinicfg(self, source) -> IniConfig:
+    def getinicfg(self, source: str) -> SectionWrapper:
         """Return the pytest section from the tox.ini config file."""
         p = self.makeini(source)
-        return IniConfig(p)["pytest"]
-
-    def makepyprojecttoml(self, source):
+        return IniConfig(str(p))["pytest"]
+
+    def makepyprojecttoml(self, source: str) -> Path:
         """Write a pyproject.toml file with 'source' as contents.

         .. versionadded:: 6.0
         """
         return self.makefile(".toml", pyproject=source)

-    def makepyfile(self, *args, **kwargs):
+    def makepyfile(self, *args, **kwargs) -> Path:
         r"""Shortcut for .makefile() with a .py extension.

         Defaults to the test name with a '.py' extension, e.g test_foobar.py, overwriting
@@ -773,17 +861,17 @@

         .. code-block:: python

-            def test_something(testdir):
+            def test_something(pytester):
                 # Initial file is created test_something.py.
-                testdir.makepyfile("foobar")
+                pytester.makepyfile("foobar")
                 # To create multiple files, pass kwargs accordingly.
-                testdir.makepyfile(custom="foobar")
+                pytester.makepyfile(custom="foobar")
                 # At this point, both 'test_something.py' & 'custom.py' exist in the test directory.

         """
         return self._makefile(".py", args, kwargs)

-    def maketxtfile(self, *args, **kwargs):
+    def maketxtfile(self, *args, **kwargs) -> Path:
         r"""Shortcut for .makefile() with a .txt extension.

         Defaults to the test name with a '.txt' extension, e.g test_foobar.txt, overwriting
@@ -793,120 +881,121 @@

         .. code-block:: python

-            def test_something(testdir):
+            def test_something(pytester):
                 # Initial file is created test_something.txt.
-                testdir.maketxtfile("foobar")
+                pytester.maketxtfile("foobar")
                 # To create multiple files, pass kwargs accordingly.
-                testdir.maketxtfile(custom="foobar")
+                pytester.maketxtfile(custom="foobar")
                 # At this point, both 'test_something.txt' & 'custom.txt' exist in the test directory.

         """
         return self._makefile(".txt", args, kwargs)

-    def syspathinsert(self, path=None) -> None:
-        """Prepend a directory to sys.path, defaults to :py:attr:`tmpdir`.
+    def syspathinsert(
+        self, path: Optional[Union[str, "os.PathLike[str]"]] = None
+    ) -> None:
+        """Prepend a directory to sys.path, defaults to :attr:`path`.

         This is undone automatically when this object dies at the end of each
         test.
         """
         if path is None:
-            path = self.tmpdir
-
-        self.monkeypatch.syspath_prepend(str(path))
-
-    def mkdir(self, name) -> py.path.local:
+            path = self.path
+
+        self._monkeypatch.syspath_prepend(str(path))
+
+    def mkdir(self, name: str) -> Path:
         """Create a new (sub)directory."""
-        return self.tmpdir.mkdir(name)
-
-    def mkpydir(self, name) -> py.path.local:
-        """Create a new Python package.
+        p = self.path / name
+        p.mkdir()
+        return p
+
+    def mkpydir(self, name: str) -> Path:
+        """Create a new python package.

         This creates a (sub)directory with an empty ``__init__.py`` file so it
         gets recognised as a Python package.
         """
-        p = self.mkdir(name)
-        p.ensure("__init__.py")
+        p = self.path / name
+        p.mkdir()
+        p.joinpath("__init__.py").touch()
         return p

-    def copy_example(self, name=None) -> py.path.local:
+    def copy_example(self, name: Optional[str] = None) -> Path:
         """Copy file from project's directory into the testdir.

         :param str name: The name of the file to copy.
-        :returns: Path to the copied directory (inside ``self.tmpdir``).
-        """
-        import warnings
-        from _pytest.warning_types import PYTESTER_COPY_EXAMPLE
-
-        warnings.warn(PYTESTER_COPY_EXAMPLE, stacklevel=2)
-        example_dir = self.request.config.getini("pytester_example_dir")
+        :return: path to the copied directory (inside ``self.path``).
+
+        """
+        example_dir = self._request.config.getini("pytester_example_dir")
         if example_dir is None:
             raise ValueError("pytester_example_dir is unset, can't copy examples")
-        example_dir = self.request.config.rootdir.join(example_dir)
-
-        for extra_element in self.request.node.iter_markers("pytester_example_path"):
+        example_dir = self._request.config.rootpath / example_dir
+
+        for extra_element in self._request.node.iter_markers("pytester_example_path"):
             assert extra_element.args
-            example_dir = example_dir.join(*extra_element.args)
+            example_dir = example_dir.joinpath(*extra_element.args)

         if name is None:
             func_name = self._name
             maybe_dir = example_dir / func_name
             maybe_file = example_dir / (func_name + ".py")

-            if maybe_dir.isdir():
+            if maybe_dir.is_dir():
                 example_path = maybe_dir
-            elif maybe_file.isfile():
+            elif maybe_file.is_file():
                 example_path = maybe_file
             else:
                 raise LookupError(
-                    "{} cant be found as module or package in {}".format(
-                        func_name, example_dir.bestrelpath(self.request.config.rootdir)
-                    )
+                    f"{func_name} can't be found as module or package in {example_dir}"
                 )
         else:
-            example_path = example_dir.join(name)
-
-        if example_path.isdir() and not example_path.join("__init__.py").isfile():
-            example_path.copy(self.tmpdir)
-            return self.tmpdir
-        elif example_path.isfile():
-            result = self.tmpdir.join(example_path.basename)
-            example_path.copy(result)
+            example_path = example_dir.joinpath(name)
+
+        if example_path.is_dir() and not example_path.joinpath("__init__.py").is_file():
+            copytree(example_path, self.path)
+            return self.path
+        elif example_path.is_file():
+            result = self.path.joinpath(example_path.name)
+            shutil.copy(example_path, result)
             return result
         else:
             raise LookupError(
-                'example "{}" is not found as a file or directory'.format(example_path)
+                f'example "{example_path}" is not found as a file or directory'
             )

-    Session = Session
-
-    def getnode(self, config: Config, arg):
+    def getnode(
+        self, config: Config, arg: Union[str, "os.PathLike[str]"]
+    ) -> Optional[Union[Collector, Item]]:
         """Return the collection node of a file.

-        :param _pytest.config.Config config:
+        :param pytest.Config config:
            A pytest config.
            See :py:meth:`parseconfig` and :py:meth:`parseconfigure` for creating it.
-        :param py.path.local arg:
+        :param os.PathLike[str] arg:
             Path to the file.
         """
         session = Session.from_config(config)
         assert "::" not in str(arg)
-        p = py.path.local(arg)
+        p = Path(os.path.abspath(arg))
         config.hook.pytest_sessionstart(session=session)
         res = session.perform_collect([str(p)], genitems=False)[0]
         config.hook.pytest_sessionfinish(session=session, exitstatus=ExitCode.OK)
         return res

-    def getpathnode(self, path):
+    def getpathnode(self, path: Union[str, "os.PathLike[str]"]):
         """Return the collection node of a file.

         This is like :py:meth:`getnode` but uses :py:meth:`parseconfigure` to
         create the (configured) pytest Config instance.

-        :param py.path.local path: Path to the file.
-        """
+        :param os.PathLike[str] path: Path to the file.
+        """
+        path = Path(path)
         config = self.parseconfigure(path)
         session = Session.from_config(config)
-        x = session.fspath.bestrelpath(path)
+        x = bestrelpath(session.path, path)
         config.hook.pytest_sessionstart(session=session)
         res = session.perform_collect([x], genitems=False)[0]
         config.hook.pytest_sessionfinish(session=session, exitstatus=ExitCode.OK)
@@ -919,12 +1008,12 @@
         test items contained within.
         """
         session = colitems[0].session
-        result = []  # type: List[Item]
+        result: List[Item] = []
         for colitem in colitems:
             result.extend(session.genitems(colitem))
         return result

-    def runitem(self, source):
+    def runitem(self, source: str) -> Any:
         """Run the "test_func" Item.

         The calling test instance (class containing the test method) must
@@ -935,11 +1024,11 @@
         # used from runner functional tests
         item = self.getitem(source)
         # the test class where we are called from wants to provide the runner
-        testclassinstance = self.request.instance
+        testclassinstance = self._request.instance
         runner = testclassinstance.getrunner()
         return runner(item)

-    def inline_runsource(self, source, *cmdlineargs) -> HookRecorder:
+    def inline_runsource(self, source: str, *cmdlineargs) -> HookRecorder:
         """Run a test module in process using ``pytest.main()``.

         This run writes "source" into a temporary file and runs
@@ -947,10 +1036,7 @@
         for the result.

         :param source: The source code of the test module.
-
         :param cmdlineargs: Any extra command line arguments to use.
-
-        :returns: :py:class:`HookRecorder` instance of the result.
         """
         p = self.makepyfile(source)
         values = list(cmdlineargs) + [p]
@@ -968,7 +1054,10 @@
         return items, rec

     def inline_run(
-        self, *args, plugins=(), no_reraise_ctrlc: bool = False
+        self,
+        *args: Union[str, "os.PathLike[str]"],
+        plugins=(),
+        no_reraise_ctrlc: bool = False,
     ) -> HookRecorder:
         """Run ``pytest.main()`` in-process, returning a HookRecorder.

@@ -985,8 +1074,6 @@
         :param no_reraise_ctrlc:
             Typically we reraise keyboard interrupts from the child run. If
             True, the KeyboardInterrupt exception is captured.
-
-        :returns: A :py:class:`HookRecorder` instance.
         """
         # (maybe a cpython bug?) the importlib cache sometimes isn't updated
         # properly between file creation and inline_run (especially if imports
@@ -1016,7 +1103,7 @@
                     rec.append(self.make_hook_recorder(config.pluginmanager))

             plugins.append(Collect())
-            ret = pytest.main(list(args), plugins=plugins)
+            ret = main([str(x) for x in args], plugins=plugins)
             if len(rec) == 1:
                 reprec = rec.pop()
             else:
@@ -1037,7 +1124,9 @@
             for finalizer in finalizers:
                 finalizer()

-    def runpytest_inprocess(self, *args, **kwargs) -> RunResult:
+    def runpytest_inprocess(
+        self, *args: Union[str, "os.PathLike[str]"], **kwargs: Any
+    ) -> RunResult:
         """Return result of running pytest in-process, providing a similar
         interface to what self.runpytest() provides."""
         syspathinsert = kwargs.pop("syspathinsert", False)
@@ -1079,58 +1168,65 @@
         res.reprec = reprec  # type: ignore
         return res

-    def runpytest(self, *args, **kwargs) -> RunResult:
+    def runpytest(
+        self, *args: Union[str, "os.PathLike[str]"], **kwargs: Any
+    ) -> RunResult:
         """Run pytest inline or in a subprocess, depending on the command line
-        option "--runpytest" and return a :py:class:`RunResult`."""
-        args = self._ensure_basetemp(args)
+        option "--runpytest" and return a :py:class:`~pytest.RunResult`."""
+        new_args = self._ensure_basetemp(args)
         if self._method == "inprocess":
-            return self.runpytest_inprocess(*args, **kwargs)
+            return self.runpytest_inprocess(*new_args, **kwargs)
         elif self._method == "subprocess":
-            return self.runpytest_subprocess(*args, **kwargs)
-        raise RuntimeError("Unrecognized runpytest option: {}".format(self._method))
-
-    def _ensure_basetemp(self, args):
-        args = list(args)
-        for x in args:
+            return self.runpytest_subprocess(*new_args, **kwargs)
+        raise RuntimeError(f"Unrecognized runpytest option: {self._method}")
+
+    def _ensure_basetemp(
+        self, args: Sequence[Union[str, "os.PathLike[str]"]]
+    ) -> List[Union[str, "os.PathLike[str]"]]:
+        new_args = list(args)
+        for x in new_args:
             if str(x).startswith("--basetemp"):
                 break
         else:
-            args.append("--basetemp=%s" % self.tmpdir.dirpath("basetemp"))
-        return args
-
-    def parseconfig(self, *args) -> Config:
+            new_args.append("--basetemp=%s" % self.path.parent.joinpath("basetemp"))
+        return new_args
+
+    def parseconfig(self, *args: Union[str, "os.PathLike[str]"]) -> Config:
         """Return a new pytest Config instance from given commandline args.

         This invokes the pytest bootstrapping code in _pytest.config to create
         a new :py:class:`_pytest.core.PluginManager` and call the
         pytest_cmdline_parse hook to create a new
-        :py:class:`_pytest.config.Config` instance.
+        :py:class:`pytest.Config` instance.

         If :py:attr:`plugins` has been populated they should be plugin modules
         to be registered with the PluginManager.
         """
-        args = self._ensure_basetemp(args)
-
         import _pytest.config

-        config = _pytest.config._prepareconfig(args, self.plugins)  # type: ignore[arg-type]
+        new_args = self._ensure_basetemp(args)
+        new_args = [str(x) for x in new_args]
+
+        config = _pytest.config._prepareconfig(new_args, self.plugins)  # type: ignore[arg-type]
         # we don't know what the test will do with this half-setup config
         # object and thus we make sure it gets unconfigured properly in any
         # case (otherwise capturing could still be active, for example)
-        self.request.addfinalizer(config._ensure_unconfigure)
+        self._request.addfinalizer(config._ensure_unconfigure)
         return config

-    def parseconfigure(self, *args) -> Config:
+    def parseconfigure(self, *args: Union[str, "os.PathLike[str]"]) -> Config:
         """Return a new pytest configured Config instance.

-        Returns a new :py:class:`_pytest.config.Config` instance like
+        Returns a new :py:class:`pytest.Config` instance like
         :py:meth:`parseconfig`, but also calls the pytest_configure hook.
         """
         config = self.parseconfig(*args)
         config._do_configure()
         return config

-    def getitem(self, source, funcname: str = "test_func") -> Item:
+    def getitem(
+        self, source: Union[str, "os.PathLike[str]"], funcname: str = "test_func"
+    ) -> Item:
         """Return the test item for a test function.

         Writes the source to a python file and runs pytest's collection on
@@ -1150,7 +1246,7 @@
             funcname, source, items
         )

-    def getitems(self, source) -> List[Item]:
+    def getitems(self, source: Union[str, "os.PathLike[str]"]) -> List[Item]:
         """Return all test items collected from the module.

         Writes the source to a Python file and runs pytest's collection on
@@ -1159,7 +1255,13 @@
         modcol = self.getmodulecol(source)
         return self.genitems([modcol])

-    def getmodulecol(self, source, configargs=(), withinit: bool = False):
+    def getmodulecol(
+        self,
+        source: Union[str, "os.PathLike[str]"],
+        configargs=(),
+        *,
+        withinit: bool = False,
+    ):
         """Return the module collection node for ``source``.

         Writes ``source`` to a file using :py:meth:`makepyfile` and then
@@ -1176,11 +1278,11 @@
             Whether to also write an ``__init__.py`` file to the same
             directory to ensure it is a package.
         """
-        if isinstance(source, Path):
-            path = self.tmpdir.join(str(source))
+        if isinstance(source, os.PathLike):
+            path = self.path.joinpath(source)
             assert not withinit, "not supported for paths"
         else:
-            kw = {self._name: Source(source).strip()}
+            kw = {self._name: str(source)}
             path = self.makepyfile(**kw)
         if withinit:
             self.makepyfile(__init__="#")
@@ -1188,11 +1290,11 @@
         return self.getnode(config, path)

     def collect_by_name(
-        self, modcol: Module, name: str
+        self, modcol: Collector, name: str
     ) -> Optional[Union[Item, Collector]]:
         """Return the collection node for name from the module collection.

-        Searchs a module collection node for a collection node matching the
+        Searches a module collection node for a collection node matching the
         given name.

         :param modcol: A module collection node; see :py:meth:`getmodulecol`.
@@ -1207,16 +1309,16 @@

     def popen(
         self,
-        cmdargs,
-        stdout=subprocess.PIPE,
-        stderr=subprocess.PIPE,
-        stdin=CLOSE_STDIN,
-        **kw
+        cmdargs: Sequence[Union[str, "os.PathLike[str]"]],
+        stdout: Union[int, TextIO] = subprocess.PIPE,
+        stderr: Union[int, TextIO] = subprocess.PIPE,
+        stdin: Union[NotSetType, bytes, IO[Any], int] = CLOSE_STDIN,
+        **kw,
     ):
-        """Invoke subprocess.Popen.
-
-        Calls subprocess.Popen making sure the current working directory is
-        in the PYTHONPATH.
+        """Invoke :py:class:`subprocess.Popen`.
+
+        Calls :py:class:`subprocess.Popen` making sure the current working
+        directory is in ``PYTHONPATH``.

         You probably want to use :py:meth:`run` instead.
         """
@@ -1226,7 +1328,7 @@
         )
         kw["env"] = env

-        if stdin is Testdir.CLOSE_STDIN:
+        if stdin is self.CLOSE_STDIN:
             kw["stdin"] = subprocess.PIPE
         elif isinstance(stdin, bytes):
             kw["stdin"] = subprocess.PIPE
@@ -1234,7 +1336,7 @@
             kw["stdin"] = stdin

         popen = subprocess.Popen(cmdargs, stdout=stdout, stderr=stderr, **kw)
-        if stdin is Testdir.CLOSE_STDIN:
+        if stdin is self.CLOSE_STDIN:
             assert popen.stdin is not None
             popen.stdin.close()
         elif isinstance(stdin, bytes):
@@ -1244,37 +1346,47 @@
         return popen

     def run(
-        self, *cmdargs, timeout: Optional[float] = None, stdin=CLOSE_STDIN
+        self,
+        *cmdargs: Union[str, "os.PathLike[str]"],
+        timeout: Optional[float] = None,
+        stdin: Union[NotSetType, bytes, IO[Any], int] = CLOSE_STDIN,
     ) -> RunResult:
         """Run a command with arguments.

-        Run a process using subprocess.Popen saving the stdout and stderr.
-
-        :param args:
-            The sequence of arguments to pass to `subprocess.Popen()`.
+        Run a process using :py:class:`subprocess.Popen` saving the stdout and
+        stderr.
+
+        :param cmdargs:
+            The sequence of arguments to pass to :py:class:`subprocess.Popen`,
+            with path-like objects being converted to :py:class:`str`
+            automatically.
         :param timeout:
             The period in seconds after which to timeout and raise
-            :py:class:`Testdir.TimeoutExpired`.
+            :py:class:`Pytester.TimeoutExpired`.
         :param stdin:
-            Optional standard input.  Bytes are being send, closing
-            the pipe, otherwise it is passed through to ``popen``.
-            Defaults to ``CLOSE_STDIN``, which translates to using a pipe
-            (``subprocess.PIPE``) that gets closed.
-
-        :rtype: RunResult
+            Optional standard input.
+
+            - If it is :py:attr:`CLOSE_STDIN` (Default), then this method calls
+              :py:class:`subprocess.Popen` with ``stdin=subprocess.PIPE``, and
+              the standard input is closed immediately after the new command is
+              started.
+
+            - If it is of type :py:class:`bytes`, these bytes are sent to the
+              standard input of the command.
+
+            - Otherwise, it is passed through to :py:class:`subprocess.Popen`.
+              For further information in this case, consult the document of the
+              ``stdin`` parameter in :py:class:`subprocess.Popen`.
         """
         __tracebackhide__ = True

-        cmdargs = tuple(
-            str(arg) if isinstance(arg, py.path.local) else arg for arg in cmdargs
-        )
-        p1 = self.tmpdir.join("stdout")
-        p2 = self.tmpdir.join("stderr")
+        cmdargs = tuple(os.fspath(arg) for arg in cmdargs)
+        p1 = self.path.joinpath("stdout")
+        p2 = self.path.joinpath("stderr")
         print("running:", *cmdargs)
-        print("     in:", py.path.local())
-        f1 = open(str(p1), "w", encoding="utf8")
-        f2 = open(str(p2), "w", encoding="utf8")
-        try:
+        print("     in:", Path.cwd())
+
+        with p1.open("w", encoding="utf8") as f1, p2.open("w", encoding="utf8") as f2:
             now = timing.time()
             popen = self.popen(
                 cmdargs,
@@ -1283,7 +1395,7 @@
                 stderr=f2,
                 close_fds=(sys.platform != "win32"),
             )
-            if isinstance(stdin, bytes):
+            if popen.stdin is not None:
                 popen.stdin.close()

             def handle_timeout() -> None:
@@ -1305,23 +1417,16 @@
                     ret = popen.wait(timeout)
                 except subprocess.TimeoutExpired:
                     handle_timeout()
-        finally:
-            f1.close()
-            f2.close()
-        f1 = open(str(p1), encoding="utf8")
-        f2 = open(str(p2), encoding="utf8")
-        try:
+
+        with p1.open(encoding="utf8") as f1, p2.open(encoding="utf8") as f2:
             out = f1.read().splitlines()
             err = f2.read().splitlines()
-        finally:
-            f1.close()
-            f2.close()
+
         self._dump_lines(out, sys.stdout)
         self._dump_lines(err, sys.stderr)
-        try:
+
+        with contextlib.suppress(ValueError):
             ret = ExitCode(ret)
-        except ValueError:
-            pass
         return RunResult(ret, out, err, timing.time() - now)

     def _dump_lines(self, lines, fp):
@@ -1329,26 +1434,22 @@
             for line in lines:
                 print(line, file=fp)
         except UnicodeEncodeError:
-            print("couldn't print to {} because of encoding".format(fp))
+            print(f"couldn't print to {fp} because of encoding")

     def _getpytestargs(self) -> Tuple[str, ...]:
         return sys.executable, "-mpytest"

-    def runpython(self, script) -> RunResult:
-        """Run a python script using sys.executable as interpreter.
-
-        :rtype: RunResult
-        """
+    def runpython(self, script: "os.PathLike[str]") -> RunResult:
+        """Run a python script using sys.executable as interpreter."""
         return self.run(sys.executable, script)

-    def runpython_c(self, command):
-        """Run python -c "command".
-
-        :rtype: RunResult
-        """
+    def runpython_c(self, command: str) -> RunResult:
+        """Run ``python -c "command"``."""
         return self.run(sys.executable, "-c", command)

-    def runpytest_subprocess(self, *args, timeout: Optional[float] = None) -> RunResult:
+    def runpytest_subprocess(
+        self, *args: Union[str, "os.PathLike[str]"], timeout: Optional[float] = None
+    ) -> RunResult:
         """Run pytest as a subprocess with given arguments.

         Any plugins added to the :py:attr:`plugins` list will be added using the
@@ -1361,12 +1462,10 @@
             The sequence of arguments to pass to the pytest subprocess.
         :param timeout:
             The period in seconds after which to timeout and raise
-            :py:class:`Testdir.TimeoutExpired`.
-
-        :rtype: RunResult
+            :py:class:`Pytester.TimeoutExpired`.
         """
         __tracebackhide__ = True
-        p = make_numbered_dir(root=Path(str(self.tmpdir)), prefix="runpytest-")
+        p = make_numbered_dir(root=self.path, prefix="runpytest-", mode=0o700)
         args = ("--basetemp=%s" % p,) + args
         plugins = [x for x in self.plugins if isinstance(x, str)]
         if plugins:
@@ -1384,9 +1483,10 @@

         The pexpect child is returned.
         """
-        basetemp = self.tmpdir.mkdir("temp-pexpect")
+        basetemp = self.path / "temp-pexpect"
+        basetemp.mkdir(mode=0o700)
         invoke = " ".join(map(str, self._getpytestargs()))
-        cmd = "{} --basetemp={} {}".format(invoke, basetemp, string)
+        cmd = f"{invoke} --basetemp={basetemp} {string}"
         return self.spawn(cmd, expect_timeout=expect_timeout)

     def spawn(self, cmd: str, expect_timeout: float = 10.0) -> "pexpect.spawn":
@@ -1394,16 +1494,15 @@

         The pexpect child is returned.
         """
-        pexpect = pytest.importorskip("pexpect", "3.0")
+        pexpect = importorskip("pexpect", "3.0")
         if hasattr(sys, "pypy_version_info") and "64" in platform.machine():
-            pytest.skip("pypy-64 bit not supported")
+            skip("pypy-64 bit not supported")
         if not hasattr(pexpect, "spawn"):
-            pytest.skip("pexpect.spawn not available")
-        logfile = self.tmpdir.join("spawn.out").open("wb")
-
-        child = pexpect.spawn(cmd, logfile=logfile)
-        self.request.addfinalizer(logfile.close)
-        child.timeout = expect_timeout
+            skip("pexpect.spawn not available")
+        logfile = self.path.joinpath("spawn.out").open("wb")
+
+        child = pexpect.spawn(cmd, logfile=logfile, timeout=expect_timeout)
+        self._request.addfinalizer(logfile.close)
         return child


@@ -1415,7 +1514,7 @@
     def assert_contains_lines(self, lines2: Sequence[str]) -> None:
         """Assert that ``lines2`` are contained (linearly) in :attr:`stringio`'s value.

-        Lines are matched using :func:`LineMatcher.fnmatch_lines`.
+        Lines are matched using :func:`LineMatcher.fnmatch_lines <pytest.LineMatcher.fnmatch_lines>`.
         """
         __tracebackhide__ = True
         val = self.stringio.getvalue()
@@ -1437,7 +1536,15 @@

     def __init__(self, lines: List[str]) -> None:
         self.lines = lines
-        self._log_output = []  # type: List[str]
+        self._log_output: List[str] = []
+
+    def __str__(self) -> str:
+        """Return the entire original text.
+
+        .. versionadded:: 6.2
+            You can use :meth:`str` in older versions.
+        """
+        return "\n".join(self.lines)

     def _getlines(self, lines2: Union[str, Sequence[str], Source]) -> Sequence[str]:
         if isinstance(lines2, str):
@@ -1530,7 +1637,7 @@
         match_func: Callable[[str, str], bool],
         match_nickname: str,
         *,
-        consecutive: bool = False
+        consecutive: bool = False,
     ) -> None:
         """Underlying implementation of ``fnmatch_lines`` and ``re_match_lines``.

@@ -1548,10 +1655,9 @@
             Match lines consecutively?
         """
         if not isinstance(lines2, collections.abc.Sequence):
-            raise TypeError("invalid type for lines2: {}".format(type(lines2).__name__))
+            raise TypeError(f"invalid type for lines2: {type(lines2).__name__}")
         lines2 = self._getlines(lines2)
         lines1 = self.lines[:]
-        nextline = None
         extralines = []
         __tracebackhide__ = True
         wnick = len(match_nickname) + 1
@@ -1573,7 +1679,7 @@
                     break
                 else:
                     if consecutive and started:
-                        msg = "no consecutive match: {!r}".format(line)
+                        msg = f"no consecutive match: {line!r}"
                         self._log(msg)
                         self._log(
                             "{:>{width}}".format("with:", width=wnick), repr(nextline)
@@ -1587,7 +1693,7 @@
                     self._log("{:>{width}}".format("and:", width=wnick), repr(nextline))
                 extralines.append(nextline)
             else:
-                msg = "remains unmatched: {!r}".format(line)
+                msg = f"remains unmatched: {line!r}"
                 self._log(msg)
                 self._fail(msg)
         self._log_output = []
@@ -1622,7 +1728,7 @@
         wnick = len(match_nickname) + 1
         for line in self.lines:
             if match_func(line, pat):
-                msg = "{}: {!r}".format(match_nickname, pat)
+                msg = f"{match_nickname}: {pat!r}"
                 self._log(msg)
                 self._log("{:>{width}}".format("with:", width=wnick), repr(line))
                 self._fail(msg)
@@ -1637,8 +1743,8 @@
         __tracebackhide__ = True
         log_text = self._log_text
         self._log_output = []
-        pytest.fail(log_text)
+        fail(log_text)

     def str(self) -> str:
         """Return the entire original text."""
-        return "\n".join(self.lines)
+        return str(self)
('src/_pytest', 'faulthandler.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -8,10 +8,11 @@
 from _pytest.config import Config
 from _pytest.config.argparsing import Parser
 from _pytest.nodes import Item
-from _pytest.store import StoreKey
+from _pytest.stash import StashKey


-fault_handler_stderr_key = StoreKey[TextIO]()
+fault_handler_stderr_key = StashKey[TextIO]()
+fault_handler_originally_enabled_key = StashKey[bool]()


 def pytest_addoption(parser: Parser) -> None:
@@ -25,87 +26,72 @@
 def pytest_configure(config: Config) -> None:
     import faulthandler

-    if not faulthandler.is_enabled():
-        # faulthhandler is not enabled, so install plugin that does the actual work
-        # of enabling faulthandler before each test executes.
-        config.pluginmanager.register(FaultHandlerHooks(), "faulthandler-hooks")
-    else:
-        # Do not handle dumping to stderr if faulthandler is already enabled, so warn
-        # users that the option is being ignored.
-        timeout = FaultHandlerHooks.get_timeout_config_value(config)
-        if timeout > 0:
-            config.issue_config_time_warning(
-                pytest.PytestConfigWarning(
-                    "faulthandler module enabled before pytest configuration step, "
-                    "'faulthandler_timeout' option ignored"
-                ),
-                stacklevel=2,
-            )
+    stderr_fd_copy = os.dup(get_stderr_fileno())
+    config.stash[fault_handler_stderr_key] = open(stderr_fd_copy, "w")
+    config.stash[fault_handler_originally_enabled_key] = faulthandler.is_enabled()
+    faulthandler.enable(file=config.stash[fault_handler_stderr_key])


-class FaultHandlerHooks:
-    """Implements hooks that will actually install fault handler before tests execute,
-    as well as correctly handle pdb and internal errors."""
+def pytest_unconfigure(config: Config) -> None:
+    import faulthandler

-    def pytest_configure(self, config: Config) -> None:
+    faulthandler.disable()
+    # Close the dup file installed during pytest_configure.
+    if fault_handler_stderr_key in config.stash:
+        config.stash[fault_handler_stderr_key].close()
+        del config.stash[fault_handler_stderr_key]
+    if config.stash.get(fault_handler_originally_enabled_key, False):
+        # Re-enable the faulthandler if it was originally enabled.
+        faulthandler.enable(file=get_stderr_fileno())
+
+
+def get_stderr_fileno() -> int:
+    try:
+        fileno = sys.stderr.fileno()
+        # The Twisted Logger will return an invalid file descriptor since it is not backed
+        # by an FD. So, let's also forward this to the same code path as with pytest-xdist.
+        if fileno == -1:
+            raise AttributeError()
+        return fileno
+    except (AttributeError, io.UnsupportedOperation):
+        # pytest-xdist monkeypatches sys.stderr with an object that is not an actual file.
+        # https://docs.python.org/3/library/faulthandler.html#issue-with-file-descriptors
+        # This is potentially dangerous, but the best we can do.
+        return sys.__stderr__.fileno()
+
+
+def get_timeout_config_value(config: Config) -> float:
+    return float(config.getini("faulthandler_timeout") or 0.0)
+
+
+@pytest.hookimpl(hookwrapper=True, trylast=True)
+def pytest_runtest_protocol(item: Item) -> Generator[None, None, None]:
+    timeout = get_timeout_config_value(item.config)
+    stderr = item.config.stash[fault_handler_stderr_key]
+    if timeout > 0 and stderr is not None:
         import faulthandler

-        stderr_fd_copy = os.dup(self._get_stderr_fileno())
-        config._store[fault_handler_stderr_key] = open(stderr_fd_copy, "w")
-        faulthandler.enable(file=config._store[fault_handler_stderr_key])
+        faulthandler.dump_traceback_later(timeout, file=stderr)
+        try:
+            yield
+        finally:
+            faulthandler.cancel_dump_traceback_later()
+    else:
+        yield

-    def pytest_unconfigure(self, config: Config) -> None:
-        import faulthandler

-        faulthandler.disable()
-        # close our dup file installed during pytest_configure
-        # re-enable the faulthandler, attaching it to the default sys.stderr
-        # so we can see crashes after pytest has finished, usually during
-        # garbage collection during interpreter shutdown
-        config._store[fault_handler_stderr_key].close()
-        del config._store[fault_handler_stderr_key]
-        faulthandler.enable(file=self._get_stderr_fileno())
+@pytest.hookimpl(tryfirst=True)
+def pytest_enter_pdb() -> None:
+    """Cancel any traceback dumping due to timeout before entering pdb."""
+    import faulthandler

-    @staticmethod
-    def _get_stderr_fileno():
-        try:
-            return sys.stderr.fileno()
-        except (AttributeError, io.UnsupportedOperation):
-            # pytest-xdist monkeypatches sys.stderr with an object that is not an actual file.
-            # https://docs.python.org/3/library/faulthandler.html#issue-with-file-descriptors
-            # This is potentially dangerous, but the best we can do.
-            return sys.__stderr__.fileno()
+    faulthandler.cancel_dump_traceback_later()

-    @staticmethod
-    def get_timeout_config_value(config):
-        return float(config.getini("faulthandler_timeout") or 0.0)

-    @pytest.hookimpl(hookwrapper=True, trylast=True)
-    def pytest_runtest_protocol(self, item: Item) -> Generator[None, None, None]:
-        timeout = self.get_timeout_config_value(item.config)
-        stderr = item.config._store[fault_handler_stderr_key]
-        if timeout > 0 and stderr is not None:
-            import faulthandler
+@pytest.hookimpl(tryfirst=True)
+def pytest_exception_interact() -> None:
+    """Cancel any traceback dumping due to an interactive exception being
+    raised."""
+    import faulthandler

-            faulthandler.dump_traceback_later(timeout, file=stderr)
-            try:
-                yield
-            finally:
-                faulthandler.cancel_dump_traceback_later()
-        else:
-            yield
-
-    @pytest.hookimpl(tryfirst=True)
-    def pytest_enter_pdb(self) -> None:
-        """Cancel any traceback dumping due to timeout before entering pdb."""
-        import faulthandler
-
-        faulthandler.cancel_dump_traceback_later()
-
-    @pytest.hookimpl(tryfirst=True)
-    def pytest_exception_interact(self) -> None:
-        """Cancel any traceback dumping due to an interactive exception being
-        raised."""
-        import faulthandler
-
-        faulthandler.cancel_dump_traceback_later()
+    faulthandler.cancel_dump_traceback_later()
('src/_pytest', 'outcomes.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,17 +1,20 @@
 """Exception classes and constants handling test outcomes as well as
 functions creating them."""
 import sys
+import warnings
 from typing import Any
 from typing import Callable
 from typing import cast
 from typing import Optional
+from typing import Type
 from typing import TypeVar
+
+from _pytest.deprecated import KEYWORD_MSG_ARG

 TYPE_CHECKING = False  # Avoid circular import through compat.

 if TYPE_CHECKING:
     from typing import NoReturn
-    from typing import Type  # noqa: F401 (used in type string)
     from typing_extensions import Protocol
 else:
     # typing.Protocol is only available starting from Python 3.8. It is also
@@ -33,14 +36,14 @@
                 "Perhaps you meant to use a mark?"
             )
             raise TypeError(error_msg.format(type(self).__name__, type(msg).__name__))
-        BaseException.__init__(self, msg)
+        super().__init__(msg)
         self.msg = msg
         self.pytrace = pytrace

     def __repr__(self) -> str:
-        if self.msg:
+        if self.msg is not None:
             return self.msg
-        return "<{} instance>".format(self.__class__.__name__)
+        return f"<{self.__class__.__name__} instance>"

     __str__ = __repr__

@@ -58,9 +61,14 @@
         msg: Optional[str] = None,
         pytrace: bool = True,
         allow_module_level: bool = False,
+        *,
+        _use_item_location: bool = False,
     ) -> None:
-        OutcomeException.__init__(self, msg=msg, pytrace=pytrace)
+        super().__init__(msg=msg, pytrace=pytrace)
         self.allow_module_level = allow_module_level
+        # If true, the skip location is reported as the item's location,
+        # instead of the place that raises the exception/calls skip().
+        self._use_item_location = _use_item_location


 class Failed(OutcomeException):
@@ -84,12 +92,12 @@
 # Ideally would just be `exit.Exception = Exit` etc.

 _F = TypeVar("_F", bound=Callable[..., object])
-_ET = TypeVar("_ET", bound="Type[BaseException]")
+_ET = TypeVar("_ET", bound=Type[BaseException])


 class _WithException(Protocol[_F, _ET]):
-    Exception = None  # type: _ET
-    __call__ = None  # type: _F
+    Exception: _ET
+    __call__: _F


 def _with_exception(exception_type: _ET) -> Callable[[_F], _WithException[_F, _ET]]:
@@ -105,52 +113,124 @@


 @_with_exception(Exit)
-def exit(msg: str, returncode: Optional[int] = None) -> "NoReturn":
+def exit(
+    reason: str = "", returncode: Optional[int] = None, *, msg: Optional[str] = None
+) -> "NoReturn":
     """Exit testing process.

-    :param str msg: Message to display upon exit.
-    :param int returncode: Return code to be used when exiting pytest.
-    """
-    __tracebackhide__ = True
-    raise Exit(msg, returncode)
+    :param reason:
+        The message to show as the reason for exiting pytest.  reason has a default value
+        only because `msg` is deprecated.
+
+    :param returncode:
+        Return code to be used when exiting pytest.
+
+    :param msg:
+        Same as ``reason``, but deprecated. Will be removed in a future version, use ``reason`` instead.
+    """
+    __tracebackhide__ = True
+    from _pytest.config import UsageError
+
+    if reason and msg:
+        raise UsageError(
+            "cannot pass reason and msg to exit(), `msg` is deprecated, use `reason`."
+        )
+    if not reason:
+        if msg is None:
+            raise UsageError("exit() requires a reason argument")
+        warnings.warn(KEYWORD_MSG_ARG.format(func="exit"), stacklevel=2)
+        reason = msg
+    raise Exit(reason, returncode)


 @_with_exception(Skipped)
-def skip(msg: str = "", *, allow_module_level: bool = False) -> "NoReturn":
+def skip(
+    reason: str = "", *, allow_module_level: bool = False, msg: Optional[str] = None
+) -> "NoReturn":
     """Skip an executing test with the given message.

     This function should be called only during testing (setup, call or teardown) or
     during collection by using the ``allow_module_level`` flag.  This function can
     be called in doctests as well.

-    :param bool allow_module_level:
+    :param reason:
+        The message to show the user as reason for the skip.
+
+    :param allow_module_level:
         Allows this function to be called at module level, skipping the rest
         of the module. Defaults to False.
+
+    :param msg:
+        Same as ``reason``, but deprecated. Will be removed in a future version, use ``reason`` instead.

     .. note::
         It is better to use the :ref:`pytest.mark.skipif ref` marker when
         possible to declare a test to be skipped under certain conditions
         like mismatching platforms or dependencies.
-        Similarly, use the ``# doctest: +SKIP`` directive (see `doctest.SKIP
-        <https://docs.python.org/3/library/doctest.html#doctest.SKIP>`_)
+        Similarly, use the ``# doctest: +SKIP`` directive (see :py:data:`doctest.SKIP`)
         to skip a doctest statically.
     """
     __tracebackhide__ = True
-    raise Skipped(msg=msg, allow_module_level=allow_module_level)
+    reason = _resolve_msg_to_reason("skip", reason, msg)
+    raise Skipped(msg=reason, allow_module_level=allow_module_level)


 @_with_exception(Failed)
-def fail(msg: str = "", pytrace: bool = True) -> "NoReturn":
+def fail(
+    reason: str = "", pytrace: bool = True, msg: Optional[str] = None
+) -> "NoReturn":
     """Explicitly fail an executing test with the given message.

-    :param str msg:
+    :param reason:
         The message to show the user as reason for the failure.
-    :param bool pytrace:
+
+    :param pytrace:
         If False, msg represents the full failure information and no
         python traceback will be reported.
-    """
-    __tracebackhide__ = True
-    raise Failed(msg=msg, pytrace=pytrace)
+
+    :param msg:
+        Same as ``reason``, but deprecated. Will be removed in a future version, use ``reason`` instead.
+    """
+    __tracebackhide__ = True
+    reason = _resolve_msg_to_reason("fail", reason, msg)
+    raise Failed(msg=reason, pytrace=pytrace)
+
+
+def _resolve_msg_to_reason(
+    func_name: str, reason: str, msg: Optional[str] = None
+) -> str:
+    """
+    Handles converting the deprecated msg parameter if provided into
+    reason, raising a deprecation warning.  This function will be removed
+    when the optional msg argument is removed from here in future.
+
+    :param str func_name:
+        The name of the offending function, this is formatted into the deprecation message.
+
+    :param str reason:
+        The reason= passed into either pytest.fail() or pytest.skip()
+
+    :param str msg:
+        The msg= passed into either pytest.fail() or pytest.skip().  This will
+        be converted into reason if it is provided to allow pytest.skip(msg=) or
+        pytest.fail(msg=) to continue working in the interim period.
+
+    :returns:
+        The value to use as reason.
+
+    """
+    __tracebackhide__ = True
+    if msg is not None:
+
+        if reason:
+            from pytest import UsageError
+
+            raise UsageError(
+                f"Passing both ``reason`` and ``msg`` to pytest.{func_name}(...) is not permitted."
+            )
+        warnings.warn(KEYWORD_MSG_ARG.format(func=func_name), stacklevel=3)
+        reason = msg
+    return reason


 class XFailed(Failed):
@@ -208,7 +288,7 @@
             __import__(modname)
         except ImportError as exc:
             if reason is None:
-                reason = "could not import {!r}: {}".format(modname, exc)
+                reason = f"could not import {modname!r}: {exc}"
             raise Skipped(reason, allow_module_level=True) from None
     mod = sys.modules[modname]
     if minversion is None:
('src/_pytest', 'stepwise.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,5 +1,6 @@
 from typing import List
 from typing import Optional
+from typing import TYPE_CHECKING

 import pytest
 from _pytest import nodes
@@ -8,6 +9,11 @@
 from _pytest.main import Session
 from _pytest.reports import TestReport

+if TYPE_CHECKING:
+    from _pytest.cacheprovider import Cache
+
+STEPWISE_CACHE_DIR = "cache/stepwise"
+

 def pytest_addoption(parser: Parser) -> None:
     group = parser.getgroup("general")
@@ -15,76 +21,75 @@
         "--sw",
         "--stepwise",
         action="store_true",
+        default=False,
         dest="stepwise",
         help="exit on test failure and continue from last failing test next time",
     )
     group.addoption(
+        "--sw-skip",
         "--stepwise-skip",
         action="store_true",
+        default=False,
         dest="stepwise_skip",
-        help="ignore the first failing test but stop on the next failing test",
+        help="ignore the first failing test but stop on the next failing test.\n"
+        "implicitly enables --stepwise.",
     )


 @pytest.hookimpl
 def pytest_configure(config: Config) -> None:
-    config.pluginmanager.register(StepwisePlugin(config), "stepwiseplugin")
+    if config.option.stepwise_skip:
+        # allow --stepwise-skip to work on it's own merits.
+        config.option.stepwise = True
+    if config.getoption("stepwise"):
+        config.pluginmanager.register(StepwisePlugin(config), "stepwiseplugin")
+
+
+def pytest_sessionfinish(session: Session) -> None:
+    if not session.config.getoption("stepwise"):
+        assert session.config.cache is not None
+        # Clear the list of failing tests if the plugin is not active.
+        session.config.cache.set(STEPWISE_CACHE_DIR, [])


 class StepwisePlugin:
     def __init__(self, config: Config) -> None:
         self.config = config
-        self.active = config.getvalue("stepwise")
-        self.session = None  # type: Optional[Session]
+        self.session: Optional[Session] = None
         self.report_status = ""
-
-        if self.active:
-            assert config.cache is not None
-            self.lastfailed = config.cache.get("cache/stepwise", None)
-            self.skip = config.getvalue("stepwise_skip")
+        assert config.cache is not None
+        self.cache: Cache = config.cache
+        self.lastfailed: Optional[str] = self.cache.get(STEPWISE_CACHE_DIR, None)
+        self.skip: bool = config.getoption("stepwise_skip")

     def pytest_sessionstart(self, session: Session) -> None:
         self.session = session

     def pytest_collection_modifyitems(
-        self, session: Session, config: Config, items: List[nodes.Item]
+        self, config: Config, items: List[nodes.Item]
     ) -> None:
-        if not self.active:
-            return
         if not self.lastfailed:
             self.report_status = "no previously failed tests, not skipping."
             return

-        already_passed = []
-        found = False
-
-        # Make a list of all tests that have been run before the last failing one.
-        for item in items:
+        # check all item nodes until we find a match on last failed
+        failed_index = None
+        for index, item in enumerate(items):
             if item.nodeid == self.lastfailed:
-                found = True
+                failed_index = index
                 break
-            else:
-                already_passed.append(item)

         # If the previously failed test was not found among the test items,
         # do not skip any tests.
-        if not found:
+        if failed_index is None:
             self.report_status = "previously failed test not found, not skipping."
-            already_passed = []
         else:
-            self.report_status = "skipping {} already passed items.".format(
-                len(already_passed)
-            )
-
-        for item in already_passed:
-            items.remove(item)
-
-        config.hook.pytest_deselected(items=already_passed)
+            self.report_status = f"skipping {failed_index} already passed items."
+            deselected = items[:failed_index]
+            del items[:failed_index]
+            config.hook.pytest_deselected(items=deselected)

     def pytest_runtest_logreport(self, report: TestReport) -> None:
-        if not self.active:
-            return
-
         if report.failed:
             if self.skip:
                 # Remove test from the failed ones (if it exists) and unset the skip option
@@ -109,14 +114,9 @@
                     self.lastfailed = None

     def pytest_report_collectionfinish(self) -> Optional[str]:
-        if self.active and self.config.getoption("verbose") >= 0 and self.report_status:
-            return "stepwise: %s" % self.report_status
+        if self.config.getoption("verbose") >= 0 and self.report_status:
+            return f"stepwise: {self.report_status}"
         return None

-    def pytest_sessionfinish(self, session: Session) -> None:
-        assert self.config.cache is not None
-        if self.active:
-            self.config.cache.set("cache/stepwise", self.lastfailed)
-        else:
-            # Clear the list of failing tests if the plugin is not active.
-            self.config.cache.set("cache/stepwise", [])
+    def pytest_sessionfinish(self) -> None:
+        self.cache.set(STEPWISE_CACHE_DIR, self.lastfailed)
('src/_pytest', 'junitxml.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -30,11 +30,11 @@
 from _pytest.config.argparsing import Parser
 from _pytest.fixtures import FixtureRequest
 from _pytest.reports import TestReport
-from _pytest.store import StoreKey
+from _pytest.stash import StashKey
 from _pytest.terminal import TerminalReporter


-xml_key = StoreKey["LogXML"]()
+xml_key = StashKey["LogXML"]()


 def bin_xml_escape(arg: object) -> str:
@@ -92,10 +92,10 @@
         self.xml = xml
         self.add_stats = self.xml.add_stats
         self.family = self.xml.family
-        self.duration = 0
-        self.properties = []  # type: List[Tuple[str, str]]
-        self.nodes = []  # type: List[ET.Element]
-        self.attrs = {}  # type: Dict[str, str]
+        self.duration = 0.0
+        self.properties: List[Tuple[str, str]] = []
+        self.nodes: List[ET.Element] = []
+        self.attrs: Dict[str, str] = {}

     def append(self, node: ET.Element) -> None:
         self.xml.add_stats(node.tag)
@@ -122,11 +122,11 @@
         classnames = names[:-1]
         if self.xml.prefix:
             classnames.insert(0, self.xml.prefix)
-        attrs = {
+        attrs: Dict[str, str] = {
             "classname": ".".join(classnames),
             "name": bin_xml_escape(names[-1]),
             "file": testreport.location[0],
-        }  # type: Dict[str, str]
+        }
         if testreport.location[1] is not None:
             attrs["line"] = str(testreport.location[1])
         if hasattr(testreport, "url"):
@@ -199,9 +199,9 @@
             self._add_simple("skipped", "xfail-marked test passes unexpectedly")
         else:
             assert report.longrepr is not None
-            reprcrash = getattr(
+            reprcrash: Optional[ReprFileLocation] = getattr(
                 report.longrepr, "reprcrash", None
-            )  # type: Optional[ReprFileLocation]
+            )
             if reprcrash is not None:
                 message = reprcrash.message
             else:
@@ -219,18 +219,18 @@

     def append_error(self, report: TestReport) -> None:
         assert report.longrepr is not None
-        reprcrash = getattr(
+        reprcrash: Optional[ReprFileLocation] = getattr(
             report.longrepr, "reprcrash", None
-        )  # type: Optional[ReprFileLocation]
+        )
         if reprcrash is not None:
             reason = reprcrash.message
         else:
             reason = str(report.longrepr)

         if report.when == "teardown":
-            msg = 'failed on teardown with "{}"'.format(reason)
+            msg = f'failed on teardown with "{reason}"'
         else:
-            msg = 'failed on setup with "{}"'.format(reason)
+            msg = f'failed on setup with "{reason}"'
         self._add_simple("error", msg, str(report.longrepr))

     def append_skipped(self, report: TestReport) -> None:
@@ -246,7 +246,7 @@
             filename, lineno, skipreason = report.longrepr
             if skipreason.startswith("Skipped: "):
                 skipreason = skipreason[9:]
-            details = "{}:{}: {}".format(filename, lineno, skipreason)
+            details = f"{filename}:{lineno}: {skipreason}"

             skipped = ET.Element("skipped", type="pytest.skip", message=skipreason)
             skipped.text = bin_xml_escape(details)
@@ -256,7 +256,7 @@
     def finalize(self) -> None:
         data = self.to_xml()
         self.__dict__.clear()
-        # Type ignored becuase mypy doesn't like overriding a method.
+        # Type ignored because mypy doesn't like overriding a method.
         # Also the return value doesn't match...
         self.to_xml = lambda: data  # type: ignore[assignment]

@@ -267,7 +267,7 @@
     """Emit a PytestWarning about the given fixture being incompatible with newer xunit revisions."""
     from _pytest.warning_types import PytestWarning

-    xml = request.config._store.get(xml_key, None)
+    xml = request.config.stash.get(xml_key, None)
     if xml is not None and xml.family not in ("xunit1", "legacy"):
         request.node.warn(
             PytestWarning(
@@ -322,7 +322,7 @@

     attr_func = add_attr_noop

-    xml = request.config._store.get(xml_key, None)
+    xml = request.config.stash.get(xml_key, None)
     if xml is not None:
         node_reporter = xml.node_reporter(request.node.nodeid)
         attr_func = node_reporter.add_attribute
@@ -359,8 +359,8 @@
     .. warning::

         Currently this fixture **does not work** with the
-        `pytest-xdist <https://github.com/pytest-dev/pytest-xdist>`__ plugin. See issue
-        `#7767 <https://github.com/pytest-dev/pytest/issues/7767>`__ for details.
+        `pytest-xdist <https://github.com/pytest-dev/pytest-xdist>`__ plugin. See
+        :issue:`7767` for details.
     """

     __tracebackhide__ = True
@@ -370,7 +370,7 @@
         __tracebackhide__ = True
         _check_record_param_type("name", name)

-    xml = request.config._store.get(xml_key, None)
+    xml = request.config.stash.get(xml_key, None)
     if xml is not None:
         record_func = xml.add_global_property  # noqa
     return record_func
@@ -428,7 +428,7 @@
     # Prevent opening xmllog on worker nodes (xdist).
     if xmlpath and not hasattr(config, "workerinput"):
         junit_family = config.getini("junit_family")
-        config._store[xml_key] = LogXML(
+        config.stash[xml_key] = LogXML(
             xmlpath,
             config.option.junitprefix,
             config.getini("junit_suite_name"),
@@ -437,23 +437,19 @@
             junit_family,
             config.getini("junit_log_passing_tests"),
         )
-        config.pluginmanager.register(config._store[xml_key])
+        config.pluginmanager.register(config.stash[xml_key])


 def pytest_unconfigure(config: Config) -> None:
-    xml = config._store.get(xml_key, None)
+    xml = config.stash.get(xml_key, None)
     if xml:
-        del config._store[xml_key]
+        del config.stash[xml_key]
         config.pluginmanager.unregister(xml)


 def mangle_test_address(address: str) -> List[str]:
     path, possible_open_bracket, params = address.partition("[")
     names = path.split("::")
-    try:
-        names.remove("()")
-    except ValueError:
-        pass
     # Convert file path to dotted path.
     names[0] = names[0].replace(nodes.SEP, ".")
     names[0] = re.sub(r"\.py$", "", names[0])
@@ -481,17 +477,17 @@
         self.log_passing_tests = log_passing_tests
         self.report_duration = report_duration
         self.family = family
-        self.stats = dict.fromkeys(
+        self.stats: Dict[str, int] = dict.fromkeys(
             ["error", "passed", "failure", "skipped"], 0
-        )  # type: Dict[str, int]
-        self.node_reporters = (
-            {}
-        )  # type: Dict[Tuple[Union[str, TestReport], object], _NodeReporter]
-        self.node_reporters_ordered = []  # type: List[_NodeReporter]
-        self.global_properties = []  # type: List[Tuple[str, str]]
+        )
+        self.node_reporters: Dict[
+            Tuple[Union[str, TestReport], object], _NodeReporter
+        ] = {}
+        self.node_reporters_ordered: List[_NodeReporter] = []
+        self.global_properties: List[Tuple[str, str]] = []

         # List of reports that failed on call but teardown is pending.
-        self.open_reports = []  # type: List[TestReport]
+        self.open_reports: List[TestReport] = []
         self.cnt_double_fail_tests = 0

         # Replaces convenience family with real family.
@@ -507,7 +503,7 @@
             reporter.finalize()

     def node_reporter(self, report: Union[TestReport, str]) -> _NodeReporter:
-        nodeid = getattr(report, "nodeid", report)  # type: Union[str, TestReport]
+        nodeid: Union[str, TestReport] = getattr(report, "nodeid", report)
         # Local hack to handle xdist report order.
         workernode = getattr(report, "node", None)

@@ -648,42 +644,42 @@
         dirname = os.path.dirname(os.path.abspath(self.logfile))
         if not os.path.isdir(dirname):
             os.makedirs(dirname)
-        logfile = open(self.logfile, "w", encoding="utf-8")
-        suite_stop_time = timing.time()
-        suite_time_delta = suite_stop_time - self.suite_start_time
-
-        numtests = (
-            self.stats["passed"]
-            + self.stats["failure"]
-            + self.stats["skipped"]
-            + self.stats["error"]
-            - self.cnt_double_fail_tests
-        )
-        logfile.write('<?xml version="1.0" encoding="utf-8"?>')
-
-        suite_node = ET.Element(
-            "testsuite",
-            name=self.suite_name,
-            errors=str(self.stats["error"]),
-            failures=str(self.stats["failure"]),
-            skipped=str(self.stats["skipped"]),
-            tests=str(numtests),
-            time="%.3f" % suite_time_delta,
-            timestamp=datetime.fromtimestamp(self.suite_start_time).isoformat(),
-            hostname=platform.node(),
-        )
-        global_properties = self._get_global_properties_node()
-        if global_properties is not None:
-            suite_node.append(global_properties)
-        for node_reporter in self.node_reporters_ordered:
-            suite_node.append(node_reporter.to_xml())
-        testsuites = ET.Element("testsuites")
-        testsuites.append(suite_node)
-        logfile.write(ET.tostring(testsuites, encoding="unicode"))
-        logfile.close()
+
+        with open(self.logfile, "w", encoding="utf-8") as logfile:
+            suite_stop_time = timing.time()
+            suite_time_delta = suite_stop_time - self.suite_start_time
+
+            numtests = (
+                self.stats["passed"]
+                + self.stats["failure"]
+                + self.stats["skipped"]
+                + self.stats["error"]
+                - self.cnt_double_fail_tests
+            )
+            logfile.write('<?xml version="1.0" encoding="utf-8"?>')
+
+            suite_node = ET.Element(
+                "testsuite",
+                name=self.suite_name,
+                errors=str(self.stats["error"]),
+                failures=str(self.stats["failure"]),
+                skipped=str(self.stats["skipped"]),
+                tests=str(numtests),
+                time="%.3f" % suite_time_delta,
+                timestamp=datetime.fromtimestamp(self.suite_start_time).isoformat(),
+                hostname=platform.node(),
+            )
+            global_properties = self._get_global_properties_node()
+            if global_properties is not None:
+                suite_node.append(global_properties)
+            for node_reporter in self.node_reporters_ordered:
+                suite_node.append(node_reporter.to_xml())
+            testsuites = ET.Element("testsuites")
+            testsuites.append(suite_node)
+            logfile.write(ET.tostring(testsuites, encoding="unicode"))

     def pytest_terminal_summary(self, terminalreporter: TerminalReporter) -> None:
-        terminalreporter.write_sep("-", "generated xml file: {}".format(self.logfile))
+        terminalreporter.write_sep("-", f"generated xml file: {self.logfile}")

     def add_global_property(self, name: str, value: object) -> None:
         __tracebackhide__ = True
('src/_pytest', 'python.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -6,12 +6,11 @@
 import os
 import sys
 import types
-import typing
 import warnings
 from collections import Counter
 from collections import defaultdict
-from collections.abc import Sequence
 from functools import partial
+from pathlib import Path
 from typing import Any
 from typing import Callable
 from typing import Dict
@@ -21,11 +20,14 @@
 from typing import List
 from typing import Mapping
 from typing import Optional
+from typing import Pattern
+from typing import Sequence
 from typing import Set
 from typing import Tuple
+from typing import TYPE_CHECKING
 from typing import Union

-import py
+import attr

 import _pytest
 from _pytest import fixtures
@@ -37,6 +39,7 @@
 from _pytest._io import TerminalWriter
 from _pytest._io.saferepr import saferepr
 from _pytest.compat import ascii_escaped
+from _pytest.compat import assert_never
 from _pytest.compat import final
 from _pytest.compat import get_default_arg_names
 from _pytest.compat import get_real_func
@@ -44,17 +47,18 @@
 from _pytest.compat import getlocation
 from _pytest.compat import is_async_function
 from _pytest.compat import is_generator
+from _pytest.compat import LEGACY_PATH
 from _pytest.compat import NOTSET
-from _pytest.compat import REGEX_TYPE
 from _pytest.compat import safe_getattr
 from _pytest.compat import safe_isclass
 from _pytest.compat import STRING_TYPES
-from _pytest.compat import TYPE_CHECKING
 from _pytest.config import Config
 from _pytest.config import ExitCode
 from _pytest.config import hookimpl
 from _pytest.config.argparsing import Parser
+from _pytest.deprecated import check_ispytest
 from _pytest.deprecated import FSCOLLECTOR_GETHOOKPROXY_ISINITPATH
+from _pytest.deprecated import INSTANCE_COLLECTOR
 from _pytest.fixtures import FuncFixtureInfo
 from _pytest.main import Session
 from _pytest.mark import MARK_GEN
@@ -65,17 +69,22 @@
 from _pytest.mark.structures import normalize_mark_list
 from _pytest.outcomes import fail
 from _pytest.outcomes import skip
+from _pytest.pathlib import bestrelpath
+from _pytest.pathlib import fnmatch_ex
 from _pytest.pathlib import import_path
 from _pytest.pathlib import ImportPathMismatchError
 from _pytest.pathlib import parts
 from _pytest.pathlib import visit
+from _pytest.scope import Scope
 from _pytest.warning_types import PytestCollectionWarning
 from _pytest.warning_types import PytestUnhandledCoroutineWarning

 if TYPE_CHECKING:
-    from typing import Type
     from typing_extensions import Literal
-    from _pytest.fixtures import _Scope
+    from _pytest.scope import _ScopeName
+
+
+_PYTEST_DIR = Path(_pytest.__file__).parent


 def pytest_addoption(parser: Parser) -> None:
@@ -136,8 +145,7 @@

 def pytest_generate_tests(metafunc: "Metafunc") -> None:
     for marker in metafunc.definition.iter_markers(name="parametrize"):
-        # TODO: Fix this type-ignore (overlapping kwargs).
-        metafunc.parametrize(*marker.args, **marker.kwargs, _param_mark=marker)  # type: ignore[misc]
+        metafunc.parametrize(*marker.args, **marker.kwargs, _param_mark=marker)


 def pytest_configure(config: Config) -> None:
@@ -149,14 +157,14 @@
         "or a list of tuples of values if argnames specifies multiple names. "
         "Example: @parametrize('arg1', [1,2]) would lead to two calls of the "
         "decorated test function, one with arg1=1 and another with arg1=2."
-        "see https://docs.pytest.org/en/stable/parametrize.html for more info "
+        "see https://docs.pytest.org/en/stable/how-to/parametrize.html for more info "
         "and examples.",
     )
     config.addinivalue_line(
         "markers",
         "usefixtures(fixturename1, fixturename2, ...): mark tests as needing "
         "all of the specified fixtures. see "
-        "https://docs.pytest.org/en/stable/fixture.html#usefixtures ",
+        "https://docs.pytest.org/en/stable/explanation/fixtures.html#usefixtures ",
     )


@@ -171,7 +179,7 @@
     msg += "  - pytest-trio\n"
     msg += "  - pytest-twisted"
     warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))
-    skip(msg="async def function and no async plugin installed (see warnings)")
+    skip(reason="async def function and no async plugin installed (see warnings)")


 @hookimpl(trylast=True)
@@ -187,43 +195,44 @@
     return True


-def pytest_collect_file(
-    path: py.path.local, parent: nodes.Collector
-) -> Optional["Module"]:
-    ext = path.ext
-    if ext == ".py":
-        if not parent.session.isinitpath(path):
+def pytest_collect_file(file_path: Path, parent: nodes.Collector) -> Optional["Module"]:
+    if file_path.suffix == ".py":
+        if not parent.session.isinitpath(file_path):
             if not path_matches_patterns(
-                path, parent.config.getini("python_files") + ["__init__.py"]
+                file_path, parent.config.getini("python_files") + ["__init__.py"]
             ):
                 return None
-        ihook = parent.session.gethookproxy(path)
-        module = ihook.pytest_pycollect_makemodule(
-            path=path, parent=parent
-        )  # type: Module
+        ihook = parent.session.gethookproxy(file_path)
+        module: Module = ihook.pytest_pycollect_makemodule(
+            module_path=file_path, parent=parent
+        )
         return module
     return None


-def path_matches_patterns(path: py.path.local, patterns: Iterable[str]) -> bool:
+def path_matches_patterns(path: Path, patterns: Iterable[str]) -> bool:
     """Return whether path matches any of the patterns in the list of globs given."""
-    return any(path.fnmatch(pattern) for pattern in patterns)
-
-
-def pytest_pycollect_makemodule(path: py.path.local, parent) -> "Module":
-    if path.basename == "__init__.py":
-        pkg = Package.from_parent(parent, fspath=path)  # type: Package
+    return any(fnmatch_ex(pattern, path) for pattern in patterns)
+
+
+def pytest_pycollect_makemodule(module_path: Path, parent) -> "Module":
+    if module_path.name == "__init__.py":
+        pkg: Package = Package.from_parent(parent, path=module_path)
         return pkg
-    mod = Module.from_parent(parent, fspath=path)  # type: Module
+    mod: Module = Module.from_parent(parent, path=module_path)
     return mod


 @hookimpl(trylast=True)
-def pytest_pycollect_makeitem(collector: "PyCollector", name: str, obj: object):
+def pytest_pycollect_makeitem(
+    collector: Union["Module", "Class"], name: str, obj: object
+) -> Union[None, nodes.Item, nodes.Collector, List[Union[nodes.Item, nodes.Collector]]]:
+    assert isinstance(collector, (Class, Module)), type(collector)
     # Nothing was collected elsewhere, let's do it here.
     if safe_isclass(obj):
         if collector.istestclass(obj, name):
-            return Class.from_parent(collector, name=name, obj=obj)
+            klass: Class = Class.from_parent(collector, name=name, obj=obj)
+            return klass
     elif collector.istestfunction(obj, name):
         # mock seems to store unbound methods (issue473), normalize it.
         obj = getattr(obj, "__func__", obj)
@@ -242,31 +251,25 @@
             )
         elif getattr(obj, "__test__", True):
             if is_generator(obj):
-                res = Function.from_parent(collector, name=name)
+                res: Function = Function.from_parent(collector, name=name)
                 reason = "yield tests were removed in pytest 4.0 - {name} will be ignored".format(
                     name=name
                 )
                 res.add_marker(MARK_GEN.xfail(run=False, reason=reason))
                 res.warn(PytestCollectionWarning(reason))
+                return res
             else:
-                res = list(collector._genfunctions(name, obj))
-            return res
-
-
-class PyobjMixin:
+                return list(collector._genfunctions(name, obj))
+    return None
+
+
+class PyobjMixin(nodes.Node):
+    """this mix-in inherits from Node to carry over the typing information
+
+    as its intended to always mix in before a node
+    its position in the mro is unaffected"""
+
     _ALLOW_MARKERS = True
-
-    # Function and attributes that the mixin needs (for type-checking only).
-    if TYPE_CHECKING:
-        name = ""  # type: str
-        parent = None  # type: Optional[nodes.Node]
-        own_markers = []  # type: List[Mark]
-
-        def getparent(self, cls: Type[nodes._NodeType]) -> Optional[nodes._NodeType]:
-            ...
-
-        def listchain(self) -> List[nodes.Node]:
-            ...

     @property
     def module(self):
@@ -282,9 +285,13 @@

     @property
     def instance(self):
-        """Python instance object this node was collected from (can be None)."""
-        node = self.getparent(Instance)
-        return node.obj if node is not None else None
+        """Python instance object the function is bound to.
+
+        Returns None if not a test method, e.g. for a standalone test function,
+        a staticmethod, a class or a module.
+        """
+        node = self.getparent(Function)
+        return getattr(node.obj, "__self__", None) if node is not None else None

     @property
     def obj(self):
@@ -293,9 +300,12 @@
         if obj is None:
             self._obj = obj = self._getobj()
             # XXX evil hack
-            # used to avoid Instance collector marker duplication
+            # used to avoid Function marker duplication
             if self._ALLOW_MARKERS:
                 self.own_markers.extend(get_unpacked_marks(self.obj))
+                # This assumes that `obj` is called before there is a chance
+                # to add custom keys to `self.keywords`, so no fear of overriding.
+                self.keywords.update((mark.name, mark) for mark in self.own_markers)
         return obj

     @obj.setter
@@ -315,8 +325,6 @@
         chain.reverse()
         parts = []
         for node in chain:
-            if isinstance(node, Instance):
-                continue
             name = node.name
             if isinstance(node, Module):
                 name = os.path.splitext(name)[0]
@@ -328,22 +336,23 @@
         parts.reverse()
         return ".".join(parts)

-    def reportinfo(self) -> Tuple[Union[py.path.local, str], int, str]:
+    def reportinfo(self) -> Tuple[Union["os.PathLike[str]", str], Optional[int], str]:
         # XXX caching?
         obj = self.obj
         compat_co_firstlineno = getattr(obj, "compat_co_firstlineno", None)
         if isinstance(compat_co_firstlineno, int):
             # nose compatibility
             file_path = sys.modules[obj.__module__].__file__
+            assert file_path is not None
             if file_path.endswith(".pyc"):
                 file_path = file_path[:-1]
-            fspath = file_path  # type: Union[py.path.local, str]
+            path: Union["os.PathLike[str]", str] = file_path
             lineno = compat_co_firstlineno
         else:
-            fspath, lineno = getfslineno(obj)
+            path, lineno = getfslineno(obj)
         modpath = self.getmodpath()
         assert isinstance(lineno, int)
-        return fspath, lineno, modpath
+        return path, lineno, modpath


 # As an optimization, these builtin attribute names are pre-ignored when
@@ -387,10 +396,7 @@
             if isinstance(obj, staticmethod):
                 # staticmethods need to be unwrapped.
                 obj = safe_getattr(obj, "__func__", False)
-            return (
-                safe_getattr(obj, "__call__", False)
-                and fixtures.getfixturemarker(obj) is None
-            )
+            return callable(obj) and fixtures.getfixturemarker(obj) is None
         else:
             return False

@@ -416,15 +422,19 @@
         if not getattr(self.obj, "__test__", True):
             return []

-        # NB. we avoid random getattrs and peek in the __dict__ instead
-        # (XXX originally introduced from a PyPy need, still true?)
+        # Avoid random getattrs and peek in the __dict__ instead.
         dicts = [getattr(self.obj, "__dict__", {})]
-        for basecls in self.obj.__class__.__mro__:
-            dicts.append(basecls.__dict__)
-        seen = set()  # type: Set[str]
-        values = []  # type: List[Union[nodes.Item, nodes.Collector]]
+        if isinstance(self.obj, type):
+            for basecls in self.obj.__mro__:
+                dicts.append(basecls.__dict__)
+
+        # In each class, nodes should be definition ordered.
+        # __dict__ is definition ordered.
+        seen: Set[str] = set()
+        dict_values: List[List[Union[nodes.Item, nodes.Collector]]] = []
         ihook = self.ihook
         for dic in dicts:
+            values: List[Union[nodes.Item, nodes.Collector]] = []
             # Note: seems like the dict can change during iteration -
             # be careful not to remove the list() without consideration.
             for name, obj in list(dic.items()):
@@ -442,13 +452,14 @@
                     values.extend(res)
                 else:
                     values.append(res)
-
-        def sort_key(item):
-            fspath, lineno, _ = item.reportinfo()
-            return (str(fspath), lineno)
-
-        values.sort(key=sort_key)
-        return values
+            dict_values.append(values)
+
+        # Between classes in the class hierarchy, reverse-MRO order -- nodes
+        # inherited from base classes should come before subclasses.
+        result = []
+        for values in reversed(dict_values):
+            result.extend(values)
+        return result

     def _genfunctions(self, name: str, funcobj) -> Iterator["Function"]:
         modulecol = self.getparent(Module)
@@ -456,26 +467,32 @@
         module = modulecol.obj
         clscol = self.getparent(Class)
         cls = clscol and clscol.obj or None
-        fm = self.session._fixturemanager

         definition = FunctionDefinition.from_parent(self, name=name, callobj=funcobj)
         fixtureinfo = definition._fixtureinfo

+        # pytest_generate_tests impls call metafunc.parametrize() which fills
+        # metafunc._calls, the outcome of the hook.
         metafunc = Metafunc(
-            definition, fixtureinfo, self.config, cls=cls, module=module
+            definition=definition,
+            fixtureinfo=fixtureinfo,
+            config=self.config,
+            cls=cls,
+            module=module,
+            _ispytest=True,
         )
         methods = []
         if hasattr(module, "pytest_generate_tests"):
             methods.append(module.pytest_generate_tests)
         if cls is not None and hasattr(cls, "pytest_generate_tests"):
             methods.append(cls().pytest_generate_tests)
-
         self.ihook.pytest_generate_tests.call_extra(methods, dict(metafunc=metafunc))

         if not metafunc._calls:
             yield Function.from_parent(self, name=name, fixtureinfo=fixtureinfo)
         else:
             # Add funcargs() as fixturedefs to fixtureinfo.arg2fixturedefs.
+            fm = self.session._fixturemanager
             fixtures.add_funcarg_pseudo_fixture_def(self, metafunc, fm)

             # Add_funcarg_pseudo_fixture_def may have shadowed some fixtures
@@ -484,12 +501,11 @@
             fixtureinfo.prune_dependency_tree()

             for callspec in metafunc._calls:
-                subname = "{}[{}]".format(name, callspec.id)
+                subname = f"{name}[{callspec.id}]"
                 yield Function.from_parent(
                     self,
                     name=subname,
                     callspec=callspec,
-                    callobj=funcobj,
                     fixtureinfo=fixtureinfo,
                     keywords={callspec.id: True},
                     originalname=name,
@@ -515,17 +531,33 @@
         Using a fixture to invoke this methods ensures we play nicely and unsurprisingly with
         other fixtures (#517).
         """
+        has_nose = self.config.pluginmanager.has_plugin("nose")
         setup_module = _get_first_non_fixture_func(
             self.obj, ("setUpModule", "setup_module")
         )
+        if setup_module is None and has_nose:
+            # The name "setup" is too common - only treat as fixture if callable.
+            setup_module = _get_first_non_fixture_func(self.obj, ("setup",))
+            if not callable(setup_module):
+                setup_module = None
         teardown_module = _get_first_non_fixture_func(
             self.obj, ("tearDownModule", "teardown_module")
         )
+        if teardown_module is None and has_nose:
+            teardown_module = _get_first_non_fixture_func(self.obj, ("teardown",))
+            # Same as "setup" above - only treat as fixture if callable.
+            if not callable(teardown_module):
+                teardown_module = None

         if setup_module is None and teardown_module is None:
             return

-        @fixtures.fixture(autouse=True, scope="module")
+        @fixtures.fixture(
+            autouse=True,
+            scope="module",
+            # Use a unique name to speed up lookup.
+            name=f"_xunit_setup_module_fixture_{self.obj.__name__}",
+        )
         def xunit_setup_module_fixture(request) -> Generator[None, None, None]:
             if setup_module is not None:
                 _call_with_optional_argument(setup_module, request.module)
@@ -549,7 +581,12 @@
         if setup_function is None and teardown_function is None:
             return

-        @fixtures.fixture(autouse=True, scope="function")
+        @fixtures.fixture(
+            autouse=True,
+            scope="function",
+            # Use a unique name to speed up lookup.
+            name=f"_xunit_setup_function_fixture_{self.obj.__name__}",
+        )
         def xunit_setup_function_fixture(request) -> Generator[None, None, None]:
             if request.instance is not None:
                 # in this case we are bound to an instance, so we need to let
@@ -568,7 +605,7 @@
         # We assume we are only called once per module.
         importmode = self.config.getoption("--import-mode")
         try:
-            mod = import_path(self.fspath, mode=importmode)
+            mod = import_path(self.path, mode=importmode, root=self.config.rootpath)
         except SyntaxError as e:
             raise self.CollectError(
                 ExceptionInfo.from_current().getrepr(style="short")
@@ -594,19 +631,19 @@
             )
             formatted_tb = str(exc_repr)
             raise self.CollectError(
-                "ImportError while importing test module '{fspath}'.\n"
+                "ImportError while importing test module '{path}'.\n"
                 "Hint: make sure your test modules/packages have valid Python names.\n"
                 "Traceback:\n"
-                "{traceback}".format(fspath=self.fspath, traceback=formatted_tb)
+                "{traceback}".format(path=self.path, traceback=formatted_tb)
             ) from e
         except skip.Exception as e:
             if e.allow_module_level:
                 raise
             raise self.CollectError(
-                "Using pytest.skip outside of a test is not allowed. "
-                "To decorate a test function, use the @pytest.mark.skip "
-                "or @pytest.mark.skipif decorators instead, and to skip a "
-                "module use `pytestmark = pytest.mark.{skip,skipif}."
+                "Using pytest.skip outside of a test will skip the entire module. "
+                "If that's your intention, pass `allow_module_level=True`. "
+                "If you want to skip a specific test or an entire class, "
+                "use the @pytest.mark.skip or @pytest.mark.skipif decorators."
             ) from e
         self.config.pluginmanager.consider_module(mod)
         return mod
@@ -615,20 +652,27 @@
 class Package(Module):
     def __init__(
         self,
-        fspath: py.path.local,
+        fspath: Optional[LEGACY_PATH],
         parent: nodes.Collector,
         # NOTE: following args are unused:
         config=None,
         session=None,
         nodeid=None,
+        path=Optional[Path],
     ) -> None:
         # NOTE: Could be just the following, but kept as-is for compat.
         # nodes.FSCollector.__init__(self, fspath, parent=parent)
         session = parent.session
         nodes.FSCollector.__init__(
-            self, fspath, parent=parent, config=config, session=session, nodeid=nodeid
+            self,
+            fspath=fspath,
+            path=path,
+            parent=parent,
+            config=config,
+            session=session,
+            nodeid=nodeid,
         )
-        self.name = os.path.basename(str(fspath.dirname))
+        self.name = self.path.parent.name

     def setup(self) -> None:
         # Not using fixtures to call setup_module here because autouse fixtures
@@ -646,69 +690,69 @@
             func = partial(_call_with_optional_argument, teardown_module, self.obj)
             self.addfinalizer(func)

-    def gethookproxy(self, fspath: py.path.local):
+    def gethookproxy(self, fspath: "os.PathLike[str]"):
         warnings.warn(FSCOLLECTOR_GETHOOKPROXY_ISINITPATH, stacklevel=2)
         return self.session.gethookproxy(fspath)

-    def isinitpath(self, path: py.path.local) -> bool:
+    def isinitpath(self, path: Union[str, "os.PathLike[str]"]) -> bool:
         warnings.warn(FSCOLLECTOR_GETHOOKPROXY_ISINITPATH, stacklevel=2)
         return self.session.isinitpath(path)

     def _recurse(self, direntry: "os.DirEntry[str]") -> bool:
         if direntry.name == "__pycache__":
             return False
-        path = py.path.local(direntry.path)
-        ihook = self.session.gethookproxy(path.dirpath())
-        if ihook.pytest_ignore_collect(path=path, config=self.config):
+        fspath = Path(direntry.path)
+        ihook = self.session.gethookproxy(fspath.parent)
+        if ihook.pytest_ignore_collect(collection_path=fspath, config=self.config):
             return False
         norecursepatterns = self.config.getini("norecursedirs")
-        if any(path.check(fnmatch=pat) for pat in norecursepatterns):
+        if any(fnmatch_ex(pat, fspath) for pat in norecursepatterns):
             return False
         return True

     def _collectfile(
-        self, path: py.path.local, handle_dupes: bool = True
-    ) -> typing.Sequence[nodes.Collector]:
+        self, fspath: Path, handle_dupes: bool = True
+    ) -> Sequence[nodes.Collector]:
         assert (
-            path.isfile()
+            fspath.is_file()
         ), "{!r} is not a file (isdir={!r}, exists={!r}, islink={!r})".format(
-            path, path.isdir(), path.exists(), path.islink()
+            fspath, fspath.is_dir(), fspath.exists(), fspath.is_symlink()
         )
-        ihook = self.session.gethookproxy(path)
-        if not self.session.isinitpath(path):
-            if ihook.pytest_ignore_collect(path=path, config=self.config):
+        ihook = self.session.gethookproxy(fspath)
+        if not self.session.isinitpath(fspath):
+            if ihook.pytest_ignore_collect(collection_path=fspath, config=self.config):
                 return ()

         if handle_dupes:
             keepduplicates = self.config.getoption("keepduplicates")
             if not keepduplicates:
                 duplicate_paths = self.config.pluginmanager._duplicatepaths
-                if path in duplicate_paths:
+                if fspath in duplicate_paths:
                     return ()
                 else:
-                    duplicate_paths.add(path)
-
-        return ihook.pytest_collect_file(path=path, parent=self)  # type: ignore[no-any-return]
+                    duplicate_paths.add(fspath)
+
+        return ihook.pytest_collect_file(file_path=fspath, parent=self)  # type: ignore[no-any-return]

     def collect(self) -> Iterable[Union[nodes.Item, nodes.Collector]]:
-        this_path = self.fspath.dirpath()
-        init_module = this_path.join("__init__.py")
-        if init_module.check(file=1) and path_matches_patterns(
+        this_path = self.path.parent
+        init_module = this_path / "__init__.py"
+        if init_module.is_file() and path_matches_patterns(
             init_module, self.config.getini("python_files")
         ):
-            yield Module.from_parent(self, fspath=init_module)
-        pkg_prefixes = set()  # type: Set[py.path.local]
+            yield Module.from_parent(self, path=init_module)
+        pkg_prefixes: Set[Path] = set()
         for direntry in visit(str(this_path), recurse=self._recurse):
-            path = py.path.local(direntry.path)
+            path = Path(direntry.path)

             # We will visit our own __init__.py file, in which case we skip it.
             if direntry.is_file():
-                if direntry.name == "__init__.py" and path.dirpath() == this_path:
+                if direntry.name == "__init__.py" and path.parent == this_path:
                     continue

             parts_ = parts(direntry.path)
             if any(
-                str(pkg_prefix) in parts_ and pkg_prefix.join("__init__.py") != path
+                str(pkg_prefix) in parts_ and pkg_prefix / "__init__.py" != path
                 for pkg_prefix in pkg_prefixes
             ):
                 continue
@@ -718,7 +762,7 @@
             elif not direntry.is_dir():
                 # Broken symlink or invalid/missing file.
                 continue
-            elif path.join("__init__.py").check(file=1):
+            elif path.joinpath("__init__.py").is_file():
                 pkg_prefixes.add(path)


@@ -734,22 +778,26 @@
         func()


-def _get_first_non_fixture_func(obj: object, names: Iterable[str]):
+def _get_first_non_fixture_func(obj: object, names: Iterable[str]) -> Optional[object]:
     """Return the attribute from the given object to be used as a setup/teardown
     xunit-style function, but only if not marked as a fixture to avoid calling it twice."""
     for name in names:
-        meth = getattr(obj, name, None)
+        meth: Optional[object] = getattr(obj, name, None)
         if meth is not None and fixtures.getfixturemarker(meth) is None:
             return meth
+    return None


 class Class(PyCollector):
     """Collector for test methods."""

     @classmethod
-    def from_parent(cls, parent, *, name, obj=None):
+    def from_parent(cls, parent, *, name, obj=None, **kw):
         """The public constructor."""
-        return super().from_parent(name=name, parent=parent)
+        return super().from_parent(name=name, parent=parent, **kw)
+
+    def newinstance(self):
+        return self.obj()

     def collect(self) -> Iterable[Union[nodes.Item, nodes.Collector]]:
         if not safe_getattr(self.obj, "__test__", True):
@@ -778,7 +826,9 @@
         self._inject_setup_class_fixture()
         self._inject_setup_method_fixture()

-        return [Instance.from_parent(self, name="()")]
+        self.session._fixturemanager.parsefactories(self.newinstance(), self.nodeid)
+
+        return super().collect()

     def _inject_setup_class_fixture(self) -> None:
         """Inject a hidden autouse, class scoped fixture into the collected class object
@@ -792,7 +842,12 @@
         if setup_class is None and teardown_class is None:
             return

-        @fixtures.fixture(autouse=True, scope="class")
+        @fixtures.fixture(
+            autouse=True,
+            scope="class",
+            # Use a unique name to speed up lookup.
+            name=f"_xunit_setup_class_fixture_{self.obj.__qualname__}",
+        )
         def xunit_setup_class_fixture(cls) -> Generator[None, None, None]:
             if setup_class is not None:
                 func = getimfunc(setup_class)
@@ -811,85 +866,280 @@
         Using a fixture to invoke this methods ensures we play nicely and unsurprisingly with
         other fixtures (#517).
         """
-        setup_method = _get_first_non_fixture_func(self.obj, ("setup_method",))
-        teardown_method = getattr(self.obj, "teardown_method", None)
+        has_nose = self.config.pluginmanager.has_plugin("nose")
+        setup_name = "setup_method"
+        setup_method = _get_first_non_fixture_func(self.obj, (setup_name,))
+        if setup_method is None and has_nose:
+            setup_name = "setup"
+            setup_method = _get_first_non_fixture_func(self.obj, (setup_name,))
+        teardown_name = "teardown_method"
+        teardown_method = getattr(self.obj, teardown_name, None)
+        if teardown_method is None and has_nose:
+            teardown_name = "teardown"
+            teardown_method = getattr(self.obj, teardown_name, None)
         if setup_method is None and teardown_method is None:
             return

-        @fixtures.fixture(autouse=True, scope="function")
+        @fixtures.fixture(
+            autouse=True,
+            scope="function",
+            # Use a unique name to speed up lookup.
+            name=f"_xunit_setup_method_fixture_{self.obj.__qualname__}",
+        )
         def xunit_setup_method_fixture(self, request) -> Generator[None, None, None]:
             method = request.function
             if setup_method is not None:
-                func = getattr(self, "setup_method")
+                func = getattr(self, setup_name)
                 _call_with_optional_argument(func, method)
             yield
             if teardown_method is not None:
-                func = getattr(self, "teardown_method")
+                func = getattr(self, teardown_name)
                 _call_with_optional_argument(func, method)

         self.obj.__pytest_setup_method = xunit_setup_method_fixture


-class Instance(PyCollector):
-    _ALLOW_MARKERS = False  # hack, destroy later
-    # Instances share the object with their parents in a way
-    # that duplicates markers instances if not taken out
-    # can be removed at node structure reorganization time.
-
-    def _getobj(self):
-        # TODO: Improve the type of `parent` such that assert/ignore aren't needed.
-        assert self.parent is not None
-        obj = self.parent.obj  # type: ignore[attr-defined]
-        return obj()
-
-    def collect(self) -> Iterable[Union[nodes.Item, nodes.Collector]]:
-        self.session._fixturemanager.parsefactories(self)
-        return super().collect()
-
-    def newinstance(self):
-        self.obj = self._getobj()
-        return self.obj
+class InstanceDummy:
+    """Instance used to be a node type between Class and Function. It has been
+    removed in pytest 7.0. Some plugins exist which reference `pytest.Instance`
+    only to ignore it; this dummy class keeps them working. This will be removed
+    in pytest 8."""
+
+
+def __getattr__(name: str) -> object:
+    if name == "Instance":
+        warnings.warn(INSTANCE_COLLECTOR, 2)
+        return InstanceDummy
+    raise AttributeError(f"module {__name__} has no attribute {name}")


 def hasinit(obj: object) -> bool:
-    init = getattr(obj, "__init__", None)  # type: object
+    init: object = getattr(obj, "__init__", None)
     if init:
         return init != object.__init__
     return False


 def hasnew(obj: object) -> bool:
-    new = getattr(obj, "__new__", None)  # type: object
+    new: object = getattr(obj, "__new__", None)
     if new:
         return new != object.__new__
     return False


 @final
+@attr.s(frozen=True, auto_attribs=True, slots=True)
+class IdMaker:
+    """Make IDs for a parametrization."""
+
+    # The argnames of the parametrization.
+    argnames: Sequence[str]
+    # The ParameterSets of the parametrization.
+    parametersets: Sequence[ParameterSet]
+    # Optionally, a user-provided callable to make IDs for parameters in a
+    # ParameterSet.
+    idfn: Optional[Callable[[Any], Optional[object]]]
+    # Optionally, explicit IDs for ParameterSets by index.
+    ids: Optional[Sequence[Optional[object]]]
+    # Optionally, the pytest config.
+    # Used for controlling ASCII escaping, and for calling the
+    # :hook:`pytest_make_parametrize_id` hook.
+    config: Optional[Config]
+    # Optionally, the ID of the node being parametrized.
+    # Used only for clearer error messages.
+    nodeid: Optional[str]
+    # Optionally, the ID of the function being parametrized.
+    # Used only for clearer error messages.
+    func_name: Optional[str]
+
+    def make_unique_parameterset_ids(self) -> List[str]:
+        """Make a unique identifier for each ParameterSet, that may be used to
+        identify the parametrization in a node ID.
+
+        Format is <prm_1_token>-...-<prm_n_token>[counter], where prm_x_token is
+        - user-provided id, if given
+        - else an id derived from the value, applicable for certain types
+        - else <argname><parameterset index>
+        The counter suffix is appended only in case a string wouldn't be unique
+        otherwise.
+        """
+        resolved_ids = list(self._resolve_ids())
+        # All IDs must be unique!
+        if len(resolved_ids) != len(set(resolved_ids)):
+            # Record the number of occurrences of each ID.
+            id_counts = Counter(resolved_ids)
+            # Map the ID to its next suffix.
+            id_suffixes: Dict[str, int] = defaultdict(int)
+            # Suffix non-unique IDs to make them unique.
+            for index, id in enumerate(resolved_ids):
+                if id_counts[id] > 1:
+                    resolved_ids[index] = f"{id}{id_suffixes[id]}"
+                    id_suffixes[id] += 1
+        return resolved_ids
+
+    def _resolve_ids(self) -> Iterable[str]:
+        """Resolve IDs for all ParameterSets (may contain duplicates)."""
+        for idx, parameterset in enumerate(self.parametersets):
+            if parameterset.id is not None:
+                # ID provided directly - pytest.param(..., id="...")
+                yield parameterset.id
+            elif self.ids and idx < len(self.ids) and self.ids[idx] is not None:
+                # ID provided in the IDs list - parametrize(..., ids=[...]).
+                yield self._idval_from_value_required(self.ids[idx], idx)
+            else:
+                # ID not provided - generate it.
+                yield "-".join(
+                    self._idval(val, argname, idx)
+                    for val, argname in zip(parameterset.values, self.argnames)
+                )
+
+    def _idval(self, val: object, argname: str, idx: int) -> str:
+        """Make an ID for a parameter in a ParameterSet."""
+        idval = self._idval_from_function(val, argname, idx)
+        if idval is not None:
+            return idval
+        idval = self._idval_from_hook(val, argname)
+        if idval is not None:
+            return idval
+        idval = self._idval_from_value(val)
+        if idval is not None:
+            return idval
+        return self._idval_from_argname(argname, idx)
+
+    def _idval_from_function(
+        self, val: object, argname: str, idx: int
+    ) -> Optional[str]:
+        """Try to make an ID for a parameter in a ParameterSet using the
+        user-provided id callable, if given."""
+        if self.idfn is None:
+            return None
+        try:
+            id = self.idfn(val)
+        except Exception as e:
+            prefix = f"{self.nodeid}: " if self.nodeid is not None else ""
+            msg = "error raised while trying to determine id of parameter '{}' at position {}"
+            msg = prefix + msg.format(argname, idx)
+            raise ValueError(msg) from e
+        if id is None:
+            return None
+        return self._idval_from_value(id)
+
+    def _idval_from_hook(self, val: object, argname: str) -> Optional[str]:
+        """Try to make an ID for a parameter in a ParameterSet by calling the
+        :hook:`pytest_make_parametrize_id` hook."""
+        if self.config:
+            id: Optional[str] = self.config.hook.pytest_make_parametrize_id(
+                config=self.config, val=val, argname=argname
+            )
+            return id
+        return None
+
+    def _idval_from_value(self, val: object) -> Optional[str]:
+        """Try to make an ID for a parameter in a ParameterSet from its value,
+        if the value type is supported."""
+        if isinstance(val, STRING_TYPES):
+            return _ascii_escaped_by_config(val, self.config)
+        elif val is None or isinstance(val, (float, int, bool, complex)):
+            return str(val)
+        elif isinstance(val, Pattern):
+            return ascii_escaped(val.pattern)
+        elif val is NOTSET:
+            # Fallback to default. Note that NOTSET is an enum.Enum.
+            pass
+        elif isinstance(val, enum.Enum):
+            return str(val)
+        elif isinstance(getattr(val, "__name__", None), str):
+            # Name of a class, function, module, etc.
+            name: str = getattr(val, "__name__")
+            return name
+        return None
+
+    def _idval_from_value_required(self, val: object, idx: int) -> str:
+        """Like _idval_from_value(), but fails if the type is not supported."""
+        id = self._idval_from_value(val)
+        if id is not None:
+            return id
+
+        # Fail.
+        if self.func_name is not None:
+            prefix = f"In {self.func_name}: "
+        elif self.nodeid is not None:
+            prefix = f"In {self.nodeid}: "
+        else:
+            prefix = ""
+        msg = (
+            f"{prefix}ids contains unsupported value {saferepr(val)} (type: {type(val)!r}) at index {idx}. "
+            "Supported types are: str, bytes, int, float, complex, bool, enum, regex or anything with a __name__."
+        )
+        fail(msg, pytrace=False)
+
+    @staticmethod
+    def _idval_from_argname(argname: str, idx: int) -> str:
+        """Make an ID for a parameter in a ParameterSet from the argument name
+        and the index of the ParameterSet."""
+        return str(argname) + str(idx)
+
+
+@final
+@attr.s(frozen=True, slots=True, auto_attribs=True)
 class CallSpec2:
-    def __init__(self, metafunc: "Metafunc") -> None:
-        self.metafunc = metafunc
-        self.funcargs = {}  # type: Dict[str, object]
-        self._idlist = []  # type: List[str]
-        self.params = {}  # type: Dict[str, object]
-        # Used for sorting parametrized resources.
-        self._arg2scopenum = {}  # type: Dict[str, int]
-        self.marks = []  # type: List[Mark]
-        self.indices = {}  # type: Dict[str, int]
-
-    def copy(self) -> "CallSpec2":
-        cs = CallSpec2(self.metafunc)
-        cs.funcargs.update(self.funcargs)
-        cs.params.update(self.params)
-        cs.marks.extend(self.marks)
-        cs.indices.update(self.indices)
-        cs._arg2scopenum.update(self._arg2scopenum)
-        cs._idlist = list(self._idlist)
-        return cs
-
-    def _checkargnotcontained(self, arg: str) -> None:
-        if arg in self.params or arg in self.funcargs:
-            raise ValueError("duplicate {!r}".format(arg))
+    """A planned parameterized invocation of a test function.
+
+    Calculated during collection for a given test function's Metafunc.
+    Once collection is over, each callspec is turned into a single Item
+    and stored in item.callspec.
+    """
+
+    # arg name -> arg value which will be passed to the parametrized test
+    # function (direct parameterization).
+    funcargs: Dict[str, object] = attr.Factory(dict)
+    # arg name -> arg value which will be passed to a fixture of the same name
+    # (indirect parametrization).
+    params: Dict[str, object] = attr.Factory(dict)
+    # arg name -> arg index.
+    indices: Dict[str, int] = attr.Factory(dict)
+    # Used for sorting parametrized resources.
+    _arg2scope: Dict[str, Scope] = attr.Factory(dict)
+    # Parts which will be added to the item's name in `[..]` separated by "-".
+    _idlist: List[str] = attr.Factory(list)
+    # Marks which will be applied to the item.
+    marks: List[Mark] = attr.Factory(list)
+
+    def setmulti(
+        self,
+        *,
+        valtypes: Mapping[str, "Literal['params', 'funcargs']"],
+        argnames: Iterable[str],
+        valset: Iterable[object],
+        id: str,
+        marks: Iterable[Union[Mark, MarkDecorator]],
+        scope: Scope,
+        param_index: int,
+    ) -> "CallSpec2":
+        funcargs = self.funcargs.copy()
+        params = self.params.copy()
+        indices = self.indices.copy()
+        arg2scope = self._arg2scope.copy()
+        for arg, val in zip(argnames, valset):
+            if arg in params or arg in funcargs:
+                raise ValueError(f"duplicate {arg!r}")
+            valtype_for_arg = valtypes[arg]
+            if valtype_for_arg == "params":
+                params[arg] = val
+            elif valtype_for_arg == "funcargs":
+                funcargs[arg] = val
+            else:
+                assert_never(valtype_for_arg)
+            indices[arg] = param_index
+            arg2scope[arg] = scope
+        return CallSpec2(
+            funcargs=funcargs,
+            params=params,
+            arg2scope=arg2scope,
+            indices=indices,
+            idlist=[*self._idlist, id],
+            marks=[*self.marks, *normalize_mark_list(marks)],
+        )

     def getparam(self, name: str) -> object:
         try:
@@ -899,36 +1149,12 @@

     @property
     def id(self) -> str:
-        return "-".join(map(str, self._idlist))
-
-    def setmulti2(
-        self,
-        valtypes: Mapping[str, "Literal['params', 'funcargs']"],
-        argnames: typing.Sequence[str],
-        valset: Iterable[object],
-        id: str,
-        marks: Iterable[Union[Mark, MarkDecorator]],
-        scopenum: int,
-        param_index: int,
-    ) -> None:
-        for arg, val in zip(argnames, valset):
-            self._checkargnotcontained(arg)
-            valtype_for_arg = valtypes[arg]
-            if valtype_for_arg == "params":
-                self.params[arg] = val
-            elif valtype_for_arg == "funcargs":
-                self.funcargs[arg] = val
-            else:  # pragma: no cover
-                assert False, "Unhandled valtype for arg: {}".format(valtype_for_arg)
-            self.indices[arg] = param_index
-            self._arg2scopenum[arg] = scopenum
-        self._idlist.append(id)
-        self.marks.extend(normalize_mark_list(marks))
+        return "-".join(self._idlist)


 @final
 class Metafunc:
-    """Objects passed to the :func:`pytest_generate_tests <_pytest.hookspec.pytest_generate_tests>` hook.
+    """Objects passed to the :hook:`pytest_generate_tests` hook.

     They help to inspect a test function and to generate tests according to
     test configuration or values specified in the class or module where a
@@ -942,10 +1168,15 @@
         config: Config,
         cls=None,
         module=None,
+        *,
+        _ispytest: bool = False,
     ) -> None:
+        check_ispytest(_ispytest)
+
+        #: Access to the underlying :class:`_pytest.python.FunctionDefinition`.
         self.definition = definition

-        #: Access to the :class:`_pytest.config.Config` object for the test session.
+        #: Access to the :class:`pytest.Config` object for the test session.
         self.config = config

         #: The module object where the test function is defined in.
@@ -960,28 +1191,36 @@
         #: Class object where the test function is defined in or ``None``.
         self.cls = cls

-        self._calls = []  # type: List[CallSpec2]
         self._arg2fixturedefs = fixtureinfo.name2fixturedefs
+
+        # Result of parametrize().
+        self._calls: List[CallSpec2] = []

     def parametrize(
         self,
         argnames: Union[str, List[str], Tuple[str, ...]],
-        argvalues: Iterable[Union[ParameterSet, typing.Sequence[object], object]],
-        indirect: Union[bool, typing.Sequence[str]] = False,
+        argvalues: Iterable[Union[ParameterSet, Sequence[object], object]],
+        indirect: Union[bool, Sequence[str]] = False,
         ids: Optional[
-            Union[
-                Iterable[Union[None, str, float, int, bool]],
-                Callable[[Any], Optional[object]],
-            ]
+            Union[Iterable[Optional[object]], Callable[[Any], Optional[object]]]
         ] = None,
-        scope: "Optional[_Scope]" = None,
+        scope: "Optional[_ScopeName]" = None,
         *,
-        _param_mark: Optional[Mark] = None
+        _param_mark: Optional[Mark] = None,
     ) -> None:
         """Add new invocations to the underlying test function using the list
-        of argvalues for the given argnames.  Parametrization is performed
-        during the collection phase.  If you need to setup expensive resources
-        see about setting indirect to do it rather at test setup time.
+        of argvalues for the given argnames. Parametrization is performed
+        during the collection phase. If you need to setup expensive resources
+        see about setting indirect to do it rather than at test setup time.
+
+        Can be called multiple times, in which case each call parametrizes all
+        previous parametrizations, e.g.
+
+        ::
+
+            unparametrized:         t
+            parametrize ["x", "y"]: t[x], t[y]
+            parametrize [1, 2]:     t[x-1], t[x-2], t[y-1], t[y-2]

         :param argnames:
             A comma-separated string denoting one or more argument names, or
@@ -1030,9 +1269,7 @@
             It will also override any fixture-function defined scope, allowing
             to set a dynamic scope using test context or configuration.
         """
-        from _pytest.fixtures import scope2index
-
-        argnames, parameters = ParameterSet._for_parametrize(
+        argnames, parametersets = ParameterSet._for_parametrize(
             argnames,
             argvalues,
             self.function,
@@ -1047,8 +1284,12 @@
                 pytrace=False,
             )

-        if scope is None:
-            scope = _find_parametrized_scope(argnames, self._arg2fixturedefs, indirect)
+        if scope is not None:
+            scope_ = Scope.from_user(
+                scope, descr=f"parametrize() call in {self.function.__name__}"
+            )
+        else:
+            scope_ = _find_parametrized_scope(argnames, self._arg2fixturedefs, indirect)

         self._validate_if_using_arg_names(argnames, indirect)

@@ -1060,58 +1301,57 @@
             if generated_ids is not None:
                 ids = generated_ids

-        ids = self._resolve_arg_ids(
-            argnames, ids, parameters, nodeid=self.definition.nodeid
+        ids = self._resolve_parameter_set_ids(
+            argnames, ids, parametersets, nodeid=self.definition.nodeid
         )

         # Store used (possibly generated) ids with parametrize Marks.
         if _param_mark and _param_mark._param_ids_from and generated_ids is None:
             object.__setattr__(_param_mark._param_ids_from, "_param_ids_generated", ids)
-
-        scopenum = scope2index(
-            scope, descr="parametrize() call in {}".format(self.function.__name__)
-        )

         # Create the new calls: if we are parametrize() multiple times (by applying the decorator
         # more than once) then we accumulate those calls generating the cartesian product
         # of all calls.
         newcalls = []
-        for callspec in self._calls or [CallSpec2(self)]:
-            for param_index, (param_id, param_set) in enumerate(zip(ids, parameters)):
-                newcallspec = callspec.copy()
-                newcallspec.setmulti2(
-                    arg_values_types,
-                    argnames,
-                    param_set.values,
-                    param_id,
-                    param_set.marks,
-                    scopenum,
-                    param_index,
+        for callspec in self._calls or [CallSpec2()]:
+            for param_index, (param_id, param_set) in enumerate(
+                zip(ids, parametersets)
+            ):
+                newcallspec = callspec.setmulti(
+                    valtypes=arg_values_types,
+                    argnames=argnames,
+                    valset=param_set.values,
+                    id=param_id,
+                    marks=param_set.marks,
+                    scope=scope_,
+                    param_index=param_index,
                 )
                 newcalls.append(newcallspec)
         self._calls = newcalls

-    def _resolve_arg_ids(
+    def _resolve_parameter_set_ids(
         self,
-        argnames: typing.Sequence[str],
+        argnames: Sequence[str],
         ids: Optional[
-            Union[
-                Iterable[Union[None, str, float, int, bool]],
-                Callable[[Any], Optional[object]],
-            ]
+            Union[Iterable[Optional[object]], Callable[[Any], Optional[object]]]
         ],
-        parameters: typing.Sequence[ParameterSet],
+        parametersets: Sequence[ParameterSet],
         nodeid: str,
     ) -> List[str]:
-        """Resolve the actual ids for the given argnames, based on the ``ids`` parameter given
-        to ``parametrize``.
-
-        :param List[str] argnames: List of argument names passed to ``parametrize()``.
-        :param ids: The ids parameter of the parametrized call (see docs).
-        :param List[ParameterSet] parameters: The list of parameter values, same size as ``argnames``.
-        :param str str: The nodeid of the item that generated this parametrized call.
-        :rtype: List[str]
-        :returns: The list of ids for each argname given.
+        """Resolve the actual ids for the given parameter sets.
+
+        :param argnames:
+            Argument names passed to ``parametrize()``.
+        :param ids:
+            The `ids` parameter of the ``parametrize()`` call (see docs).
+        :param parametersets:
+            The parameter sets, each containing a set of values corresponding
+            to ``argnames``.
+        :param nodeid str:
+            The nodeid of the definition item that generated this
+            parametrization.
+        :returns:
+            List with ids for each parameter set given.
         """
         if ids is None:
             idfn = None
@@ -1121,15 +1361,24 @@
             ids_ = None
         else:
             idfn = None
-            ids_ = self._validate_ids(ids, parameters, self.function.__name__)
-        return idmaker(argnames, parameters, idfn, ids_, self.config, nodeid=nodeid)
+            ids_ = self._validate_ids(ids, parametersets, self.function.__name__)
+        id_maker = IdMaker(
+            argnames,
+            parametersets,
+            idfn,
+            ids_,
+            self.config,
+            nodeid=nodeid,
+            func_name=self.function.__name__,
+        )
+        return id_maker.make_unique_parameterset_ids()

     def _validate_ids(
         self,
-        ids: Iterable[Union[None, str, float, int, bool]],
-        parameters: typing.Sequence[ParameterSet],
+        ids: Iterable[Optional[object]],
+        parametersets: Sequence[ParameterSet],
         func_name: str,
-    ) -> List[Union[None, str]]:
+    ) -> List[Optional[object]]:
         try:
             num_ids = len(ids)  # type: ignore[arg-type]
         except TypeError:
@@ -1137,34 +1386,19 @@
                 iter(ids)
             except TypeError as e:
                 raise TypeError("ids must be a callable or an iterable") from e
-            num_ids = len(parameters)
+            num_ids = len(parametersets)

         # num_ids == 0 is a special case: https://github.com/pytest-dev/pytest/issues/1849
-        if num_ids != len(parameters) and num_ids != 0:
+        if num_ids != len(parametersets) and num_ids != 0:
             msg = "In {}: {} parameter sets specified, with different number of ids: {}"
-            fail(msg.format(func_name, len(parameters), num_ids), pytrace=False)
-
-        new_ids = []
-        for idx, id_value in enumerate(itertools.islice(ids, num_ids)):
-            if id_value is None or isinstance(id_value, str):
-                new_ids.append(id_value)
-            elif isinstance(id_value, (float, int, bool)):
-                new_ids.append(str(id_value))
-            else:
-                msg = (  # type: ignore[unreachable]
-                    "In {}: ids must be list of string/float/int/bool, "
-                    "found: {} (type: {!r}) at index {}"
-                )
-                fail(
-                    msg.format(func_name, saferepr(id_value), type(id_value), idx),
-                    pytrace=False,
-                )
-        return new_ids
+            fail(msg.format(func_name, len(parametersets), num_ids), pytrace=False)
+
+        return list(itertools.islice(ids, num_ids))

     def _resolve_arg_value_types(
         self,
-        argnames: typing.Sequence[str],
-        indirect: Union[bool, typing.Sequence[str]],
+        argnames: Sequence[str],
+        indirect: Union[bool, Sequence[str]],
     ) -> Dict[str, "Literal['params', 'funcargs']"]:
         """Resolve if each parametrized argument must be considered a
         parameter to a fixture or a "funcarg" to the function, based on the
@@ -1178,9 +1412,9 @@
             * "funcargs" if the argname should be a parameter to the parametrized test function.
         """
         if isinstance(indirect, bool):
-            valtypes = dict.fromkeys(
+            valtypes: Dict[str, Literal["params", "funcargs"]] = dict.fromkeys(
                 argnames, "params" if indirect else "funcargs"
-            )  # type: Dict[str, Literal["params", "funcargs"]]
+            )
         elif isinstance(indirect, Sequence):
             valtypes = dict.fromkeys(argnames, "funcargs")
             for arg in indirect:
@@ -1203,8 +1437,8 @@

     def _validate_if_using_arg_names(
         self,
-        argnames: typing.Sequence[str],
-        indirect: Union[bool, typing.Sequence[str]],
+        argnames: Sequence[str],
+        indirect: Union[bool, Sequence[str]],
     ) -> None:
         """Check if all argnames are being used, by default values, or directly/indirectly.

@@ -1229,16 +1463,16 @@
                     else:
                         name = "fixture" if indirect else "argument"
                     fail(
-                        "In {}: function uses no {} '{}'".format(func_name, name, arg),
+                        f"In {func_name}: function uses no {name} '{arg}'",
                         pytrace=False,
                     )


 def _find_parametrized_scope(
-    argnames: typing.Sequence[str],
-    arg2fixturedefs: Mapping[str, typing.Sequence[fixtures.FixtureDef[object]]],
-    indirect: Union[bool, typing.Sequence[str]],
-) -> "fixtures._Scope":
+    argnames: Sequence[str],
+    arg2fixturedefs: Mapping[str, Sequence[fixtures.FixtureDef[object]]],
+    indirect: Union[bool, Sequence[str]],
+) -> Scope:
     """Find the most appropriate scope for a parametrized call based on its arguments.

     When there's at least one direct argument, always use "function" scope.
@@ -1256,17 +1490,14 @@
     if all_arguments_are_fixtures:
         fixturedefs = arg2fixturedefs or {}
         used_scopes = [
-            fixturedef[0].scope
+            fixturedef[0]._scope
             for name, fixturedef in fixturedefs.items()
             if name in argnames
         ]
-        if used_scopes:
-            # Takes the most narrow scope from used fixtures.
-            for scope in reversed(fixtures.scopes):
-                if scope in used_scopes:
-                    return scope
-
-    return "function"
+        # Takes the most narrow scope from used fixtures.
+        return min(used_scopes, default=Scope.Function)
+
+    return Scope.Function


 def _ascii_escaped_by_config(val: Union[str, bytes], config: Optional[Config]) -> str:
@@ -1282,103 +1513,14 @@
     return val if escape_option else ascii_escaped(val)  # type: ignore


-def _idval(
-    val: object,
-    argname: str,
-    idx: int,
-    idfn: Optional[Callable[[Any], Optional[object]]],
-    nodeid: Optional[str],
-    config: Optional[Config],
-) -> str:
-    if idfn:
-        try:
-            generated_id = idfn(val)
-            if generated_id is not None:
-                val = generated_id
-        except Exception as e:
-            prefix = "{}: ".format(nodeid) if nodeid is not None else ""
-            msg = "error raised while trying to determine id of parameter '{}' at position {}"
-            msg = prefix + msg.format(argname, idx)
-            raise ValueError(msg) from e
-    elif config:
-        hook_id = config.hook.pytest_make_parametrize_id(
-            config=config, val=val, argname=argname
-        )  # type: Optional[str]
-        if hook_id:
-            return hook_id
-
-    if isinstance(val, STRING_TYPES):
-        return _ascii_escaped_by_config(val, config)
-    elif val is None or isinstance(val, (float, int, bool)):
-        return str(val)
-    elif isinstance(val, REGEX_TYPE):
-        return ascii_escaped(val.pattern)
-    elif val is NOTSET:
-        # Fallback to default. Note that NOTSET is an enum.Enum.
-        pass
-    elif isinstance(val, enum.Enum):
-        return str(val)
-    elif isinstance(getattr(val, "__name__", None), str):
-        # Name of a class, function, module, etc.
-        name = getattr(val, "__name__")  # type: str
-        return name
-    return str(argname) + str(idx)
-
-
-def _idvalset(
-    idx: int,
-    parameterset: ParameterSet,
-    argnames: Iterable[str],
-    idfn: Optional[Callable[[Any], Optional[object]]],
-    ids: Optional[List[Union[None, str]]],
-    nodeid: Optional[str],
-    config: Optional[Config],
-) -> str:
-    if parameterset.id is not None:
-        return parameterset.id
-    id = None if ids is None or idx >= len(ids) else ids[idx]
-    if id is None:
-        this_id = [
-            _idval(val, argname, idx, idfn, nodeid=nodeid, config=config)
-            for val, argname in zip(parameterset.values, argnames)
-        ]
-        return "-".join(this_id)
-    else:
-        return _ascii_escaped_by_config(id, config)
-
-
-def idmaker(
-    argnames: Iterable[str],
-    parametersets: Iterable[ParameterSet],
-    idfn: Optional[Callable[[Any], Optional[object]]] = None,
-    ids: Optional[List[Union[None, str]]] = None,
-    config: Optional[Config] = None,
-    nodeid: Optional[str] = None,
-) -> List[str]:
-    resolved_ids = [
-        _idvalset(
-            valindex, parameterset, argnames, idfn, ids, config=config, nodeid=nodeid
-        )
-        for valindex, parameterset in enumerate(parametersets)
-    ]
-
-    # All IDs must be unique!
-    unique_ids = set(resolved_ids)
-    if len(unique_ids) != len(resolved_ids):
-
-        # Record the number of occurrences of each test ID.
-        test_id_counts = Counter(resolved_ids)
-
-        # Map the test ID to its next suffix.
-        test_id_suffixes = defaultdict(int)  # type: Dict[str, int]
-
-        # Suffix non-unique IDs to make them unique.
-        for index, test_id in enumerate(resolved_ids):
-            if test_id_counts[test_id] > 1:
-                resolved_ids[index] = "{}{}".format(test_id, test_id_suffixes[test_id])
-                test_id_suffixes[test_id] += 1
-
-    return resolved_ids
+def _pretty_fixture_path(func) -> str:
+    cwd = Path.cwd()
+    loc = Path(getlocation(func, str(cwd)))
+    prefix = Path("...", "_pytest")
+    try:
+        return str(prefix / loc.relative_to(_PYTEST_DIR))
+    except ValueError:
+        return bestrelpath(cwd, loc)


 def show_fixtures_per_test(config):
@@ -1391,40 +1533,40 @@
     import _pytest.config

     session.perform_collect()
-    curdir = py.path.local()
+    curdir = Path.cwd()
     tw = _pytest.config.create_terminal_writer(config)
     verbose = config.getvalue("verbose")

-    def get_best_relpath(func):
+    def get_best_relpath(func) -> str:
         loc = getlocation(func, str(curdir))
-        return curdir.bestrelpath(py.path.local(loc))
+        return bestrelpath(curdir, Path(loc))

     def write_fixture(fixture_def: fixtures.FixtureDef[object]) -> None:
         argname = fixture_def.argname
         if verbose <= 0 and argname.startswith("_"):
             return
-        if verbose > 0:
-            bestrel = get_best_relpath(fixture_def.func)
-            funcargspec = "{} -- {}".format(argname, bestrel)
-        else:
-            funcargspec = argname
-        tw.line(funcargspec, green=True)
+        prettypath = _pretty_fixture_path(fixture_def.func)
+        tw.write(f"{argname}", green=True)
+        tw.write(f" -- {prettypath}", yellow=True)
+        tw.write("\n")
         fixture_doc = inspect.getdoc(fixture_def.func)
         if fixture_doc:
-            write_docstring(tw, fixture_doc)
+            write_docstring(
+                tw, fixture_doc.split("\n\n")[0] if verbose <= 0 else fixture_doc
+            )
         else:
             tw.line("    no docstring available", red=True)

     def write_item(item: nodes.Item) -> None:
         # Not all items have _fixtureinfo attribute.
-        info = getattr(item, "_fixtureinfo", None)  # type: Optional[FuncFixtureInfo]
+        info: Optional[FuncFixtureInfo] = getattr(item, "_fixtureinfo", None)
         if info is None or not info.name2fixturedefs:
             # This test item does not use any fixtures.
             return
         tw.line()
-        tw.sep("-", "fixtures used by {}".format(item.name))
+        tw.sep("-", f"fixtures used by {item.name}")
         # TODO: Fix this type ignore.
-        tw.sep("-", "({})".format(get_best_relpath(item.function)))  # type: ignore[attr-defined]
+        tw.sep("-", f"({get_best_relpath(item.function)})")  # type: ignore[attr-defined]
         # dict key not used in loop but needed for sorting.
         for _, fixturedefs in sorted(info.name2fixturedefs.items()):
             assert fixturedefs is not None
@@ -1447,14 +1589,14 @@
     import _pytest.config

     session.perform_collect()
-    curdir = py.path.local()
+    curdir = Path.cwd()
     tw = _pytest.config.create_terminal_writer(config)
     verbose = config.getvalue("verbose")

     fm = session._fixturemanager

     available = []
-    seen = set()  # type: Set[Tuple[str, str]]
+    seen: Set[Tuple[str, str]] = set()

     for argname, fixturedefs in fm._arg2fixturedefs.items():
         assert fixturedefs is not None
@@ -1469,7 +1611,7 @@
                 (
                     len(fixturedef.baseid),
                     fixturedef.func.__module__,
-                    curdir.bestrelpath(py.path.local(loc)),
+                    _pretty_fixture_path(fixturedef.func),
                     fixturedef.argname,
                     fixturedef,
                 )
@@ -1477,26 +1619,24 @@

     available.sort()
     currentmodule = None
-    for baseid, module, bestrel, argname, fixturedef in available:
+    for baseid, module, prettypath, argname, fixturedef in available:
         if currentmodule != module:
             if not module.startswith("_pytest."):
                 tw.line()
-                tw.sep("-", "fixtures defined from {}".format(module))
+                tw.sep("-", f"fixtures defined from {module}")
                 currentmodule = module
-        if verbose <= 0 and argname[0] == "_":
+        if verbose <= 0 and argname.startswith("_"):
             continue
-        tw.write(argname, green=True)
+        tw.write(f"{argname}", green=True)
         if fixturedef.scope != "function":
             tw.write(" [%s scope]" % fixturedef.scope, cyan=True)
-        if verbose > 0:
-            tw.write(" -- %s" % bestrel, yellow=True)
+        tw.write(f" -- {prettypath}", yellow=True)
         tw.write("\n")
-        loc = getlocation(fixturedef.func, str(curdir))
         doc = inspect.getdoc(fixturedef.func)
         if doc:
-            write_docstring(tw, doc)
+            write_docstring(tw, doc.split("\n\n")[0] if verbose <= 0 else doc)
         else:
-            tw.line("    {}: no docstring available".format(loc), red=True)
+            tw.line("    no docstring available", red=True)
         tw.line()


@@ -1508,26 +1648,26 @@
 class Function(PyobjMixin, nodes.Item):
     """An Item responsible for setting up and executing a Python test function.

-    param name:
+    :param name:
         The full function name, including any decorations like those
         added by parametrization (``my_func[my_param]``).
-    param parent:
+    :param parent:
         The parent Node.
-    param config:
+    :param config:
         The pytest Config object.
-    param callspec:
+    :param callspec:
         If given, this is function has been parametrized and the callspec contains
         meta information about the parametrization.
-    param callobj:
+    :param callobj:
         If given, the object which will be called when the Function is invoked,
         otherwise the callobj will be obtained from ``parent`` using ``originalname``.
-    param keywords:
+    :param keywords:
         Keywords bound to the function object for "-k" matching.
-    param session:
+    :param session:
         The pytest Session object.
-    param fixtureinfo:
+    :param fixtureinfo:
         Fixture information already resolved at this fixture node..
-    param originalname:
+    :param originalname:
         The attribute name to use for accessing the underlying function object.
         Defaults to ``name``. Set this if name is different from the original name,
         for example when it contains decorations like those added by parametrization
@@ -1544,7 +1684,7 @@
         config: Optional[Config] = None,
         callspec: Optional[CallSpec2] = None,
         callobj=NOTSET,
-        keywords=None,
+        keywords: Optional[Mapping[str, Any]] = None,
         session: Optional[Session] = None,
         fixtureinfo: Optional[FuncFixtureInfo] = None,
         originalname: Optional[str] = None,
@@ -1565,37 +1705,26 @@
         # Note: when FunctionDefinition is introduced, we should change ``originalname``
         # to a readonly property that returns FunctionDefinition.name.

-        self.keywords.update(self.obj.__dict__)
         self.own_markers.extend(get_unpacked_marks(self.obj))
         if callspec:
             self.callspec = callspec
-            # this is total hostile and a mess
-            # keywords are broken by design by now
-            # this will be redeemed later
-            for mark in callspec.marks:
-                # feel free to cry, this was broken for years before
-                # and keywords cant fix it per design
-                self.keywords[mark.name] = mark
-            self.own_markers.extend(normalize_mark_list(callspec.marks))
+            self.own_markers.extend(callspec.marks)
+
+        # todo: this is a hell of a hack
+        # https://github.com/pytest-dev/pytest/issues/4569
+        # Note: the order of the updates is important here; indicates what
+        # takes priority (ctor argument over function attributes over markers).
+        # Take own_markers only; NodeKeywords handles parent traversal on its own.
+        self.keywords.update((mark.name, mark) for mark in self.own_markers)
+        self.keywords.update(self.obj.__dict__)
         if keywords:
             self.keywords.update(keywords)
-
-        # todo: this is a hell of a hack
-        # https://github.com/pytest-dev/pytest/issues/4569
-
-        self.keywords.update(
-            {
-                mark.name: True
-                for mark in self.iter_markers()
-                if mark.name not in self.keywords
-            }
-        )

         if fixtureinfo is None:
             fixtureinfo = self.session._fixturemanager.getfixtureinfo(
                 self, self.obj, self.cls, funcargs=True
             )
-        self._fixtureinfo = fixtureinfo  # type: FuncFixtureInfo
+        self._fixtureinfo: FuncFixtureInfo = fixtureinfo
         self.fixturenames = fixtureinfo.names_closure
         self._initrequest()

@@ -1605,8 +1734,8 @@
         return super().from_parent(parent=parent, **kw)

     def _initrequest(self) -> None:
-        self.funcargs = {}  # type: Dict[str, object]
-        self._request = fixtures.FixtureRequest(self)
+        self.funcargs: Dict[str, object] = {}
+        self._request = fixtures.FixtureRequest(self, _ispytest=True)

     @property
     def function(self):
@@ -1615,7 +1744,12 @@

     def _getobj(self):
         assert self.parent is not None
-        return getattr(self.parent.obj, self.originalname)  # type: ignore[attr-defined]
+        if isinstance(self.parent, Class):
+            # Each Function gets a fresh class instance.
+            parent_obj = self.parent.newinstance()
+        else:
+            parent_obj = self.parent.obj  # type: ignore[attr-defined]
+        return getattr(parent_obj, self.originalname)

     @property
     def _pyfuncitem(self):
@@ -1627,14 +1761,11 @@
         self.ihook.pytest_pyfunc_call(pyfuncitem=self)

     def setup(self) -> None:
-        if isinstance(self.parent, Instance):
-            self.parent.newinstance()
-            self.obj = self._getobj()
         self._request._fillfixtures()

     def _prunetraceback(self, excinfo: ExceptionInfo[BaseException]) -> None:
         if hasattr(self, "_obj") and not self.config.getoption("fulltrace", False):
-            code = _pytest._code.Code(get_real_func(self.obj))
+            code = _pytest._code.Code.from_function(get_real_func(self.obj))
             path, firstlineno = code.path, code.firstlineno
             traceback = excinfo.traceback
             ntraceback = traceback.cut(path=path, firstlineno=firstlineno)
@@ -1655,7 +1786,8 @@

     # TODO: Type ignored -- breaks Liskov Substitution.
     def repr_failure(  # type: ignore[override]
-        self, excinfo: ExceptionInfo[BaseException],
+        self,
+        excinfo: ExceptionInfo[BaseException],
     ) -> Union[str, TerminalRepr]:
         style = self.config.getoption("tbstyle", "auto")
         if style == "auto":
@@ -1664,10 +1796,12 @@


 class FunctionDefinition(Function):
-    """Internal hack until we get actual definition nodes instead of the
-    crappy metafunc hack."""
+    """
+    This class is a step gap solution until we evolve to have actual function definition nodes
+    and manage to get rid of ``metafunc``.
+    """

     def runtest(self) -> None:
-        raise RuntimeError("function definitions are not supposed to be used")
+        raise RuntimeError("function definitions are not supposed to be run as tests")

     setup = runtest
('src/_pytest', 'reports.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,3 +1,4 @@
+import os
 from io import StringIO
 from pprint import pprint
 from typing import Any
@@ -6,13 +7,15 @@
 from typing import Iterable
 from typing import Iterator
 from typing import List
+from typing import Mapping
 from typing import Optional
 from typing import Tuple
+from typing import Type
+from typing import TYPE_CHECKING
 from typing import TypeVar
 from typing import Union

 import attr
-import py

 from _pytest._code.code import ExceptionChainRepr
 from _pytest._code.code import ExceptionInfo
@@ -27,16 +30,13 @@
 from _pytest._code.code import TerminalRepr
 from _pytest._io import TerminalWriter
 from _pytest.compat import final
-from _pytest.compat import TYPE_CHECKING
 from _pytest.config import Config
 from _pytest.nodes import Collector
 from _pytest.nodes import Item
 from _pytest.outcomes import skip
-from _pytest.pathlib import Path

 if TYPE_CHECKING:
     from typing import NoReturn
-    from typing_extensions import Type
     from typing_extensions import Literal

     from _pytest.runner import CallInfo
@@ -58,13 +58,14 @@


 class BaseReport:
-    when = None  # type: Optional[str]
-    location = None  # type: Optional[Tuple[str, Optional[int], str]]
-    longrepr = (
-        None
-    )  # type: Union[None, ExceptionInfo[BaseException], Tuple[str, int, str], str, TerminalRepr]
-    sections = []  # type: List[Tuple[str, str]]
-    nodeid = None  # type: str
+    when: Optional[str]
+    location: Optional[Tuple[str, Optional[int], str]]
+    longrepr: Union[
+        None, ExceptionInfo[BaseException], Tuple[str, int, str], str, TerminalRepr
+    ]
+    sections: List[Tuple[str, str]]
+    nodeid: str
+    outcome: "Literal['passed', 'failed', 'skipped']"

     def __init__(self, **kw: Any) -> None:
         self.__dict__.update(kw)
@@ -76,7 +77,9 @@

     def toterminal(self, out: TerminalWriter) -> None:
         if hasattr(self, "node"):
-            out.line(getworkerinfoline(self.node))
+            worker_info = getworkerinfoline(self.node)
+            if worker_info:
+                out.line(worker_info)

         longrepr = self.longrepr
         if longrepr is None:
@@ -141,12 +144,24 @@
             content for (prefix, content) in self.get_sections("Captured stderr")
         )

-    passed = property(lambda x: x.outcome == "passed")
-    failed = property(lambda x: x.outcome == "failed")
-    skipped = property(lambda x: x.outcome == "skipped")
+    @property
+    def passed(self) -> bool:
+        """Whether the outcome is passed."""
+        return self.outcome == "passed"
+
+    @property
+    def failed(self) -> bool:
+        """Whether the outcome is failed."""
+        return self.outcome == "failed"
+
+    @property
+    def skipped(self) -> bool:
+        """Whether the outcome is skipped."""
+        return self.outcome == "skipped"

     @property
     def fspath(self) -> str:
+        """The path portion of the reported node, as a string."""
         return self.nodeid.split("::")[0]

     @property
@@ -199,7 +214,7 @@
         return _report_to_json(self)

     @classmethod
-    def _from_json(cls: "Type[_R]", reportdict: Dict[str, object]) -> _R:
+    def _from_json(cls: Type[_R], reportdict: Dict[str, object]) -> _R:
         """Create either a TestReport or CollectReport, depending on the calling class.

         It is the callers responsibility to know which class to pass here.
@@ -213,7 +228,7 @@


 def _report_unserialization_failure(
-    type_name: str, report_class: "Type[BaseReport]", reportdict
+    type_name: str, report_class: Type[BaseReport], reportdict
 ) -> "NoReturn":
     url = "https://github.com/pytest-dev/pytest/issues"
     stream = StringIO()
@@ -229,7 +244,10 @@
 @final
 class TestReport(BaseReport):
     """Basic test report object (also used for setup and teardown calls if
-    they fail)."""
+    they fail).
+
+    Reports can contain arbitrary extra attributes.
+    """

     __test__ = False

@@ -237,7 +255,7 @@
         self,
         nodeid: str,
         location: Tuple[str, Optional[int], str],
-        keywords,
+        keywords: Mapping[str, Any],
         outcome: "Literal['passed', 'failed', 'skipped']",
         longrepr: Union[
             None, ExceptionInfo[BaseException], Tuple[str, int, str], str, TerminalRepr
@@ -246,7 +264,7 @@
         sections: Iterable[Tuple[str, str]] = (),
         duration: float = 0,
         user_properties: Optional[Iterable[Tuple[str, object]]] = None,
-        **extra
+        **extra,
     ) -> None:
         #: Normalized collection nodeid.
         self.nodeid = nodeid
@@ -254,7 +272,7 @@
         #: A (filesystempath, lineno, domaininfo) tuple indicating the
         #: actual location of a test item - it might be different from the
         #: collected one e.g. if a method is inherited from a different module.
-        self.location = location  # type: Tuple[str, Optional[int], str]
+        self.location: Tuple[str, Optional[int], str] = location

         #: A name -> value dictionary containing all keywords and
         #: markers associated with a test invocation.
@@ -273,10 +291,10 @@
         #: defined properties of the test.
         self.user_properties = list(user_properties or [])

-        #: List of pairs ``(str, str)`` of extra information which needs to
-        #: marshallable. Used by pytest to add captured text
-        #: from ``stdout`` and ``stderr``, but may be used by other plugins
-        #: to add arbitrary information to reports.
+        #: Tuples of str ``(heading, content)`` with extra information
+        #: for the test report. Used by pytest to add text captured
+        #: from ``stdout``, ``stderr``, and intercepted logging events. May
+        #: be used by other plugins to add arbitrary information to reports.
         self.sections = list(sections)

         #: Time it took to run just the test.
@@ -300,10 +318,14 @@
         excinfo = call.excinfo
         sections = []
         if not call.excinfo:
-            outcome = "passed"  # type: Literal["passed", "failed", "skipped"]
-            longrepr = (
-                None
-            )  # type: Union[None, ExceptionInfo[BaseException], Tuple[str, int, str], str, TerminalRepr]
+            outcome: Literal["passed", "failed", "skipped"] = "passed"
+            longrepr: Union[
+                None,
+                ExceptionInfo[BaseException],
+                Tuple[str, int, str],
+                str,
+                TerminalRepr,
+            ] = None
         else:
             if not isinstance(excinfo, ExceptionInfo):
                 outcome = "failed"
@@ -311,7 +333,12 @@
             elif isinstance(excinfo.value, skip.Exception):
                 outcome = "skipped"
                 r = excinfo._getreprcrash()
-                longrepr = (str(r.path), r.lineno, r.message)
+                if excinfo.value._use_item_location:
+                    path, line = item.reportinfo()[:2]
+                    assert line is not None
+                    longrepr = os.fspath(path), line + 1, r.message
+                else:
+                    longrepr = (str(r.path), r.lineno, r.message)
             else:
                 outcome = "failed"
                 if call.when == "call":
@@ -321,7 +348,7 @@
                         excinfo, style=item.config.getoption("tbstyle", "auto")
                     )
         for rwhen, key, content in item._report_sections:
-            sections.append(("Captured {} {}".format(key, rwhen), content))
+            sections.append((f"Captured {key} {rwhen}", content))
         return cls(
             item.nodeid,
             item.location,
@@ -337,18 +364,23 @@

 @final
 class CollectReport(BaseReport):
-    """Collection report object."""
+    """Collection report object.
+
+    Reports can contain arbitrary extra attributes.
+    """

     when = "collect"

     def __init__(
         self,
         nodeid: str,
-        outcome: "Literal['passed', 'skipped', 'failed']",
-        longrepr,
+        outcome: "Literal['passed', 'failed', 'skipped']",
+        longrepr: Union[
+            None, ExceptionInfo[BaseException], Tuple[str, int, str], str, TerminalRepr
+        ],
         result: Optional[List[Union[Item, Collector]]],
         sections: Iterable[Tuple[str, str]] = (),
-        **extra
+        **extra,
     ) -> None:
         #: Normalized collection nodeid.
         self.nodeid = nodeid
@@ -362,11 +394,10 @@
         #: The collected items and collection nodes.
         self.result = result or []

-        #: List of pairs ``(str, str)`` of extra information which needs to
-        #: marshallable.
-        # Used by pytest to add captured text : from ``stdout`` and ``stderr``,
-        # but may be used by other plugins : to add arbitrary information to
-        # reports.
+        #: Tuples of str ``(heading, content)`` with extra information
+        #: for the test report. Used by pytest to add text captured
+        #: from ``stdout``, ``stderr``, and intercepted logging events. May
+        #: be used by other plugins to add arbitrary information to reports.
         self.sections = list(sections)

         self.__dict__.update(extra)
@@ -450,11 +481,11 @@
         assert rep.longrepr is not None
         # TODO: Investigate whether the duck typing is really necessary here.
         longrepr = cast(ExceptionRepr, rep.longrepr)
-        result = {
+        result: Dict[str, Any] = {
             "reprcrash": serialize_repr_crash(longrepr.reprcrash),
             "reprtraceback": serialize_repr_traceback(longrepr.reprtraceback),
             "sections": longrepr.sections,
-        }  # type: Dict[str, Any]
+        }
         if isinstance(longrepr, ExceptionChainRepr):
             result["chain"] = []
             for repr_traceback, repr_crash, description in longrepr.chain:
@@ -480,8 +511,8 @@
     else:
         d["longrepr"] = report.longrepr
     for name in d:
-        if isinstance(d[name], (py.path.local, Path)):
-            d[name] = str(d[name])
+        if isinstance(d[name], os.PathLike):
+            d[name] = os.fspath(d[name])
         elif name == "result":
             d[name] = None  # for now
     return d
@@ -508,13 +539,13 @@
             if data["reprlocals"]:
                 reprlocals = ReprLocals(data["reprlocals"]["lines"])

-            reprentry = ReprEntry(
+            reprentry: Union[ReprEntry, ReprEntryNative] = ReprEntry(
                 lines=data["lines"],
                 reprfuncargs=reprfuncargs,
                 reprlocals=reprlocals,
                 reprfileloc=reprfileloc,
                 style=data["style"],
-            )  # type: Union[ReprEntry, ReprEntryNative]
+            )
         elif entry_type == "ReprEntryNative":
             reprentry = ReprEntryNative(data["lines"])
         else:
@@ -555,9 +586,9 @@
                         description,
                     )
                 )
-            exception_info = ExceptionChainRepr(
-                chain
-            )  # type: Union[ExceptionChainRepr,ReprExceptionInfo]
+            exception_info: Union[
+                ExceptionChainRepr, ReprExceptionInfo
+            ] = ExceptionChainRepr(chain)
         else:
             exception_info = ReprExceptionInfo(reprtraceback, reprcrash)

('src/_pytest', 'doctest.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,12 +1,14 @@
 """Discover and run doctests in modules and test files."""
 import bdb
 import inspect
+import os
 import platform
 import sys
 import traceback
 import types
 import warnings
 from contextlib import contextmanager
+from pathlib import Path
 from typing import Any
 from typing import Callable
 from typing import Dict
@@ -17,9 +19,9 @@
 from typing import Pattern
 from typing import Sequence
 from typing import Tuple
+from typing import Type
+from typing import TYPE_CHECKING
 from typing import Union
-
-import py.path

 import pytest
 from _pytest import outcomes
@@ -28,19 +30,18 @@
 from _pytest._code.code import TerminalRepr
 from _pytest._io import TerminalWriter
 from _pytest.compat import safe_getattr
-from _pytest.compat import TYPE_CHECKING
 from _pytest.config import Config
 from _pytest.config.argparsing import Parser
 from _pytest.fixtures import FixtureRequest
 from _pytest.nodes import Collector
 from _pytest.outcomes import OutcomeException
+from _pytest.pathlib import fnmatch_ex
 from _pytest.pathlib import import_path
 from _pytest.python_api import approx
 from _pytest.warning_types import PytestWarning

 if TYPE_CHECKING:
     import doctest
-    from typing import Type

 DOCTEST_REPORT_CHOICE_NONE = "none"
 DOCTEST_REPORT_CHOICE_CDIFF = "cdiff"
@@ -59,7 +60,7 @@
 # Lazy definition of runner class
 RUNNER_CLASS = None
 # Lazy definition of output checker class
-CHECKER_CLASS = None  # type: Optional[Type[doctest.OutputChecker]]
+CHECKER_CLASS: Optional[Type["doctest.OutputChecker"]] = None


 def pytest_addoption(parser: Parser) -> None:
@@ -119,34 +120,38 @@


 def pytest_collect_file(
-    path: py.path.local, parent: Collector,
+    file_path: Path,
+    parent: Collector,
 ) -> Optional[Union["DoctestModule", "DoctestTextfile"]]:
     config = parent.config
-    if path.ext == ".py":
-        if config.option.doctestmodules and not _is_setup_py(path):
-            mod = DoctestModule.from_parent(parent, fspath=path)  # type: DoctestModule
+    if file_path.suffix == ".py":
+        if config.option.doctestmodules and not any(
+            (_is_setup_py(file_path), _is_main_py(file_path))
+        ):
+            mod: DoctestModule = DoctestModule.from_parent(parent, path=file_path)
             return mod
-    elif _is_doctest(config, path, parent):
-        txt = DoctestTextfile.from_parent(parent, fspath=path)  # type: DoctestTextfile
+    elif _is_doctest(config, file_path, parent):
+        txt: DoctestTextfile = DoctestTextfile.from_parent(parent, path=file_path)
         return txt
     return None


-def _is_setup_py(path: py.path.local) -> bool:
-    if path.basename != "setup.py":
+def _is_setup_py(path: Path) -> bool:
+    if path.name != "setup.py":
         return False
-    contents = path.read_binary()
+    contents = path.read_bytes()
     return b"setuptools" in contents or b"distutils" in contents


-def _is_doctest(config: Config, path: py.path.local, parent) -> bool:
-    if path.ext in (".txt", ".rst") and parent.session.isinitpath(path):
+def _is_doctest(config: Config, path: Path, parent: Collector) -> bool:
+    if path.suffix in (".txt", ".rst") and parent.session.isinitpath(path):
         return True
     globs = config.getoption("doctestglob") or ["test*.txt"]
-    for glob in globs:
-        if path.check(fnmatch=glob):
-            return True
-    return False
+    return any(fnmatch_ex(glob, path) for glob in globs)
+
+
+def _is_main_py(path: Path) -> bool:
+    return path.name == "__main__.py"


 class ReprFailDoctest(TerminalRepr):
@@ -163,12 +168,12 @@


 class MultipleDoctestFailures(Exception):
-    def __init__(self, failures: "Sequence[doctest.DocTestFailure]") -> None:
+    def __init__(self, failures: Sequence["doctest.DocTestFailure"]) -> None:
         super().__init__()
         self.failures = failures


-def _init_runner_class() -> "Type[doctest.DocTestRunner]":
+def _init_runner_class() -> Type["doctest.DocTestRunner"]:
     import doctest

     class PytestDoctestRunner(doctest.DebugRunner):
@@ -180,18 +185,20 @@

         def __init__(
             self,
-            checker: Optional[doctest.OutputChecker] = None,
+            checker: Optional["doctest.OutputChecker"] = None,
             verbose: Optional[bool] = None,
             optionflags: int = 0,
             continue_on_failure: bool = True,
         ) -> None:
-            doctest.DebugRunner.__init__(
-                self, checker=checker, verbose=verbose, optionflags=optionflags
-            )
+            super().__init__(checker=checker, verbose=verbose, optionflags=optionflags)
             self.continue_on_failure = continue_on_failure

         def report_failure(
-            self, out, test: "doctest.DocTest", example: "doctest.Example", got: str,
+            self,
+            out,
+            test: "doctest.DocTest",
+            example: "doctest.Example",
+            got: str,
         ) -> None:
             failure = doctest.DocTestFailure(test, example, got)
             if self.continue_on_failure:
@@ -204,7 +211,7 @@
             out,
             test: "doctest.DocTest",
             example: "doctest.Example",
-            exc_info: "Tuple[Type[BaseException], BaseException, types.TracebackType]",
+            exc_info: Tuple[Type[BaseException], BaseException, types.TracebackType],
         ) -> None:
             if isinstance(exc_info[1], OutcomeException):
                 raise exc_info[1]
@@ -251,7 +258,7 @@
         self.runner = runner
         self.dtest = dtest
         self.obj = None
-        self.fixture_request = None  # type: Optional[FixtureRequest]
+        self.fixture_request: Optional[FixtureRequest] = None

     @classmethod
     def from_parent(  # type: ignore
@@ -260,9 +267,9 @@
         *,
         name: str,
         runner: "doctest.DocTestRunner",
-        dtest: "doctest.DocTest"
+        dtest: "doctest.DocTest",
     ):
-        # incompatible signature due to to imposed limits on sublcass
+        # incompatible signature due to imposed limits on subclass
         """The public named constructor."""
         return super().from_parent(name=name, parent=parent, runner=runner, dtest=dtest)

@@ -281,7 +288,7 @@
         assert self.runner is not None
         _check_all_skipped(self.dtest)
         self._disable_output_capturing_for_darwin()
-        failures = []  # type: List[doctest.DocTestFailure]
+        failures: List["doctest.DocTestFailure"] = []
         # Type ignored because we change the type of `out` from what
         # doctest expects.
         self.runner.run(self.dtest, out=failures)  # type: ignore[arg-type]
@@ -301,13 +308,14 @@

     # TODO: Type ignored -- breaks Liskov Substitution.
     def repr_failure(  # type: ignore[override]
-        self, excinfo: ExceptionInfo[BaseException],
+        self,
+        excinfo: ExceptionInfo[BaseException],
     ) -> Union[str, TerminalRepr]:
         import doctest

-        failures = (
-            None
-        )  # type: Optional[Sequence[Union[doctest.DocTestFailure, doctest.UnexpectedException]]]
+        failures: Optional[
+            Sequence[Union[doctest.DocTestFailure, doctest.UnexpectedException]]
+        ] = None
         if isinstance(
             excinfo.value, (doctest.DocTestFailure, doctest.UnexpectedException)
         ):
@@ -315,61 +323,57 @@
         elif isinstance(excinfo.value, MultipleDoctestFailures):
             failures = excinfo.value.failures

-        if failures is not None:
-            reprlocation_lines = []
-            for failure in failures:
-                example = failure.example
-                test = failure.test
-                filename = test.filename
-                if test.lineno is None:
-                    lineno = None
-                else:
-                    lineno = test.lineno + example.lineno + 1
-                message = type(failure).__name__
-                # TODO: ReprFileLocation doesn't expect a None lineno.
-                reprlocation = ReprFileLocation(filename, lineno, message)  # type: ignore[arg-type]
-                checker = _get_checker()
-                report_choice = _get_report_choice(
-                    self.config.getoption("doctestreport")
-                )
-                if lineno is not None:
-                    assert failure.test.docstring is not None
-                    lines = failure.test.docstring.splitlines(False)
-                    # add line numbers to the left of the error message
-                    assert test.lineno is not None
-                    lines = [
-                        "%03d %s" % (i + test.lineno + 1, x)
-                        for (i, x) in enumerate(lines)
-                    ]
-                    # trim docstring error lines to 10
-                    lines = lines[max(example.lineno - 9, 0) : example.lineno + 1]
-                else:
-                    lines = [
-                        "EXAMPLE LOCATION UNKNOWN, not showing all tests of that example"
-                    ]
-                    indent = ">>>"
-                    for line in example.source.splitlines():
-                        lines.append("??? {} {}".format(indent, line))
-                        indent = "..."
-                if isinstance(failure, doctest.DocTestFailure):
-                    lines += checker.output_difference(
-                        example, failure.got, report_choice
-                    ).split("\n")
-                else:
-                    inner_excinfo = ExceptionInfo(failure.exc_info)
-                    lines += ["UNEXPECTED EXCEPTION: %s" % repr(inner_excinfo.value)]
-                    lines += [
-                        x.strip("\n")
-                        for x in traceback.format_exception(*failure.exc_info)
-                    ]
-                reprlocation_lines.append((reprlocation, lines))
-            return ReprFailDoctest(reprlocation_lines)
-        else:
+        if failures is None:
             return super().repr_failure(excinfo)

-    def reportinfo(self):
+        reprlocation_lines = []
+        for failure in failures:
+            example = failure.example
+            test = failure.test
+            filename = test.filename
+            if test.lineno is None:
+                lineno = None
+            else:
+                lineno = test.lineno + example.lineno + 1
+            message = type(failure).__name__
+            # TODO: ReprFileLocation doesn't expect a None lineno.
+            reprlocation = ReprFileLocation(filename, lineno, message)  # type: ignore[arg-type]
+            checker = _get_checker()
+            report_choice = _get_report_choice(self.config.getoption("doctestreport"))
+            if lineno is not None:
+                assert failure.test.docstring is not None
+                lines = failure.test.docstring.splitlines(False)
+                # add line numbers to the left of the error message
+                assert test.lineno is not None
+                lines = [
+                    "%03d %s" % (i + test.lineno + 1, x) for (i, x) in enumerate(lines)
+                ]
+                # trim docstring error lines to 10
+                lines = lines[max(example.lineno - 9, 0) : example.lineno + 1]
+            else:
+                lines = [
+                    "EXAMPLE LOCATION UNKNOWN, not showing all tests of that example"
+                ]
+                indent = ">>>"
+                for line in example.source.splitlines():
+                    lines.append(f"??? {indent} {line}")
+                    indent = "..."
+            if isinstance(failure, doctest.DocTestFailure):
+                lines += checker.output_difference(
+                    example, failure.got, report_choice
+                ).split("\n")
+            else:
+                inner_excinfo = ExceptionInfo.from_exc_info(failure.exc_info)
+                lines += ["UNEXPECTED EXCEPTION: %s" % repr(inner_excinfo.value)]
+                lines += [
+                    x.strip("\n") for x in traceback.format_exception(*failure.exc_info)
+                ]
+            reprlocation_lines.append((reprlocation, lines))
+        return ReprFailDoctest(reprlocation_lines)
+
+    def reportinfo(self) -> Tuple[Union["os.PathLike[str]", str], Optional[int], str]:
         assert self.dtest is not None
-        return self.fspath, self.dtest.lineno, "[doctest] %s" % self.name
+        return self.path, self.dtest.lineno, "[doctest] %s" % self.name


 def _get_flag_lookup() -> Dict[str, int]:
@@ -416,9 +420,9 @@
         # Inspired by doctest.testfile; ideally we would use it directly,
         # but it doesn't support passing a custom checker.
         encoding = self.config.getini("doctest_encoding")
-        text = self.fspath.read_text(encoding)
-        filename = str(self.fspath)
-        name = self.fspath.basename
+        text = self.path.read_text(encoding)
+        filename = str(self.path)
+        name = self.path.name
         globs = {"__name__": "__main__"}

         optionflags = get_optionflags(self)
@@ -500,15 +504,22 @@

             def _find_lineno(self, obj, source_lines):
                 """Doctest code does not take into account `@property`, this
-                is a hackish way to fix it.
-
-                https://bugs.python.org/issue17446
+                is a hackish way to fix it. https://bugs.python.org/issue17446
+
+                Wrapped Doctests will need to be unwrapped so the correct
+                line number is returned. This will be reported upstream. #8796
                 """
                 if isinstance(obj, property):
                     obj = getattr(obj, "fget", obj)
+
+                if hasattr(obj, "__wrapped__"):
+                    # Get the main obj in case of it being wrapped
+                    obj = inspect.unwrap(obj)
+
                 # Type ignored because this is a private function.
-                return doctest.DocTestFinder._find_lineno(  # type: ignore
-                    self, obj, source_lines,
+                return super()._find_lineno(  # type:ignore[misc]
+                    obj,
+                    source_lines,
                 )

             def _find(
@@ -519,20 +530,22 @@
                 with _patch_unwrap_mock_aware():

                     # Type ignored because this is a private function.
-                    doctest.DocTestFinder._find(  # type: ignore
-                        self, tests, obj, name, module, source_lines, globs, seen
+                    super()._find(  # type:ignore[misc]
+                        tests, obj, name, module, source_lines, globs, seen
                     )

-        if self.fspath.basename == "conftest.py":
+        if self.path.name == "conftest.py":
             module = self.config.pluginmanager._importconftest(
-                self.fspath, self.config.getoption("importmode")
+                self.path,
+                self.config.getoption("importmode"),
+                rootpath=self.config.rootpath,
             )
         else:
             try:
-                module = import_path(self.fspath)
+                module = import_path(self.path, root=self.config.rootpath)
             except ImportError:
                 if self.config.getvalue("doctest_ignore_import_errors"):
-                    pytest.skip("unable to import module %r" % self.fspath)
+                    pytest.skip("unable to import module %r" % self.path)
                 else:
                     raise
         # Uses internal doctest module parsing mechanism.
@@ -563,12 +576,12 @@
     doctest_item._fixtureinfo = fm.getfixtureinfo(  # type: ignore[attr-defined]
         node=doctest_item, func=func, cls=None, funcargs=False
     )
-    fixture_request = FixtureRequest(doctest_item)
+    fixture_request = FixtureRequest(doctest_item, _ispytest=True)
     fixture_request._fillfixtures()
     return fixture_request


-def _init_checker_class() -> "Type[doctest.OutputChecker]":
+def _init_checker_class() -> Type["doctest.OutputChecker"]:
     import doctest
     import re

@@ -603,7 +616,7 @@
         )

         def check_output(self, want: str, got: str, optionflags: int) -> bool:
-            if doctest.OutputChecker.check_output(self, want, got, optionflags):
+            if super().check_output(want, got, optionflags):
                 return True

             allow_unicode = optionflags & _get_allow_unicode_flag()
@@ -627,7 +640,7 @@
             if allow_number:
                 got = self._remove_unwanted_precision(want, got)

-            return doctest.OutputChecker.check_output(self, want, got, optionflags)
+            return super().check_output(want, got, optionflags)

         def _remove_unwanted_precision(self, want: str, got: str) -> str:
             wants = list(self._number_re.finditer(want))
@@ -636,17 +649,14 @@
                 return got
             offset = 0
             for w, g in zip(wants, gots):
-                fraction = w.group("fraction")  # type: Optional[str]
-                exponent = w.group("exponent1")  # type: Optional[str]
+                fraction: Optional[str] = w.group("fraction")
+                exponent: Optional[str] = w.group("exponent1")
                 if exponent is None:
                     exponent = w.group("exponent2")
-                if fraction is None:
-                    precision = 0
-                else:
-                    precision = len(fraction)
+                precision = 0 if fraction is None else len(fraction)
                 if exponent is not None:
                     precision -= int(exponent)
-                if float(w.group()) == approx(float(g.group()), abs=10 ** -precision):
+                if float(w.group()) == approx(float(g.group()), abs=10**-precision):
                     # They're close enough. Replace the text we actually
                     # got with the text we want, so that it will match when we
                     # check the string literally.
('src/_pytest', 'setuponly.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -9,6 +9,7 @@
 from _pytest.config.argparsing import Parser
 from _pytest.fixtures import FixtureDef
 from _pytest.fixtures import SubRequest
+from _pytest.scope import Scope


 def pytest_addoption(parser: Parser) -> None:
@@ -64,7 +65,9 @@

     tw = config.get_terminal_writer()
     tw.line()
-    tw.write(" " * 2 * fixturedef.scopenum)
+    # Use smaller indentation the higher the scope: Session = 0, Package = 1, etc.
+    scope_indent = list(reversed(Scope)).index(fixturedef._scope)
+    tw.write(" " * 2 * scope_indent)
     tw.write(
         "{step} {scope} {fixture}".format(
             step=msg.ljust(8),  # align the output to TEARDOWN
@@ -79,7 +82,7 @@
             tw.write(" (fixtures used: {})".format(", ".join(deps)))

     if hasattr(fixturedef, "cached_param"):
-        tw.write("[{}]".format(saferepr(fixturedef.cached_param, maxsize=42)))  # type: ignore[attr-defined]
+        tw.write(f"[{saferepr(fixturedef.cached_param, maxsize=42)}]")  # type: ignore[attr-defined]

     tw.flush()

('src/_pytest', 'nose.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,39 +1,42 @@
 """Run testsuites written for nose."""
-from _pytest import python
-from _pytest import unittest
 from _pytest.config import hookimpl
+from _pytest.fixtures import getfixturemarker
 from _pytest.nodes import Item
+from _pytest.python import Function
+from _pytest.unittest import TestCaseFunction


 @hookimpl(trylast=True)
-def pytest_runtest_setup(item):
-    if is_potential_nosetest(item):
-        if not call_optional(item.obj, "setup"):
-            # Call module level setup if there is no object level one.
-            call_optional(item.parent.obj, "setup")
-        # XXX This implies we only call teardown when setup worked.
-        item.session._setupstate.addfinalizer((lambda: teardown_nose(item)), item)
+def pytest_runtest_setup(item: Item) -> None:
+    if not isinstance(item, Function):
+        return
+    # Don't do nose style setup/teardown on direct unittest style classes.
+    if isinstance(item, TestCaseFunction):
+        return
+
+    # Capture the narrowed type of item for the teardown closure,
+    # see https://github.com/python/mypy/issues/2608
+    func = item
+
+    call_optional(func.obj, "setup")
+    func.addfinalizer(lambda: call_optional(func.obj, "teardown"))
+
+    # NOTE: Module- and class-level fixtures are handled in python.py
+    # with `pluginmanager.has_plugin("nose")` checks.
+    # It would have been nicer to implement them outside of core, but
+    # it's not straightforward.


-def teardown_nose(item):
-    if is_potential_nosetest(item):
-        if not call_optional(item.obj, "teardown"):
-            call_optional(item.parent.obj, "teardown")
-
-
-def is_potential_nosetest(item: Item) -> bool:
-    # Extra check needed since we do not do nose style setup/teardown
-    # on direct unittest style classes.
-    return isinstance(item, python.Function) and not isinstance(
-        item, unittest.TestCaseFunction
-    )
-
-
-def call_optional(obj, name):
+def call_optional(obj: object, name: str) -> bool:
     method = getattr(obj, name, None)
-    isfixture = hasattr(method, "_pytestfixturefunction")
-    if method is not None and not isfixture and callable(method):
-        # If there's any problems allow the exception to raise rather than
-        # silently ignoring them.
-        method()
-        return True
+    if method is None:
+        return False
+    is_fixture = getfixturemarker(method) is not None
+    if is_fixture:
+        return False
+    if not callable(method):
+        return False
+    # If there are any problems allow the exception to raise rather than
+    # silently ignoring it.
+    method()
+    return True
('src/_pytest', 'nodes.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,94 +1,125 @@
 import os
 import warnings
-from functools import lru_cache
+from inspect import signature
+from pathlib import Path
 from typing import Any
 from typing import Callable
-from typing import Dict
+from typing import cast
 from typing import Iterable
 from typing import Iterator
 from typing import List
+from typing import MutableMapping
 from typing import Optional
+from typing import overload
 from typing import Set
 from typing import Tuple
+from typing import Type
+from typing import TYPE_CHECKING
 from typing import TypeVar
 from typing import Union
-
-import py

 import _pytest._code
 from _pytest._code import getfslineno
 from _pytest._code.code import ExceptionInfo
 from _pytest._code.code import TerminalRepr
 from _pytest.compat import cached_property
-from _pytest.compat import overload
-from _pytest.compat import TYPE_CHECKING
+from _pytest.compat import LEGACY_PATH
 from _pytest.config import Config
 from _pytest.config import ConftestImportFailure
 from _pytest.deprecated import FSCOLLECTOR_GETHOOKPROXY_ISINITPATH
-from _pytest.fixtures import FixtureDef
-from _pytest.fixtures import FixtureLookupError
+from _pytest.deprecated import NODE_CTOR_FSPATH_ARG
 from _pytest.mark.structures import Mark
 from _pytest.mark.structures import MarkDecorator
 from _pytest.mark.structures import NodeKeywords
 from _pytest.outcomes import fail
 from _pytest.pathlib import absolutepath
-from _pytest.pathlib import Path
-from _pytest.store import Store
+from _pytest.pathlib import commonpath
+from _pytest.stash import Stash
+from _pytest.warning_types import PytestWarning

 if TYPE_CHECKING:
-    from typing import Type
-
     # Imported here due to circular import.
     from _pytest.main import Session
-    from _pytest.warning_types import PytestWarning
     from _pytest._code.code import _TracebackStyle


 SEP = "/"

-tracebackcutdir = py.path.local(_pytest.__file__).dirpath()
-
-
-@lru_cache(maxsize=None)
-def _splitnode(nodeid: str) -> Tuple[str, ...]:
-    """Split a nodeid into constituent 'parts'.
-
-    Node IDs are strings, and can be things like:
-        ''
-        'testing/code'
-        'testing/code/test_excinfo.py'
-        'testing/code/test_excinfo.py::TestFormattedExcinfo'
-
-    Return values are lists e.g.
-        []
-        ['testing', 'code']
-        ['testing', 'code', 'test_excinfo.py']
-        ['testing', 'code', 'test_excinfo.py', 'TestFormattedExcinfo']
+tracebackcutdir = Path(_pytest.__file__).parent
+
+
+def iterparentnodeids(nodeid: str) -> Iterator[str]:
+    """Return the parent node IDs of a given node ID, inclusive.
+
+    For the node ID
+
+        "testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_source"
+
+    the result would be
+
+        ""
+        "testing"
+        "testing/code"
+        "testing/code/test_excinfo.py"
+        "testing/code/test_excinfo.py::TestFormattedExcinfo"
+        "testing/code/test_excinfo.py::TestFormattedExcinfo::test_repr_source"
+
+    Note that / components are only considered until the first ::.
     """
-    if nodeid == "":
-        # If there is no root node at all, return an empty list so the caller's
-        # logic can remain sane.
-        return ()
-    parts = nodeid.split(SEP)
-    # Replace single last element 'test_foo.py::Bar' with multiple elements
-    # 'test_foo.py', 'Bar'.
-    parts[-1:] = parts[-1].split("::")
-    # Convert parts into a tuple to avoid possible errors with caching of a
-    # mutable type.
-    return tuple(parts)
-
-
-def ischildnode(baseid: str, nodeid: str) -> bool:
-    """Return True if the nodeid is a child node of the baseid.
-
-    E.g. 'foo/bar::Baz' is a child of 'foo', 'foo/bar' and 'foo/bar::Baz',
-    but not of 'foo/blorp'.
-    """
-    base_parts = _splitnode(baseid)
-    node_parts = _splitnode(nodeid)
-    if len(node_parts) < len(base_parts):
-        return False
-    return node_parts[: len(base_parts)] == base_parts
+    pos = 0
+    first_colons: Optional[int] = nodeid.find("::")
+    if first_colons == -1:
+        first_colons = None
+    # The root Session node - always present.
+    yield ""
+    # Eagerly consume SEP parts until first colons.
+    while True:
+        at = nodeid.find(SEP, pos, first_colons)
+        if at == -1:
+            break
+        if at > 0:
+            yield nodeid[:at]
+        pos = at + len(SEP)
+    # Eagerly consume :: parts.
+    while True:
+        at = nodeid.find("::", pos)
+        if at == -1:
+            break
+        if at > 0:
+            yield nodeid[:at]
+        pos = at + len("::")
+    # The node ID itself.
+    if nodeid:
+        yield nodeid
+
+
+def _check_path(path: Path, fspath: LEGACY_PATH) -> None:
+    if Path(fspath) != path:
+        raise ValueError(
+            f"Path({fspath!r}) != {path!r}\n"
+            "if both path and fspath are given they need to be equal"
+        )
+
+
+def _imply_path(
+    node_type: Type["Node"],
+    path: Optional[Path],
+    fspath: Optional[LEGACY_PATH],
+) -> Path:
+    if fspath is not None:
+        warnings.warn(
+            NODE_CTOR_FSPATH_ARG.format(
+                node_type_name=node_type.__name__,
+            ),
+            stacklevel=6,
+        )
+    if path is not None:
+        if fspath is not None:
+            _check_path(path, fspath)
+        return path
+    else:
+        assert fspath is not None
+        return Path(fspath)


 _NodeType = TypeVar("_NodeType", bound="Node")
@@ -101,11 +132,27 @@
             "See "
             "https://docs.pytest.org/en/stable/deprecations.html#node-construction-changed-to-node-from-parent"
             " for more details."
-        ).format(name=self.__name__)
+        ).format(name=f"{self.__module__}.{self.__name__}")
         fail(msg, pytrace=False)

     def _create(self, *k, **kw):
-        return super().__call__(*k, **kw)
+        try:
+            return super().__call__(*k, **kw)
+        except TypeError:
+            sig = signature(getattr(self, "__init__"))
+            known_kw = {k: v for k, v in kw.items() if k in sig.parameters}
+            from .warning_types import PytestDeprecationWarning
+
+            warnings.warn(
+                PytestDeprecationWarning(
+                    f"{self} is not using a cooperative constructor and only takes {set(known_kw)}.\n"
+                    "See https://docs.pytest.org/en/stable/deprecations.html"
+                    "#constructors-of-custom-pytest-node-subclasses-should-take-kwargs "
+                    "for more details."
+                )
+            )
+
+            return super().__call__(*k, **known_kw)


 class Node(metaclass=NodeMeta):
@@ -114,6 +161,13 @@

     Collector subclasses have children; Items are leaf nodes.
     """
+
+    # Implemented in the legacypath plugin.
+    #: A ``LEGACY_PATH`` copy of the :attr:`path` attribute. Intended for usage
+    #: for methods not migrated to ``pathlib.Path`` yet, such as
+    #: :meth:`Item.reportinfo`. Will be deprecated in a future release, prefer
+    #: using :attr:`path` instead.
+    fspath: LEGACY_PATH

     # Use __slots__ to make attribute access faster.
     # Note that __dict__ is still available.
@@ -122,7 +176,7 @@
         "parent",
         "config",
         "session",
-        "fspath",
+        "path",
         "_nodeid",
         "_store",
         "__dict__",
@@ -134,7 +188,8 @@
         parent: "Optional[Node]" = None,
         config: Optional[Config] = None,
         session: "Optional[Session]" = None,
-        fspath: Optional[py.path.local] = None,
+        fspath: Optional[LEGACY_PATH] = None,
+        path: Optional[Path] = None,
         nodeid: Optional[str] = None,
     ) -> None:
         #: A unique name within the scope of the parent node.
@@ -143,36 +198,36 @@
         #: The parent collector node.
         self.parent = parent

-        #: The pytest config object.
         if config:
-            self.config = config  # type: Config
+            #: The pytest config object.
+            self.config: Config = config
         else:
             if not parent:
                 raise TypeError("config or parent must be provided")
             self.config = parent.config

-        #: The pytest session this node is part of.
         if session:
+            #: The pytest session this node is part of.
             self.session = session
         else:
             if not parent:
                 raise TypeError("session or parent must be provided")
             self.session = parent.session

+        if path is None and fspath is None:
+            path = getattr(parent, "path", None)
         #: Filesystem path where this node was collected from (can be None).
-        self.fspath = fspath or getattr(parent, "fspath", None)
-
+        self.path: Path = _imply_path(type(self), path, fspath=fspath)
+
+        # The explicit annotation is to avoid publicly exposing NodeKeywords.
         #: Keywords/markers collected from all scopes.
-        self.keywords = NodeKeywords(self)
+        self.keywords: MutableMapping[str, Any] = NodeKeywords(self)

         #: The marker objects belonging to this node.
-        self.own_markers = []  # type: List[Mark]
+        self.own_markers: List[Mark] = []

         #: Allow adding of extra keywords to use for matching.
-        self.extra_keyword_matches = set()  # type: Set[str]
-
-        # Used for storing artificial fixturedefs for direct parametrization.
-        self._name2pseudofixturedef = {}  # type: Dict[str, FixtureDef[Any]]
+        self.extra_keyword_matches: Set[str] = set()

         if nodeid is not None:
             assert "::()" not in nodeid
@@ -180,13 +235,15 @@
         else:
             if not self.parent:
                 raise TypeError("nodeid or parent must be provided")
-            self._nodeid = self.parent.nodeid
-            if self.name != "()":
-                self._nodeid += "::" + self.name
-
-        # A place where plugins can store information on the node for their
-        # own use. Currently only intended for internal plugins.
-        self._store = Store()
+            self._nodeid = self.parent.nodeid + "::" + self.name
+
+        #: A place where plugins can store information on the node for their
+        #: own use.
+        #:
+        #: :type: Stash
+        self.stash = Stash()
+        # Deprecated alias. Was never public. Can be removed in a few releases.
+        self._store = self.stash

     @classmethod
     def from_parent(cls, parent: "Node", **kw):
@@ -209,39 +266,46 @@
     @property
     def ihook(self):
         """fspath-sensitive hook proxy used to call pytest hooks."""
-        return self.session.gethookproxy(self.fspath)
+        return self.session.gethookproxy(self.path)

     def __repr__(self) -> str:
         return "<{} {}>".format(self.__class__.__name__, getattr(self, "name", None))

-    def warn(self, warning: "PytestWarning") -> None:
+    def warn(self, warning: Warning) -> None:
         """Issue a warning for this Node.

         Warnings will be displayed after the test session, unless explicitly suppressed.

         :param Warning warning:
-            The warning instance to issue. Must be a subclass of PytestWarning.
-
-        :raises ValueError: If ``warning`` instance is not a subclass of PytestWarning.
+            The warning instance to issue.
+
+        :raises ValueError: If ``warning`` instance is not a subclass of Warning.

         Example usage:

         .. code-block:: python

             node.warn(PytestWarning("some message"))
-        """
-        from _pytest.warning_types import PytestWarning
-
-        if not isinstance(warning, PytestWarning):
+            node.warn(UserWarning("some message"))
+
+        .. versionchanged:: 6.2
+            Any subclass of :class:`Warning` is now accepted, rather than only
+            :class:`PytestWarning <pytest.PytestWarning>` subclasses.
+        """
+        # enforce type checks here to avoid getting a generic type error later otherwise.
+        if not isinstance(warning, Warning):
             raise ValueError(
-                "warning must be an instance of PytestWarning or subclass, got {!r}".format(
+                "warning must be an instance of Warning or subclass, got {!r}".format(
                     warning
                 )
             )
         path, lineno = get_fslocation_from_item(self)
         assert lineno is not None
         warnings.warn_explicit(
-            warning, category=None, filename=str(path), lineno=lineno + 1,
+            warning,
+            category=None,
+            filename=str(path),
+            lineno=lineno + 1,
         )

     # Methods for ordering nodes.
@@ -264,7 +328,7 @@
         """Return list of all parent collectors up to self, starting from
         the root of collection tree."""
         chain = []
-        item = self  # type: Optional[Node]
+        item: Optional[Node] = self
         while item is not None:
             chain.append(item)
             item = item.parent
@@ -317,11 +381,11 @@
     def get_closest_marker(self, name: str) -> Optional[Mark]:
         ...

-    @overload  # noqa: F811
-    def get_closest_marker(self, name: str, default: Mark) -> Mark:  # noqa: F811
+    @overload
+    def get_closest_marker(self, name: str, default: Mark) -> Mark:
         ...

-    def get_closest_marker(  # noqa: F811
+    def get_closest_marker(
         self, name: str, default: Optional[Mark] = None
     ) -> Optional[Mark]:
         """Return the first marker matching the name, from closest (for
@@ -334,7 +398,7 @@

     def listextrakeywords(self) -> Set[str]:
         """Return a set of all extra keywords in self and any parents."""
-        extra_keywords = set()  # type: Set[str]
+        extra_keywords: Set[str] = set()
         for item in self.listchain():
             extra_keywords.update(item.extra_keyword_matches)
         return extra_keywords
@@ -350,10 +414,10 @@
         """
         self.session._setupstate.addfinalizer(fin, self)

-    def getparent(self, cls: "Type[_NodeType]") -> Optional[_NodeType]:
+    def getparent(self, cls: Type[_NodeType]) -> Optional[_NodeType]:
         """Get the next parent node (including self) which is an instance of
         the given class."""
-        current = self  # type: Optional[Node]
+        current: Optional[Node] = self
         while current and not isinstance(current, cls):
             current = current.parent
         assert current is None or isinstance(current, cls)
@@ -367,8 +431,10 @@
         excinfo: ExceptionInfo[BaseException],
         style: "Optional[_TracebackStyle]" = None,
     ) -> TerminalRepr:
+        from _pytest.fixtures import FixtureLookupError
+
         if isinstance(excinfo.value, ConftestImportFailure):
-            excinfo = ExceptionInfo(excinfo.value.excinfo)
+            excinfo = ExceptionInfo.from_exc_info(excinfo.value.excinfo)
         if isinstance(excinfo.value, fail.Exception):
             if not excinfo.value.pytrace:
                 style = "value"
@@ -422,26 +488,24 @@
     ) -> Union[str, TerminalRepr]:
         """Return a representation of a collection or test failure.

+        .. seealso:: :ref:`non-python tests`
+
         :param excinfo: Exception information for the failure.
         """
         return self._repr_failure_py(excinfo, style)


-def get_fslocation_from_item(
-    node: "Node",
-) -> Tuple[Union[str, py.path.local], Optional[int]]:
+def get_fslocation_from_item(node: "Node") -> Tuple[Union[str, Path], Optional[int]]:
     """Try to extract the actual location from a node, depending on available attributes:

     * "location": a pair (path, lineno)
     * "obj": a Python object that the node wraps.
     * "fspath": just a path

-    :rtype: A tuple of (str|py.path.local, int) with filename and line number.
+    :rtype: A tuple of (str|Path, int) with filename and line number.
     """
     # See Item.location.
-    location = getattr(
-        node, "location", None
-    )  # type: Optional[Tuple[str, Optional[int], str]]
+    location: Optional[Tuple[str, Optional[int], str]] = getattr(node, "location", None)
     if location is not None:
         return location[:2]
     obj = getattr(node, "obj", None)
@@ -485,59 +549,94 @@
         return self._repr_failure_py(excinfo, style=tbstyle)

     def _prunetraceback(self, excinfo: ExceptionInfo[BaseException]) -> None:
-        if hasattr(self, "fspath"):
+        if hasattr(self, "path"):
             traceback = excinfo.traceback
-            ntraceback = traceback.cut(path=self.fspath)
+            ntraceback = traceback.cut(path=self.path)
             if ntraceback == traceback:
                 ntraceback = ntraceback.cut(excludepath=tracebackcutdir)
             excinfo.traceback = ntraceback.filter()


-def _check_initialpaths_for_relpath(session, fspath):
+def _check_initialpaths_for_relpath(session: "Session", path: Path) -> Optional[str]:
     for initial_path in session._initialpaths:
-        if fspath.common(initial_path) == initial_path:
-            return fspath.relto(initial_path)
+        if commonpath(path, initial_path) == initial_path:
+            rel = str(path.relative_to(initial_path))
+            return "" if rel == "." else rel
+    return None


 class FSCollector(Collector):
     def __init__(
         self,
-        fspath: py.path.local,
-        parent=None,
+        fspath: Optional[LEGACY_PATH] = None,
+        path_or_parent: Optional[Union[Path, Node]] = None,
+        path: Optional[Path] = None,
+        name: Optional[str] = None,
+        parent: Optional[Node] = None,
         config: Optional[Config] = None,
         session: Optional["Session"] = None,
         nodeid: Optional[str] = None,
     ) -> None:
-        name = fspath.basename
-        if parent is not None:
-            rel = fspath.relto(parent.fspath)
-            if rel:
-                name = rel
-            name = name.replace(os.sep, SEP)
-        self.fspath = fspath
-
-        session = session or parent.session
+        if path_or_parent:
+            if isinstance(path_or_parent, Node):
+                assert parent is None
+                parent = cast(FSCollector, path_or_parent)
+            elif isinstance(path_or_parent, Path):
+                assert path is None
+                path = path_or_parent
+
+        path = _imply_path(type(self), path, fspath=fspath)
+        if name is None:
+            name = path.name
+            if parent is not None and parent.path != path:
+                try:
+                    rel = path.relative_to(parent.path)
+                except ValueError:
+                    pass
+                else:
+                    name = str(rel)
+                name = name.replace(os.sep, SEP)
+        self.path = path
+
+        if session is None:
+            assert parent is not None
+            session = parent.session

         if nodeid is None:
-            nodeid = self.fspath.relto(session.config.rootdir)
-
-            if not nodeid:
-                nodeid = _check_initialpaths_for_relpath(session, fspath)
+            try:
+                nodeid = str(self.path.relative_to(session.config.rootpath))
+            except ValueError:
+                nodeid = _check_initialpaths_for_relpath(session, path)
+
             if nodeid and os.sep != SEP:
                 nodeid = nodeid.replace(os.sep, SEP)

-        super().__init__(name, parent, config, session, nodeid=nodeid, fspath=fspath)
+        super().__init__(
+            name=name,
+            parent=parent,
+            config=config,
+            session=session,
+            nodeid=nodeid,
+            path=path,
+        )

     @classmethod
-    def from_parent(cls, parent, *, fspath, **kw):
+    def from_parent(
+        cls,
+        parent,
+        *,
+        fspath: Optional[LEGACY_PATH] = None,
+        path: Optional[Path] = None,
+        **kw,
+    ):
         """The public constructor."""
-        return super().from_parent(parent=parent, fspath=fspath, **kw)
-
-    def gethookproxy(self, fspath: py.path.local):
+        return super().from_parent(parent=parent, fspath=fspath, path=path, **kw)
+
+    def gethookproxy(self, fspath: "os.PathLike[str]"):
         warnings.warn(FSCOLLECTOR_GETHOOKPROXY_ISINITPATH, stacklevel=2)
         return self.session.gethookproxy(fspath)

-    def isinitpath(self, path: py.path.local) -> bool:
+    def isinitpath(self, path: Union[str, "os.PathLike[str]"]) -> bool:
         warnings.warn(FSCOLLECTOR_GETHOOKPROXY_ISINITPATH, stacklevel=2)
         return self.session.isinitpath(path)

@@ -564,15 +663,64 @@
         config: Optional[Config] = None,
         session: Optional["Session"] = None,
         nodeid: Optional[str] = None,
+        **kw,
     ) -> None:
-        super().__init__(name, parent, config, session, nodeid=nodeid)
-        self._report_sections = []  # type: List[Tuple[str, str, str]]
+        # The first two arguments are intentionally passed positionally,
+        # to keep plugins who define a node type which inherits from
+        # (pytest.Item, pytest.File) working (see issue #8435).
+        # They can be made kwargs when the deprecation above is done.
+        super().__init__(
+            name,
+            parent,
+            config=config,
+            session=session,
+            nodeid=nodeid,
+            **kw,
+        )
+        self._report_sections: List[Tuple[str, str, str]] = []

         #: A list of tuples (name, value) that holds user defined properties
         #: for this test.
-        self.user_properties = []  # type: List[Tuple[str, object]]
+        self.user_properties: List[Tuple[str, object]] = []
+
+        self._check_item_and_collector_diamond_inheritance()
+
+    def _check_item_and_collector_diamond_inheritance(self) -> None:
+        """
+        Check if the current type inherits from both File and Collector
+        at the same time, emitting a warning accordingly (#8447).
+        """
+        cls = type(self)
+
+        # We inject an attribute in the type to avoid issuing this warning
+        # for the same class more than once, which is not helpful.
+        # It is a hack, but was deemed acceptable in order to avoid
+        # flooding the user in the common case.
+        attr_name = "_pytest_diamond_inheritance_warning_shown"
+        if getattr(cls, attr_name, False):
+            return
+        setattr(cls, attr_name, True)
+
+        problems = ", ".join(
+            base.__name__ for base in cls.__bases__ if issubclass(base, Collector)
+        )
+        if problems:
+            warnings.warn(
+                f"{cls.__name__} is an Item subclass and should not be a collector, "
+                f"however its bases {problems} are collectors.\n"
+                "Please split the Collectors and the Item into separate node types.\n"
+                "Pytest Doc example: https://docs.pytest.org/en/latest/example/nonpython.html\n"
+                "example pull request on a plugin: https://github.com/asmeurer/pytest-flakes/pull/40/",
+                PytestWarning,
+            )

     def runtest(self) -> None:
+        """Run the test case for this item.
+
+        Must be implemented by subclasses.
+
+        .. seealso:: :ref:`non-python tests`
+        """
         raise NotImplementedError("runtest must be implemented by Item subclass")

     def add_report_section(self, when: str, key: str, content: str) -> None:
@@ -592,13 +740,23 @@
         if content:
             self._report_sections.append((when, key, content))

-    def reportinfo(self) -> Tuple[Union[py.path.local, str], Optional[int], str]:
-        return self.fspath, None, ""
+    def reportinfo(self) -> Tuple[Union["os.PathLike[str]", str], Optional[int], str]:
+        """Get location information for this item for test reports.
+
+        Returns a tuple with three elements:
+
+        - The path of the test (default ``self.path``)
+        - The line number of the test (default ``None``)
+        - A name of the test to be shown (default ``""``)
+
+        .. seealso:: :ref:`non-python tests`
+        """
+        return self.path, None, ""

     @cached_property
     def location(self) -> Tuple[str, Optional[int], str]:
         location = self.reportinfo()
-        fspath = absolutepath(str(location[0]))
-        relfspath = self.session._node_location_to_relpath(fspath)
+        path = absolutepath(os.fspath(location[0]))
+        relfspath = self.session._node_location_to_relpath(path)
         assert type(location[2]) is str
         return (relfspath, location[1], location[2])
('src/_pytest', 'main.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -5,25 +5,26 @@
 import importlib
 import os
 import sys
+from pathlib import Path
 from typing import Callable
 from typing import Dict
 from typing import FrozenSet
 from typing import Iterator
 from typing import List
 from typing import Optional
+from typing import overload
 from typing import Sequence
 from typing import Set
 from typing import Tuple
+from typing import Type
+from typing import TYPE_CHECKING
 from typing import Union

 import attr
-import py

 import _pytest._code
 from _pytest import nodes
 from _pytest.compat import final
-from _pytest.compat import overload
-from _pytest.compat import TYPE_CHECKING
 from _pytest.config import Config
 from _pytest.config import directory_arg
 from _pytest.config import ExitCode
@@ -35,7 +36,7 @@
 from _pytest.outcomes import exit
 from _pytest.pathlib import absolutepath
 from _pytest.pathlib import bestrelpath
-from _pytest.pathlib import Path
+from _pytest.pathlib import fnmatch_ex
 from _pytest.pathlib import visit
 from _pytest.reports import CollectReport
 from _pytest.reports import TestReport
@@ -44,7 +45,6 @@


 if TYPE_CHECKING:
-    from typing import Type
     from typing_extensions import Literal


@@ -53,7 +53,17 @@
         "norecursedirs",
         "directory patterns to avoid for recursion",
         type="args",
-        default=[".*", "build", "dist", "CVS", "_darcs", "{arch}", "*.egg", "venv"],
+        default=[
+            "*.egg",
+            ".*",
+            "_darcs",
+            "build",
+            "CVS",
+            "dist",
+            "node_modules",
+            "venv",
+            "{arch}",
+        ],
     )
     parser.addini(
         "testpaths",
@@ -101,9 +111,13 @@
     )
     group._addoption(
         "--strict-markers",
+        action="store_true",
+        help="markers not registered in the `markers` section of the configuration file raise errors.",
+    )
+    group._addoption(
         "--strict",
         action="store_true",
-        help="markers not registered in the `markers` section of the configuration file raise errors.",
+        help="(deprecated) alias to --strict-markers.",
     )
     group._addoption(
         "-c",
@@ -225,10 +239,7 @@
         """Return whether query is an ancestor of base."""
         if base == query:
             return True
-        for parent in base.parents:
-            if parent == query:
-                return True
-        return False
+        return query in base.parents

     # check if path is an ancestor of cwd
     if is_ancestor(Path.cwd(), Path(path).absolute()):
@@ -262,14 +273,12 @@
             session.exitstatus = ExitCode.TESTS_FAILED
         except (KeyboardInterrupt, exit.Exception):
             excinfo = _pytest._code.ExceptionInfo.from_current()
-            exitstatus = ExitCode.INTERRUPTED  # type: Union[int, ExitCode]
+            exitstatus: Union[int, ExitCode] = ExitCode.INTERRUPTED
             if isinstance(excinfo.value, exit.Exception):
                 if excinfo.value.returncode is not None:
                     exitstatus = excinfo.value.returncode
                 if initstate < 2:
-                    sys.stderr.write(
-                        "{}: {}\n".format(excinfo.typename, excinfo.value.msg)
-                    )
+                    sys.stderr.write(f"{excinfo.typename}: {excinfo.value.msg}\n")
             config.hook.pytest_keyboard_interrupt(excinfo=excinfo)
             session.exitstatus = exitstatus
         except BaseException:
@@ -280,7 +289,7 @@
             except exit.Exception as exc:
                 if exc.returncode is not None:
                     session.exitstatus = exc.returncode
-                sys.stderr.write("{}: {}\n".format(type(exc).__name__, exc))
+                sys.stderr.write(f"{type(exc).__name__}: {exc}\n")
             else:
                 if isinstance(excinfo.value, SystemExit):
                     sys.stderr.write("mainloop: caught unexpected SystemExit!\n")
@@ -288,7 +297,7 @@
     finally:
         # Explicitly break reference cycle.
         excinfo = None  # type: ignore
-        session.startdir.chdir()
+        os.chdir(session.startpath)
         if initstate >= 2:
             try:
                 config.hook.pytest_sessionfinish(
@@ -297,7 +306,7 @@
             except exit.Exception as exc:
                 if exc.returncode is not None:
                     session.exitstatus = exc.returncode
-                sys.stderr.write("{}: {}\n".format(type(exc).__name__, exc))
+                sys.stderr.write(f"{type(exc).__name__}: {exc}\n")
         config._ensure_unconfigure()
     return session.exitstatus

@@ -343,11 +352,14 @@
     return True


-def _in_venv(path: py.path.local) -> bool:
+def _in_venv(path: Path) -> bool:
     """Attempt to detect if ``path`` is the root of a Virtual Environment by
     checking for the existence of the appropriate activate script."""
-    bindir = path.join("Scripts" if sys.platform.startswith("win") else "bin")
-    if not bindir.isdir():
+    bindir = path.joinpath("Scripts" if sys.platform.startswith("win") else "bin")
+    try:
+        if not bindir.is_dir():
+            return False
+    except OSError:
         return False
     activates = (
         "activate",
@@ -357,32 +369,34 @@
         "Activate.bat",
         "Activate.ps1",
     )
-    return any([fname.basename in activates for fname in bindir.listdir()])
-
-
-def pytest_ignore_collect(path: py.path.local, config: Config) -> Optional[bool]:
-    ignore_paths = config._getconftest_pathlist("collect_ignore", path=path.dirpath())
+    return any(fname.name in activates for fname in bindir.iterdir())
+
+
+def pytest_ignore_collect(collection_path: Path, config: Config) -> Optional[bool]:
+    ignore_paths = config._getconftest_pathlist(
+        "collect_ignore", path=collection_path.parent, rootpath=config.rootpath
+    )
     ignore_paths = ignore_paths or []
     excludeopt = config.getoption("ignore")
     if excludeopt:
-        ignore_paths.extend([py.path.local(x) for x in excludeopt])
-
-    if py.path.local(path) in ignore_paths:
+        ignore_paths.extend(absolutepath(x) for x in excludeopt)
+
+    if collection_path in ignore_paths:
         return True

     ignore_globs = config._getconftest_pathlist(
-        "collect_ignore_glob", path=path.dirpath()
+        "collect_ignore_glob", path=collection_path.parent, rootpath=config.rootpath
     )
     ignore_globs = ignore_globs or []
     excludeglobopt = config.getoption("ignore_glob")
     if excludeglobopt:
-        ignore_globs.extend([py.path.local(x) for x in excludeglobopt])
-
-    if any(fnmatch.fnmatch(str(path), str(glob)) for glob in ignore_globs):
+        ignore_globs.extend(absolutepath(x) for x in excludeglobopt)
+
+    if any(fnmatch.fnmatch(str(collection_path), str(glob)) for glob in ignore_globs):
         return True

     allow_in_venv = config.getoption("collect_in_virtualenv")
-    if not allow_in_venv and _in_venv(path):
+    if not allow_in_venv and _in_venv(collection_path):
         return True
     return None

@@ -426,9 +440,9 @@
     """Signals a stop as failed test run."""


-@attr.s
+@attr.s(slots=True, auto_attribs=True)
 class _bestrelpath_cache(Dict[Path, str]):
-    path = attr.ib(type=Path)
+    path: Path

     def __missing__(self, path: Path) -> str:
         r = bestrelpath(self.path, path)
@@ -441,32 +455,34 @@
     Interrupted = Interrupted
     Failed = Failed
     # Set on the session by runner.pytest_sessionstart.
-    _setupstate = None  # type: SetupState
+    _setupstate: SetupState
     # Set on the session by fixtures.pytest_sessionstart.
-    _fixturemanager = None  # type: FixtureManager
-    exitstatus = None  # type: Union[int, ExitCode]
+    _fixturemanager: FixtureManager
+    exitstatus: Union[int, ExitCode]

     def __init__(self, config: Config) -> None:
         super().__init__(
-            config.rootdir, parent=None, config=config, session=self, nodeid=""
+            path=config.rootpath,
+            fspath=None,
+            parent=None,
+            config=config,
+            session=self,
+            nodeid="",
         )
         self.testsfailed = 0
         self.testscollected = 0
-        self.shouldstop = False  # type: Union[bool, str]
-        self.shouldfail = False  # type: Union[bool, str]
+        self.shouldstop: Union[bool, str] = False
+        self.shouldfail: Union[bool, str] = False
         self.trace = config.trace.root.get("collection")
-        self.startdir = config.invocation_dir
-        self._initialpaths = frozenset()  # type: FrozenSet[py.path.local]
-
-        self._bestrelpathcache = _bestrelpath_cache(
-            config.rootpath
-        )  # type: Dict[Path, str]
+        self._initialpaths: FrozenSet[Path] = frozenset()
+
+        self._bestrelpathcache: Dict[Path, str] = _bestrelpath_cache(config.rootpath)

         self.config.pluginmanager.register(self, name="session")

     @classmethod
     def from_config(cls, config: Config) -> "Session":
-        session = cls._create(config)  # type: Session
+        session: Session = cls._create(config=config)
         return session

     def __repr__(self) -> str:
@@ -477,6 +493,14 @@
             self.testsfailed,
             self.testscollected,
         )
+
+    @property
+    def startpath(self) -> Path:
+        """The path from which pytest was invoked.
+
+        .. versionadded:: 7.0.0
+        """
+        return self.config.invocation_params.dir

     def _node_location_to_relpath(self, node_path: Path) -> str:
         # bestrelpath is a quite slow function.
@@ -501,20 +525,28 @@

     pytest_collectreport = pytest_runtest_logreport

-    def isinitpath(self, path: py.path.local) -> bool:
-        return path in self._initialpaths
-
-    def gethookproxy(self, fspath: py.path.local):
+    def isinitpath(self, path: Union[str, "os.PathLike[str]"]) -> bool:
+        # Optimization: Path(Path(...)) is much slower than isinstance.
+        path_ = path if isinstance(path, Path) else Path(path)
+        return path_ in self._initialpaths
+
+    def gethookproxy(self, fspath: "os.PathLike[str]"):
+        # Optimization: Path(Path(...)) is much slower than isinstance.
+        path = fspath if isinstance(fspath, Path) else Path(fspath)
+        pm = self.config.pluginmanager
         # Check if we have the common case of running
         # hooks with all conftest.py files.
-        pm = self.config.pluginmanager
         my_conftestmodules = pm._getconftestmodules(
-            fspath, self.config.getoption("importmode")
+            path,
+            self.config.getoption("importmode"),
+            rootpath=self.config.rootpath,
         )
         remove_mods = pm._conftest_plugins.difference(my_conftestmodules)
         if remove_mods:
             # One or more conftests are not in use at this fspath.
-            proxy = FSHookProxy(pm, remove_mods)
+            from .config.compat import PathAwareHookProxy
+
+            proxy = PathAwareHookProxy(FSHookProxy(pm, remove_mods))
         else:
             # All plugins are active for this fspath.
             proxy = self.config.hook
@@ -523,38 +555,38 @@
     def _recurse(self, direntry: "os.DirEntry[str]") -> bool:
         if direntry.name == "__pycache__":
             return False
-        path = py.path.local(direntry.path)
-        ihook = self.gethookproxy(path.dirpath())
-        if ihook.pytest_ignore_collect(path=path, config=self.config):
+        fspath = Path(direntry.path)
+        ihook = self.gethookproxy(fspath.parent)
+        if ihook.pytest_ignore_collect(collection_path=fspath, config=self.config):
             return False
         norecursepatterns = self.config.getini("norecursedirs")
-        if any(path.check(fnmatch=pat) for pat in norecursepatterns):
+        if any(fnmatch_ex(pat, fspath) for pat in norecursepatterns):
             return False
         return True

     def _collectfile(
-        self, path: py.path.local, handle_dupes: bool = True
+        self, fspath: Path, handle_dupes: bool = True
     ) -> Sequence[nodes.Collector]:
         assert (
-            path.isfile()
+            fspath.is_file()
         ), "{!r} is not a file (isdir={!r}, exists={!r}, islink={!r})".format(
-            path, path.isdir(), path.exists(), path.islink()
+            fspath, fspath.is_dir(), fspath.exists(), fspath.is_symlink()
         )
-        ihook = self.gethookproxy(path)
-        if not self.isinitpath(path):
-            if ihook.pytest_ignore_collect(path=path, config=self.config):
+        ihook = self.gethookproxy(fspath)
+        if not self.isinitpath(fspath):
+            if ihook.pytest_ignore_collect(collection_path=fspath, config=self.config):
                 return ()

         if handle_dupes:
             keepduplicates = self.config.getoption("keepduplicates")
             if not keepduplicates:
                 duplicate_paths = self.config.pluginmanager._duplicatepaths
-                if path in duplicate_paths:
+                if fspath in duplicate_paths:
                     return ()
                 else:
-                    duplicate_paths.add(path)
-
-        return ihook.pytest_collect_file(path=path, parent=self)  # type: ignore[no-any-return]
+                    duplicate_paths.add(fspath)
+
+        return ihook.pytest_collect_file(file_path=fspath, parent=self)  # type: ignore[no-any-return]

     @overload
     def perform_collect(
@@ -562,19 +594,18 @@
     ) -> Sequence[nodes.Item]:
         ...

-    @overload  # noqa: F811
-    def perform_collect(  # noqa: F811
+    @overload
+    def perform_collect(
         self, args: Optional[Sequence[str]] = ..., genitems: bool = ...
     ) -> Sequence[Union[nodes.Item, nodes.Collector]]:
         ...

-    def perform_collect(  # noqa: F811
+    def perform_collect(
         self, args: Optional[Sequence[str]] = None, genitems: bool = True
     ) -> Sequence[Union[nodes.Item, nodes.Collector]]:
         """Perform the collection phase for this session.

-        This is called by the default
-        :func:`pytest_collection <_pytest.hookspec.pytest_collection>` hook
+        This is called by the default :hook:`pytest_collection` hook
         implementation; see the documentation of this hook for more details.
         For testing purposes, it may also be called directly on a fresh
         ``Session``.
@@ -591,15 +622,15 @@
         self.trace("perform_collect", self, args)
         self.trace.root.indent += 1

-        self._notfound = []  # type: List[Tuple[str, Sequence[nodes.Collector]]]
-        self._initial_parts = []  # type: List[Tuple[py.path.local, List[str]]]
-        self.items = []  # type: List[nodes.Item]
+        self._notfound: List[Tuple[str, Sequence[nodes.Collector]]] = []
+        self._initial_parts: List[Tuple[Path, List[str]]] = []
+        self.items: List[nodes.Item] = []

         hook = self.config.hook

-        items = self.items  # type: Sequence[Union[nodes.Item, nodes.Collector]]
+        items: Sequence[Union[nodes.Item, nodes.Collector]] = self.items
         try:
-            initialpaths = []  # type: List[py.path.local]
+            initialpaths: List[Path] = []
             for arg in args:
                 fspath, parts = resolve_collection_argument(
                     self.config.invocation_params.dir,
@@ -615,8 +646,8 @@
             if self._notfound:
                 errors = []
                 for arg, cols in self._notfound:
-                    line = "(no name {!r} in any of {!r})".format(arg, cols)
-                    errors.append("not found: {}\n{}".format(arg, line))
+                    line = f"(no name {arg!r} in any of {cols!r})"
+                    errors.append(f"not found: {arg}\n{line}")
                 raise UsageError(*errors)
             if not genitems:
                 items = rep.result
@@ -639,19 +670,15 @@
         from _pytest.python import Package

         # Keep track of any collected nodes in here, so we don't duplicate fixtures.
-        node_cache1 = {}  # type: Dict[py.path.local, Sequence[nodes.Collector]]
-        node_cache2 = (
-            {}
-        )  # type: Dict[Tuple[Type[nodes.Collector], py.path.local], nodes.Collector]
+        node_cache1: Dict[Path, Sequence[nodes.Collector]] = {}
+        node_cache2: Dict[Tuple[Type[nodes.Collector], Path], nodes.Collector] = {}

         # Keep track of any collected collectors in matchnodes paths, so they
         # are not collected more than once.
-        matchnodes_cache = (
-            {}
-        )  # type: Dict[Tuple[Type[nodes.Collector], str], CollectReport]
+        matchnodes_cache: Dict[Tuple[Type[nodes.Collector], str], CollectReport] = {}

         # Dirnames of pkgs with dunder-init files.
-        pkg_roots = {}  # type: Dict[str, Package]
+        pkg_roots: Dict[str, Package] = {}

         for argpath, names in self._initial_parts:
             self.trace("processing argument", (argpath, names))
@@ -662,36 +689,36 @@
             # No point in finding packages when collecting doctests.
             if not self.config.getoption("doctestmodules", False):
                 pm = self.config.pluginmanager
-                for parent in reversed(argpath.parts()):
-                    if pm._confcutdir and pm._confcutdir.relto(parent):
+                for parent in (argpath, *argpath.parents):
+                    if not pm._is_in_confcutdir(argpath):
                         break

-                    if parent.isdir():
-                        pkginit = parent.join("__init__.py")
-                        if pkginit.isfile() and pkginit not in node_cache1:
+                    if parent.is_dir():
+                        pkginit = parent / "__init__.py"
+                        if pkginit.is_file() and pkginit not in node_cache1:
                             col = self._collectfile(pkginit, handle_dupes=False)
                             if col:
                                 if isinstance(col[0], Package):
                                     pkg_roots[str(parent)] = col[0]
-                                node_cache1[col[0].fspath] = [col[0]]
+                                node_cache1[col[0].path] = [col[0]]

             # If it's a directory argument, recurse and look for any Subpackages.
             # Let the Package collector deal with subnodes, don't collect here.
-            if argpath.check(dir=1):
-                assert not names, "invalid arg {!r}".format((argpath, names))
-
-                seen_dirs = set()  # type: Set[py.path.local]
+            if argpath.is_dir():
+                assert not names, f"invalid arg {(argpath, names)!r}"
+
+                seen_dirs: Set[Path] = set()
                 for direntry in visit(str(argpath), self._recurse):
                     if not direntry.is_file():
                         continue

-                    path = py.path.local(direntry.path)
-                    dirpath = path.dirpath()
+                    path = Path(direntry.path)
+                    dirpath = path.parent

                     if dirpath not in seen_dirs:
                         # Collect packages first.
                         seen_dirs.add(dirpath)
-                        pkginit = dirpath.join("__init__.py")
+                        pkginit = dirpath / "__init__.py"
                         if pkginit.exists():
                             for x in self._collectfile(pkginit):
                                 yield x
@@ -702,27 +729,27 @@
                         continue

                     for x in self._collectfile(path):
-                        key = (type(x), x.fspath)
-                        if key in node_cache2:
-                            yield node_cache2[key]
+                        key2 = (type(x), x.path)
+                        if key2 in node_cache2:
+                            yield node_cache2[key2]
                         else:
-                            node_cache2[key] = x
+                            node_cache2[key2] = x
                             yield x
             else:
-                assert argpath.check(file=1)
+                assert argpath.is_file()

                 if argpath in node_cache1:
                     col = node_cache1[argpath]
                 else:
-                    collect_root = pkg_roots.get(argpath.dirname, self)
+                    collect_root = pkg_roots.get(str(argpath.parent), self)
                     col = collect_root._collectfile(argpath, handle_dupes=False)
                     if col:
                         node_cache1[argpath] = col

                 matching = []
-                work = [
-                    (col, names)
-                ]  # type: List[Tuple[Sequence[Union[nodes.Item, nodes.Collector]], Sequence[str]]]
+                work: List[
+                    Tuple[Sequence[Union[nodes.Item, nodes.Collector]], Sequence[str]]
+                ] = [(col, names)]
                 while work:
                     self.trace("matchnodes", col, names)
                     self.trace.root.indent += 1
@@ -752,9 +779,6 @@
                                     submatchnodes.append(r)
                             if submatchnodes:
                                 work.append((submatchnodes, matchnames[1:]))
-                            # XXX Accept IDs that don't have "()" for class instances.
-                            elif len(rep.result) == 1 and rep.result[0].name == "()":
-                                work.append((rep.result, matchnames))
                         else:
                             # Report collection failures here to avoid failing to run some test
                             # specified in the command line because the module could not be
@@ -769,12 +793,12 @@
                     self._notfound.append((report_arg, col))
                     continue

-                # If __init__.py was the only file requested, then the matched node will be
-                # the corresponding Package, and the first yielded item will be the __init__
-                # Module itself, so just use that. If this special case isn't taken, then all
-                # the files in the package will be yielded.
-                if argpath.basename == "__init__.py":
-                    assert isinstance(matching[0], nodes.Collector)
+                # If __init__.py was the only file requested, then the matched
+                # node will be the corresponding Package (by default), and the
+                # first yielded item will be the __init__ Module itself, so
+                # just use that. If this special case isn't taken, then all the
+                # files in the package will be yielded.
+                if argpath.name == "__init__.py" and isinstance(matching[0], Package):
                     try:
                         yield next(iter(matching[0].collect()))
                     except StopIteration:
@@ -823,7 +847,7 @@

 def resolve_collection_argument(
     invocation_path: Path, arg: str, *, as_pypath: bool = False
-) -> Tuple[py.path.local, List[str]]:
+) -> Tuple[Path, List[str]]:
     """Parse path arguments optionally containing selection parts and return (fspath, names).

     Command-line arguments can point to files and/or directories, and optionally contain
@@ -833,7 +857,7 @@

     This function ensures the path exists, and returns a tuple:

-        (py.path.path("/full/path/to/pkg/tests/test_foo.py"), ["TestClass", "test_foo"])
+        (Path("/full/path/to/pkg/tests/test_foo.py"), ["TestClass", "test_foo"])

     When as_pypath is True, expects that the command-line argument actually contains
     module paths instead of file-system paths:
@@ -846,7 +870,10 @@
     If the path doesn't exist, raise UsageError.
     If the path is a directory and selection parts are present, raise UsageError.
     """
-    strpath, *parts = str(arg).split("::")
+    base, squacket, rest = str(arg).partition("[")
+    strpath, *parts = base.split("::")
+    if parts:
+        parts[-1] = f"{parts[-1]}{squacket}{rest}"
     if as_pypath:
         strpath = search_pypath(strpath)
     fspath = invocation_path / strpath
@@ -865,4 +892,4 @@
             else "directory argument cannot contain :: selection parts: {arg}"
         )
         raise UsageError(msg.format(arg=arg))
-    return py.path.local(str(fspath)), parts
+    return fspath, parts
('src/_pytest', 'monkeypatch.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -9,15 +9,14 @@
 from typing import List
 from typing import MutableMapping
 from typing import Optional
+from typing import overload
 from typing import Tuple
 from typing import TypeVar
 from typing import Union

-import pytest
 from _pytest.compat import final
-from _pytest.compat import overload
 from _pytest.fixtures import fixture
-from _pytest.pathlib import Path
+from _pytest.warning_types import PytestWarning

 RE_IMPORT_ERROR_NAME = re.compile(r"^No module named (.*)$")

@@ -37,7 +36,7 @@
         monkeypatch.delattr(obj, name, raising=True)
         monkeypatch.setitem(mapping, name, value)
         monkeypatch.delitem(obj, name, raising=True)
-        monkeypatch.setenv(name, value, prepend=False)
+        monkeypatch.setenv(name, value, prepend=None)
         monkeypatch.delenv(name, raising=True)
         monkeypatch.syspath_prepend(path)
         monkeypatch.chdir(path)
@@ -56,7 +55,7 @@
     parts = name.split(".")

     used = parts.pop(0)
-    found = __import__(used)
+    found: object = __import__(used)
     for part in parts:
         used += "." + part
         try:
@@ -74,7 +73,7 @@
             if expected == used:
                 raise
             else:
-                raise ImportError("import error in {}: {}".format(used, ex)) from ex
+                raise ImportError(f"import error in {used}: {ex}") from ex
         found = annotated_getattr(found, part, used)
     return found

@@ -92,10 +91,8 @@


 def derive_importpath(import_path: str, raising: bool) -> Tuple[str, object]:
-    if not isinstance(import_path, str) or "." not in import_path:  # type: ignore[unreachable]
-        raise TypeError(
-            "must be absolute import path string, not {!r}".format(import_path)
-        )
+    if not isinstance(import_path, str) or "." not in import_path:
+        raise TypeError(f"must be absolute import path string, not {import_path!r}")
     module, attr = import_path.rsplit(".", 1)
     target = resolve(module)
     if raising:
@@ -113,19 +110,27 @@

 @final
 class MonkeyPatch:
-    """Object returned by the ``monkeypatch`` fixture keeping a record of
-    setattr/item/env/syspath changes."""
+    """Helper to conveniently monkeypatch attributes/items/environment
+    variables/syspath.
+
+    Returned by the :fixture:`monkeypatch` fixture.
+
+    :versionchanged:: 6.2
+        Can now also be used directly as `pytest.MonkeyPatch()`, for when
+        the fixture is not available. In this case, use
+        :meth:`with MonkeyPatch.context() as mp: <context>` or remember to call
+        :meth:`undo` explicitly.
+    """

     def __init__(self) -> None:
-        self._setattr = []  # type: List[Tuple[object, str, object]]
-        self._setitem = (
-            []
-        )  # type: List[Tuple[MutableMapping[Any, Any], object, object]]
-        self._cwd = None  # type: Optional[str]
-        self._savesyspath = None  # type: Optional[List[str]]
-
+        self._setattr: List[Tuple[object, str, object]] = []
+        self._setitem: List[Tuple[MutableMapping[Any, Any], object, object]] = []
+        self._cwd: Optional[str] = None
+        self._savesyspath: Optional[List[str]] = None
+
+    @classmethod
     @contextmanager
-    def context(self) -> Generator["MonkeyPatch", None, None]:
+    def context(cls) -> Generator["MonkeyPatch", None, None]:
         """Context manager that returns a new :class:`MonkeyPatch` object
         which undoes any patching done inside the ``with`` block upon exit.

@@ -142,9 +147,9 @@

         Useful in situations where it is desired to undo some patches before the test ends,
         such as mocking ``stdlib`` functions that might break pytest itself if mocked (for examples
-        of this see `#3290 <https://github.com/pytest-dev/pytest/issues/3290>`_.
-        """
-        m = MonkeyPatch()
+        of this see :issue:`3290`).
+        """
+        m = cls()
         try:
             yield m
         finally:
@@ -152,17 +157,25 @@

     @overload
     def setattr(
-        self, target: str, name: object, value: Notset = ..., raising: bool = ...,
+        self,
+        target: str,
+        name: object,
+        value: Notset = ...,
+        raising: bool = ...,
     ) -> None:
         ...

-    @overload  # noqa: F811
-    def setattr(  # noqa: F811
-        self, target: object, name: str, value: object, raising: bool = ...,
+    @overload
+    def setattr(
+        self,
+        target: object,
+        name: str,
+        value: object,
+        raising: bool = ...,
     ) -> None:
         ...

-    def setattr(  # noqa: F811
+    def setattr(
         self,
         target: Union[str, object],
         name: Union[object, str],
@@ -202,7 +215,7 @@

         oldval = getattr(target, name, notset)
         if raising and oldval is notset:
-            raise AttributeError("{!r} has no attribute {!r}".format(target, name))
+            raise AttributeError(f"{target!r} has no attribute {name!r}")

         # avoid class descriptors like staticmethod/classmethod
         if inspect.isclass(target):
@@ -275,7 +288,7 @@
         """
         if not isinstance(value, str):
             warnings.warn(  # type: ignore[unreachable]
-                pytest.PytestWarning(
+                PytestWarning(
                     "Value of environment variable {name} type should be str, but got "
                     "{value!r} (type: {type}); converted to str implicitly".format(
                         name=name, value=value, type=type(value).__name__
@@ -294,19 +307,22 @@
         Raises ``KeyError`` if it does not exist, unless ``raising`` is set to
         False.
         """
-        environ = os.environ  # type: MutableMapping[str, str]
+        environ: MutableMapping[str, str] = os.environ
         self.delitem(environ, name, raising=raising)

     def syspath_prepend(self, path) -> None:
         """Prepend ``path`` to ``sys.path`` list of import locations."""
-        from pkg_resources import fixup_namespace_packages

         if self._savesyspath is None:
             self._savesyspath = sys.path[:]
         sys.path.insert(0, str(path))

         # https://github.com/pypa/setuptools/blob/d8b901bc/docs/pkg_resources.txt#L162-L171
-        fixup_namespace_packages(str(path))
+        # this is only needed when pkg_resources was already loaded by the namespace package
+        if "pkg_resources" in sys.modules:
+            from pkg_resources import fixup_namespace_packages
+
+            fixup_namespace_packages(str(path))

         # A call to syspathinsert() usually means that the caller wants to
         # import some dynamically created files, thus with python3 we
@@ -319,20 +335,14 @@

         invalidate_caches()

-    def chdir(self, path) -> None:
+    def chdir(self, path: Union[str, "os.PathLike[str]"]) -> None:
         """Change the current working directory to the specified path.

-        Path can be a string or a py.path.local object.
+        Path can be a string or a path object.
         """
         if self._cwd is None:
             self._cwd = os.getcwd()
-        if hasattr(path, "chdir"):
-            path.chdir()
-        elif isinstance(path, Path):
-            # Modern python uses the fspath protocol here LEGACY
-            os.chdir(str(path))
-        else:
-            os.chdir(path)
+        os.chdir(path)

     def undo(self) -> None:
         """Undo previous changes.
('src/_pytest', 'pathlib.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -9,14 +9,21 @@
 import uuid
 import warnings
 from enum import Enum
+from errno import EBADF
+from errno import ELOOP
+from errno import ENOENT
+from errno import ENOTDIR
 from functools import partial
 from os.path import expanduser
 from os.path import expandvars
 from os.path import isabs
 from os.path import sep
+from pathlib import Path
+from pathlib import PurePath
 from posixpath import sep as posix_sep
 from types import ModuleType
 from typing import Callable
+from typing import Dict
 from typing import Iterable
 from typing import Iterator
 from typing import Optional
@@ -24,35 +31,36 @@
 from typing import TypeVar
 from typing import Union

-import py
-
 from _pytest.compat import assert_never
 from _pytest.outcomes import skip
 from _pytest.warning_types import PytestWarning

-if sys.version_info[:2] >= (3, 6):
-    from pathlib import Path, PurePath
-else:
-    from pathlib2 import Path, PurePath
-
-__all__ = ["Path", "PurePath"]
-
-
 LOCK_TIMEOUT = 60 * 60 * 24 * 3


 _AnyPurePath = TypeVar("_AnyPurePath", bound=PurePath)
+
+# The following function, variables and comments were
+# copied from cpython 3.9 Lib/pathlib.py file.
+
+# EBADF - guard against macOS `stat` throwing EBADF
+_IGNORED_ERRORS = (ENOENT, ENOTDIR, EBADF, ELOOP)
+
+_IGNORED_WINERRORS = (
+    21,  # ERROR_NOT_READY - drive exists but is not accessible
+    1921,  # ERROR_CANT_RESOLVE_FILENAME - fix for broken symlink pointing to itself
+)
+
+
+def _ignore_error(exception):
+    return (
+        getattr(exception, "errno", None) in _IGNORED_ERRORS
+        or getattr(exception, "winerror", None) in _IGNORED_WINERRORS
+    )


 def get_lock_path(path: _AnyPurePath) -> _AnyPurePath:
     return path.joinpath(".lock")
-
-
-def ensure_reset_dir(path: Path) -> None:
-    """Ensure the given path is an empty directory."""
-    if path.exists():
-        rm_rf(path)
-    path.mkdir()


 def on_rm_rf_error(func, path: str, exc, *, start_path: Path) -> bool:
@@ -69,9 +77,7 @@

     if not isinstance(excvalue, PermissionError):
         warnings.warn(
-            PytestWarning(
-                "(rm_rf) error removing {}\n{}: {}".format(path, exctype, excvalue)
-            )
+            PytestWarning(f"(rm_rf) error removing {path}\n{exctype}: {excvalue}")
         )
         return False

@@ -200,15 +206,15 @@
         pass


-def make_numbered_dir(root: Path, prefix: str) -> Path:
+def make_numbered_dir(root: Path, prefix: str, mode: int = 0o700) -> Path:
     """Create a directory with an increased number as suffix for the given prefix."""
     for i in range(10):
         # try up to 10 times to create the folder
         max_existing = max(map(parse_num, find_suffixes(root, prefix)), default=-1)
         new_number = max_existing + 1
-        new_path = root.joinpath("{}{}".format(prefix, new_number))
+        new_path = root.joinpath(f"{prefix}{new_number}")
         try:
-            new_path.mkdir()
+            new_path.mkdir(mode=mode)
         except Exception:
             pass
         else:
@@ -227,7 +233,7 @@
     try:
         fd = os.open(str(lock_path), os.O_WRONLY | os.O_CREAT | os.O_EXCL, 0o644)
     except FileExistsError as e:
-        raise OSError("cannot create lockfile in {path}".format(path=p)) from e
+        raise OSError(f"cannot create lockfile in {p}") from e
     else:
         pid = os.getpid()
         spid = str(pid).encode()
@@ -264,7 +270,7 @@
         lock_path = create_cleanup_lock(path)
         parent = path.parent

-        garbage = parent.joinpath("garbage-{}".format(uuid.uuid4()))
+        garbage = parent.joinpath(f"garbage-{uuid.uuid4()}")
         path.rename(garbage)
         rm_rf(garbage)
     except OSError:
@@ -340,13 +346,17 @@


 def make_numbered_dir_with_cleanup(
-    root: Path, prefix: str, keep: int, lock_timeout: float
+    root: Path,
+    prefix: str,
+    keep: int,
+    lock_timeout: float,
+    mode: int,
 ) -> Path:
     """Create a numbered dir with a cleanup lock and remove old ones."""
     e = None
     for i in range(10):
         try:
-            p = make_numbered_dir(root, prefix)
+            p = make_numbered_dir(root, prefix, mode)
             lock_path = create_cleanup_lock(p)
             register_cleanup_lock_removal(lock_path)
         except Exception as exc:
@@ -375,7 +385,7 @@
         return rootpath.joinpath(input)


-def fnmatch_ex(pattern: str, path) -> bool:
+def fnmatch_ex(pattern: str, path: Union[str, "os.PathLike[str]"]) -> bool:
     """A port of FNMatcher from py.path.common which works with PurePath() instances.

     The difference between this algorithm and PurePath.match() is that the
@@ -407,7 +417,7 @@
     else:
         name = str(path)
         if path.is_absolute() and not os.path.isabs(pattern):
-            pattern = "*{}{}".format(os.sep, pattern)
+            pattern = f"*{os.sep}{pattern}"
     return fnmatch.fnmatch(name, pattern)


@@ -421,7 +431,7 @@
     try:
         os.symlink(str(src), str(dst), **kwargs)
     except OSError as e:
-        skip("symlinks not supported: {}".format(e))
+        skip(f"symlinks not supported: {e}")


 class ImportMode(Enum):
@@ -442,9 +452,10 @@


 def import_path(
-    p: Union[str, py.path.local, Path],
+    p: Union[str, "os.PathLike[str]"],
     *,
-    mode: Union[str, ImportMode] = ImportMode.prepend
+    mode: Union[str, ImportMode] = ImportMode.prepend,
+    root: Path,
 ) -> ModuleType:
     """Import and return a module from the given path, which can be a file (a module) or
     a directory (a package).
@@ -462,19 +473,24 @@
       to import the module, which avoids having to use `__import__` and muck with `sys.path`
       at all. It effectively allows having same-named test modules in different places.

+    :param root:
+        Used as an anchor when mode == ImportMode.importlib to obtain
+        a unique name for the module being imported so it can safely be stored
+        into ``sys.modules``.
+
     :raises ImportPathMismatchError:
         If after importing the given `path` and the module `__file__`
         are different. Only raised in `prepend` and `append` modes.
     """
     mode = ImportMode(mode)

-    path = Path(str(p))
+    path = Path(p)

     if not path.exists():
         raise ImportError(path)

     if mode is ImportMode.importlib:
-        module_name = path.stem
+        module_name = module_name_from_path(path, root)

         for meta_importer in sys.meta_path:
             spec = meta_importer.find_spec(module_name, [str(path.parent)])
@@ -484,11 +500,11 @@
             spec = importlib.util.spec_from_file_location(module_name, str(path))

         if spec is None:
-            raise ImportError(
-                "Can't find module {} at location {}".format(module_name, str(path))
-            )
+            raise ImportError(f"Can't find module {module_name} at location {path}")
         mod = importlib.util.module_from_spec(spec)
+        sys.modules[module_name] = mod
         spec.loader.exec_module(mod)  # type: ignore[union-attr]
+        insert_missing_modules(sys.modules, module_name)
         return mod

     pkg_path = resolve_package_path(path)
@@ -523,13 +539,16 @@
     ignore = os.environ.get("PY_IGNORE_IMPORTMISMATCH", "")
     if ignore != "1":
         module_file = mod.__file__
+        if module_file is None:
+            raise ImportPathMismatchError(module_name, module_file, path)
+
         if module_file.endswith((".pyc", ".pyo")):
             module_file = module_file[:-1]
         if module_file.endswith(os.path.sep + "__init__.py"):
             module_file = module_file[: -(len(os.path.sep + "__init__.py"))]

         try:
-            is_same = os.path.samefile(str(path), module_file)
+            is_same = _is_same(str(path), module_file)
         except FileNotFoundError:
             is_same = False

@@ -537,6 +556,69 @@
             raise ImportPathMismatchError(module_name, module_file, path)

     return mod
+
+
+# Implement a special _is_same function on Windows which returns True if the two filenames
+# compare equal, to circumvent os.path.samefile returning False for mounts in UNC (#7678).
+if sys.platform.startswith("win"):
+
+    def _is_same(f1: str, f2: str) -> bool:
+        return Path(f1) == Path(f2) or os.path.samefile(f1, f2)
+
+else:
+
+    def _is_same(f1: str, f2: str) -> bool:
+        return os.path.samefile(f1, f2)
+
+
+def module_name_from_path(path: Path, root: Path) -> str:
+    """
+    Return a dotted module name based on the given path, anchored on root.
+
+    For example: path="projects/src/tests/test_foo.py" and root="/projects", the
+    resulting module name will be "src.tests.test_foo".
+    """
+    path = path.with_suffix("")
+    try:
+        relative_path = path.relative_to(root)
+    except ValueError:
+        # If we can't get a relative path to root, use the full path, except
+        # for the first part ("d:\\" or "/" depending on the platform, for example).
+        path_parts = path.parts[1:]
+    else:
+        # Use the parts for the relative path to the root path.
+        path_parts = relative_path.parts
+
+    return ".".join(path_parts)
+
+
+def insert_missing_modules(modules: Dict[str, ModuleType], module_name: str) -> None:
+    """
+    Used by ``import_path`` to create intermediate modules when using mode=importlib.
+
+    When we want to import a module as "src.tests.test_foo" for example, we need
+    to create empty modules "src" and "src.tests" after inserting "src.tests.test_foo",
+    otherwise "src.tests.test_foo" is not importable by ``__import__``.
+    """
+    module_parts = module_name.split(".")
+    while module_name:
+        if module_name not in modules:
+            try:
+                # If sys.meta_path is empty, calling import_module will issue
+                # a warning and raise ModuleNotFoundError. To avoid the
+                # warning, we check sys.meta_path explicitly and raise the error
+                # ourselves to fall back to creating a dummy module.
+                if not sys.meta_path:
+                    raise ModuleNotFoundError
+                importlib.import_module(module_name)
+            except ModuleNotFoundError:
+                module = ModuleType(
+                    module_name,
+                    doc="Empty module created by pytest's importmode=importlib.",
+                )
+                modules[module_name] = module
+        module_parts.pop(-1)
+        module_name = ".".join(module_parts)


 def resolve_package_path(path: Path) -> Optional[Path]:
@@ -557,16 +639,31 @@


 def visit(
-    path: str, recurse: Callable[["os.DirEntry[str]"], bool]
+    path: Union[str, "os.PathLike[str]"], recurse: Callable[["os.DirEntry[str]"], bool]
 ) -> Iterator["os.DirEntry[str]"]:
     """Walk a directory recursively, in breadth-first order.

     Entries at each directory level are sorted.
     """
-    entries = sorted(os.scandir(path), key=lambda entry: entry.name)
+
+    # Skip entries with symlink loops and other brokenness, so the caller doesn't
+    # have to deal with it.
+    entries = []
+    for entry in os.scandir(path):
+        try:
+            entry.is_file()
+        except OSError as err:
+            if _ignore_error(err):
+                continue
+            raise
+        entries.append(entry)
+
+    entries.sort(key=lambda entry: entry.name)
+
     yield from entries
+
     for entry in entries:
-        if entry.is_dir(follow_symlinks=False) and recurse(entry):
+        if entry.is_dir() and recurse(entry):
             yield from visit(entry.path, recurse)


@@ -581,7 +678,10 @@

 def commonpath(path1: Path, path2: Path) -> Optional[Path]:
     """Return the common part shared with the other path, or None if there is
-    no common part."""
+    no common part.
+
+    If one path is relative and one is absolute, returns None.
+    """
     try:
         return Path(os.path.commonpath((str(path1), str(path2))))
     except ValueError:
@@ -592,13 +692,19 @@
     """Return a string which is a relative path from directory to dest such
     that directory/bestrelpath == dest.

+    The paths must be either both absolute or both relative.
+
     If no such path can be determined, returns dest.
     """
+    assert isinstance(directory, Path)
+    assert isinstance(dest, Path)
     if dest == directory:
         return os.curdir
     # Find the longest common directory.
     base = commonpath(directory, dest)
-    # Can be the case on Windows.
+    # Can be the case on Windows for two absolute paths on different drives.
+    # Can be the case for two relative paths without common prefix.
+    # Can be the case for a relative path and an absolute path.
     if not base:
         return str(dest)
     reldirectory = directory.relative_to(base)
@@ -609,3 +715,21 @@
         # Forward from base to dest.
         *reldest.parts,
     )
+
+
+# Originates from py. path.local.copy(), with siginficant trims and adjustments.
+# TODO(py38): Replace with shutil.copytree(..., symlinks=True, dirs_exist_ok=True)
+def copytree(source: Path, target: Path) -> None:
+    """Recursively copy a source directory to target."""
+    assert source.is_dir()
+    for entry in visit(source, recurse=lambda entry: not entry.is_symlink()):
+        x = Path(entry)
+        relpath = x.relative_to(source)
+        newx = target / relpath
+        newx.parent.mkdir(exist_ok=True)
+        if x.is_symlink():
+            newx.symlink_to(os.readlink(x))
+        elif x.is_file():
+            shutil.copyfile(x, newx)
+        elif x.is_dir():
+            newx.mkdir(exist_ok=True)
('src/_pytest', 'freeze_support.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -9,16 +9,15 @@
 def freeze_includes() -> List[str]:
     """Return a list of module names used by pytest that should be
     included by cx_freeze."""
-    import py
     import _pytest

-    result = list(_iter_all_modules(py))
-    result += list(_iter_all_modules(_pytest))
+    result = list(_iter_all_modules(_pytest))
     return result


 def _iter_all_modules(
-    package: Union[str, types.ModuleType], prefix: str = "",
+    package: Union[str, types.ModuleType],
+    prefix: str = "",
 ) -> Iterator[str]:
     """Iterate over the names of all modules that can be found in the given
     package, recursively.
('src/_pytest', 'fixtures.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -5,6 +5,8 @@
 import warnings
 from collections import defaultdict
 from collections import deque
+from contextlib import suppress
+from pathlib import Path
 from types import TracebackType
 from typing import Any
 from typing import Callable
@@ -15,23 +17,28 @@
 from typing import Iterable
 from typing import Iterator
 from typing import List
+from typing import MutableMapping
 from typing import Optional
+from typing import overload
 from typing import Sequence
 from typing import Set
 from typing import Tuple
+from typing import Type
+from typing import TYPE_CHECKING
 from typing import TypeVar
 from typing import Union

 import attr
-import py

 import _pytest
+from _pytest import nodes
 from _pytest._code import getfslineno
 from _pytest._code.code import FormattedExcinfo
 from _pytest._code.code import TerminalRepr
 from _pytest._io import TerminalWriter
 from _pytest.compat import _format_args
 from _pytest.compat import _PytestWrapper
+from _pytest.compat import assert_never
 from _pytest.compat import final
 from _pytest.compat import get_real_func
 from _pytest.compat import get_real_method
@@ -40,48 +47,47 @@
 from _pytest.compat import getlocation
 from _pytest.compat import is_generator
 from _pytest.compat import NOTSET
-from _pytest.compat import order_preserving_dict
-from _pytest.compat import overload
 from _pytest.compat import safe_getattr
-from _pytest.compat import TYPE_CHECKING
 from _pytest.config import _PluggyPlugin
 from _pytest.config import Config
 from _pytest.config.argparsing import Parser
-from _pytest.deprecated import FILLFUNCARGS
+from _pytest.deprecated import check_ispytest
+from _pytest.deprecated import YIELD_FIXTURE
 from _pytest.mark import Mark
 from _pytest.mark import ParameterSet
+from _pytest.mark.structures import MarkDecorator
 from _pytest.outcomes import fail
 from _pytest.outcomes import TEST_OUTCOME
 from _pytest.pathlib import absolutepath
+from _pytest.pathlib import bestrelpath
+from _pytest.scope import HIGH_SCOPES
+from _pytest.scope import Scope
+from _pytest.stash import StashKey
+

 if TYPE_CHECKING:
     from typing import Deque
     from typing import NoReturn
-    from typing import Type
-    from typing_extensions import Literal
-
-    from _pytest import nodes
+
+    from _pytest.scope import _ScopeName
     from _pytest.main import Session
     from _pytest.python import CallSpec2
-    from _pytest.python import Function
     from _pytest.python import Metafunc

-    _Scope = Literal["session", "package", "module", "class", "function"]
-

 # The value of the fixture -- return/yield of the fixture function (type variable).
-_FixtureValue = TypeVar("_FixtureValue")
+FixtureValue = TypeVar("FixtureValue")
 # The type of the fixture function (type variable).
-_FixtureFunction = TypeVar("_FixtureFunction", bound=Callable[..., object])
+FixtureFunction = TypeVar("FixtureFunction", bound=Callable[..., object])
 # The type of a fixture function (type alias generic in fixture value).
 _FixtureFunc = Union[
-    Callable[..., _FixtureValue], Callable[..., Generator[_FixtureValue, None, None]]
+    Callable[..., FixtureValue], Callable[..., Generator[FixtureValue, None, None]]
 ]
 # The type of FixtureDef.cached_result (type alias generic in fixture value).
 _FixtureCachedResult = Union[
     Tuple[
         # The result.
-        _FixtureValue,
+        FixtureValue,
         # Cache key.
         object,
         None,
@@ -91,34 +97,19 @@
         # Cache key.
         object,
         # Exc info if raised.
-        Tuple["Type[BaseException]", BaseException, TracebackType],
+        Tuple[Type[BaseException], BaseException, TracebackType],
     ],
 ]


-@attr.s(frozen=True)
-class PseudoFixtureDef(Generic[_FixtureValue]):
-    cached_result = attr.ib(type="_FixtureCachedResult[_FixtureValue]")
-    scope = attr.ib(type="_Scope")
+@attr.s(frozen=True, auto_attribs=True)
+class PseudoFixtureDef(Generic[FixtureValue]):
+    cached_result: "_FixtureCachedResult[FixtureValue]"
+    _scope: Scope


 def pytest_sessionstart(session: "Session") -> None:
-    import _pytest.python
-    import _pytest.nodes
-
-    scopename2class.update(
-        {
-            "package": _pytest.python.Package,
-            "class": _pytest.python.Class,
-            "module": _pytest.python.Module,
-            "function": _pytest.nodes.Item,
-            "session": _pytest.main.Session,
-        }
-    )
     session._fixturemanager = FixtureManager(session)
-
-
-scopename2class = {}  # type: Dict[str, Type[nodes.Node]]


 def get_scope_package(node, fixturedef: "FixtureDef[object]"):
@@ -136,15 +127,31 @@
     return current


-def get_scope_node(node, scope):
-    cls = scopename2class.get(scope)
-    if cls is None:
-        raise ValueError("unknown scope")
-    return node.getparent(cls)
+def get_scope_node(
+    node: nodes.Node, scope: Scope
+) -> Optional[Union[nodes.Item, nodes.Collector]]:
+    import _pytest.python
+
+    if scope is Scope.Function:
+        return node.getparent(nodes.Item)
+    elif scope is Scope.Class:
+        return node.getparent(_pytest.python.Class)
+    elif scope is Scope.Module:
+        return node.getparent(_pytest.python.Module)
+    elif scope is Scope.Package:
+        return node.getparent(_pytest.python.Package)
+    elif scope is Scope.Session:
+        return node.getparent(_pytest.main.Session)
+    else:
+        assert_never(scope)
+
+
+# Used for storing artificial fixturedefs for direct parametrization.
+name2pseudofixturedef_key = StashKey[Dict[str, "FixtureDef[Any]"]]()


 def add_funcarg_pseudo_fixture_def(
-    collector, metafunc: "Metafunc", fixturemanager: "FixtureManager"
+    collector: nodes.Collector, metafunc: "Metafunc", fixturemanager: "FixtureManager"
 ) -> None:
     # This function will transform all collected calls to functions
     # if they use direct funcargs (i.e. direct parametrization)
@@ -156,8 +163,8 @@
         # This function call does not have direct parametrization.
         return
     # Collect funcargs of all callspecs into a list of values.
-    arg2params = {}  # type: Dict[str, List[object]]
-    arg2scope = {}  # type: Dict[str, _Scope]
+    arg2params: Dict[str, List[object]] = {}
+    arg2scope: Dict[str, Scope] = {}
     for callspec in metafunc._calls:
         for argname, argvalue in callspec.funcargs.items():
             assert argname not in callspec.params
@@ -166,8 +173,8 @@
             callspec.indices[argname] = len(arg2params_list)
             arg2params_list.append(argvalue)
             if argname not in arg2scope:
-                scopenum = callspec._arg2scopenum.get(argname, scopenum_function)
-                arg2scope[argname] = scopes[scopenum]
+                scope = callspec._arg2scope.get(argname, Scope.Function)
+                arg2scope[argname] = scope
         callspec.funcargs.clear()

     # Register artificial FixtureDef's so that later at test execution
@@ -180,14 +187,23 @@
         # node related to the scope.
         scope = arg2scope[argname]
         node = None
-        if scope != "function":
+        if scope is not Scope.Function:
             node = get_scope_node(collector, scope)
             if node is None:
-                assert scope == "class" and isinstance(collector, _pytest.python.Module)
+                assert scope is Scope.Class and isinstance(
+                    collector, _pytest.python.Module
+                )
                 # Use module-level collector for class-scope (for now).
                 node = collector
-        if node and argname in node._name2pseudofixturedef:
-            arg2fixturedefs[argname] = [node._name2pseudofixturedef[argname]]
+        if node is None:
+            name2pseudofixturedef = None
+        else:
+            default: Dict[str, FixtureDef[Any]] = {}
+            name2pseudofixturedef = node.stash.setdefault(
+                name2pseudofixturedef_key, default
+            )
+        if name2pseudofixturedef is not None and argname in name2pseudofixturedef:
+            arg2fixturedefs[argname] = [name2pseudofixturedef[argname]]
         else:
             fixturedef = FixtureDef(
                 fixturemanager=fixturemanager,
@@ -200,17 +216,17 @@
                 ids=None,
             )
             arg2fixturedefs[argname] = [fixturedef]
-            if node is not None:
-                node._name2pseudofixturedef[argname] = fixturedef
+            if name2pseudofixturedef is not None:
+                name2pseudofixturedef[argname] = fixturedef


 def getfixturemarker(obj: object) -> Optional["FixtureFunctionMarker"]:
     """Return fixturemarker or None if it doesn't exist or raised
     exceptions."""
     try:
-        fixturemarker = getattr(
+        fixturemarker: Optional[FixtureFunctionMarker] = getattr(
             obj, "_pytestfixturefunction", None
-        )  # type: Optional[FixtureFunctionMarker]
+        )
     except TEST_OUTCOME:
         # some objects raise errors like request (from flask import request)
         # we don't expect them to be fixture functions
@@ -222,98 +238,93 @@
 _Key = Tuple[object, ...]


-def get_parametrized_fixture_keys(item: "nodes.Item", scopenum: int) -> Iterator[_Key]:
+def get_parametrized_fixture_keys(item: nodes.Item, scope: Scope) -> Iterator[_Key]:
     """Return list of keys for all parametrized arguments which match
-    the specified scope. """
-    assert scopenum < scopenum_function  # function
+    the specified scope."""
+    assert scope is not Scope.Function
     try:
         callspec = item.callspec  # type: ignore[attr-defined]
     except AttributeError:
         pass
     else:
-        cs = callspec  # type: CallSpec2
+        cs: CallSpec2 = callspec
         # cs.indices.items() is random order of argnames.  Need to
         # sort this so that different calls to
         # get_parametrized_fixture_keys will be deterministic.
         for argname, param_index in sorted(cs.indices.items()):
-            if cs._arg2scopenum[argname] != scopenum:
+            if cs._arg2scope[argname] != scope:
                 continue
-            if scopenum == 0:  # session
-                key = (argname, param_index)  # type: _Key
-            elif scopenum == 1:  # package
-                key = (argname, param_index, item.fspath.dirpath())
-            elif scopenum == 2:  # module
-                key = (argname, param_index, item.fspath)
-            elif scopenum == 3:  # class
+            if scope is Scope.Session:
+                key: _Key = (argname, param_index)
+            elif scope is Scope.Package:
+                key = (argname, param_index, item.path.parent)
+            elif scope is Scope.Module:
+                key = (argname, param_index, item.path)
+            elif scope is Scope.Class:
                 item_cls = item.cls  # type: ignore[attr-defined]
-                key = (argname, param_index, item.fspath, item_cls)
+                key = (argname, param_index, item.path, item_cls)
+            else:
+                assert_never(scope)
             yield key


 # Algorithm for sorting on a per-parametrized resource setup basis.
-# It is called for scopenum==0 (session) first and performs sorting
+# It is called for Session scope first and performs sorting
 # down to the lower scopes such as to minimize number of "high scope"
 # setups and teardowns.


-def reorder_items(items: "Sequence[nodes.Item]") -> "List[nodes.Item]":
-    argkeys_cache = {}  # type: Dict[int, Dict[nodes.Item, Dict[_Key, None]]]
-    items_by_argkey = {}  # type: Dict[int, Dict[_Key, Deque[nodes.Item]]]
-    for scopenum in range(0, scopenum_function):
-        d = {}  # type: Dict[nodes.Item, Dict[_Key, None]]
-        argkeys_cache[scopenum] = d
-        item_d = defaultdict(deque)  # type: Dict[_Key, Deque[nodes.Item]]
-        items_by_argkey[scopenum] = item_d
+def reorder_items(items: Sequence[nodes.Item]) -> List[nodes.Item]:
+    argkeys_cache: Dict[Scope, Dict[nodes.Item, Dict[_Key, None]]] = {}
+    items_by_argkey: Dict[Scope, Dict[_Key, Deque[nodes.Item]]] = {}
+    for scope in HIGH_SCOPES:
+        d: Dict[nodes.Item, Dict[_Key, None]] = {}
+        argkeys_cache[scope] = d
+        item_d: Dict[_Key, Deque[nodes.Item]] = defaultdict(deque)
+        items_by_argkey[scope] = item_d
         for item in items:
-            # cast is a workaround for https://github.com/python/typeshed/issues/3800.
-            keys = cast(
-                "Dict[_Key, None]",
-                order_preserving_dict.fromkeys(
-                    get_parametrized_fixture_keys(item, scopenum), None
-                ),
-            )
+            keys = dict.fromkeys(get_parametrized_fixture_keys(item, scope), None)
             if keys:
                 d[item] = keys
                 for key in keys:
                     item_d[key].append(item)
-    # cast is a workaround for https://github.com/python/typeshed/issues/3800.
-    items_dict = cast(
-        "Dict[nodes.Item, None]", order_preserving_dict.fromkeys(items, None)
+    items_dict = dict.fromkeys(items, None)
+    return list(
+        reorder_items_atscope(items_dict, argkeys_cache, items_by_argkey, Scope.Session)
     )
-    return list(reorder_items_atscope(items_dict, argkeys_cache, items_by_argkey, 0))


 def fix_cache_order(
-    item: "nodes.Item",
-    argkeys_cache: "Dict[int, Dict[nodes.Item, Dict[_Key, None]]]",
-    items_by_argkey: "Dict[int, Dict[_Key, Deque[nodes.Item]]]",
+    item: nodes.Item,
+    argkeys_cache: Dict[Scope, Dict[nodes.Item, Dict[_Key, None]]],
+    items_by_argkey: Dict[Scope, Dict[_Key, "Deque[nodes.Item]"]],
 ) -> None:
-    for scopenum in range(0, scopenum_function):
-        for key in argkeys_cache[scopenum].get(item, []):
-            items_by_argkey[scopenum][key].appendleft(item)
+    for scope in HIGH_SCOPES:
+        for key in argkeys_cache[scope].get(item, []):
+            items_by_argkey[scope][key].appendleft(item)


 def reorder_items_atscope(
-    items: "Dict[nodes.Item, None]",
-    argkeys_cache: "Dict[int, Dict[nodes.Item, Dict[_Key, None]]]",
-    items_by_argkey: "Dict[int, Dict[_Key, Deque[nodes.Item]]]",
-    scopenum: int,
-) -> "Dict[nodes.Item, None]":
-    if scopenum >= scopenum_function or len(items) < 3:
+    items: Dict[nodes.Item, None],
+    argkeys_cache: Dict[Scope, Dict[nodes.Item, Dict[_Key, None]]],
+    items_by_argkey: Dict[Scope, Dict[_Key, "Deque[nodes.Item]"]],
+    scope: Scope,
+) -> Dict[nodes.Item, None]:
+    if scope is Scope.Function or len(items) < 3:
         return items
-    ignore = set()  # type: Set[Optional[_Key]]
+    ignore: Set[Optional[_Key]] = set()
     items_deque = deque(items)
-    items_done = order_preserving_dict()  # type: Dict[nodes.Item, None]
-    scoped_items_by_argkey = items_by_argkey[scopenum]
-    scoped_argkeys_cache = argkeys_cache[scopenum]
+    items_done: Dict[nodes.Item, None] = {}
+    scoped_items_by_argkey = items_by_argkey[scope]
+    scoped_argkeys_cache = argkeys_cache[scope]
     while items_deque:
-        no_argkey_group = order_preserving_dict()  # type: Dict[nodes.Item, None]
+        no_argkey_group: Dict[nodes.Item, None] = {}
         slicing_argkey = None
         while items_deque:
             item = items_deque.popleft()
             if item in items_done or item in no_argkey_group:
                 continue
-            argkeys = order_preserving_dict.fromkeys(
+            argkeys = dict.fromkeys(
                 (k for k in scoped_argkeys_cache.get(item, []) if k not in ignore), None
             )
             if not argkeys:
@@ -331,7 +342,7 @@
                 break
         if no_argkey_group:
             no_argkey_group = reorder_items_atscope(
-                no_argkey_group, argkeys_cache, items_by_argkey, scopenum + 1
+                no_argkey_group, argkeys_cache, items_by_argkey, scope.next_lower()
             )
             for item in no_argkey_group:
                 items_done[item] = None
@@ -339,57 +350,20 @@
     return items_done


-def _fillfuncargs(function: "Function") -> None:
-    """Fill missing fixtures for a test function, old public API (deprecated)."""
-    warnings.warn(FILLFUNCARGS.format(name="pytest._fillfuncargs()"), stacklevel=2)
-    _fill_fixtures_impl(function)
-
-
-def fillfixtures(function: "Function") -> None:
-    """Fill missing fixtures for a test function (deprecated)."""
-    warnings.warn(
-        FILLFUNCARGS.format(name="_pytest.fixtures.fillfixtures()"), stacklevel=2
-    )
-    _fill_fixtures_impl(function)
-
-
-def _fill_fixtures_impl(function: "Function") -> None:
-    """Internal implementation to fill fixtures on the given function object."""
-    try:
-        request = function._request
-    except AttributeError:
-        # XXX this special code path is only expected to execute
-        # with the oejskit plugin.  It uses classes with funcargs
-        # and we thus have to work a bit to allow this.
-        fm = function.session._fixturemanager
-        assert function.parent is not None
-        fi = fm.getfixtureinfo(function.parent, function.obj, None)
-        function._fixtureinfo = fi
-        request = function._request = FixtureRequest(function)
-        request._fillfixtures()
-        # Prune out funcargs for jstests.
-        newfuncargs = {}
-        for name in fi.argnames:
-            newfuncargs[name] = function.funcargs[name]
-        function.funcargs = newfuncargs
-    else:
-        request._fillfixtures()
-
-
 def get_direct_param_fixture_func(request):
     return request.param


-@attr.s(slots=True)
+@attr.s(slots=True, auto_attribs=True)
 class FuncFixtureInfo:
     # Original function argument names.
-    argnames = attr.ib(type=Tuple[str, ...])
+    argnames: Tuple[str, ...]
     # Argnames that function immediately requires. These include argnames +
     # fixture names specified via usefixtures and via autouse=True in fixture
     # definitions.
-    initialnames = attr.ib(type=Tuple[str, ...])
-    names_closure = attr.ib(type=List[str])
-    name2fixturedefs = attr.ib(type=Dict[str, Sequence["FixtureDef[Any]"]])
+    initialnames: Tuple[str, ...]
+    names_closure: List[str]
+    name2fixturedefs: Dict[str, Sequence["FixtureDef[Any]"]]

     def prune_dependency_tree(self) -> None:
         """Recompute names_closure from initialnames and name2fixturedefs.
@@ -402,7 +376,7 @@
         tree. In this way the dependency tree can get pruned, and the closure
         of argnames may get reduced.
         """
-        closure = set()  # type: Set[str]
+        closure: Set[str] = set()
         working_set = set(self.initialnames)
         while working_set:
             argname = working_set.pop()
@@ -427,19 +401,22 @@
     indirectly.
     """

-    def __init__(self, pyfuncitem) -> None:
+    def __init__(self, pyfuncitem, *, _ispytest: bool = False) -> None:
+        check_ispytest(_ispytest)
         self._pyfuncitem = pyfuncitem
         #: Fixture for which this request is being performed.
-        self.fixturename = None  # type: Optional[str]
-        #: Scope string, one of "function", "class", "module", "session".
-        self.scope = "function"  # type: _Scope
-        self._fixture_defs = {}  # type: Dict[str, FixtureDef[Any]]
-        fixtureinfo = pyfuncitem._fixtureinfo  # type: FuncFixtureInfo
+        self.fixturename: Optional[str] = None
+        self._scope = Scope.Function
+        self._fixture_defs: Dict[str, FixtureDef[Any]] = {}
+        fixtureinfo: FuncFixtureInfo = pyfuncitem._fixtureinfo
         self._arg2fixturedefs = fixtureinfo.name2fixturedefs.copy()
-        self._arg2index = {}  # type: Dict[str, int]
-        self._fixturemanager = (
-            pyfuncitem.session._fixturemanager
-        )  # type: FixtureManager
+        self._arg2index: Dict[str, int] = {}
+        self._fixturemanager: FixtureManager = pyfuncitem.session._fixturemanager
+
+    @property
+    def scope(self) -> "_ScopeName":
+        """Scope string, one of "function", "class", "module", "package", "session"."""
+        return self._scope.value

     @property
     def fixturenames(self) -> List[str]:
@@ -451,7 +428,7 @@
     @property
     def node(self):
         """Underlying collection node (depends on current request scope)."""
-        return self._getscopeitem(self.scope)
+        return self._getscopeitem(self._scope)

     def _getnextfixturedef(self, argname: str) -> "FixtureDef[Any]":
         fixturedefs = self._arg2fixturedefs.get(argname, None)
@@ -475,14 +452,14 @@
     @property
     def config(self) -> Config:
         """The pytest config object associated with this request."""
-        return self._pyfuncitem.config  # type: ignore[no-any-return] # noqa: F723
+        return self._pyfuncitem.config  # type: ignore[no-any-return]

     @property
     def function(self):
         """Test function object if the request has a per-function scope."""
         if self.scope != "function":
             raise AttributeError(
-                "function not available in {}-scoped context".format(self.scope)
+                f"function not available in {self.scope}-scoped context"
             )
         return self._pyfuncitem.obj

@@ -490,9 +467,7 @@
     def cls(self):
         """Class (can be None) where the test function was collected."""
         if self.scope not in ("class", "function"):
-            raise AttributeError(
-                "cls not available in {}-scoped context".format(self.scope)
-            )
+            raise AttributeError(f"cls not available in {self.scope}-scoped context")
         clscol = self._pyfuncitem.getparent(_pytest.python.Class)
         if clscol:
             return clscol.obj
@@ -511,30 +486,26 @@
     def module(self):
         """Python module object where the test function was collected."""
         if self.scope not in ("function", "class", "module"):
-            raise AttributeError(
-                "module not available in {}-scoped context".format(self.scope)
-            )
+            raise AttributeError(f"module not available in {self.scope}-scoped context")
         return self._pyfuncitem.getparent(_pytest.python.Module).obj

     @property
-    def fspath(self) -> py.path.local:
-        """The file system path of the test module which collected this test."""
+    def path(self) -> Path:
         if self.scope not in ("function", "class", "module", "package"):
-            raise AttributeError(
-                "module not available in {}-scoped context".format(self.scope)
-            )
+            raise AttributeError(f"path not available in {self.scope}-scoped context")
         # TODO: Remove ignore once _pyfuncitem is properly typed.
-        return self._pyfuncitem.fspath  # type: ignore
+        return self._pyfuncitem.path  # type: ignore

     @property
-    def keywords(self):
+    def keywords(self) -> MutableMapping[str, Any]:
         """Keywords/markers dictionary for the underlying node."""
-        return self.node.keywords
+        node: nodes.Node = self.node
+        return node.keywords

     @property
-    def session(self):
+    def session(self) -> "Session":
         """Pytest session object."""
-        return self._pyfuncitem.session
+        return self._pyfuncitem.session  # type: ignore[no-any-return]

     def addfinalizer(self, finalizer: Callable[[], object]) -> None:
         """Add finalizer/teardown function to be called after the last test
@@ -543,19 +514,17 @@
         self._addfinalizer(finalizer, scope=self.scope)

     def _addfinalizer(self, finalizer: Callable[[], object], scope) -> None:
-        colitem = self._getscopeitem(scope)
-        self._pyfuncitem.session._setupstate.addfinalizer(
-            finalizer=finalizer, colitem=colitem
-        )
-
-    def applymarker(self, marker) -> None:
+        node = self._getscopeitem(scope)
+        node.addfinalizer(finalizer)
+
+    def applymarker(self, marker: Union[str, MarkDecorator]) -> None:
         """Apply a marker to a single test function invocation.

         This method is useful if you don't want to have a keyword/marker
         on all function invocations.

         :param marker:
-            A :py:class:`_pytest.mark.MarkDecorator` object created by a call
+            A :class:`pytest.MarkDecorator` object created by a call
             to ``pytest.mark.NAME(...)``.
         """
         self.node.add_marker(marker)
@@ -597,8 +566,7 @@
             except FixtureLookupError:
                 if argname == "request":
                     cached_result = (self, [0], None)
-                    scope = "function"  # type: _Scope
-                    return PseudoFixtureDef(cached_result, scope)
+                    return PseudoFixtureDef(cached_result, Scope.Function)
                 raise
         # Remove indent to prevent the python3 exception
         # from leaking into the call.
@@ -608,15 +576,12 @@

     def _get_fixturestack(self) -> List["FixtureDef[Any]"]:
         current = self
-        values = []  # type: List[FixtureDef[Any]]
-        while 1:
-            fixturedef = getattr(current, "_fixturedef", None)
-            if fixturedef is None:
-                values.reverse()
-                return values
-            values.append(fixturedef)
-            assert isinstance(current, SubRequest)
+        values: List[FixtureDef[Any]] = []
+        while isinstance(current, SubRequest):
+            values.append(current._fixturedef)  # type: ignore[has-type]
             current = current._parent_request
+        values.reverse()
+        return values

     def _compute_fixture_value(self, fixturedef: "FixtureDef[object]") -> None:
         """Create a SubRequest based on "self" and call the execute method
@@ -630,10 +595,19 @@
         # (latter managed by fixturedef)
         argname = fixturedef.argname
         funcitem = self._pyfuncitem
-        scope = fixturedef.scope
+        scope = fixturedef._scope
         try:
-            param = funcitem.callspec.getparam(argname)
-        except (AttributeError, ValueError):
+            callspec = funcitem.callspec
+        except AttributeError:
+            callspec = None
+        if callspec is not None and argname in callspec.params:
+            param = callspec.params[argname]
+            param_index = callspec.indices[argname]
+            # If a parametrize invocation set a scope it will override
+            # the static scope defined with the fixture function.
+            with suppress(KeyError):
+                scope = callspec._arg2scope[argname]
+        else:
             param = NOTSET
             param_index = 0
             has_params = fixturedef.params is not None
@@ -652,12 +626,13 @@
             if has_params:
                 frame = inspect.stack()[3]
                 frameinfo = inspect.getframeinfo(frame[0])
-                source_path = py.path.local(frameinfo.filename)
+                source_path = absolutepath(frameinfo.filename)
                 source_lineno = frameinfo.lineno
-                rel_source_path = source_path.relto(funcitem.config.rootdir)
-                if rel_source_path:
-                    source_path_str = rel_source_path
-                else:
+                try:
+                    source_path_str = str(
+                        source_path.relative_to(funcitem.config.rootpath)
+                    )
+                except ValueError:
                     source_path_str = str(source_path)
                 msg = (
                     "The requested fixture has no parameter defined for test:\n"
@@ -666,24 +641,19 @@
                     "\n\nRequested here:\n{}:{}".format(
                         funcitem.nodeid,
                         fixturedef.argname,
-                        getlocation(fixturedef.func, funcitem.config.rootdir),
+                        getlocation(fixturedef.func, funcitem.config.rootpath),
                         source_path_str,
                         source_lineno,
                     )
                 )
                 fail(msg, pytrace=False)
-        else:
-            param_index = funcitem.callspec.indices[argname]
-            # If a parametrize invocation set a scope it will override
-            # the static scope defined with the fixture function.
-            paramscopenum = funcitem.callspec._arg2scopenum.get(argname)
-            if paramscopenum is not None:
-                scope = scopes[paramscopenum]
-
-        subrequest = SubRequest(self, scope, param, param_index, fixturedef)
+
+        subrequest = SubRequest(
+            self, scope, param, param_index, fixturedef, _ispytest=True
+        )

         # Check if a higher-level scoped fixture accesses a lower level one.
-        subrequest._check_scope(argname, self.scope, scope)
+        subrequest._check_scope(argname, self._scope, scope)
         try:
             # Call the fixture function.
             fixturedef.execute(request=subrequest)
@@ -694,21 +664,23 @@
         self, fixturedef: "FixtureDef[object]", subrequest: "SubRequest"
     ) -> None:
         # If fixture function failed it might have registered finalizers.
-        self.session._setupstate.addfinalizer(
-            functools.partial(fixturedef.finish, request=subrequest), subrequest.node
-        )
-
-    def _check_scope(self, argname, invoking_scope: "_Scope", requested_scope) -> None:
+        subrequest.node.addfinalizer(lambda: fixturedef.finish(request=subrequest))
+
+    def _check_scope(
+        self,
+        argname: str,
+        invoking_scope: Scope,
+        requested_scope: Scope,
+    ) -> None:
         if argname == "request":
             return
-        if scopemismatch(invoking_scope, requested_scope):
+        if invoking_scope > requested_scope:
             # Try to report something helpful.
-            lines = self._factorytraceback()
+            text = "\n".join(self._factorytraceback())
             fail(
-                "ScopeMismatch: You tried to access the %r scoped "
-                "fixture %r with a %r scoped request object, "
-                "involved factories\n%s"
-                % ((requested_scope, argname, invoking_scope, "\n".join(lines))),
+                f"ScopeMismatch: You tried to access the {requested_scope.value} scoped "
+                f"fixture {argname} with a {invoking_scope.value} scoped request object, "
+                f"involved factories:\n{text}",
                 pytrace=False,
             )

@@ -717,22 +689,30 @@
         for fixturedef in self._get_fixturestack():
             factory = fixturedef.func
             fs, lineno = getfslineno(factory)
-            p = self._pyfuncitem.session.fspath.bestrelpath(fs)
+            if isinstance(fs, Path):
+                session: Session = self._pyfuncitem.session
+                p = bestrelpath(session.path, fs)
+            else:
+                p = fs
             args = _format_args(factory)
             lines.append("%s:%d:  def %s%s" % (p, lineno + 1, factory.__name__, args))
         return lines

-    def _getscopeitem(self, scope):
-        if scope == "function":
+    def _getscopeitem(
+        self, scope: Union[Scope, "_ScopeName"]
+    ) -> Union[nodes.Item, nodes.Collector]:
+        if isinstance(scope, str):
+            scope = Scope(scope)
+        if scope is Scope.Function:
             # This might also be a non-function Item despite its attribute name.
-            return self._pyfuncitem
-        if scope == "package":
+            node: Optional[Union[nodes.Item, nodes.Collector]] = self._pyfuncitem
+        elif scope is Scope.Package:
             # FIXME: _fixturedef is not defined on FixtureRequest (this class),
             # but on FixtureRequest (a subclass).
             node = get_scope_package(self._pyfuncitem, self._fixturedef)  # type: ignore[attr-defined]
         else:
             node = get_scope_node(self._pyfuncitem, scope)
-        if node is None and scope == "class":
+        if node is None and scope is Scope.Class:
             # Fallback to function item itself.
             node = self._pyfuncitem
         assert node, 'Could not obtain a node for scope "{}" for function {!r}'.format(
@@ -751,17 +731,20 @@
     def __init__(
         self,
         request: "FixtureRequest",
-        scope: "_Scope",
-        param,
+        scope: Scope,
+        param: Any,
         param_index: int,
         fixturedef: "FixtureDef[object]",
+        *,
+        _ispytest: bool = False,
     ) -> None:
+        check_ispytest(_ispytest)
         self._parent_request = request
         self.fixturename = fixturedef.argname
         if param is not NOTSET:
             self.param = param
         self.param_index = param_index
-        self.scope = scope
+        self._scope = scope
         self._fixturedef = fixturedef
         self._pyfuncitem = request._pyfuncitem
         self._fixture_defs = request._fixture_defs
@@ -770,9 +753,11 @@
         self._fixturemanager = request._fixturemanager

     def __repr__(self) -> str:
-        return "<SubRequest {!r} for {!r}>".format(self.fixturename, self._pyfuncitem)
+        return f"<SubRequest {self.fixturename!r} for {self._pyfuncitem!r}>"

     def addfinalizer(self, finalizer: Callable[[], object]) -> None:
+        """Add finalizer/teardown function to be called after the last test
+        within the requesting test context finished execution."""
         self._fixturedef.addfinalizer(finalizer)

     def _schedule_finalizers(
@@ -788,29 +773,6 @@
         super()._schedule_finalizers(fixturedef, subrequest)


-scopes = ["session", "package", "module", "class", "function"]  # type: List[_Scope]
-scopenum_function = scopes.index("function")
-
-
-def scopemismatch(currentscope: "_Scope", newscope: "_Scope") -> bool:
-    return scopes.index(newscope) > scopes.index(currentscope)
-
-
-def scope2index(scope: str, descr: str, where: Optional[str] = None) -> int:
-    """Look up the index of ``scope`` and raise a descriptive value error
-    if not defined."""
-    strscopes = scopes  # type: Sequence[str]
-    try:
-        return strscopes.index(scope)
-    except ValueError:
-        fail(
-            "{} {}got an unexpected scope value '{}'".format(
-                descr, "from {} ".format(where) if where else "", scope
-            ),
-            pytrace=False,
-        )
-
-
 @final
 class FixtureLookupError(LookupError):
     """Could not return a requested fixture (missing or invalid)."""
@@ -824,7 +786,7 @@
         self.msg = msg

     def formatrepr(self) -> "FixtureLookupErrorRepr":
-        tblines = []  # type: List[str]
+        tblines: List[str] = []
         addline = tblines.append
         stack = [self.request._pyfuncitem.obj]
         stack.extend(map(lambda x: x.func, self.fixturestack))
@@ -841,7 +803,7 @@
                 error_msg = "file %s, line %s: source code not available"
                 addline(error_msg % (fspath, lineno + 1))
             else:
-                addline("file {}, line {}".format(fspath, lineno + 1))
+                addline(f"file {fspath}, line {lineno + 1}")
                 for i, line in enumerate(lines):
                     line = line.rstrip()
                     addline("  " + line)
@@ -861,7 +823,7 @@
                     self.argname
                 )
             else:
-                msg = "fixture '{}' not found".format(self.argname)
+                msg = f"fixture '{self.argname}' not found"
             msg += "\n available fixtures: {}".format(", ".join(sorted(available)))
             msg += "\n use 'pytest --fixtures [testpath]' for help on them."

@@ -871,7 +833,7 @@
 class FixtureLookupErrorRepr(TerminalRepr):
     def __init__(
         self,
-        filename: Union[str, py.path.local],
+        filename: Union[str, "os.PathLike[str]"],
         firstlineno: int,
         tblines: Sequence[str],
         errorstring: str,
@@ -890,43 +852,41 @@
         lines = self.errorstring.split("\n")
         if lines:
             tw.line(
-                "{}       {}".format(FormattedExcinfo.fail_marker, lines[0].strip()),
+                f"{FormattedExcinfo.fail_marker}       {lines[0].strip()}",
                 red=True,
             )
             for line in lines[1:]:
                 tw.line(
-                    "{}       {}".format(FormattedExcinfo.flow_marker, line.strip()),
+                    f"{FormattedExcinfo.flow_marker}       {line.strip()}",
                     red=True,
                 )
         tw.line()
-        tw.line("%s:%d" % (self.filename, self.firstlineno + 1))
+        tw.line("%s:%d" % (os.fspath(self.filename), self.firstlineno + 1))


 def fail_fixturefunc(fixturefunc, msg: str) -> "NoReturn":
     fs, lineno = getfslineno(fixturefunc)
-    location = "{}:{}".format(fs, lineno + 1)
+    location = f"{fs}:{lineno + 1}"
     source = _pytest._code.Source(fixturefunc)
     fail(msg + ":\n\n" + str(source.indent()) + "\n" + location, pytrace=False)


 def call_fixture_func(
-    fixturefunc: "_FixtureFunc[_FixtureValue]", request: FixtureRequest, kwargs
-) -> _FixtureValue:
+    fixturefunc: "_FixtureFunc[FixtureValue]", request: FixtureRequest, kwargs
+) -> FixtureValue:
     if is_generator(fixturefunc):
         fixturefunc = cast(
-            Callable[..., Generator[_FixtureValue, None, None]], fixturefunc
+            Callable[..., Generator[FixtureValue, None, None]], fixturefunc
         )
         generator = fixturefunc(**kwargs)
         try:
             fixture_result = next(generator)
         except StopIteration:
-            raise ValueError(
-                "{} did not yield a value".format(request.fixturename)
-            ) from None
+            raise ValueError(f"{request.fixturename} did not yield a value") from None
         finalizer = functools.partial(_teardown_yield_fixture, fixturefunc, generator)
         request.addfinalizer(finalizer)
     else:
-        fixturefunc = cast(Callable[..., _FixtureValue], fixturefunc)
+        fixturefunc = cast(Callable[..., FixtureValue], fixturefunc)
         fixture_result = fixturefunc(**kwargs)
     return fixture_result

@@ -944,10 +904,10 @@


 def _eval_scope_callable(
-    scope_callable: "Callable[[str, Config], _Scope]",
+    scope_callable: "Callable[[str, Config], _ScopeName]",
     fixture_name: str,
     config: Config,
-) -> "_Scope":
+) -> "_ScopeName":
     try:
         # Type ignored because there is no typing mechanism to specify
         # keyword arguments, currently.
@@ -969,49 +929,76 @@


 @final
-class FixtureDef(Generic[_FixtureValue]):
-    """A container for a factory definition."""
+class FixtureDef(Generic[FixtureValue]):
+    """A container for a fixture definition."""

     def __init__(
         self,
         fixturemanager: "FixtureManager",
-        baseid,
+        baseid: Optional[str],
         argname: str,
-        func: "_FixtureFunc[_FixtureValue]",
-        scope: "Union[_Scope, Callable[[str, Config], _Scope]]",
+        func: "_FixtureFunc[FixtureValue]",
+        scope: Union[Scope, "_ScopeName", Callable[[str, Config], "_ScopeName"], None],
         params: Optional[Sequence[object]],
         unittest: bool = False,
         ids: Optional[
-            Union[
-                Tuple[Union[None, str, float, int, bool], ...],
-                Callable[[Any], Optional[object]],
-            ]
+            Union[Tuple[Optional[object], ...], Callable[[Any], Optional[object]]]
         ] = None,
     ) -> None:
         self._fixturemanager = fixturemanager
+        # The "base" node ID for the fixture.
+        #
+        # This is a node ID prefix. A fixture is only available to a node (e.g.
+        # a `Function` item) if the fixture's baseid is a parent of the node's
+        # nodeid (see the `iterparentnodeids` function for what constitutes a
+        # "parent" and a "prefix" in this context).
+        #
+        # For a fixture found in a Collector's object (e.g. a `Module`s module,
+        # a `Class`'s class), the baseid is the Collector's nodeid.
+        #
+        # For a fixture found in a conftest plugin, the baseid is the conftest's
+        # directory path relative to the rootdir.
+        #
+        # For other plugins, the baseid is the empty string (always matches).
         self.baseid = baseid or ""
+        # Whether the fixture was found from a node or a conftest in the
+        # collection tree. Will be false for fixtures defined in non-conftest
+        # plugins.
         self.has_location = baseid is not None
+        # The fixture factory function.
         self.func = func
+        # The name by which the fixture may be requested.
         self.argname = argname
-        if callable(scope):
-            scope_ = _eval_scope_callable(scope, argname, fixturemanager.config)
-        else:
-            scope_ = scope
-        self.scopenum = scope2index(
-            # TODO: Check if the `or` here is really necessary.
-            scope_ or "function",  # type: ignore[unreachable]
-            descr="Fixture '{}'".format(func.__name__),
-            where=baseid,
-        )
-        self.scope = scope_
-        self.params = params  # type: Optional[Sequence[object]]
-        self.argnames = getfuncargnames(
-            func, name=argname, is_method=unittest
-        )  # type: Tuple[str, ...]
+        if scope is None:
+            scope = Scope.Function
+        elif callable(scope):
+            scope = _eval_scope_callable(scope, argname, fixturemanager.config)
+        if isinstance(scope, str):
+            scope = Scope.from_user(
+                scope, descr=f"Fixture '{func.__name__}'", where=baseid
+            )
+        self._scope = scope
+        # If the fixture is directly parametrized, the parameter values.
+        self.params: Optional[Sequence[object]] = params
+        # If the fixture is directly parametrized, a tuple of explicit IDs to
+        # assign to the parameter values, or a callable to generate an ID given
+        # a parameter value.
+        self.ids = ids
+        # The names requested by the fixtures.
+        self.argnames = getfuncargnames(func, name=argname, is_method=unittest)
+        # Whether the fixture was collected from a unittest TestCase class.
+        # Note that it really only makes sense to define autouse fixtures in
+        # unittest TestCases.
         self.unittest = unittest
-        self.ids = ids
-        self.cached_result = None  # type: Optional[_FixtureCachedResult[_FixtureValue]]
-        self._finalizers = []  # type: List[Callable[[], object]]
+        # If the fixture was executed, the current value of the fixture.
+        # Can change if the fixture is executed with different parameters.
+        self.cached_result: Optional[_FixtureCachedResult[FixtureValue]] = None
+        self._finalizers: List[Callable[[], object]] = []
+
+    @property
+    def scope(self) -> "_ScopeName":
+        """Scope string, one of "function", "class", "module", "package", "session"."""
+        return self._scope.value

     def addfinalizer(self, finalizer: Callable[[], object]) -> None:
         self._finalizers.append(finalizer)
@@ -1031,15 +1018,15 @@
             if exc:
                 raise exc
         finally:
-            hook = self._fixturemanager.session.gethookproxy(request.node.fspath)
-            hook.pytest_fixture_post_finalizer(fixturedef=self, request=request)
+            ihook = request.node.ihook
+            ihook.pytest_fixture_post_finalizer(fixturedef=self, request=request)
             # Even if finalization fails, we invalidate the cached fixture
             # value and remove all finalizers because they may be bound methods
             # which will keep instances alive.
             self.cached_result = None
             self._finalizers = []

-    def execute(self, request: SubRequest) -> _FixtureValue:
+    def execute(self, request: SubRequest) -> FixtureValue:
         # Get required arguments and register our own finish()
         # with their finalization.
         for argname in self.argnames:
@@ -1066,8 +1053,8 @@
             self.finish(request)
             assert self.cached_result is None

-        hook = self._fixturemanager.session.gethookproxy(request.node.fspath)
-        result = hook.pytest_fixture_setup(fixturedef=self, request=request)
+        ihook = request.node.ihook
+        result = ihook.pytest_fixture_setup(fixturedef=self, request=request)
         return result

     def cache_key(self, request: SubRequest) -> object:
@@ -1080,8 +1067,8 @@


 def resolve_fixture_function(
-    fixturedef: FixtureDef[_FixtureValue], request: FixtureRequest
-) -> "_FixtureFunc[_FixtureValue]":
+    fixturedef: FixtureDef[FixtureValue], request: FixtureRequest
+) -> "_FixtureFunc[FixtureValue]":
     """Get the actual callable that can be called to obtain the fixture
     value, dealing with unittest-specific instances and bound methods."""
     fixturefunc = fixturedef.func
@@ -1107,15 +1094,15 @@


 def pytest_fixture_setup(
-    fixturedef: FixtureDef[_FixtureValue], request: SubRequest
-) -> _FixtureValue:
+    fixturedef: FixtureDef[FixtureValue], request: SubRequest
+) -> FixtureValue:
     """Execution of fixture setup."""
     kwargs = {}
     for argname in fixturedef.argnames:
         fixdef = request._get_active_fixturedef(argname)
         assert fixdef.cached_result is not None
         result, arg_cache_key, exc = fixdef.cached_result
-        request._check_scope(argname, request.scope, fixdef.scope)
+        request._check_scope(argname, request._scope, fixdef._scope)
         kwargs[argname] = result

     fixturefunc = resolve_fixture_function(fixturedef, request)
@@ -1132,18 +1119,8 @@


 def _ensure_immutable_ids(
-    ids: Optional[
-        Union[
-            Iterable[Union[None, str, float, int, bool]],
-            Callable[[Any], Optional[object]],
-        ]
-    ],
-) -> Optional[
-    Union[
-        Tuple[Union[None, str, float, int, bool], ...],
-        Callable[[Any], Optional[object]],
-    ]
-]:
+    ids: Optional[Union[Sequence[Optional[object]], Callable[[Any], Optional[object]]]]
+) -> Optional[Union[Tuple[Optional[object], ...], Callable[[Any], Optional[object]]]]:
     if ids is None:
         return None
     if callable(ids):
@@ -1157,13 +1134,16 @@
     return tuple(params) if params is not None else None


-def wrap_function_to_error_out_if_called_directly(function, fixture_marker):
+def wrap_function_to_error_out_if_called_directly(
+    function: FixtureFunction,
+    fixture_marker: "FixtureFunctionMarker",
+) -> FixtureFunction:
     """Wrap the given fixture function so we can raise an error about it being called directly,
     instead of used as an argument in a test function."""
     message = (
         'Fixture "{name}" called directly. Fixtures are not meant to be called directly,\n'
         "but are created automatically when test functions request them as parameters.\n"
-        "See https://docs.pytest.org/en/stable/fixture.html for more information about fixtures, and\n"
+        "See https://docs.pytest.org/en/stable/explanation/fixtures.html for more information about fixtures, and\n"
         "https://docs.pytest.org/en/stable/deprecations.html#calling-fixtures-directly about how to update your code."
     ).format(name=fixture_marker.name or function.__name__)

@@ -1175,26 +1155,24 @@
     # further than this point and lose useful wrappings like @mock.patch (#3774).
     result.__pytest_wrapped__ = _PytestWrapper(function)  # type: ignore[attr-defined]

-    return result
+    return cast(FixtureFunction, result)


 @final
-@attr.s(frozen=True)
+@attr.s(frozen=True, auto_attribs=True)
 class FixtureFunctionMarker:
-    scope = attr.ib(type="Union[_Scope, Callable[[str, Config], _Scope]]")
-    params = attr.ib(type=Optional[Tuple[object, ...]], converter=_params_converter)
-    autouse = attr.ib(type=bool, default=False)
-    ids = attr.ib(
-        type=Union[
-            Tuple[Union[None, str, float, int, bool], ...],
-            Callable[[Any], Optional[object]],
-        ],
+    scope: "Union[_ScopeName, Callable[[str, Config], _ScopeName]]"
+    params: Optional[Tuple[object, ...]] = attr.ib(converter=_params_converter)
+    autouse: bool = False
+    ids: Optional[
+        Union[Tuple[Optional[object], ...], Callable[[Any], Optional[object]]]
+    ] = attr.ib(
         default=None,
         converter=_ensure_immutable_ids,
     )
-    name = attr.ib(type=Optional[str], default=None)
-
-    def __call__(self, function: _FixtureFunction) -> _FixtureFunction:
+    name: Optional[str] = None
+
+    def __call__(self, function: FixtureFunction) -> FixtureFunction:
         if inspect.isclass(function):
             raise ValueError("class fixtures not supported (maybe in the future)")

@@ -1222,54 +1200,45 @@

 @overload
 def fixture(
-    fixture_function: _FixtureFunction,
+    fixture_function: FixtureFunction,
     *,
-    scope: "Union[_Scope, Callable[[str, Config], _Scope]]" = ...,
+    scope: "Union[_ScopeName, Callable[[str, Config], _ScopeName]]" = ...,
     params: Optional[Iterable[object]] = ...,
     autouse: bool = ...,
     ids: Optional[
-        Union[
-            Iterable[Union[None, str, float, int, bool]],
-            Callable[[Any], Optional[object]],
-        ]
+        Union[Sequence[Optional[object]], Callable[[Any], Optional[object]]]
     ] = ...,
-    name: Optional[str] = ...
-) -> _FixtureFunction:
+    name: Optional[str] = ...,
+) -> FixtureFunction:
     ...


-@overload  # noqa: F811
-def fixture(  # noqa: F811
+@overload
+def fixture(
     fixture_function: None = ...,
     *,
-    scope: "Union[_Scope, Callable[[str, Config], _Scope]]" = ...,
+    scope: "Union[_ScopeName, Callable[[str, Config], _ScopeName]]" = ...,
     params: Optional[Iterable[object]] = ...,
     autouse: bool = ...,
     ids: Optional[
-        Union[
-            Iterable[Union[None, str, float, int, bool]],
-            Callable[[Any], Optional[object]],
-        ]
+        Union[Sequence[Optional[object]], Callable[[Any], Optional[object]]]
     ] = ...,
-    name: Optional[str] = None
+    name: Optional[str] = None,
 ) -> FixtureFunctionMarker:
     ...


-def fixture(  # noqa: F811
-    fixture_function: Optional[_FixtureFunction] = None,
+def fixture(
+    fixture_function: Optional[FixtureFunction] = None,
     *,
-    scope: "Union[_Scope, Callable[[str, Config], _Scope]]" = "function",
+    scope: "Union[_ScopeName, Callable[[str, Config], _ScopeName]]" = "function",
     params: Optional[Iterable[object]] = None,
     autouse: bool = False,
     ids: Optional[
-        Union[
-            Iterable[Union[None, str, float, int, bool]],
-            Callable[[Any], Optional[object]],
-        ]
+        Union[Sequence[Optional[object]], Callable[[Any], Optional[object]]]
     ] = None,
-    name: Optional[str] = None
-) -> Union[FixtureFunctionMarker, _FixtureFunction]:
+    name: Optional[str] = None,
+) -> Union[FixtureFunctionMarker, FixtureFunction]:
     """Decorator to mark a fixture factory function.

     This decorator can be used, with or without parameters, to define a
@@ -1308,7 +1277,7 @@
         the fixture.

     :param ids:
-        List of string ids each corresponding to the params so that they are
+        Sequence of ids each corresponding to the params so that they are
         part of the test id. If no ids are provided they will be generated
         automatically from the params.

@@ -1321,7 +1290,11 @@
         ``@pytest.fixture(name='<fixturename>')``.
     """
     fixture_marker = FixtureFunctionMarker(
-        scope=scope, params=params, autouse=autouse, ids=ids, name=name,
+        scope=scope,
+        params=params,
+        autouse=autouse,
+        ids=ids,
+        name=name,
     )

     # Direct decoration.
@@ -1338,13 +1311,14 @@
     params=None,
     autouse=False,
     ids=None,
-    name=None
+    name=None,
 ):
     """(Return a) decorator to mark a yield-fixture factory function.

     .. deprecated:: 3.0
         Use :py:func:`pytest.fixture` directly instead.
     """
+    warnings.warn(YIELD_FIXTURE, stacklevel=2)
     return fixture(
         fixture_function,
         *args,
@@ -1358,7 +1332,8 @@

 @fixture(scope="session")
 def pytestconfig(request: FixtureRequest) -> Config:
-    """Session-scoped fixture that returns the :class:`_pytest.config.Config` object.
+    """Session-scoped fixture that returns the session's :class:`pytest.Config`
+    object.

     Example::

@@ -1415,15 +1390,16 @@

     def __init__(self, session: "Session") -> None:
         self.session = session
-        self.config = session.config  # type: Config
-        self._arg2fixturedefs = {}  # type: Dict[str, List[FixtureDef[Any]]]
-        self._holderobjseen = set()  # type: Set[object]
-        self._nodeid_and_autousenames = [
-            ("", self.config.getini("usefixtures"))
-        ]  # type: List[Tuple[str, List[str]]]
+        self.config: Config = session.config
+        self._arg2fixturedefs: Dict[str, List[FixtureDef[Any]]] = {}
+        self._holderobjseen: Set[object] = set()
+        # A mapping from a nodeid to a list of autouse fixtures it defines.
+        self._nodeid_autousenames: Dict[str, List[str]] = {
+            "": self.config.getini("usefixtures"),
+        }
         session.config.pluginmanager.register(self, "funcmanage")

-    def _get_direct_parametrize_args(self, node: "nodes.Node") -> List[str]:
+    def _get_direct_parametrize_args(self, node: nodes.Node) -> List[str]:
         """Return all direct parametrization arguments of a node, so we don't
         mistake them for fixtures.

@@ -1432,7 +1408,7 @@
         These things are done later as well when dealing with parametrization
         so this could be improved.
         """
-        parametrize_argnames = []  # type: List[str]
+        parametrize_argnames: List[str] = []
         for marker in node.iter_markers(name="parametrize"):
             if not marker.kwargs.get("indirect", False):
                 p_argnames, _ = ParameterSet._parse_parametrize_args(
@@ -1443,7 +1419,7 @@
         return parametrize_argnames

     def getfixtureinfo(
-        self, node: "nodes.Node", func, cls, funcargs: bool = True
+        self, node: nodes.Node, func, cls, funcargs: bool = True
     ) -> FuncFixtureInfo:
         if funcargs and not getattr(node, "nofuncargs", False):
             argnames = getfuncargnames(func, name=node.name, cls=cls)
@@ -1467,8 +1443,6 @@
         except AttributeError:
             pass
         else:
-            from _pytest import nodes
-
             # Construct the base nodeid which is later used to check
             # what fixtures are visible for particular tests (as denoted
             # by their test id).
@@ -1484,21 +1458,18 @@

         self.parsefactories(plugin, nodeid)

-    def _getautousenames(self, nodeid: str) -> List[str]:
-        """Return a list of fixture names to be used."""
-        autousenames = []  # type: List[str]
-        for baseid, basenames in self._nodeid_and_autousenames:
-            if nodeid.startswith(baseid):
-                if baseid:
-                    i = len(baseid)
-                    nextchar = nodeid[i : i + 1]
-                    if nextchar and nextchar not in ":/":
-                        continue
-                autousenames.extend(basenames)
-        return autousenames
+    def _getautousenames(self, nodeid: str) -> Iterator[str]:
+        """Return the names of autouse fixtures applicable to nodeid."""
+        for parentnodeid in nodes.iterparentnodeids(nodeid):
+            basenames = self._nodeid_autousenames.get(parentnodeid)
+            if basenames:
+                yield from basenames

     def getfixtureclosure(
-        self, fixturenames: Tuple[str, ...], parentnode, ignore_args: Sequence[str] = ()
+        self,
+        fixturenames: Tuple[str, ...],
+        parentnode: nodes.Node,
+        ignore_args: Sequence[str] = (),
     ) -> Tuple[Tuple[str, ...], List[str], Dict[str, Sequence[FixtureDef[Any]]]]:
         # Collect the closure of all fixtures, starting with the given
         # fixturenames as the initial set.  As we have to visit all
@@ -1508,7 +1479,7 @@
         # (discovering matching fixtures for a given name/node is expensive).

         parentid = parentnode.nodeid
-        fixturenames_closure = self._getautousenames(parentid)
+        fixturenames_closure = list(self._getautousenames(parentid))

         def merge(otherlist: Iterable[str]) -> None:
             for arg in otherlist:
@@ -1522,7 +1493,7 @@
         # need to return it as well, so save this.
         initialnames = tuple(fixturenames_closure)

-        arg2fixturedefs = {}  # type: Dict[str, Sequence[FixtureDef[Any]]]
+        arg2fixturedefs: Dict[str, Sequence[FixtureDef[Any]]] = {}
         lastlen = -1
         while lastlen != len(fixturenames_closure):
             lastlen = len(fixturenames_closure)
@@ -1536,15 +1507,15 @@
                     arg2fixturedefs[argname] = fixturedefs
                     merge(fixturedefs[-1].argnames)

-        def sort_by_scope(arg_name: str) -> int:
+        def sort_by_scope(arg_name: str) -> Scope:
             try:
                 fixturedefs = arg2fixturedefs[arg_name]
             except KeyError:
-                return scopes.index("function")
+                return Scope.Function
             else:
-                return fixturedefs[-1].scopenum
-
-        fixturenames_closure.sort(key=sort_by_scope)
+                return fixturedefs[-1]._scope
+
+        fixturenames_closure.sort(key=sort_by_scope, reverse=True)
         return initialnames, fixturenames_closure, arg2fixturedefs

     def pytest_generate_tests(self, metafunc: "Metafunc") -> None:
@@ -1592,7 +1563,7 @@

                 # Try next super fixture, if any.

-    def pytest_collection_modifyitems(self, items: "List[nodes.Item]") -> None:
+    def pytest_collection_modifyitems(self, items: List[nodes.Item]) -> None:
         # Separate parametrized setups.
         items[:] = reorder_items(items)

@@ -1610,6 +1581,11 @@
         self._holderobjseen.add(holderobj)
         autousenames = []
         for name in dir(holderobj):
+            # ugly workaround for one of the fspath deprecated property of node
+            # todo: safely generalize
+            if isinstance(holderobj, nodes.Node) and name == "fspath":
+                continue
+
             # The attribute can be an arbitrary descriptor, so the attribute
             # access below can raise. safe_getatt() ignores such exceptions.
             obj = safe_getattr(holderobj, name, None)
@@ -1653,7 +1629,7 @@
                 autousenames.append(name)

         if autousenames:
-            self._nodeid_and_autousenames.append((nodeid or "", autousenames))
+            self._nodeid_autousenames.setdefault(nodeid or "", []).extend(autousenames)

     def getfixturedefs(
         self, argname: str, nodeid: str
@@ -1673,8 +1649,7 @@
     def _matchfactories(
         self, fixturedefs: Iterable[FixtureDef[Any]], nodeid: str
     ) -> Iterator[FixtureDef[Any]]:
-        from _pytest import nodes
-
+        parentnodeids = set(nodes.iterparentnodeids(nodeid))
         for fixturedef in fixturedefs:
-            if nodes.ischildnode(fixturedef.baseid, nodeid):
+            if fixturedef.baseid in parentnodeids:
                 yield fixturedef
('src/_pytest', 'cacheprovider.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -3,6 +3,7 @@
 # pytest-cache version.
 import json
 import os
+from pathlib import Path
 from typing import Dict
 from typing import Generator
 from typing import Iterable
@@ -12,20 +13,19 @@
 from typing import Union

 import attr
-import py
-
-import pytest
-from .pathlib import Path
+
 from .pathlib import resolve_from_str
 from .pathlib import rm_rf
 from .reports import CollectReport
 from _pytest import nodes
 from _pytest._io import TerminalWriter
 from _pytest.compat import final
-from _pytest.compat import order_preserving_dict
 from _pytest.config import Config
 from _pytest.config import ExitCode
+from _pytest.config import hookimpl
 from _pytest.config.argparsing import Parser
+from _pytest.deprecated import check_ispytest
+from _pytest.fixtures import fixture
 from _pytest.fixtures import FixtureRequest
 from _pytest.main import Session
 from _pytest.python import Module
@@ -41,49 +41,75 @@

 **Do not** commit this to version control.

-See [the docs](https://docs.pytest.org/en/stable/cache.html) for more information.
+See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.
 """

 CACHEDIR_TAG_CONTENT = b"""\
 Signature: 8a477f597d28d172789f06886806bc55
 # This file is a cache directory tag created by pytest.
 # For information about cache directory tags, see:
-#	http://www.bford.info/cachedir/spec.html
+#	https://bford.info/cachedir/spec.html
 """


 @final
-@attr.s
+@attr.s(init=False, auto_attribs=True)
 class Cache:
-    _cachedir = attr.ib(type=Path, repr=False)
-    _config = attr.ib(type=Config, repr=False)
-
-    # sub-directory under cache-dir for directories created by "makedir"
+    _cachedir: Path = attr.ib(repr=False)
+    _config: Config = attr.ib(repr=False)
+
+    # Sub-directory under cache-dir for directories created by `mkdir()`.
     _CACHE_PREFIX_DIRS = "d"

-    # sub-directory under cache-dir for values created by "set"
+    # Sub-directory under cache-dir for values created by `set()`.
     _CACHE_PREFIX_VALUES = "v"

+    def __init__(
+        self, cachedir: Path, config: Config, *, _ispytest: bool = False
+    ) -> None:
+        check_ispytest(_ispytest)
+        self._cachedir = cachedir
+        self._config = config
+
     @classmethod
-    def for_config(cls, config: Config) -> "Cache":
-        cachedir = cls.cache_dir_from_config(config)
+    def for_config(cls, config: Config, *, _ispytest: bool = False) -> "Cache":
+        """Create the Cache instance for a Config.
+
+        :meta private:
+        """
+        check_ispytest(_ispytest)
+        cachedir = cls.cache_dir_from_config(config, _ispytest=True)
         if config.getoption("cacheclear") and cachedir.is_dir():
-            cls.clear_cache(cachedir)
-        return cls(cachedir, config)
+            cls.clear_cache(cachedir, _ispytest=True)
+        return cls(cachedir, config, _ispytest=True)

     @classmethod
-    def clear_cache(cls, cachedir: Path) -> None:
-        """Clear the sub-directories used to hold cached directories and values."""
+    def clear_cache(cls, cachedir: Path, _ispytest: bool = False) -> None:
+        """Clear the sub-directories used to hold cached directories and values.
+
+        :meta private:
+        """
+        check_ispytest(_ispytest)
         for prefix in (cls._CACHE_PREFIX_DIRS, cls._CACHE_PREFIX_VALUES):
             d = cachedir / prefix
             if d.is_dir():
                 rm_rf(d)

     @staticmethod
-    def cache_dir_from_config(config: Config) -> Path:
+    def cache_dir_from_config(config: Config, *, _ispytest: bool = False) -> Path:
+        """Get the path to the cache directory for a Config.
+
+        :meta private:
+        """
+        check_ispytest(_ispytest)
         return resolve_from_str(config.getini("cache_dir"), config.rootpath)

-    def warn(self, fmt: str, **args: object) -> None:
+    def warn(self, fmt: str, *, _ispytest: bool = False, **args: object) -> None:
+        """Issue a cache warning.
+
+        :meta private:
+        """
+        check_ispytest(_ispytest)
         import warnings
         from _pytest.warning_types import PytestCacheWarning

@@ -93,12 +119,14 @@
             stacklevel=3,
         )

-    def makedir(self, name: str) -> py.path.local:
+    def mkdir(self, name: str) -> Path:
         """Return a directory path object with the given name.

         If the directory does not yet exist, it will be created. You can use
         it to manage files to e.g. store/retrieve database dumps across test
         sessions.
+
+        .. versionadded:: 7.0

         :param name:
             Must be a string not containing a ``/`` separator.
@@ -110,7 +138,7 @@
             raise ValueError("name is not allowed to contain path separators")
         res = self._cachedir.joinpath(self._CACHE_PREFIX_DIRS, path)
         res.mkdir(exist_ok=True, parents=True)
-        return py.path.local(res)
+        return res

     def _getvaluepath(self, key: str) -> Path:
         return self._cachedir.joinpath(self._CACHE_PREFIX_VALUES, Path(key))
@@ -152,15 +180,15 @@
                 cache_dir_exists_already = self._cachedir.exists()
                 path.parent.mkdir(exist_ok=True, parents=True)
         except OSError:
-            self.warn("could not create cache path {path}", path=path)
+            self.warn("could not create cache path {path}", path=path, _ispytest=True)
             return
         if not cache_dir_exists_already:
             self._ensure_supporting_files()
-        data = json.dumps(value, indent=2, sort_keys=True)
+        data = json.dumps(value, indent=2)
         try:
             f = path.open("w")
         except OSError:
-            self.warn("cache could not write path {path}", path=path)
+            self.warn("cache could not write path {path}", path=path, _ispytest=True)
         else:
             with f:
                 f.write(data)
@@ -183,21 +211,25 @@
         self.lfplugin = lfplugin
         self._collected_at_least_one_failure = False

-    @pytest.hookimpl(hookwrapper=True)
+    @hookimpl(hookwrapper=True)
     def pytest_make_collect_report(self, collector: nodes.Collector):
         if isinstance(collector, Session):
             out = yield
-            res = out.get_result()  # type: CollectReport
+            res: CollectReport = out.get_result()

             # Sort any lf-paths to the beginning.
             lf_paths = self.lfplugin._last_failed_paths
+
             res.result = sorted(
-                res.result, key=lambda x: 0 if Path(str(x.fspath)) in lf_paths else 1,
+                res.result,
+                # use stable sort to priorize last failed
+                key=lambda x: x.path in lf_paths,
+                reverse=True,
             )
             return

         elif isinstance(collector, Module):
-            if Path(str(collector.fspath)) in self.lfplugin._last_failed_paths:
+            if collector.path in self.lfplugin._last_failed_paths:
                 out = yield
                 res = out.get_result()
                 result = res.result
@@ -218,7 +250,7 @@
                     for x in result
                     if x.nodeid in lastfailed
                     # Include any passed arguments (not trivial to filter).
-                    or session.isinitpath(x.fspath)
+                    or session.isinitpath(x.path)
                     # Keep all sub-collectors.
                     or isinstance(x, nodes.Collector)
                 ]
@@ -230,7 +262,7 @@
     def __init__(self, lfplugin: "LFPlugin") -> None:
         self.lfplugin = lfplugin

-    @pytest.hookimpl
+    @hookimpl
     def pytest_make_collect_report(
         self, collector: nodes.Collector
     ) -> Optional[CollectReport]:
@@ -238,7 +270,7 @@
         # test-bearing paths and doesn't try to include the paths of their
         # packages, so don't filter them.
         if isinstance(collector, Module) and not isinstance(collector, Package):
-            if Path(str(collector.fspath)) not in self.lfplugin._last_failed_paths:
+            if collector.path not in self.lfplugin._last_failed_paths:
                 self.lfplugin._skipped_files += 1

                 return CollectReport(
@@ -255,11 +287,9 @@
         active_keys = "lf", "failedfirst"
         self.active = any(config.getoption(key) for key in active_keys)
         assert config.cache
-        self.lastfailed = config.cache.get(
-            "cache/lastfailed", {}
-        )  # type: Dict[str, bool]
-        self._previously_failed_count = None  # type: Optional[int]
-        self._report_status = None  # type: Optional[str]
+        self.lastfailed: Dict[str, bool] = config.cache.get("cache/lastfailed", {})
+        self._previously_failed_count: Optional[int] = None
+        self._report_status: Optional[str] = None
         self._skipped_files = 0  # count skipped files during collection due to --lf

         if config.getoption("lf"):
@@ -294,7 +324,7 @@
         else:
             self.lastfailed[report.nodeid] = True

-    @pytest.hookimpl(hookwrapper=True, tryfirst=True)
+    @hookimpl(hookwrapper=True, tryfirst=True)
     def pytest_collection_modifyitems(
         self, config: Config, items: List[nodes.Item]
     ) -> Generator[None, None, None]:
@@ -366,15 +396,15 @@
         assert config.cache is not None
         self.cached_nodeids = set(config.cache.get("cache/nodeids", []))

-    @pytest.hookimpl(hookwrapper=True, tryfirst=True)
+    @hookimpl(hookwrapper=True, tryfirst=True)
     def pytest_collection_modifyitems(
         self, items: List[nodes.Item]
     ) -> Generator[None, None, None]:
         yield

         if self.active:
-            new_items = order_preserving_dict()  # type: Dict[str, nodes.Item]
-            other_items = order_preserving_dict()  # type: Dict[str, nodes.Item]
+            new_items: Dict[str, nodes.Item] = {}
+            other_items: Dict[str, nodes.Item] = {}
             for item in items:
                 if item.nodeid not in self.cached_nodeids:
                     new_items[item.nodeid] = item
@@ -389,7 +419,7 @@
             self.cached_nodeids.update(item.nodeid for item in items)

     def _get_increasing_order(self, items: Iterable[nodes.Item]) -> List[nodes.Item]:
-        return sorted(items, key=lambda item: item.fspath.mtime(), reverse=True)
+        return sorted(items, key=lambda item: item.path.stat().st_mtime, reverse=True)  # type: ignore[no-any-return]

     def pytest_sessionfinish(self) -> None:
         config = self.config
@@ -469,14 +499,14 @@
     return None


-@pytest.hookimpl(tryfirst=True)
+@hookimpl(tryfirst=True)
 def pytest_configure(config: Config) -> None:
-    config.cache = Cache.for_config(config)
+    config.cache = Cache.for_config(config, _ispytest=True)
     config.pluginmanager.register(LFPlugin(config), "lfplugin")
     config.pluginmanager.register(NFPlugin(config), "nfplugin")


-@pytest.fixture
+@fixture
 def cache(request: FixtureRequest) -> Cache:
     """Return a cache object that can persist state between testing sessions.

@@ -504,7 +534,7 @@
             displaypath = cachedir.relative_to(config.rootpath)
         except ValueError:
             displaypath = cachedir
-        return "cachedir: {}".format(displaypath)
+        return f"cachedir: {displaypath}"
     return None


@@ -542,9 +572,9 @@
         contents = sorted(ddir.rglob(glob))
         tw.sep("-", "cache directories for %r" % glob)
         for p in contents:
-            # if p.check(dir=1):
-            #    print("%s/" % p.relto(basedir))
+            # if p.is_dir():
+            #    print("%s/" % p.relative_to(basedir))
             if p.is_file():
                 key = str(p.relative_to(basedir))
-                tw.line("{} is a file of length {:d}".format(key, p.stat().st_size))
+                tw.line(f"{key} is a file of length {p.stat().st_size:d}")
     return 0
('src/_pytest', 'warning_types.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,14 +1,11 @@
 from typing import Any
 from typing import Generic
+from typing import Type
 from typing import TypeVar

 import attr

 from _pytest.compat import final
-from _pytest.compat import TYPE_CHECKING
-
-if TYPE_CHECKING:
-    from typing import Type  # noqa: F401 (used in type string)


 class PytestWarning(UserWarning):
@@ -45,9 +42,15 @@
     __module__ = "pytest"


-@final
 class PytestDeprecationWarning(PytestWarning, DeprecationWarning):
     """Warning class for features that will be removed in a future version."""
+
+    __module__ = "pytest"
+
+
+@final
+class PytestRemovedIn8Warning(PytestDeprecationWarning):
+    """Warning class for features that will be removed in pytest 8."""

     __module__ = "pytest"

@@ -93,11 +96,33 @@
     __module__ = "pytest"


+@final
+class PytestUnraisableExceptionWarning(PytestWarning):
+    """An unraisable exception was reported.
+
+    Unraisable exceptions are exceptions raised in :meth:`__del__ <object.__del__>`
+    implementations and similar situations when the exception cannot be raised
+    as normal.
+    """
+
+    __module__ = "pytest"
+
+
+@final
+class PytestUnhandledThreadExceptionWarning(PytestWarning):
+    """An unhandled exception occurred in a :class:`~threading.Thread`.
+
+    Such exceptions don't propagate normally.
+    """
+
+    __module__ = "pytest"
+
+
 _W = TypeVar("_W", bound=PytestWarning)


 @final
-@attr.s
+@attr.s(auto_attribs=True)
 class UnformattedWarning(Generic[_W]):
     """A warning meant to be formatted during runtime.

@@ -105,12 +130,9 @@
     as opposed to a direct message.
     """

-    category = attr.ib(type="Type[_W]")
-    template = attr.ib(type=str)
+    category: Type["_W"]
+    template: str

     def format(self, **kwargs: Any) -> _W:
         """Return an instance of the warning category, formatted with given kwargs."""
         return self.category(self.template.format(**kwargs))
-
-
-PYTESTER_COPY_EXAMPLE = PytestExperimentalApiWarning.simple("testdir.copy_example")
('src/_pytest/config', '__init__.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,7 +1,6 @@
 """Command line options, ini-file and conftest.py processing."""
 import argparse
 import collections.abc
-import contextlib
 import copy
 import enum
 import inspect
@@ -12,9 +11,12 @@
 import types
 import warnings
 from functools import lru_cache
+from pathlib import Path
+from textwrap import dedent
 from types import TracebackType
 from typing import Any
 from typing import Callable
+from typing import cast
 from typing import Dict
 from typing import Generator
 from typing import IO
@@ -26,10 +28,11 @@
 from typing import Set
 from typing import TextIO
 from typing import Tuple
+from typing import Type
+from typing import TYPE_CHECKING
 from typing import Union

 import attr
-import py
 from pluggy import HookimplMarker
 from pluggy import HookspecMarker
 from pluggy import PluginManager
@@ -45,18 +48,17 @@
 from _pytest._io import TerminalWriter
 from _pytest.compat import final
 from _pytest.compat import importlib_metadata
-from _pytest.compat import TYPE_CHECKING
 from _pytest.outcomes import fail
 from _pytest.outcomes import Skipped
+from _pytest.pathlib import absolutepath
 from _pytest.pathlib import bestrelpath
 from _pytest.pathlib import import_path
 from _pytest.pathlib import ImportMode
-from _pytest.pathlib import Path
-from _pytest.store import Store
+from _pytest.pathlib import resolve_package_path
+from _pytest.stash import Stash
 from _pytest.warning_types import PytestConfigWarning

 if TYPE_CHECKING:
-    from typing import Type

     from _pytest._code.code import _TracebackStyle
     from _pytest.terminal import TerminalReporter
@@ -103,8 +105,8 @@
 class ConftestImportFailure(Exception):
     def __init__(
         self,
-        path: py.path.local,
-        excinfo: Tuple["Type[Exception]", Exception, TracebackType],
+        path: Path,
+        excinfo: Tuple[Type[Exception], Exception, TracebackType],
     ) -> None:
         super().__init__(path, excinfo)
         self.path = path
@@ -128,7 +130,7 @@


 def main(
-    args: Optional[Union[List[str], py.path.local]] = None,
+    args: Optional[Union[List[str], "os.PathLike[str]"]] = None,
     plugins: Optional[Sequence[Union[str, _PluggyPlugin]]] = None,
 ) -> Union[int, ExitCode]:
     """Perform an in-process test run.
@@ -142,11 +144,9 @@
         try:
             config = _prepareconfig(args, plugins)
         except ConftestImportFailure as e:
-            exc_info = ExceptionInfo(e.excinfo)
+            exc_info = ExceptionInfo.from_exc_info(e.excinfo)
             tw = TerminalWriter(sys.stderr)
-            tw.line(
-                "ImportError while loading conftest '{e.path}'.".format(e=e), red=True
-            )
+            tw.line(f"ImportError while loading conftest '{e.path}'.", red=True)
             exc_info.traceback = exc_info.traceback.filter(
                 filter_traceback_for_conftest_import_failure
             )
@@ -161,9 +161,9 @@
             return ExitCode.USAGE_ERROR
         else:
             try:
-                ret = config.hook.pytest_cmdline_main(
+                ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(
                     config=config
-                )  # type: Union[ExitCode, int]
+                )
                 try:
                     return ExitCode(ret)
                 except ValueError:
@@ -173,7 +173,7 @@
     except UsageError as e:
         tw = TerminalWriter(sys.stderr)
         for msg in e.args:
-            tw.line("ERROR: {}\n".format(msg), red=True)
+            tw.line(f"ERROR: {msg}\n", red=True)
         return ExitCode.USAGE_ERROR


@@ -206,7 +206,7 @@
     :optname: Name of the option.
     """
     if os.path.isdir(path):
-        raise UsageError("{} must be a filename, given: {}".format(optname, path))
+        raise UsageError(f"{optname} must be a filename, given: {path}")
     return path


@@ -217,7 +217,7 @@
     :optname: Name of the option.
     """
     if not os.path.isdir(path):
-        raise UsageError("{} must be a directory, given: {}".format(optname, path))
+        raise UsageError(f"{optname} must be a directory, given: {path}")
     return path


@@ -237,6 +237,7 @@
     "unittest",
     "capture",
     "skipping",
+    "legacypath",
     "tmpdir",
     "monkeypatch",
     "recwarn",
@@ -253,11 +254,14 @@
     "warnings",
     "logging",
     "reports",
+    "python_path",
+    *(["unraisableexception", "threadexception"] if sys.version_info >= (3, 8) else []),
     "faulthandler",
 )

 builtin_plugins = set(default_plugins)
 builtin_plugins.add("pytester")
+builtin_plugins.add("pytester_assertions")


 def get_config(
@@ -269,7 +273,9 @@
     config = Config(
         pluginmanager,
         invocation_params=Config.InvocationParams(
-            args=args or (), plugins=plugins, dir=Path.cwd(),
+            args=args or (),
+            plugins=plugins,
+            dir=Path.cwd(),
         ),
     )

@@ -285,7 +291,7 @@

 def get_plugin_manager() -> "PytestPluginManager":
     """Obtain a new instance of the
-    :py:class:`_pytest.config.PytestPluginManager`, with default plugins
+    :py:class:`pytest.PytestPluginManager`, with default plugins
     already loaded.

     This function can be used by integration with other tools, like hooking
@@ -295,13 +301,13 @@


 def _prepareconfig(
-    args: Optional[Union[py.path.local, List[str]]] = None,
+    args: Optional[Union[List[str], "os.PathLike[str]"]] = None,
     plugins: Optional[Sequence[Union[str, _PluggyPlugin]]] = None,
 ) -> "Config":
     if args is None:
         args = sys.argv[1:]
-    elif isinstance(args, py.path.local):
-        args = [str(args)]
+    elif isinstance(args, os.PathLike):
+        args = [os.fspath(args)]
     elif not isinstance(args, list):
         msg = "`args` parameter expected to be a list of strings, got: {!r} (type: {})"
         raise TypeError(msg.format(args, type(args)))
@@ -324,6 +330,14 @@
         raise


+def _get_directory(path: Path) -> Path:
+    """Get the directory of a path - itself if already a directory."""
+    if path.is_file():
+        return path.parent
+    else:
+        return path
+
+
 @final
 class PytestPluginManager(PluginManager):
     """A :py:class:`pluggy.PluginManager <pluggy.PluginManager>` with
@@ -338,31 +352,44 @@
         import _pytest.assertion

         super().__init__("pytest")
-        # The objects are module objects, only used generically.
-        self._conftest_plugins = set()  # type: Set[types.ModuleType]
-
-        # State related to local conftest plugins.
-        self._dirpath2confmods = {}  # type: Dict[py.path.local, List[types.ModuleType]]
-        self._conftestpath2mod = {}  # type: Dict[Path, types.ModuleType]
-        self._confcutdir = None  # type: Optional[py.path.local]
+
+        # -- State related to local conftest plugins.
+        # All loaded conftest modules.
+        self._conftest_plugins: Set[types.ModuleType] = set()
+        # All conftest modules applicable for a directory.
+        # This includes the directory's own conftest modules as well
+        # as those of its parent directories.
+        self._dirpath2confmods: Dict[Path, List[types.ModuleType]] = {}
+        # Cutoff directory above which conftests are no longer discovered.
+        self._confcutdir: Optional[Path] = None
+        # If set, conftest loading is skipped.
         self._noconftest = False
-        self._duplicatepaths = set()  # type: Set[py.path.local]
+
+        # _getconftestmodules()'s call to _get_directory() causes a stat
+        # storm when it's called potentially thousands of times in a test
+        # session (#9478), often with the same path, so cache it.
+        self._get_directory = lru_cache(256)(_get_directory)
+
+        self._duplicatepaths: Set[Path] = set()

         # plugins that were explicitly skipped with pytest.skip
         # list of (module name, skip reason)
         # previously we would issue a warning when a plugin was skipped, but
         # since we refactored warnings as first citizens of Config, they are
         # just stored here to be used later.
-        self.skipped_plugins = []  # type: List[Tuple[str, str]]
+        self.skipped_plugins: List[Tuple[str, str]] = []

         self.add_hookspecs(_pytest.hookspec)
         self.register(self)
         if os.environ.get("PYTEST_DEBUG"):
-            err = sys.stderr  # type: IO[str]
-            encoding = getattr(err, "encoding", "utf8")  # type: str
+            err: IO[str] = sys.stderr
+            encoding: str = getattr(err, "encoding", "utf8")
             try:
                 err = open(
-                    os.dup(err.fileno()), mode=err.mode, buffering=1, encoding=encoding,
+                    os.dup(err.fileno()),
+                    mode=err.mode,
+                    buffering=1,
+                    encoding=encoding,
                 )
             except Exception:
                 pass
@@ -433,7 +460,7 @@
                 )
             )
             return None
-        ret = super().register(plugin, name)  # type: Optional[str]
+        ret: Optional[str] = super().register(plugin, name)
         if ret:
             self.hook.pytest_plugin_registered.call_historic(
                 kwargs=dict(plugin=plugin, manager=self)
@@ -445,7 +472,7 @@

     def getplugin(self, name: str):
         # Support deprecated naming because plugins (xdist e.g.) use it.
-        plugin = self.get_plugin(name)  # type: Optional[_PluggyPlugin]
+        plugin: Optional[_PluggyPlugin] = self.get_plugin(name)
         return plugin

     def hasplugin(self, name: str) -> bool:
@@ -471,7 +498,9 @@
     #
     # Internal API for local conftest plugin handling.
     #
-    def _set_initial_conftests(self, namespace: argparse.Namespace) -> None:
+    def _set_initial_conftests(
+        self, namespace: argparse.Namespace, rootpath: Path
+    ) -> None:
         """Load initial conftest files given a preparsed "namespace".

         As conftest files may add their own command line options which have
@@ -479,9 +508,9 @@
         All builtin and 3rd party plugins will have been loaded, however, so
         common options will not confuse our logic here.
         """
-        current = py.path.local()
+        current = Path.cwd()
         self._confcutdir = (
-            current.join(namespace.confcutdir, abs=True)
+            absolutepath(current / namespace.confcutdir)
             if namespace.confcutdir
             else None
         )
@@ -495,53 +524,67 @@
             i = path.find("::")
             if i != -1:
                 path = path[:i]
-            anchor = current.join(path, abs=1)
+            anchor = absolutepath(current / path)
             if anchor.exists():  # we found some file object
-                self._try_load_conftest(anchor, namespace.importmode)
+                self._try_load_conftest(anchor, namespace.importmode, rootpath)
                 foundanchor = True
         if not foundanchor:
-            self._try_load_conftest(current, namespace.importmode)
+            self._try_load_conftest(current, namespace.importmode, rootpath)
+
+    def _is_in_confcutdir(self, path: Path) -> bool:
+        """Whether a path is within the confcutdir.
+
+        When false, should not load conftest.
+        """
+        if self._confcutdir is None:
+            return True
+        return path not in self._confcutdir.parents

     def _try_load_conftest(
-        self, anchor: py.path.local, importmode: Union[str, ImportMode]
+        self, anchor: Path, importmode: Union[str, ImportMode], rootpath: Path
     ) -> None:
-        self._getconftestmodules(anchor, importmode)
+        self._getconftestmodules(anchor, importmode, rootpath)
         # let's also consider test* subdirs
-        if anchor.check(dir=1):
-            for x in anchor.listdir("test*"):
-                if x.check(dir=1):
-                    self._getconftestmodules(x, importmode)
-
-    @lru_cache(maxsize=128)
+        if anchor.is_dir():
+            for x in anchor.glob("test*"):
+                if x.is_dir():
+                    self._getconftestmodules(x, importmode, rootpath)
+
     def _getconftestmodules(
-        self, path: py.path.local, importmode: Union[str, ImportMode],
-    ) -> List[types.ModuleType]:
+        self, path: Path, importmode: Union[str, ImportMode], rootpath: Path
+    ) -> Sequence[types.ModuleType]:
         if self._noconftest:
             return []

-        if path.isfile():
-            directory = path.dirpath()
-        else:
-            directory = path
+        directory = self._get_directory(path)
+
+        # Optimization: avoid repeated searches in the same directory.
+        # Assumes always called with same importmode and rootpath.
+        existing_clist = self._dirpath2confmods.get(directory)
+        if existing_clist is not None:
+            return existing_clist

         # XXX these days we may rather want to use config.rootpath
         # and allow users to opt into looking into the rootdir parent
         # directories instead of requiring to specify confcutdir.
         clist = []
-        for parent in directory.parts():
-            if self._confcutdir and self._confcutdir.relto(parent):
-                continue
-            conftestpath = parent.join("conftest.py")
-            if conftestpath.isfile():
-                mod = self._importconftest(conftestpath, importmode)
-                clist.append(mod)
+        for parent in reversed((directory, *directory.parents)):
+            if self._is_in_confcutdir(parent):
+                conftestpath = parent / "conftest.py"
+                if conftestpath.is_file():
+                    mod = self._importconftest(conftestpath, importmode, rootpath)
+                    clist.append(mod)
         self._dirpath2confmods[directory] = clist
         return clist

     def _rget_with_confmod(
-        self, name: str, path: py.path.local, importmode: Union[str, ImportMode],
+        self,
+        name: str,
+        path: Path,
+        importmode: Union[str, ImportMode],
+        rootpath: Path,
     ) -> Tuple[types.ModuleType, Any]:
-        modules = self._getconftestmodules(path, importmode)
+        modules = self._getconftestmodules(path, importmode, rootpath=rootpath)
         for mod in reversed(modules):
             try:
                 return mod, getattr(mod, name)
@@ -550,24 +593,18 @@
         raise KeyError(name)

     def _importconftest(
-        self, conftestpath: py.path.local, importmode: Union[str, ImportMode],
+        self, conftestpath: Path, importmode: Union[str, ImportMode], rootpath: Path
     ) -> types.ModuleType:
-        # Use a resolved Path object as key to avoid loading the same conftest
-        # twice with build systems that create build directories containing
-        # symlinks to actual files.
-        # Using Path().resolve() is better than py.path.realpath because
-        # it resolves to the correct path/drive in case-insensitive file systems (#5792)
-        key = Path(str(conftestpath)).resolve()
-
-        with contextlib.suppress(KeyError):
-            return self._conftestpath2mod[key]
-
-        pkgpath = conftestpath.pypkgpath()
+        existing = self.get_plugin(str(conftestpath))
+        if existing is not None:
+            return cast(types.ModuleType, existing)
+
+        pkgpath = resolve_package_path(conftestpath)
         if pkgpath is None:
-            _ensure_removed_sysmodule(conftestpath.purebasename)
+            _ensure_removed_sysmodule(conftestpath.stem)

         try:
-            mod = import_path(conftestpath, mode=importmode)
+            mod = import_path(conftestpath, mode=importmode, root=rootpath)
         except Exception as e:
             assert e.__traceback__ is not None
             exc_info = (type(e), e, e.__traceback__)
@@ -576,19 +613,20 @@
         self._check_non_top_pytest_plugins(mod, conftestpath)

         self._conftest_plugins.add(mod)
-        self._conftestpath2mod[key] = mod
-        dirpath = conftestpath.dirpath()
+        dirpath = conftestpath.parent
         if dirpath in self._dirpath2confmods:
             for path, mods in self._dirpath2confmods.items():
-                if path and path.relto(dirpath) or path == dirpath:
+                if dirpath in path.parents or path == dirpath:
                     assert mod not in mods
                     mods.append(mod)
-        self.trace("loading conftestmodule {!r}".format(mod))
+        self.trace(f"loading conftestmodule {mod!r}")
         self.consider_conftest(mod)
         return mod

     def _check_non_top_pytest_plugins(
-        self, mod: types.ModuleType, conftestpath: py.path.local,
+        self,
+        mod: types.ModuleType,
+        conftestpath: Path,
     ) -> None:
         if (
             hasattr(mod, "pytest_plugins")
@@ -614,6 +652,7 @@
     def consider_preparse(
         self, args: Sequence[str], *, exclude_only: bool = False
     ) -> None:
+        """:meta private:"""
         i = 0
         n = len(args)
         while i < n:
@@ -635,6 +674,7 @@
                 self.consider_pluginarg(parg)

     def consider_pluginarg(self, arg: str) -> None:
+        """:meta private:"""
         if arg.startswith("no:"):
             name = arg[3:]
             if name in essential_plugins:
@@ -660,12 +700,15 @@
             self.import_plugin(arg, consider_entry_points=True)

     def consider_conftest(self, conftestmodule: types.ModuleType) -> None:
+        """:meta private:"""
         self.register(conftestmodule, name=conftestmodule.__file__)

     def consider_env(self) -> None:
+        """:meta private:"""
         self._import_plugin_specs(os.environ.get("PYTEST_PLUGINS"))

     def consider_module(self, mod: types.ModuleType) -> None:
+        """:meta private:"""
         self._import_plugin_specs(getattr(mod, "pytest_plugins", []))

     def _import_plugin_specs(
@@ -703,7 +746,7 @@
             __import__(importspec)
         except ImportError as e:
             raise ImportError(
-                'Error importing plugin "{}": {}'.format(modname, str(e.args[0]))
+                f'Error importing plugin "{modname}": {e.args[0]}'
             ).with_traceback(e.__traceback__) from e

         except Skipped as e:
@@ -823,6 +866,7 @@
     """Access to configuration values, pluginmanager and plugin hooks.

     :param PytestPluginManager pluginmanager:
+        A pytest PluginManager.

     :param InvocationParams invocation_params:
         Object containing parameters regarding the :func:`pytest.main`
@@ -830,7 +874,7 @@
     """

     @final
-    @attr.s(frozen=True)
+    @attr.s(frozen=True, auto_attribs=True)
     class InvocationParams:
         """Holds parameters passed during :func:`pytest.main`.

@@ -846,27 +890,18 @@
             Plugins accessing ``InvocationParams`` must be aware of that.
         """

-        args = attr.ib(type=Tuple[str, ...], converter=_args_converter)
-        """The command-line arguments as passed to :func:`pytest.main`.
-
-        :type: Tuple[str, ...]
-        """
-        plugins = attr.ib(type=Optional[Sequence[Union[str, _PluggyPlugin]]])
-        """Extra plugins, might be `None`.
-
-        :type: Optional[Sequence[Union[str, plugin]]]
-        """
-        dir = attr.ib(type=Path)
-        """The directory from which :func:`pytest.main` was invoked.
-
-        :type: pathlib.Path
-        """
+        args: Tuple[str, ...] = attr.ib(converter=_args_converter)
+        """The command-line arguments as passed to :func:`pytest.main`."""
+        plugins: Optional[Sequence[Union[str, _PluggyPlugin]]]
+        """Extra plugins, might be `None`."""
+        dir: Path
+        """The directory from which :func:`pytest.main` was invoked."""

     def __init__(
         self,
         pluginmanager: PytestPluginManager,
         *,
-        invocation_params: Optional[InvocationParams] = None
+        invocation_params: Optional[InvocationParams] = None,
     ) -> None:
         from .argparsing import Parser, FILE_OR_DIR

@@ -889,8 +924,9 @@

         _a = FILE_OR_DIR
         self._parser = Parser(
-            usage="%(prog)s [options] [{}] [{}] [...]".format(_a, _a),
+            usage=f"%(prog)s [options] [{_a}] [{_a}] [...]",
             processopt=self._processopt,
+            _ispytest=True,
         )
         self.pluginmanager = pluginmanager
         """The plugin manager handles plugin registration and hook invocation.
@@ -898,15 +934,23 @@
         :type: PytestPluginManager
         """

+        self.stash = Stash()
+        """A place where plugins can store information on the config for their
+        own use.
+
+        :type: Stash
+        """
+        # Deprecated alias. Was never public. Can be removed in a few releases.
+        self._store = self.stash
+
+        from .compat import PathAwareHookProxy
+
         self.trace = self.pluginmanager.trace.root.get("config")
-        self.hook = self.pluginmanager.hook
-        self._inicache = {}  # type: Dict[str, Any]
-        self._override_ini = ()  # type: Sequence[str]
-        self._opt2dest = {}  # type: Dict[str, str]
-        self._cleanup = []  # type: List[Callable[[], None]]
-        # A place where plugins can store information on the config for their
-        # own use. Currently only intended for internal plugins.
-        self._store = Store()
+        self.hook = PathAwareHookProxy(self.pluginmanager.hook)
+        self._inicache: Dict[str, Any] = {}
+        self._override_ini: Sequence[str] = ()
+        self._opt2dest: Dict[str, str] = {}
+        self._cleanup: List[Callable[[], None]] = []
         self.pluginmanager.register(self, "pytestconfig")
         self._configured = False
         self.hook.pytest_addoption.call_historic(
@@ -916,18 +960,7 @@
         if TYPE_CHECKING:
             from _pytest.cacheprovider import Cache

-            self.cache = None  # type: Optional[Cache]
-
-    @property
-    def invocation_dir(self) -> py.path.local:
-        """The directory from which pytest was invoked.
-
-        Prefer to use :attr:`invocation_params.dir <InvocationParams.dir>`,
-        which is a :class:`pathlib.Path`.
-
-        :type: py.path.local
-        """
-        return py.path.local(str(self.invocation_params.dir))
+            self.cache: Optional[Cache] = None

     @property
     def rootpath(self) -> Path:
@@ -940,16 +973,6 @@
         return self._rootpath

     @property
-    def rootdir(self) -> py.path.local:
-        """The path to the :ref:`rootdir <rootdir>`.
-
-        Prefer to use :attr:`rootpath`, which is a :class:`pathlib.Path`.
-
-        :type: py.path.local
-        """
-        return py.path.local(str(self.rootpath))
-
-    @property
     def inipath(self) -> Optional[Path]:
         """The path to the :ref:`configfile <configfiles>`.

@@ -959,19 +982,9 @@
         """
         return self._inipath

-    @property
-    def inifile(self) -> Optional[py.path.local]:
-        """The path to the :ref:`configfile <configfiles>`.
-
-        Prefer to use :attr:`inipath`, which is a :class:`pathlib.Path`.
-
-        :type: Optional[py.path.local]
-        """
-        return py.path.local(str(self.inipath)) if self.inipath else None
-
     def add_cleanup(self, func: Callable[[], None]) -> None:
         """Add a function to be called when the config object gets out of
-        use (usually coninciding with pytest_unconfigure)."""
+        use (usually coinciding with pytest_unconfigure)."""
         self._cleanup.append(func)

     def _do_configure(self) -> None:
@@ -991,9 +1004,9 @@
             fin()

     def get_terminal_writer(self) -> TerminalWriter:
-        terminalreporter = self.pluginmanager.get_plugin(
+        terminalreporter: TerminalReporter = self.pluginmanager.get_plugin(
             "terminalreporter"
-        )  # type: TerminalReporter
+        )
         return terminalreporter._tw

     def pytest_cmdline_parse(
@@ -1028,7 +1041,7 @@
         option: Optional[argparse.Namespace] = None,
     ) -> None:
         if option and getattr(option, "fulltrace", False):
-            style = "long"  # type: _TracebackStyle
+            style: _TracebackStyle = "long"
         else:
             style = "native"
         excrepr = excinfo.getrepr(
@@ -1067,7 +1080,9 @@

     @hookimpl(trylast=True)
     def pytest_load_initial_conftests(self, early_config: "Config") -> None:
-        self.pluginmanager._set_initial_conftests(early_config.known_args_namespace)
+        self.pluginmanager._set_initial_conftests(
+            early_config.known_args_namespace, rootpath=early_config.rootpath
+        )

     def _initini(self, args: Sequence[str]) -> None:
         ns, unknown_args = self._parser.parse_known_and_unknown_args(
@@ -1179,6 +1194,11 @@
         self._validate_plugins()
         self._warn_about_skipped_plugins()

+        if self.known_args_namespace.strict:
+            self.issue_config_time_warning(
+                _pytest.deprecated.STRICT_OPTION, stacklevel=2
+            )
+
         if self.known_args_namespace.confcutdir is None and self.inipath is not None:
             confcutdir = str(self.inipath.parent)
             self.known_args_namespace.confcutdir = confcutdir
@@ -1191,9 +1211,7 @@
                 # we don't want to prevent --help/--version to work
                 # so just let is pass and print a warning at the end
                 self.issue_config_time_warning(
-                    PytestConfigWarning(
-                        "could not load initial conftests: {}".format(e.path)
-                    ),
+                    PytestConfigWarning(f"could not load initial conftests: {e.path}"),
                     stacklevel=2,
                 )
             else:
@@ -1201,8 +1219,8 @@

     @hookimpl(hookwrapper=True)
     def pytest_collection(self) -> Generator[None, None, None]:
-        """Validate invalid ini keys after collection is done so we take in account
-        options added by late-loading conftest files."""
+        # Validate invalid ini keys after collection is done so we take in account
+        # options added by late-loading conftest files.
         yield
         self._validate_config_options()

@@ -1222,12 +1240,16 @@
             if Version(minver) > Version(pytest.__version__):
                 raise pytest.UsageError(
                     "%s: 'minversion' requires pytest-%s, actual pytest-%s'"
-                    % (self.inipath, minver, pytest.__version__,)
+                    % (
+                        self.inipath,
+                        minver,
+                        pytest.__version__,
+                    )
                 )

     def _validate_config_options(self) -> None:
         for key in sorted(self._get_unknown_ini_keys()):
-            self._warn_or_fail_if_strict("Unknown config option: {}\n".format(key))
+            self._warn_or_fail_if_strict(f"Unknown config option: {key}\n")

     def _validate_plugins(self) -> None:
         required_plugins = sorted(self.getini("required_plugins"))
@@ -1244,14 +1266,16 @@
         missing_plugins = []
         for required_plugin in required_plugins:
             try:
-                spec = Requirement(required_plugin)
+                req = Requirement(required_plugin)
             except InvalidRequirement:
                 missing_plugins.append(required_plugin)
                 continue

-            if spec.name not in plugin_dist_info:
+            if req.name not in plugin_dist_info:
                 missing_plugins.append(required_plugin)
-            elif Version(plugin_dist_info[spec.name]) not in spec.specifier:
+            elif not req.specifier.contains(
+                Version(plugin_dist_info[req.name]), prereleases=True
+            ):
                 missing_plugins.append(required_plugin)

         if missing_plugins:
@@ -1320,14 +1344,6 @@
         if records:
             frame = sys._getframe(stacklevel - 1)
             location = frame.f_code.co_filename, frame.f_lineno, frame.f_code.co_name
-            self.hook.pytest_warning_captured.call_historic(
-                kwargs=dict(
-                    warning_message=records[0],
-                    when="config",
-                    item=None,
-                    location=location,
-                )
-            )
             self.hook.pytest_warning_recorded.call_historic(
                 kwargs=dict(
                     warning_message=records[0],
@@ -1349,8 +1365,8 @@
         """Return configuration value from an :ref:`ini file <configfiles>`.

         If the specified name hasn't been registered through a prior
-        :py:func:`parser.addini <_pytest.config.argparsing.Parser.addini>`
-        call (usually from a plugin), a ValueError is raised.
+        :func:`parser.addini <pytest.Parser.addini>` call (usually from a
+        plugin), a ValueError is raised.
         """
         try:
             return self._inicache[name]
@@ -1358,11 +1374,17 @@
             self._inicache[name] = val = self._getini(name)
             return val

+    # Meant for easy monkeypatching by legacypath plugin.
+    # Can be inlined back (with no cover removed) once legacypath is gone.
+    def _getini_unknown_type(self, name: str, type: str, value: Union[str, List[str]]):
+        msg = f"unknown configuration type: {type}"
+        raise ValueError(msg, value)  # pragma: no cover
+
     def _getini(self, name: str):
         try:
             description, type, default = self._parser._inidict[name]
         except KeyError as e:
-            raise ValueError("unknown configuration value: {!r}".format(name)) from e
+            raise ValueError(f"unknown configuration value: {name!r}") from e
         override_value = self._get_override_ini_value(name)
         if override_value is None:
             try:
@@ -1390,12 +1412,12 @@
         #     a_line_list = ["tests", "acceptance"]
         #   in this case, we already have a list ready to use.
         #
-        if type == "pathlist":
+        if type == "paths":
             # TODO: This assert is probably not valid in all cases.
             assert self.inipath is not None
             dp = self.inipath.parent
             input_values = shlex.split(value) if isinstance(value, str) else value
-            return [py.path.local(str(dp / x)) for x in input_values]
+            return [dp / x for x in input_values]
         elif type == "args":
             return shlex.split(value) if isinstance(value, str) else value
         elif type == "linelist":
@@ -1405,25 +1427,31 @@
                 return value
         elif type == "bool":
             return _strtobool(str(value).strip())
+        elif type == "string":
+            return value
+        elif type is None:
+            return value
         else:
-            assert type is None
-            return value
+            return self._getini_unknown_type(name, type, value)

     def _getconftest_pathlist(
-        self, name: str, path: py.path.local
-    ) -> Optional[List[py.path.local]]:
+        self, name: str, path: Path, rootpath: Path
+    ) -> Optional[List[Path]]:
         try:
             mod, relroots = self.pluginmanager._rget_with_confmod(
-                name, path, self.getoption("importmode")
+                name, path, self.getoption("importmode"), rootpath
             )
         except KeyError:
             return None
-        modpath = py.path.local(mod.__file__).dirpath()
-        values = []  # type: List[py.path.local]
+        assert mod.__file__ is not None
+        modpath = Path(mod.__file__).parent
+        values: List[Path] = []
         for relroot in relroots:
-            if not isinstance(relroot, py.path.local):
+            if isinstance(relroot, os.PathLike):
+                relroot = Path(relroot)
+            else:
                 relroot = relroot.replace("/", os.sep)
-                relroot = modpath.join(relroot, abs=True)
+                relroot = absolutepath(modpath / relroot)
             values.append(relroot)
         return values

@@ -1467,8 +1495,8 @@
             if skip:
                 import pytest

-                pytest.skip("no {!r} option found".format(name))
-            raise ValueError("no option named {!r}".format(name)) from e
+                pytest.skip(f"no {name!r} option found")
+            raise ValueError(f"no option named {name!r}") from e

     def getvalue(self, name: str, path=None):
         """Deprecated, use getoption() instead."""
@@ -1495,13 +1523,14 @@
                     "(are you using python -O?)\n"
                 )
             self.issue_config_time_warning(
-                PytestConfigWarning(warning_text), stacklevel=3,
+                PytestConfigWarning(warning_text),
+                stacklevel=3,
             )

     def _warn_about_skipped_plugins(self) -> None:
         for module_name, msg in self.pluginmanager.skipped_plugins:
             self.issue_config_time_warning(
-                PytestConfigWarning("skipped plugin {!r}: {}".format(module_name, msg)),
+                PytestConfigWarning(f"skipped plugin {module_name!r}: {msg}"),
                 stacklevel=2,
             )

@@ -1554,28 +1583,63 @@
     elif val in ("n", "no", "f", "false", "off", "0"):
         return False
     else:
-        raise ValueError("invalid truth value {!r}".format(val))
+        raise ValueError(f"invalid truth value {val!r}")


 @lru_cache(maxsize=50)
 def parse_warning_filter(
     arg: str, *, escape: bool
-) -> "Tuple[str, str, Type[Warning], str, int]":
+) -> Tuple["warnings._ActionKind", str, Type[Warning], str, int]:
     """Parse a warnings filter string.

-    This is copied from warnings._setoption, but does not apply the filter,
-    only parses it, and makes the escaping optional.
+    This is copied from warnings._setoption with the following changes:
+
+    * Does not apply the filter.
+    * Escaping is optional.
+    * Raises UsageError so we get nice error messages on failure.
     """
+    __tracebackhide__ = True
+    error_template = dedent(
+        f"""\
+        while parsing the following warning configuration:
+
+          {arg}
+
+        This error occurred:
+
+        {{error}}
+        """
+    )
+
     parts = arg.split(":")
     if len(parts) > 5:
-        raise warnings._OptionError("too many fields (max 5): {!r}".format(arg))
+        doc_url = (
+            "https://docs.python.org/3/library/warnings.html#describing-warning-filters"
+        )
+        error = dedent(
+            f"""\
+            Too many fields ({len(parts)}), expected at most 5 separated by colons:
+
+              action:message:category:module:line
+
+            For more information please consult: {doc_url}
+            """
+        )
+        raise UsageError(error_template.format(error=error))
+
     while len(parts) < 5:
         parts.append("")
-    action_, message, category_, module, lineno_ = [s.strip() for s in parts]
-    action = warnings._getaction(action_)  # type: str # type: ignore[attr-defined]
-    category = warnings._getcategory(
-        category_
-    )  # type: Type[Warning] # type: ignore[attr-defined]
+    action_, message, category_, module, lineno_ = (s.strip() for s in parts)
+    try:
+        action: "warnings._ActionKind" = warnings._getaction(action_)  # type: ignore[attr-defined]
+    except warnings._OptionError as e:
+        raise UsageError(error_template.format(error=str(e)))
+    try:
+        category: Type[Warning] = _resolve_warning_category(category_)
+    except Exception:
+        exc_info = ExceptionInfo.from_current()
+        exception_text = exc_info.getrepr(style="native")
+        raise UsageError(error_template.format(error=exception_text))
     if message and escape:
         message = re.escape(message)
     if module and escape:
@@ -1584,12 +1648,36 @@
         try:
             lineno = int(lineno_)
             if lineno < 0:
-                raise ValueError
-        except (ValueError, OverflowError) as e:
-            raise warnings._OptionError("invalid lineno {!r}".format(lineno_)) from e
+                raise ValueError("number is negative")
+        except ValueError as e:
+            raise UsageError(
+                error_template.format(error=f"invalid lineno {lineno_!r}: {e}")
+            )
     else:
         lineno = 0
     return action, message, category, module, lineno
+
+
+def _resolve_warning_category(category: str) -> Type[Warning]:
+    """
+    Copied from warnings._getcategory, but changed so it lets exceptions (specially ImportErrors)
+    propagate so we can get access to their tracebacks (#9218).
+    """
+    __tracebackhide__ = True
+    if not category:
+        return Warning
+
+    if "." not in category:
+        import builtins as m
+
+        klass = category
+    else:
+        module, _, klass = category.rpartition(".")
+        m = __import__(module, None, None, [klass])
+    cat = getattr(m, klass)
+    if not issubclass(cat, Warning):
+        raise UsageError(f"{cat} is not a Warning subclass")
+    return cast(Type[Warning], cat)


 def apply_warning_filters(
('src/_pytest/config', 'findpaths.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,20 +1,20 @@
 import os
+from pathlib import Path
 from typing import Dict
 from typing import Iterable
 from typing import List
 from typing import Optional
 from typing import Sequence
 from typing import Tuple
+from typing import TYPE_CHECKING
 from typing import Union

 import iniconfig

 from .exceptions import UsageError
-from _pytest.compat import TYPE_CHECKING
 from _pytest.outcomes import fail
 from _pytest.pathlib import absolutepath
 from _pytest.pathlib import commonpath
-from _pytest.pathlib import Path

 if TYPE_CHECKING:
     from . import Config
@@ -27,7 +27,7 @@
     Raise UsageError if the file cannot be parsed.
     """
     try:
-        return iniconfig.IniConfig(path)
+        return iniconfig.IniConfig(str(path))
     except iniconfig.ParseError as exc:
         raise UsageError(str(exc)) from exc

@@ -64,9 +64,13 @@

     # '.toml' files are considered if they contain a [tool.pytest.ini_options] table.
     elif filepath.suffix == ".toml":
-        import toml
-
-        config = toml.load(str(filepath))
+        import tomli
+
+        toml_text = filepath.read_text(encoding="utf-8")
+        try:
+            config = tomli.loads(toml_text)
+        except tomli.TOMLDecodeError as exc:
+            raise UsageError(f"{filepath}: {exc}") from exc

         result = config.get("tool", {}).get("pytest", {}).get("ini_options", None)
         if result is not None:
@@ -83,9 +87,7 @@

 def locate_config(
     args: Iterable[Path],
-) -> Tuple[
-    Optional[Path], Optional[Path], Dict[str, Union[str, List[str]]],
-]:
+) -> Tuple[Optional[Path], Optional[Path], Dict[str, Union[str, List[str]]]]:
     """Search in the list of arguments for a valid ini-file for pytest,
     and return a tuple of (rootdir, inifile, cfg-dict)."""
     config_names = [
@@ -110,7 +112,7 @@


 def get_common_ancestor(paths: Iterable[Path]) -> Path:
-    common_ancestor = None  # type: Optional[Path]
+    common_ancestor: Optional[Path] = None
     for path in paths:
         if not path.exists():
             continue
@@ -175,10 +177,10 @@
     dirs = get_dirs_from_args(args)
     if inifile:
         inipath_ = absolutepath(inifile)
-        inipath = inipath_  # type: Optional[Path]
+        inipath: Optional[Path] = inipath_
         inicfg = load_config_dict_from_file(inipath_) or {}
         if rootdir_cmd_arg is None:
-            rootdir = get_common_ancestor(dirs)
+            rootdir = inipath_.parent
     else:
         ancestor = get_common_ancestor(dirs)
         rootdir, inipath, inicfg = locate_config([ancestor])
('src/_pytest/config', 'argparsing.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,4 +1,5 @@
 import argparse
+import os
 import sys
 import warnings
 from gettext import gettext
@@ -11,14 +12,16 @@
 from typing import Optional
 from typing import Sequence
 from typing import Tuple
+from typing import TYPE_CHECKING
 from typing import Union
-
-import py

 import _pytest._io
 from _pytest.compat import final
-from _pytest.compat import TYPE_CHECKING
 from _pytest.config.exceptions import UsageError
+from _pytest.deprecated import ARGUMENT_PERCENT_DEFAULT
+from _pytest.deprecated import ARGUMENT_TYPE_STR
+from _pytest.deprecated import ARGUMENT_TYPE_STR_CHOICE
+from _pytest.deprecated import check_ispytest

 if TYPE_CHECKING:
     from typing import NoReturn
@@ -35,20 +38,23 @@
         there's an error processing the command line arguments.
     """

-    prog = None  # type: Optional[str]
+    prog: Optional[str] = None

     def __init__(
         self,
         usage: Optional[str] = None,
         processopt: Optional[Callable[["Argument"], None]] = None,
+        *,
+        _ispytest: bool = False,
     ) -> None:
-        self._anonymous = OptionGroup("custom options", parser=self)
-        self._groups = []  # type: List[OptionGroup]
+        check_ispytest(_ispytest)
+        self._anonymous = OptionGroup("custom options", parser=self, _ispytest=True)
+        self._groups: List[OptionGroup] = []
         self._processopt = processopt
         self._usage = usage
-        self._inidict = {}  # type: Dict[str, Tuple[str, Optional[str], Any]]
-        self._ininames = []  # type: List[str]
-        self.extra_info = {}  # type: Dict[str, Any]
+        self._inidict: Dict[str, Tuple[str, Optional[str], Any]] = {}
+        self._ininames: List[str] = []
+        self.extra_info: Dict[str, Any] = {}

     def processoption(self, option: "Argument") -> None:
         if self._processopt:
@@ -65,14 +71,14 @@
         :after: Name of another group, used for ordering --help output.

         The returned group object has an ``addoption`` method with the same
-        signature as :py:func:`parser.addoption
-        <_pytest.config.argparsing.Parser.addoption>` but will be shown in the
-        respective group in the output of ``pytest. --help``.
+        signature as :func:`parser.addoption <pytest.Parser.addoption>` but
+        will be shown in the respective group in the output of
+        ``pytest. --help``.
         """
         for group in self._groups:
             if group.name == name:
                 return group
-        group = OptionGroup(name, description, parser=self)
+        group = OptionGroup(name, description, parser=self, _ispytest=True)
         i = 0
         for i, grp in enumerate(self._groups):
             if grp.name == after:
@@ -97,14 +103,14 @@

     def parse(
         self,
-        args: Sequence[Union[str, py.path.local]],
+        args: Sequence[Union[str, "os.PathLike[str]"]],
         namespace: Optional[argparse.Namespace] = None,
     ) -> argparse.Namespace:
         from _pytest._argcomplete import try_argcomplete

         self.optparser = self._getparser()
         try_argcomplete(self.optparser)
-        strargs = [str(x) if isinstance(x, py.path.local) else x for x in args]
+        strargs = [os.fspath(x) for x in args]
         return self.optparser.parse_args(strargs, namespace=namespace)

     def _getparser(self) -> "MyOptionParser":
@@ -128,7 +134,7 @@

     def parse_setoption(
         self,
-        args: Sequence[Union[str, py.path.local]],
+        args: Sequence[Union[str, "os.PathLike[str]"]],
         option: argparse.Namespace,
         namespace: Optional[argparse.Namespace] = None,
     ) -> List[str]:
@@ -139,7 +145,7 @@

     def parse_known_args(
         self,
-        args: Sequence[Union[str, py.path.local]],
+        args: Sequence[Union[str, "os.PathLike[str]"]],
         namespace: Optional[argparse.Namespace] = None,
     ) -> argparse.Namespace:
         """Parse and return a namespace object with known arguments at this point."""
@@ -147,33 +153,49 @@

     def parse_known_and_unknown_args(
         self,
-        args: Sequence[Union[str, py.path.local]],
+        args: Sequence[Union[str, "os.PathLike[str]"]],
         namespace: Optional[argparse.Namespace] = None,
     ) -> Tuple[argparse.Namespace, List[str]]:
         """Parse and return a namespace object with known arguments, and
         the remaining arguments unknown at this point."""
         optparser = self._getparser()
-        strargs = [str(x) if isinstance(x, py.path.local) else x for x in args]
+        strargs = [os.fspath(x) for x in args]
         return optparser.parse_known_args(strargs, namespace=namespace)

     def addini(
         self,
         name: str,
         help: str,
-        type: Optional["Literal['pathlist', 'args', 'linelist', 'bool']"] = None,
+        type: Optional[
+            "Literal['string', 'paths', 'pathlist', 'args', 'linelist', 'bool']"
+        ] = None,
         default=None,
     ) -> None:
         """Register an ini-file option.

-        :name: Name of the ini-variable.
-        :type: Type of the variable, can be ``pathlist``, ``args``, ``linelist``
-               or ``bool``.
-        :default: Default value if no ini-file option exists but is queried.
+        :name:
+            Name of the ini-variable.
+        :type:
+            Type of the variable. Can be:
+
+                * ``string``: a string
+                * ``bool``: a boolean
+                * ``args``: a list of strings, separated as in a shell
+                * ``linelist``: a list of strings, separated by line breaks
+                * ``paths``: a list of :class:`pathlib.Path`, separated as in a shell
+                * ``pathlist``: a list of ``py.path``, separated as in a shell
+
+            .. versionadded:: 7.0
+                The ``paths`` variable type.
+
+            Defaults to ``string`` if ``None`` or not passed.
+        :default:
+            Default value if no ini-file option exists but is queried.

         The value of ini-variables can be retrieved via a call to
-        :py:func:`config.getini(name) <_pytest.config.Config.getini>`.
+        :py:func:`config.getini(name) <pytest.Config.getini>`.
         """
-        assert type in (None, "pathlist", "args", "linelist", "bool")
+        assert type in (None, "string", "paths", "pathlist", "args", "linelist", "bool")
         self._inidict[name] = (help, type, default)
         self._ininames.append(name)

@@ -188,7 +210,7 @@

     def __str__(self) -> str:
         if self.option_id:
-            return "option {}: {}".format(self.option_id, self.msg)
+            return f"option {self.option_id}: {self.msg}"
         else:
             return self.msg

@@ -207,15 +229,10 @@
     def __init__(self, *names: str, **attrs: Any) -> None:
         """Store parms in private vars for use in add_argument."""
         self._attrs = attrs
-        self._short_opts = []  # type: List[str]
-        self._long_opts = []  # type: List[str]
+        self._short_opts: List[str] = []
+        self._long_opts: List[str] = []
         if "%default" in (attrs.get("help") or ""):
-            warnings.warn(
-                'pytest now uses argparse. "%default" should be'
-                ' changed to "%(default)s" ',
-                DeprecationWarning,
-                stacklevel=3,
-            )
+            warnings.warn(ARGUMENT_PERCENT_DEFAULT, stacklevel=3)
         try:
             typ = attrs["type"]
         except KeyError:
@@ -225,11 +242,7 @@
             if isinstance(typ, str):
                 if typ == "choice":
                     warnings.warn(
-                        "`type` argument to addoption() is the string %r."
-                        " For choices this is optional and can be omitted, "
-                        " but when supplied should be a type (for example `str` or `int`)."
-                        " (options: %s)" % (typ, names),
-                        DeprecationWarning,
+                        ARGUMENT_TYPE_STR_CHOICE.format(typ=typ, names=names),
                         stacklevel=4,
                     )
                     # argparse expects a type here take it from
@@ -237,11 +250,7 @@
                     attrs["type"] = type(attrs["choices"][0])
                 else:
                     warnings.warn(
-                        "`type` argument to addoption() is the string %r, "
-                        " but when supplied should be a type (for example `str` or `int`)."
-                        " (options: %s)" % (typ, names),
-                        DeprecationWarning,
-                        stacklevel=4,
+                        ARGUMENT_TYPE_STR.format(typ=typ, names=names), stacklevel=4
                     )
                     attrs["type"] = Argument._typ_map[typ]
                 # Used in test_parseopt -> test_parse_defaultgetter.
@@ -254,7 +263,7 @@
         except KeyError:
             pass
         self._set_opt_strings(names)
-        dest = attrs.get("dest")  # type: Optional[str]
+        dest: Optional[str] = attrs.get("dest")
         if dest:
             self.dest = dest
         elif self._long_opts:
@@ -315,7 +324,7 @@
                 self._long_opts.append(opt)

     def __repr__(self) -> str:
-        args = []  # type: List[str]
+        args: List[str] = []
         if self._short_opts:
             args += ["_short_opts: " + repr(self._short_opts)]
         if self._long_opts:
@@ -329,21 +338,29 @@


 class OptionGroup:
+    """A group of options shown in its own section."""
+
     def __init__(
-        self, name: str, description: str = "", parser: Optional[Parser] = None
+        self,
+        name: str,
+        description: str = "",
+        parser: Optional[Parser] = None,
+        *,
+        _ispytest: bool = False,
     ) -> None:
+        check_ispytest(_ispytest)
         self.name = name
         self.description = description
-        self.options = []  # type: List[Argument]
+        self.options: List[Argument] = []
         self.parser = parser

     def addoption(self, *optnames: str, **attrs: Any) -> None:
         """Add an option to this group.

         If a shortened version of a long option is specified, it will
-        be suppressed in the help. addoption('--twowords', '--two-words')
-        results in help showing '--two-words' only, but --twowords gets
-        accepted **and** the automatic destination is in args.twowords.
+        be suppressed in the help. ``addoption('--twowords', '--two-words')``
+        results in help showing ``--two-words`` only, but ``--twowords`` gets
+        accepted **and** the automatic destination is in ``args.twowords``.
         """
         conflict = set(optnames).intersection(
             name for opt in self.options for name in opt.names()
@@ -375,8 +392,7 @@
         prog: Optional[str] = None,
     ) -> None:
         self._parser = parser
-        argparse.ArgumentParser.__init__(
-            self,
+        super().__init__(
             prog=prog,
             usage=parser._usage,
             add_help=False,
@@ -389,11 +405,11 @@

     def error(self, message: str) -> "NoReturn":
         """Transform argparse error message into UsageError."""
-        msg = "{}: error: {}".format(self.prog, message)
+        msg = f"{self.prog}: error: {message}"

         if hasattr(self._parser, "_config_source_hint"):
             # Type ignored because the attribute is set dynamically.
-            msg = "{} ({})".format(msg, self._parser._config_source_hint)  # type: ignore
+            msg = f"{msg} ({self._parser._config_source_hint})"  # type: ignore

         raise UsageError(self.format_usage() + msg)

@@ -410,7 +426,7 @@
                 if arg and arg[0] == "-":
                     lines = ["unrecognized arguments: %s" % (" ".join(unrecognized))]
                     for k, v in sorted(self.extra_info.items()):
-                        lines.append("  {}: {}".format(k, v))
+                        lines.append(f"  {k}: {v}")
                     self.error("\n".join(lines))
             getattr(parsed, FILE_OR_DIR).extend(unrecognized)
         return parsed
@@ -469,12 +485,10 @@
         super().__init__(*args, **kwargs)

     def _format_action_invocation(self, action: argparse.Action) -> str:
-        orgstr = argparse.HelpFormatter._format_action_invocation(self, action)
+        orgstr = super()._format_action_invocation(action)
         if orgstr and orgstr[0] != "-":  # only optional arguments
             return orgstr
-        res = getattr(
-            action, "_formatted_action_invocation", None
-        )  # type: Optional[str]
+        res: Optional[str] = getattr(action, "_formatted_action_invocation", None)
         if res:
             return res
         options = orgstr.split(", ")
@@ -483,7 +497,7 @@
             action._formatted_action_invocation = orgstr  # type: ignore
             return orgstr
         return_list = []
-        short_long = {}  # type: Dict[str, str]
+        short_long: Dict[str, str] = {}
         for option in options:
             if len(option) == 2 or option[2] == " ":
                 continue
('src/_pytest/mark', '__init__.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,9 +1,9 @@
 """Generic mechanism for marking and selecting python functions."""
-import typing
-import warnings
 from typing import AbstractSet
+from typing import Collection
 from typing import List
 from typing import Optional
+from typing import TYPE_CHECKING
 from typing import Union

 import attr
@@ -17,15 +17,12 @@
 from .structures import MarkDecorator
 from .structures import MarkGenerator
 from .structures import ParameterSet
-from _pytest.compat import TYPE_CHECKING
 from _pytest.config import Config
 from _pytest.config import ExitCode
 from _pytest.config import hookimpl
 from _pytest.config import UsageError
 from _pytest.config.argparsing import Parser
-from _pytest.deprecated import MINUS_K_COLON
-from _pytest.deprecated import MINUS_K_DASH
-from _pytest.store import StoreKey
+from _pytest.stash import StashKey

 if TYPE_CHECKING:
     from _pytest.nodes import Item
@@ -41,13 +38,13 @@
 ]


-old_mark_config_key = StoreKey[Optional[Config]]()
+old_mark_config_key = StashKey[Optional[Config]]()


 def param(
     *values: object,
-    marks: "Union[MarkDecorator, typing.Collection[Union[MarkDecorator, Mark]]]" = (),
-    id: Optional[str] = None
+    marks: Union[MarkDecorator, Collection[Union[MarkDecorator, Mark]]] = (),
+    id: Optional[str] = None,
 ) -> ParameterSet:
     """Specify a parameter in `pytest.mark.parametrize`_ calls or
     :ref:`parametrized fixtures <fixture-parametrize-marks>`.
@@ -56,7 +53,10 @@

         @pytest.mark.parametrize(
             "test_input,expected",
-            [("3+5", 8), pytest.param("6*9", 42, marks=pytest.mark.xfail),],
+            [
+                ("3+5", 8),
+                pytest.param("6*9", 42, marks=pytest.mark.xfail),
+            ],
         )
         def test_eval(test_input, expected):
             assert eval(test_input) == expected
@@ -130,7 +130,7 @@
     return None


-@attr.s(slots=True)
+@attr.s(slots=True, auto_attribs=True)
 class KeywordMatcher:
     """A matcher for keywords.

@@ -145,7 +145,7 @@
     any item, as well as names directly assigned to test functions.
     """

-    _names = attr.ib(type=AbstractSet[str])
+    _names: AbstractSet[str]

     @classmethod
     def from_item(cls, item: "Item") -> "KeywordMatcher":
@@ -155,7 +155,7 @@
         import pytest

         for node in item.listchain():
-            if not isinstance(node, (pytest.Instance, pytest.Session)):
+            if not isinstance(node, pytest.Session):
                 mapped_names.add(node.name)

         # Add the names added as extra keywords to current or parent items.
@@ -186,32 +186,14 @@
     if not keywordexpr:
         return

-    if keywordexpr.startswith("-"):
-        # To be removed in pytest 7.0.0.
-        warnings.warn(MINUS_K_DASH, stacklevel=2)
-        keywordexpr = "not " + keywordexpr[1:]
-    selectuntil = False
-    if keywordexpr[-1:] == ":":
-        # To be removed in pytest 7.0.0.
-        warnings.warn(MINUS_K_COLON, stacklevel=2)
-        selectuntil = True
-        keywordexpr = keywordexpr[:-1]
-
-    try:
-        expression = Expression.compile(keywordexpr)
-    except ParseError as e:
-        raise UsageError(
-            "Wrong expression passed to '-k': {}: {}".format(keywordexpr, e)
-        ) from None
+    expr = _parse_expression(keywordexpr, "Wrong expression passed to '-k'")

     remaining = []
     deselected = []
     for colitem in items:
-        if keywordexpr and not expression.evaluate(KeywordMatcher.from_item(colitem)):
+        if not expr.evaluate(KeywordMatcher.from_item(colitem)):
             deselected.append(colitem)
         else:
-            if selectuntil:
-                keywordexpr = None
             remaining.append(colitem)

     if deselected:
@@ -219,17 +201,17 @@
         items[:] = remaining


-@attr.s(slots=True)
+@attr.s(slots=True, auto_attribs=True)
 class MarkMatcher:
     """A matcher for markers which are present.

     Tries to match on any marker names, attached to the given colitem.
     """

-    own_mark_names = attr.ib()
+    own_mark_names: AbstractSet[str]

     @classmethod
-    def from_item(cls, item) -> "MarkMatcher":
+    def from_item(cls, item: "Item") -> "MarkMatcher":
         mark_names = {mark.name for mark in item.iter_markers()}
         return cls(mark_names)

@@ -242,33 +224,33 @@
     if not matchexpr:
         return

-    try:
-        expression = Expression.compile(matchexpr)
-    except ParseError as e:
-        raise UsageError(
-            "Wrong expression passed to '-m': {}: {}".format(matchexpr, e)
-        ) from None
-
-    remaining = []
-    deselected = []
+    expr = _parse_expression(matchexpr, "Wrong expression passed to '-m'")
+    remaining: List[Item] = []
+    deselected: List[Item] = []
     for item in items:
-        if expression.evaluate(MarkMatcher.from_item(item)):
+        if expr.evaluate(MarkMatcher.from_item(item)):
             remaining.append(item)
         else:
             deselected.append(item)
-
     if deselected:
         config.hook.pytest_deselected(items=deselected)
         items[:] = remaining


+def _parse_expression(expr: str, exc_message: str) -> Expression:
+    try:
+        return Expression.compile(expr)
+    except ParseError as e:
+        raise UsageError(f"{exc_message}: {expr}: {e}") from None
+
+
 def pytest_collection_modifyitems(items: "List[Item]", config: Config) -> None:
     deselect_by_keyword(items, config)
     deselect_by_mark(items, config)


 def pytest_configure(config: Config) -> None:
-    config._store[old_mark_config_key] = MARK_GEN._config
+    config.stash[old_mark_config_key] = MARK_GEN._config
     MARK_GEN._config = config

     empty_parameterset = config.getini(EMPTY_PARAMETERSET_OPTION)
@@ -281,4 +263,4 @@


 def pytest_unconfigure(config: Config) -> None:
-    MARK_GEN._config = config._store.get(old_mark_config_key, None)
+    MARK_GEN._config = config.stash.get(old_mark_config_key, None)
('src/_pytest/mark', 'structures.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,18 +1,22 @@
 import collections.abc
 import inspect
-import typing
 import warnings
 from typing import Any
 from typing import Callable
+from typing import Collection
 from typing import Iterable
 from typing import Iterator
 from typing import List
 from typing import Mapping
+from typing import MutableMapping
 from typing import NamedTuple
 from typing import Optional
+from typing import overload
 from typing import Sequence
 from typing import Set
 from typing import Tuple
+from typing import Type
+from typing import TYPE_CHECKING
 from typing import TypeVar
 from typing import Union

@@ -23,15 +27,12 @@
 from ..compat import final
 from ..compat import NOTSET
 from ..compat import NotSetType
-from ..compat import overload
-from ..compat import TYPE_CHECKING
 from _pytest.config import Config
+from _pytest.deprecated import check_ispytest
 from _pytest.outcomes import fail
 from _pytest.warning_types import PytestUnknownMarkWarning

 if TYPE_CHECKING:
-    from typing import Type
-
     from ..nodes import Node


@@ -39,10 +40,7 @@


 def istestfunc(func) -> bool:
-    return (
-        hasattr(func, "__call__")
-        and getattr(func, "__name__", "<lambda>") != "<lambda>"
-    )
+    return callable(func) and getattr(func, "__name__", "<lambda>") != "<lambda>"


 def get_empty_parameterset_mark(
@@ -74,34 +72,26 @@
     return mark


-class ParameterSet(
-    NamedTuple(
-        "ParameterSet",
-        [
-            ("values", Sequence[Union[object, NotSetType]]),
-            ("marks", "typing.Collection[Union[MarkDecorator, Mark]]"),
-            ("id", Optional[str]),
-        ],
-    )
-):
+class ParameterSet(NamedTuple):
+    values: Sequence[Union[object, NotSetType]]
+    marks: Collection[Union["MarkDecorator", "Mark"]]
+    id: Optional[str]
+
     @classmethod
     def param(
         cls,
         *values: object,
-        marks: "Union[MarkDecorator, typing.Collection[Union[MarkDecorator, Mark]]]" = (),
-        id: Optional[str] = None
+        marks: Union["MarkDecorator", Collection[Union["MarkDecorator", "Mark"]]] = (),
+        id: Optional[str] = None,
     ) -> "ParameterSet":
         if isinstance(marks, MarkDecorator):
             marks = (marks,)
         else:
-            # TODO(py36): Change to collections.abc.Collection.
-            assert isinstance(marks, (collections.abc.Sequence, set))
+            assert isinstance(marks, collections.abc.Collection)

         if id is not None:
             if not isinstance(id, str):
-                raise TypeError(
-                    "Expected id to be a string, got {}: {!r}".format(type(id), id)
-                )
+                raise TypeError(f"Expected id to be a string, got {type(id)}: {id!r}")
             id = ascii_escaped(id)
         return cls(values, marks, id)

@@ -128,7 +118,7 @@
             return cls.param(parameterset)
         else:
             # TODO: Refactor to fix this type-ignore. Currently the following
-            # type-checks but crashes:
+            # passes type-checking but crashes:
             #
             #   @pytest.mark.parametrize(('x', 'y'), [1, 2])
             #   def test_foo(x, y): pass
@@ -139,7 +129,7 @@
         argnames: Union[str, List[str], Tuple[str, ...]],
         argvalues: Iterable[Union["ParameterSet", Sequence[object], object]],
         *args,
-        **kwargs
+        **kwargs,
     ) -> Tuple[Union[List[str], Tuple[str, ...]], bool]:
         if not isinstance(argnames, (tuple, list)):
             argnames = [x.strip() for x in argnames.split(",") if x.strip()]
@@ -201,21 +191,38 @@


 @final
-@attr.s(frozen=True)
+@attr.s(frozen=True, init=False, auto_attribs=True)
 class Mark:
     #: Name of the mark.
-    name = attr.ib(type=str)
+    name: str
     #: Positional arguments of the mark decorator.
-    args = attr.ib(type=Tuple[Any, ...])
+    args: Tuple[Any, ...]
     #: Keyword arguments of the mark decorator.
-    kwargs = attr.ib(type=Mapping[str, Any])
+    kwargs: Mapping[str, Any]

     #: Source Mark for ids with parametrize Marks.
-    _param_ids_from = attr.ib(type=Optional["Mark"], default=None, repr=False)
+    _param_ids_from: Optional["Mark"] = attr.ib(default=None, repr=False)
     #: Resolved/generated ids with parametrize Marks.
-    _param_ids_generated = attr.ib(
-        type=Optional[Sequence[str]], default=None, repr=False
-    )
+    _param_ids_generated: Optional[Sequence[str]] = attr.ib(default=None, repr=False)
+
+    def __init__(
+        self,
+        name: str,
+        args: Tuple[Any, ...],
+        kwargs: Mapping[str, Any],
+        param_ids_from: Optional["Mark"] = None,
+        param_ids_generated: Optional[Sequence[str]] = None,
+        *,
+        _ispytest: bool = False,
+    ) -> None:
+        """:meta private:"""
+        check_ispytest(_ispytest)
+        # Weirdness to bypass frozen=True.
+        object.__setattr__(self, "name", name)
+        object.__setattr__(self, "args", args)
+        object.__setattr__(self, "kwargs", kwargs)
+        object.__setattr__(self, "_param_ids_from", param_ids_from)
+        object.__setattr__(self, "_param_ids_generated", param_ids_generated)

     def _has_param_ids(self) -> bool:
         return "ids" in self.kwargs or len(self.args) >= 4
@@ -232,7 +239,7 @@
         assert self.name == other.name

         # Remember source of ids with parametrize Marks.
-        param_ids_from = None  # type: Optional[Mark]
+        param_ids_from: Optional[Mark] = None
         if self.name == "parametrize":
             if other._has_param_ids():
                 param_ids_from = other
@@ -244,20 +251,21 @@
             self.args + other.args,
             dict(self.kwargs, **other.kwargs),
             param_ids_from=param_ids_from,
+            _ispytest=True,
         )


 # A generic parameter designating an object to which a Mark may
 # be applied -- a test function (callable) or class.
 # Note: a lambda is not allowed, but this can't be represented.
-_Markable = TypeVar("_Markable", bound=Union[Callable[..., object], type])
-
-
-@attr.s
+Markable = TypeVar("Markable", bound=Union[Callable[..., object], type])
+
+
+@attr.s(init=False, auto_attribs=True)
 class MarkDecorator:
     """A decorator for applying a mark on test functions and classes.

-    MarkDecorators are created with ``pytest.mark``::
+    ``MarkDecorators`` are created with ``pytest.mark``::

         mark1 = pytest.mark.NAME              # Simple MarkDecorator
         mark2 = pytest.mark.NAME(name1=value) # Parametrized MarkDecorator
@@ -268,7 +276,7 @@
         def test_function():
             pass

-    When a MarkDecorator is called it does the following:
+    When a ``MarkDecorator`` is called, it does the following:

     1. If called with a single class as its only positional argument and no
        additional keyword arguments, it attaches the mark to the class so it
@@ -277,19 +285,24 @@
     2. If called with a single function as its only positional argument and
        no additional keyword arguments, it attaches the mark to the function,
        containing all the arguments already stored internally in the
-       MarkDecorator.
-
-    3. When called in any other case, it returns a new MarkDecorator instance
-       with the original MarkDecorator's content updated with the arguments
-       passed to this call.
-
-    Note: The rules above prevent MarkDecorators from storing only a single
-    function or class reference as their positional argument with no
+       ``MarkDecorator``.
+
+    3. When called in any other case, it returns a new ``MarkDecorator``
+       instance with the original ``MarkDecorator``'s content updated with
+       the arguments passed to this call.
+
+    Note: The rules above prevent a ``MarkDecorator`` from storing only a
+    single function or class reference as its positional argument with no
     additional keyword or positional arguments. You can work around this by
     using `with_args()`.
     """

-    mark = attr.ib(type=Mark, validator=attr.validators.instance_of(Mark))
+    mark: Mark
+
+    def __init__(self, mark: Mark, *, _ispytest: bool = False) -> None:
+        """:meta private:"""
+        check_ispytest(_ispytest)
+        self.mark = mark

     @property
     def name(self) -> str:
@@ -308,36 +321,30 @@

     @property
     def markname(self) -> str:
+        """:meta private:"""
         return self.name  # for backward-compat (2.4.1 had this attr)
-
-    def __repr__(self) -> str:
-        return "<MarkDecorator {!r}>".format(self.mark)

     def with_args(self, *args: object, **kwargs: object) -> "MarkDecorator":
         """Return a MarkDecorator with extra arguments added.

         Unlike calling the MarkDecorator, with_args() can be used even
         if the sole argument is a callable/class.
-
-        :rtype: MarkDecorator
         """
-        mark = Mark(self.name, args, kwargs)
-        return self.__class__(self.mark.combined_with(mark))
+        mark = Mark(self.name, args, kwargs, _ispytest=True)
+        return MarkDecorator(self.mark.combined_with(mark), _ispytest=True)

     # Type ignored because the overloads overlap with an incompatible
     # return type. Not much we can do about that. Thankfully mypy picks
     # the first match so it works out even if we break the rules.
     @overload
-    def __call__(self, arg: _Markable) -> _Markable:  # type: ignore[misc]
+    def __call__(self, arg: Markable) -> Markable:  # type: ignore[misc]
         pass

-    @overload  # noqa: F811
-    def __call__(  # noqa: F811
-        self, *args: object, **kwargs: object
-    ) -> "MarkDecorator":
+    @overload
+    def __call__(self, *args: object, **kwargs: object) -> "MarkDecorator":
         pass

-    def __call__(self, *args: object, **kwargs: object):  # noqa: F811
+    def __call__(self, *args: object, **kwargs: object):
         """Call the MarkDecorator."""
         if args and not kwargs:
             func = args[0]
@@ -348,7 +355,7 @@
         return self.with_args(*args, **kwargs)


-def get_unpacked_marks(obj) -> List[Mark]:
+def get_unpacked_marks(obj: object) -> Iterable[Mark]:
     """Obtain the unpacked marks that are stored on an object."""
     mark_list = getattr(obj, "pytestmark", [])
     if not isinstance(mark_list, list):
@@ -356,19 +363,21 @@
     return normalize_mark_list(mark_list)


-def normalize_mark_list(mark_list: Iterable[Union[Mark, MarkDecorator]]) -> List[Mark]:
-    """Normalize marker decorating helpers to mark objects.
-
-    :type List[Union[Mark, Markdecorator]] mark_list:
-    :rtype: List[Mark]
+def normalize_mark_list(
+    mark_list: Iterable[Union[Mark, MarkDecorator]]
+) -> Iterable[Mark]:
     """
-    extracted = [
-        getattr(mark, "mark", mark) for mark in mark_list
-    ]  # unpack MarkDecorator
-    for mark in extracted:
-        if not isinstance(mark, Mark):
-            raise TypeError("got {!r} instead of Mark".format(mark))
-    return [x for x in extracted if isinstance(x, Mark)]
+    Normalize an iterable of Mark or MarkDecorator objects into a list of marks
+    by retrieving the `mark` attribute on MarkDecorator instances.
+
+    :param mark_list: marks to normalize
+    :returns: A new list of the extracted Mark objects
+    """
+    for mark in mark_list:
+        mark_obj = getattr(mark, "mark", mark)
+        if not isinstance(mark_obj, Mark):
+            raise TypeError(f"got {repr(mark_obj)} instead of Mark")
+        yield mark_obj


 def store_mark(obj, mark: Mark) -> None:
@@ -379,21 +388,21 @@
     assert isinstance(mark, Mark), mark
     # Always reassign name to avoid updating pytestmark in a reference that
     # was only borrowed.
-    obj.pytestmark = get_unpacked_marks(obj) + [mark]
+    obj.pytestmark = [*get_unpacked_marks(obj), mark]


 # Typing for builtin pytest marks. This is cheating; it gives builtin marks
 # special privilege, and breaks modularity. But practicality beats purity...
 if TYPE_CHECKING:
-    from _pytest.fixtures import _Scope
+    from _pytest.scope import _ScopeName

     class _SkipMarkDecorator(MarkDecorator):
         @overload  # type: ignore[override,misc]
-        def __call__(self, arg: _Markable) -> _Markable:
-            ...
-
-        @overload  # noqa: F811
-        def __call__(self, reason: str = ...) -> "MarkDecorator":  # noqa: F811
+        def __call__(self, arg: Markable) -> Markable:
+            ...
+
+        @overload
+        def __call__(self, reason: str = ...) -> "MarkDecorator":
             ...

     class _SkipifMarkDecorator(MarkDecorator):
@@ -401,26 +410,24 @@
             self,
             condition: Union[str, bool] = ...,
             *conditions: Union[str, bool],
-            reason: str = ...
+            reason: str = ...,
         ) -> MarkDecorator:
             ...

     class _XfailMarkDecorator(MarkDecorator):
         @overload  # type: ignore[override,misc]
-        def __call__(self, arg: _Markable) -> _Markable:
-            ...
-
-        @overload  # noqa: F811
-        def __call__(  # noqa: F811
+        def __call__(self, arg: Markable) -> Markable:
+            ...
+
+        @overload
+        def __call__(
             self,
             condition: Union[str, bool] = ...,
             *conditions: Union[str, bool],
             reason: str = ...,
             run: bool = ...,
-            raises: Union[
-                "Type[BaseException]", Tuple["Type[BaseException]", ...]
-            ] = ...,
-            strict: bool = ...
+            raises: Union[Type[BaseException], Tuple[Type[BaseException], ...]] = ...,
+            strict: bool = ...,
         ) -> MarkDecorator:
             ...

@@ -437,20 +444,16 @@
                     Callable[[Any], Optional[object]],
                 ]
             ] = ...,
-            scope: Optional[_Scope] = ...
+            scope: Optional[_ScopeName] = ...,
         ) -> MarkDecorator:
             ...

     class _UsefixturesMarkDecorator(MarkDecorator):
-        def __call__(  # type: ignore[override]
-            self, *fixtures: str
-        ) -> MarkDecorator:
+        def __call__(self, *fixtures: str) -> MarkDecorator:  # type: ignore[override]
             ...

     class _FilterwarningsMarkDecorator(MarkDecorator):
-        def __call__(  # type: ignore[override]
-            self, *filters: str
-        ) -> MarkDecorator:
+        def __call__(self, *filters: str) -> MarkDecorator:  # type: ignore[override]
             ...


@@ -470,20 +473,22 @@
     applies a 'slowtest' :class:`Mark` on ``test_function``.
     """

-    _config = None  # type: Optional[Config]
-    _markers = set()  # type: Set[str]
-
     # See TYPE_CHECKING above.
     if TYPE_CHECKING:
-        # TODO(py36): Change to builtin annotation syntax.
-        skip = _SkipMarkDecorator(Mark("skip", (), {}))
-        skipif = _SkipifMarkDecorator(Mark("skipif", (), {}))
-        xfail = _XfailMarkDecorator(Mark("xfail", (), {}))
-        parametrize = _ParametrizeMarkDecorator(Mark("parametrize", (), {}))
-        usefixtures = _UsefixturesMarkDecorator(Mark("usefixtures", (), {}))
-        filterwarnings = _FilterwarningsMarkDecorator(Mark("filterwarnings", (), {}))
+        skip: _SkipMarkDecorator
+        skipif: _SkipifMarkDecorator
+        xfail: _XfailMarkDecorator
+        parametrize: _ParametrizeMarkDecorator
+        usefixtures: _UsefixturesMarkDecorator
+        filterwarnings: _FilterwarningsMarkDecorator
+
+    def __init__(self, *, _ispytest: bool = False) -> None:
+        check_ispytest(_ispytest)
+        self._config: Optional[Config] = None
+        self._markers: Set[str] = set()

     def __getattr__(self, name: str) -> MarkDecorator:
+        """Generate a new :class:`MarkDecorator` with the given name."""
         if name[0] == "_":
             raise AttributeError("Marker name must NOT start with underscore")

@@ -502,34 +507,35 @@
             # If the name is not in the set of known marks after updating,
             # then it really is time to issue a warning or an error.
             if name not in self._markers:
-                if self._config.option.strict_markers:
+                if self._config.option.strict_markers or self._config.option.strict:
                     fail(
-                        "{!r} not found in `markers` configuration option".format(name),
+                        f"{name!r} not found in `markers` configuration option",
                         pytrace=False,
                     )

                 # Raise a specific error for common misspellings of "parametrize".
                 if name in ["parameterize", "parametrise", "parameterise"]:
                     __tracebackhide__ = True
-                    fail("Unknown '{}' mark, did you mean 'parametrize'?".format(name))
+                    fail(f"Unknown '{name}' mark, did you mean 'parametrize'?")

                 warnings.warn(
                     "Unknown pytest.mark.%s - is this a typo?  You can register "
                     "custom marks to avoid this warning - for details, see "
-                    "https://docs.pytest.org/en/stable/mark.html" % name,
+                    "https://docs.pytest.org/en/stable/how-to/mark.html" % name,
                     PytestUnknownMarkWarning,
                     2,
                 )

-        return MarkDecorator(Mark(name, (), {}))
-
-
-MARK_GEN = MarkGenerator()
-
-
-# TODO(py36): inherit from typing.MutableMapping[str, Any].
+        return MarkDecorator(Mark(name, (), {}, _ispytest=True), _ispytest=True)
+
+
+MARK_GEN = MarkGenerator(_ispytest=True)
+
+
 @final
-class NodeKeywords(collections.abc.MutableMapping):  # type: ignore[type-arg]
+class NodeKeywords(MutableMapping[str, Any]):
+    __slots__ = ("node", "parent", "_markers")
+
     def __init__(self, node: "Node") -> None:
         self.node = node
         self.parent = node.parent
@@ -546,21 +552,39 @@
     def __setitem__(self, key: str, value: Any) -> None:
         self._markers[key] = value

+    # Note: we could've avoided explicitly implementing some of the methods
+    # below and use the collections.abc fallback, but that would be slow.
+
+    def __contains__(self, key: object) -> bool:
+        return (
+            key in self._markers
+            or self.parent is not None
+            and key in self.parent.keywords
+        )
+
+    def update(  # type: ignore[override]
+        self,
+        other: Union[Mapping[str, Any], Iterable[Tuple[str, Any]]] = (),
+        **kwds: Any,
+    ) -> None:
+        self._markers.update(other)
+        self._markers.update(kwds)
+
     def __delitem__(self, key: str) -> None:
         raise ValueError("cannot delete key in keywords dict")

     def __iter__(self) -> Iterator[str]:
-        seen = self._seen()
-        return iter(seen)
-
-    def _seen(self) -> Set[str]:
-        seen = set(self._markers)
+        # Doesn't need to be fast.
+        yield from self._markers
         if self.parent is not None:
-            seen.update(self.parent.keywords)
-        return seen
+            for keyword in self.parent.keywords:
+                # self._marks and self.parent.keywords can have duplicates.
+                if keyword not in self._markers:
+                    yield keyword

     def __len__(self) -> int:
-        return len(self._seen())
+        # Doesn't need to be fast.
+        return sum(1 for keyword in self)

     def __repr__(self) -> str:
-        return "<NodeKeywords for node {}>".format(self.node)
+        return f"<NodeKeywords for node {self.node}>"
('src/_pytest/mark', 'expression.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -6,7 +6,7 @@
 expr:       and_expr ('or' and_expr)*
 and_expr:   not_expr ('and' not_expr)*
 not_expr:   'not' not_expr | '(' expr ')' | ident
-ident:      (\w|:|\+|-|\.|\[|\])+
+ident:      (\w|:|\+|-|\.|\[|\]|\\|/)+

 The semantics are:

@@ -23,10 +23,9 @@
 from typing import Mapping
 from typing import Optional
 from typing import Sequence
+from typing import TYPE_CHECKING

 import attr
-
-from _pytest.compat import TYPE_CHECKING

 if TYPE_CHECKING:
     from typing import NoReturn
@@ -48,11 +47,11 @@
     EOF = "end of input"


-@attr.s(frozen=True, slots=True)
+@attr.s(frozen=True, slots=True, auto_attribs=True)
 class Token:
-    type = attr.ib(type=TokenType)
-    value = attr.ib(type=str)
-    pos = attr.ib(type=int)
+    type: TokenType
+    value: str
+    pos: int


 class ParseError(Exception):
@@ -67,7 +66,7 @@
         self.message = message

     def __str__(self) -> str:
-        return "at column {}: {}".format(self.column, self.message)
+        return f"at column {self.column}: {self.message}"


 class Scanner:
@@ -89,7 +88,7 @@
                 yield Token(TokenType.RPAREN, ")", pos)
                 pos += 1
             else:
-                match = re.match(r"(:?\w|:|\+|-|\.|\[|\])+", input[pos:])
+                match = re.match(r"(:?\w|:|\+|-|\.|\[|\]|\\|/)+", input[pos:])
                 if match:
                     value = match.group(0)
                     if value == "or":
@@ -103,7 +102,8 @@
                     pos += len(value)
                 else:
                     raise ParseError(
-                        pos + 1, 'unexpected character "{}"'.format(input[pos]),
+                        pos + 1,
+                        f'unexpected character "{input[pos]}"',
                     )
         yield Token(TokenType.EOF, "", pos)

@@ -121,7 +121,8 @@
         raise ParseError(
             self.current.pos + 1,
             "expected {}; got {}".format(
-                " OR ".join(type.value for type in expected), self.current.type.value,
+                " OR ".join(type.value for type in expected),
+                self.current.type.value,
             ),
         )

@@ -134,7 +135,7 @@

 def expression(s: Scanner) -> ast.Expression:
     if s.accept(TokenType.EOF):
-        ret = ast.NameConstant(False)  # type: ast.expr
+        ret: ast.expr = ast.NameConstant(False)
     else:
         ret = expr(s)
         s.accept(TokenType.EOF, reject=True)
@@ -189,7 +190,7 @@
 class Expression:
     """A compiled match expression as used by -k and -m.

-    The expression can be evaulated against different matchers.
+    The expression can be evaluated against different matchers.
     """

     __slots__ = ("code",)
@@ -204,9 +205,11 @@
         :param input: The input expression - one line.
         """
         astexpr = expression(Scanner(input))
-        code = compile(
-            astexpr, filename="<pytest match expression>", mode="eval",
-        )  # type: types.CodeType
+        code: types.CodeType = compile(
+            astexpr,
+            filename="<pytest match expression>",
+            mode="eval",
+        )
         return Expression(code)

     def evaluate(self, matcher: Callable[[str], bool]) -> bool:
@@ -218,7 +221,5 @@

         :returns: Whether the expression matches or not.
         """
-        ret = eval(
-            self.code, {"__builtins__": {}}, MatcherAdapter(matcher)
-        )  # type: bool
+        ret: bool = eval(self.code, {"__builtins__": {}}, MatcherAdapter(matcher))
         return ret
('src/_pytest/_code', 'code.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,33 +1,39 @@
+import ast
 import inspect
+import os
 import re
 import sys
 import traceback
 from inspect import CO_VARARGS
 from inspect import CO_VARKEYWORDS
 from io import StringIO
+from pathlib import Path
 from traceback import format_exception_only
 from types import CodeType
 from types import FrameType
 from types import TracebackType
 from typing import Any
 from typing import Callable
+from typing import ClassVar
 from typing import Dict
 from typing import Generic
 from typing import Iterable
 from typing import List
 from typing import Mapping
 from typing import Optional
+from typing import overload
 from typing import Pattern
 from typing import Sequence
 from typing import Set
 from typing import Tuple
+from typing import Type
+from typing import TYPE_CHECKING
 from typing import TypeVar
 from typing import Union
 from weakref import ref

 import attr
 import pluggy
-import py

 import _pytest
 from _pytest._code.source import findsource
@@ -37,16 +43,15 @@
 from _pytest._io import TerminalWriter
 from _pytest._io.saferepr import safeformat
 from _pytest._io.saferepr import saferepr
-from _pytest.compat import ATTRS_EQ_FIELD
 from _pytest.compat import final
 from _pytest.compat import get_real_func
-from _pytest.compat import overload
-from _pytest.compat import TYPE_CHECKING
-from _pytest.pathlib import Path
+from _pytest.deprecated import check_ispytest
+from _pytest.pathlib import absolutepath
+from _pytest.pathlib import bestrelpath

 if TYPE_CHECKING:
-    from typing import Type
     from typing_extensions import Literal
+    from typing_extensions import SupportsIndex
     from weakref import ReferenceType

     _TracebackStyle = Literal["long", "short", "line", "no", "native", "value", "auto"]
@@ -55,15 +60,14 @@
 class Code:
     """Wrapper around Python code objects."""

-    def __init__(self, rawcode) -> None:
-        if not hasattr(rawcode, "co_filename"):
-            rawcode = getrawcode(rawcode)
-        if not isinstance(rawcode, CodeType):
-            raise TypeError("not a code object: {!r}".format(rawcode))
-        self.filename = rawcode.co_filename
-        self.firstlineno = rawcode.co_firstlineno - 1
-        self.name = rawcode.co_name
-        self.raw = rawcode
+    __slots__ = ("raw",)
+
+    def __init__(self, obj: CodeType) -> None:
+        self.raw = obj
+
+    @classmethod
+    def from_function(cls, obj: object) -> "Code":
+        return cls(getrawcode(obj))

     def __eq__(self, other):
         return self.raw == other.raw
@@ -72,16 +76,24 @@
     __hash__ = None  # type: ignore

     @property
-    def path(self) -> Union[py.path.local, str]:
+    def firstlineno(self) -> int:
+        return self.raw.co_firstlineno - 1
+
+    @property
+    def name(self) -> str:
+        return self.raw.co_name
+
+    @property
+    def path(self) -> Union[Path, str]:
         """Return a path object pointing to source code, or an ``str`` in
         case of ``OSError`` / non-existing file."""
         if not self.raw.co_filename:
             return ""
         try:
-            p = py.path.local(self.raw.co_filename)
+            p = absolutepath(self.raw.co_filename)
             # maybe don't try this checking
-            if not p.check():
-                raise OSError("py.path check failed.")
+            if not p.exists():
+                raise OSError("path check failed.")
             return p
         except OSError:
             # XXX maybe try harder like the weird logic
@@ -118,12 +130,26 @@
     """Wrapper around a Python frame holding f_locals and f_globals
     in which expressions can be evaluated."""

+    __slots__ = ("raw",)
+
     def __init__(self, frame: FrameType) -> None:
-        self.lineno = frame.f_lineno - 1
-        self.f_globals = frame.f_globals
-        self.f_locals = frame.f_locals
         self.raw = frame
-        self.code = Code(frame.f_code)
+
+    @property
+    def lineno(self) -> int:
+        return self.raw.f_lineno - 1
+
+    @property
+    def f_globals(self) -> Dict[str, Any]:
+        return self.raw.f_globals
+
+    @property
+    def f_locals(self) -> Dict[str, Any]:
+        return self.raw.f_locals
+
+    @property
+    def code(self) -> Code:
+        return Code(self.raw.f_code)

     @property
     def statement(self) -> "Source":
@@ -165,17 +191,20 @@
 class TracebackEntry:
     """A single entry in a Traceback."""

-    _repr_style = None  # type: Optional[Literal["short", "long"]]
-    exprinfo = None
+    __slots__ = ("_rawentry", "_excinfo", "_repr_style")

     def __init__(
         self,
         rawentry: TracebackType,
         excinfo: Optional["ReferenceType[ExceptionInfo[BaseException]]"] = None,
     ) -> None:
+        self._rawentry = rawentry
         self._excinfo = excinfo
-        self._rawentry = rawentry
-        self.lineno = rawentry.tb_lineno - 1
+        self._repr_style: Optional['Literal["short", "long"]'] = None
+
+    @property
+    def lineno(self) -> int:
+        return self._rawentry.tb_lineno - 1

     def set_repr_style(self, mode: "Literal['short', 'long']") -> None:
         assert mode in ("short", "long")
@@ -200,7 +229,7 @@
         return source.getstatement(self.lineno)

     @property
-    def path(self) -> Union[py.path.local, str]:
+    def path(self) -> Union[Path, str]:
         """Path to the source code."""
         return self.frame.code.path

@@ -212,7 +241,9 @@
     def getfirstlinesource(self) -> int:
         return self.frame.code.firstlineno

-    def getsource(self, astcache=None) -> Optional["Source"]:
+    def getsource(
+        self, astcache: Optional[Dict[Union[str, Path], ast.AST]] = None
+    ) -> Optional["Source"]:
         """Return failing source code."""
         # we use the passed in astcache to not reparse asttrees
         # within exception info printing
@@ -232,7 +263,7 @@
         except SyntaxError:
             end = self.lineno + 1
         else:
-            if key is not None:
+            if key is not None and astcache is not None:
                 astcache[key] = astnode
         return source[start:end]

@@ -247,9 +278,9 @@

         Mostly for internal use.
         """
-        tbh = (
-            False
-        )  # type: Union[bool, Callable[[Optional[ExceptionInfo[BaseException]]], bool]]
+        tbh: Union[
+            bool, Callable[[Optional[ExceptionInfo[BaseException]]], bool]
+        ] = False
         for maybe_ns_dct in (self.frame.f_locals, self.frame.f_globals):
             # in normal cases, f_locals and f_globals are dictionaries
             # however via `exec(...)` / `eval(...)` they can be other types
@@ -302,7 +333,7 @@
         if isinstance(tb, TracebackType):

             def f(cur: TracebackType) -> Iterable[TracebackEntry]:
-                cur_ = cur  # type: Optional[TracebackType]
+                cur_: Optional[TracebackType] = cur
                 while cur_ is not None:
                     yield TracebackEntry(cur_, excinfo=excinfo)
                     cur_ = cur_.tb_next
@@ -313,10 +344,10 @@

     def cut(
         self,
-        path=None,
+        path: Optional[Union["os.PathLike[str]", str]] = None,
         lineno: Optional[int] = None,
         firstlineno: Optional[int] = None,
-        excludepath: Optional[py.path.local] = None,
+        excludepath: Optional["os.PathLike[str]"] = None,
     ) -> "Traceback":
         """Return a Traceback instance wrapping part of this Traceback.

@@ -327,32 +358,36 @@
         for formatting reasons (removing some uninteresting bits that deal
         with handling of the exception/traceback).
         """
+        path_ = None if path is None else os.fspath(path)
+        excludepath_ = None if excludepath is None else os.fspath(excludepath)
         for x in self:
             code = x.frame.code
             codepath = code.path
+            if path is not None and str(codepath) != path_:
+                continue
             if (
-                (path is None or codepath == path)
-                and (
-                    excludepath is None
-                    or not isinstance(codepath, py.path.local)
-                    or not codepath.relto(excludepath)
-                )
-                and (lineno is None or x.lineno == lineno)
-                and (firstlineno is None or x.frame.code.firstlineno == firstlineno)
+                excludepath is not None
+                and isinstance(codepath, Path)
+                and excludepath_ in (str(p) for p in codepath.parents)  # type: ignore[operator]
             ):
-                return Traceback(x._rawentry, self._excinfo)
+                continue
+            if lineno is not None and x.lineno != lineno:
+                continue
+            if firstlineno is not None and x.frame.code.firstlineno != firstlineno:
+                continue
+            return Traceback(x._rawentry, self._excinfo)
         return self

     @overload
-    def __getitem__(self, key: int) -> TracebackEntry:
+    def __getitem__(self, key: "SupportsIndex") -> TracebackEntry:
         ...

-    @overload  # noqa: F811
-    def __getitem__(self, key: slice) -> "Traceback":  # noqa: F811
+    @overload
+    def __getitem__(self, key: slice) -> "Traceback":
         ...

-    def __getitem__(  # noqa: F811
-        self, key: Union[int, slice]
+    def __getitem__(
+        self, key: Union["SupportsIndex", slice]
     ) -> Union[TracebackEntry, "Traceback"]:
         if isinstance(key, slice):
             return self.__class__(super().__getitem__(key))
@@ -384,7 +419,7 @@
     def recursionindex(self) -> Optional[int]:
         """Return the index of the frame/TracebackEntry where recursion originates if
         appropriate, None if no recursion occurred."""
-        cache = {}  # type: Dict[Tuple[Any, int, int], List[Dict[str, Any]]]
+        cache: Dict[Tuple[Any, int, int], List[Dict[str, Any]]] = {}
         for i, entry in enumerate(self):
             # id for the code.raw is needed to work around
             # the strange metaprogramming in the decorator lib from pypi
@@ -397,41 +432,45 @@
                 f = entry.frame
                 loc = f.f_locals
                 for otherloc in values:
-                    if f.eval(
-                        co_equal,
-                        __recursioncache_locals_1=loc,
-                        __recursioncache_locals_2=otherloc,
-                    ):
+                    if otherloc == loc:
                         return i
             values.append(entry.frame.f_locals)
         return None


-co_equal = compile(
-    "__recursioncache_locals_1 == __recursioncache_locals_2", "?", "eval"
-)
-
-
-_E = TypeVar("_E", bound=BaseException, covariant=True)
+E = TypeVar("E", bound=BaseException, covariant=True)


 @final
-@attr.s(repr=False)
-class ExceptionInfo(Generic[_E]):
+@attr.s(repr=False, init=False, auto_attribs=True)
+class ExceptionInfo(Generic[E]):
     """Wraps sys.exc_info() objects and offers help for navigating the traceback."""

-    _assert_start_repr = "AssertionError('assert "
-
-    _excinfo = attr.ib(type=Optional[Tuple["Type[_E]", "_E", TracebackType]])
-    _striptext = attr.ib(type=str, default="")
-    _traceback = attr.ib(type=Optional[Traceback], default=None)
+    _assert_start_repr: ClassVar = "AssertionError('assert "
+
+    _excinfo: Optional[Tuple[Type["E"], "E", TracebackType]]
+    _striptext: str
+    _traceback: Optional[Traceback]
+
+    def __init__(
+        self,
+        excinfo: Optional[Tuple[Type["E"], "E", TracebackType]],
+        striptext: str = "",
+        traceback: Optional[Traceback] = None,
+        *,
+        _ispytest: bool = False,
+    ) -> None:
+        check_ispytest(_ispytest)
+        self._excinfo = excinfo
+        self._striptext = striptext
+        self._traceback = traceback

     @classmethod
     def from_exc_info(
         cls,
-        exc_info: Tuple["Type[_E]", "_E", TracebackType],
+        exc_info: Tuple[Type[E], E, TracebackType],
         exprinfo: Optional[str] = None,
-    ) -> "ExceptionInfo[_E]":
+    ) -> "ExceptionInfo[E]":
         """Return an ExceptionInfo for an existing exc_info tuple.

         .. warning::
@@ -451,7 +490,7 @@
             if exprinfo and exprinfo.startswith(cls._assert_start_repr):
                 _striptext = "AssertionError: "

-        return cls(exc_info, _striptext)
+        return cls(exc_info, _striptext, _ispytest=True)

     @classmethod
     def from_current(
@@ -476,17 +515,17 @@
         return ExceptionInfo.from_exc_info(exc_info, exprinfo)

     @classmethod
-    def for_later(cls) -> "ExceptionInfo[_E]":
+    def for_later(cls) -> "ExceptionInfo[E]":
         """Return an unfilled ExceptionInfo."""
-        return cls(None)
-
-    def fill_unfilled(self, exc_info: Tuple["Type[_E]", _E, TracebackType]) -> None:
+        return cls(None, _ispytest=True)
+
+    def fill_unfilled(self, exc_info: Tuple[Type[E], E, TracebackType]) -> None:
         """Fill an unfilled ExceptionInfo created with ``for_later()``."""
         assert self._excinfo is None, "ExceptionInfo was already filled"
         self._excinfo = exc_info

     @property
-    def type(self) -> "Type[_E]":
+    def type(self) -> Type[E]:
         """The exception class."""
         assert (
             self._excinfo is not None
@@ -494,7 +533,7 @@
         return self._excinfo[0]

     @property
-    def value(self) -> _E:
+    def value(self) -> E:
         """The exception value."""
         assert (
             self._excinfo is not None
@@ -538,10 +577,10 @@
     def exconly(self, tryshort: bool = False) -> str:
         """Return the exception as a string.

-        When 'tryshort' resolves to True, and the exception is a
-        _pytest._code._AssertionError, only the actual exception part of
-        the exception representation is returned (so 'AssertionError: ' is
-        removed from the beginning).
+        When 'tryshort' resolves to True, and the exception is an
+        AssertionError, only the actual exception part of the exception
+        representation is returned (so 'AssertionError: ' is removed from
+        the beginning).
         """
         lines = format_exception_only(self.type, self.value)
         text = "".join(lines)
@@ -552,7 +591,7 @@
         return text

     def errisinstance(
-        self, exc: Union["Type[BaseException]", Tuple["Type[BaseException]", ...]]
+        self, exc: Union[Type[BaseException], Tuple[Type[BaseException], ...]]
     ) -> bool:
         """Return True if the exception is an instance of exc.

@@ -626,7 +665,7 @@
         )
         return fmt.repr_excinfo(self)

-    def match(self, regexp: "Union[str, Pattern[str]]") -> "Literal[True]":
+    def match(self, regexp: Union[str, Pattern[str]]) -> "Literal[True]":
         """Check whether the regular expression `regexp` matches the string
         representation of the exception using :func:`python:re.search`.

@@ -641,22 +680,24 @@
         return True


-@attr.s
+@attr.s(auto_attribs=True)
 class FormattedExcinfo:
     """Presenting information about failing Functions and Generators."""

     # for traceback entries
-    flow_marker = ">"
-    fail_marker = "E"
-
-    showlocals = attr.ib(type=bool, default=False)
-    style = attr.ib(type="_TracebackStyle", default="long")
-    abspath = attr.ib(type=bool, default=True)
-    tbfilter = attr.ib(type=bool, default=True)
-    funcargs = attr.ib(type=bool, default=False)
-    truncate_locals = attr.ib(type=bool, default=True)
-    chain = attr.ib(type=bool, default=True)
-    astcache = attr.ib(default=attr.Factory(dict), init=False, repr=False)
+    flow_marker: ClassVar = ">"
+    fail_marker: ClassVar = "E"
+
+    showlocals: bool = False
+    style: "_TracebackStyle" = "long"
+    abspath: bool = True
+    tbfilter: bool = True
+    funcargs: bool = False
+    truncate_locals: bool = True
+    chain: bool = True
+    astcache: Dict[Union[str, Path], ast.AST] = attr.ib(
+        factory=dict, init=False, repr=False
+    )

     def _getindent(self, source: "Source") -> int:
         # Figure out indent for the given source.
@@ -750,7 +791,7 @@
                     else:
                         str_repr = safeformat(value)
                     # if len(str_repr) < 70 or not isinstance(value, (list, tuple, dict)):
-                    lines.append("{:<10} = {}".format(name, str_repr))
+                    lines.append(f"{name:<10} = {str_repr}")
                     # else:
                     #    self._line("%-10s =\\" % (name,))
                     #    # XXX
@@ -763,7 +804,7 @@
         entry: TracebackEntry,
         excinfo: Optional[ExceptionInfo[BaseException]] = None,
     ) -> "ReprEntry":
-        lines = []  # type: List[str]
+        lines: List[str] = []
         style = entry._repr_style if entry._repr_style is not None else self.style
         if style in ("short", "long"):
             source = self._getentrysource(entry)
@@ -780,7 +821,8 @@
                 message = "in %s" % (entry.name)
             else:
                 message = excinfo and excinfo.typename or ""
-            path = self._makepath(entry.path)
+            entry_path = entry.path
+            path = self._makepath(entry_path)
             reprfileloc = ReprFileLocation(path, entry.lineno + 1, message)
             localsrepr = self.repr_locals(entry.locals)
             return ReprEntry(lines, reprargs, localsrepr, reprfileloc, style)
@@ -793,15 +835,15 @@
                 lines.extend(self.get_exconly(excinfo, indent=4))
             return ReprEntry(lines, None, None, None, style)

-    def _makepath(self, path):
-        if not self.abspath:
+    def _makepath(self, path: Union[Path, str]) -> str:
+        if not self.abspath and isinstance(path, Path):
             try:
-                np = py.path.local().bestrelpath(path)
+                np = bestrelpath(Path.cwd(), path)
             except OSError:
-                return path
+                return str(path)
             if len(np) < len(str(path)):
-                path = np
-        return path
+                return np
+        return str(path)

     def repr_traceback(self, excinfo: ExceptionInfo[BaseException]) -> "ReprTraceback":
         traceback = excinfo.traceback
@@ -845,7 +887,7 @@
             recursionindex = traceback.recursionindex()
         except Exception as e:
             max_frames = 10
-            extraline = (
+            extraline: Optional[str] = (
                 "!!! Recursion error detected, but an error occurred locating the origin of recursion.\n"
                 "  The following exception happened when comparing locals in the stack frame:\n"
                 "    {exc_type}: {exc_msg}\n"
@@ -855,8 +897,8 @@
                 exc_msg=str(e),
                 max_frames=max_frames,
                 total=len(traceback),
-            )  # type: Optional[str]
-            # Type ignored because adding two instaces of a List subtype
+            )
+            # Type ignored because adding two instances of a List subtype
             # currently incorrectly has type List instead of the subtype.
             traceback = traceback[:max_frames] + traceback[-max_frames:]  # type: ignore
         else:
@@ -871,20 +913,20 @@
     def repr_excinfo(
         self, excinfo: ExceptionInfo[BaseException]
     ) -> "ExceptionChainRepr":
-        repr_chain = (
-            []
-        )  # type: List[Tuple[ReprTraceback, Optional[ReprFileLocation], Optional[str]]]
-        e = excinfo.value  # type: Optional[BaseException]
-        excinfo_ = excinfo  # type: Optional[ExceptionInfo[BaseException]]
+        repr_chain: List[
+            Tuple[ReprTraceback, Optional[ReprFileLocation], Optional[str]]
+        ] = []
+        e: Optional[BaseException] = excinfo.value
+        excinfo_: Optional[ExceptionInfo[BaseException]] = excinfo
         descr = None
-        seen = set()  # type: Set[int]
+        seen: Set[int] = set()
         while e is not None and id(e) not in seen:
             seen.add(id(e))
             if excinfo_:
                 reprtraceback = self.repr_traceback(excinfo_)
-                reprcrash = (
+                reprcrash: Optional[ReprFileLocation] = (
                     excinfo_._getreprcrash() if self.style != "value" else None
-                )  # type: Optional[ReprFileLocation]
+                )
             else:
                 # Fallback to native repr if the exception doesn't have a traceback:
                 # ExceptionInfo objects require a full traceback to work.
@@ -897,7 +939,7 @@
             if e.__cause__ is not None and self.chain:
                 e = e.__cause__
                 excinfo_ = (
-                    ExceptionInfo((type(e), e, e.__traceback__))
+                    ExceptionInfo.from_exc_info((type(e), e, e.__traceback__))
                     if e.__traceback__
                     else None
                 )
@@ -907,7 +949,7 @@
             ):
                 e = e.__context__
                 excinfo_ = (
-                    ExceptionInfo((type(e), e, e.__traceback__))
+                    ExceptionInfo.from_exc_info((type(e), e, e.__traceback__))
                     if e.__traceback__
                     else None
                 )
@@ -918,7 +960,7 @@
         return ExceptionChainRepr(repr_chain)


-@attr.s(**{ATTRS_EQ_FIELD: False})  # type: ignore
+@attr.s(eq=False, auto_attribs=True)
 class TerminalRepr:
     def __str__(self) -> str:
         # FYI this is called from pytest-xdist's serialization of exception
@@ -929,21 +971,21 @@
         return io.getvalue().strip()

     def __repr__(self) -> str:
-        return "<{} instance at {:0x}>".format(self.__class__, id(self))
+        return f"<{self.__class__} instance at {id(self):0x}>"

     def toterminal(self, tw: TerminalWriter) -> None:
         raise NotImplementedError()


 # This class is abstract -- only subclasses are instantiated.
-@attr.s(**{ATTRS_EQ_FIELD: False})  # type: ignore
+@attr.s(eq=False)
 class ExceptionRepr(TerminalRepr):
     # Provided by subclasses.
-    reprcrash = None  # type: Optional[ReprFileLocation]
-    reprtraceback = None  # type: ReprTraceback
+    reprcrash: Optional["ReprFileLocation"]
+    reprtraceback: "ReprTraceback"

     def __attrs_post_init__(self) -> None:
-        self.sections = []  # type: List[Tuple[str, str, str]]
+        self.sections: List[Tuple[str, str, str]] = []

     def addsection(self, name: str, content: str, sep: str = "-") -> None:
         self.sections.append((name, content, sep))
@@ -954,13 +996,9 @@
             tw.line(content)


-@attr.s(**{ATTRS_EQ_FIELD: False})  # type: ignore
+@attr.s(eq=False, auto_attribs=True)
 class ExceptionChainRepr(ExceptionRepr):
-    chain = attr.ib(
-        type=Sequence[
-            Tuple["ReprTraceback", Optional["ReprFileLocation"], Optional[str]]
-        ]
-    )
+    chain: Sequence[Tuple["ReprTraceback", Optional["ReprFileLocation"], Optional[str]]]

     def __attrs_post_init__(self) -> None:
         super().__attrs_post_init__()
@@ -978,23 +1016,23 @@
         super().toterminal(tw)


-@attr.s(**{ATTRS_EQ_FIELD: False})  # type: ignore
+@attr.s(eq=False, auto_attribs=True)
 class ReprExceptionInfo(ExceptionRepr):
-    reprtraceback = attr.ib(type="ReprTraceback")
-    reprcrash = attr.ib(type="ReprFileLocation")
+    reprtraceback: "ReprTraceback"
+    reprcrash: "ReprFileLocation"

     def toterminal(self, tw: TerminalWriter) -> None:
         self.reprtraceback.toterminal(tw)
         super().toterminal(tw)


-@attr.s(**{ATTRS_EQ_FIELD: False})  # type: ignore
+@attr.s(eq=False, auto_attribs=True)
 class ReprTraceback(TerminalRepr):
-    reprentries = attr.ib(type=Sequence[Union["ReprEntry", "ReprEntryNative"]])
-    extraline = attr.ib(type=Optional[str])
-    style = attr.ib(type="_TracebackStyle")
-
-    entrysep = "_ "
+    reprentries: Sequence[Union["ReprEntry", "ReprEntryNative"]]
+    extraline: Optional[str]
+    style: "_TracebackStyle"
+
+    entrysep: ClassVar = "_ "

     def toterminal(self, tw: TerminalWriter) -> None:
         # The entries might have different styles.
@@ -1022,22 +1060,23 @@
         self.extraline = None


-@attr.s(**{ATTRS_EQ_FIELD: False})  # type: ignore
+@attr.s(eq=False, auto_attribs=True)
 class ReprEntryNative(TerminalRepr):
-    lines = attr.ib(type=Sequence[str])
-    style = "native"  # type: _TracebackStyle
+    lines: Sequence[str]
+
+    style: ClassVar["_TracebackStyle"] = "native"

     def toterminal(self, tw: TerminalWriter) -> None:
         tw.write("".join(self.lines))


-@attr.s(**{ATTRS_EQ_FIELD: False})  # type: ignore
+@attr.s(eq=False, auto_attribs=True)
 class ReprEntry(TerminalRepr):
-    lines = attr.ib(type=Sequence[str])
-    reprfuncargs = attr.ib(type=Optional["ReprFuncArgs"])
-    reprlocals = attr.ib(type=Optional["ReprLocals"])
-    reprfileloc = attr.ib(type=Optional["ReprFileLocation"])
-    style = attr.ib(type="_TracebackStyle")
+    lines: Sequence[str]
+    reprfuncargs: Optional["ReprFuncArgs"]
+    reprlocals: Optional["ReprLocals"]
+    reprfileloc: Optional["ReprFileLocation"]
+    style: "_TracebackStyle"

     def _write_entry_lines(self, tw: TerminalWriter) -> None:
         """Write the source code portions of a list of traceback entries with syntax highlighting.
@@ -1059,11 +1098,11 @@
         # separate indents and source lines that are not failures: we want to
         # highlight the code but not the indentation, which may contain markers
         # such as ">   assert 0"
-        fail_marker = "{}   ".format(FormattedExcinfo.fail_marker)
+        fail_marker = f"{FormattedExcinfo.fail_marker}   "
         indent_size = len(fail_marker)
-        indents = []  # type: List[str]
-        source_lines = []  # type: List[str]
-        failure_lines = []  # type: List[str]
+        indents: List[str] = []
+        source_lines: List[str] = []
+        failure_lines: List[str] = []
         for index, line in enumerate(self.lines):
             is_failure_line = line.startswith(fail_marker)
             if is_failure_line:
@@ -1111,11 +1150,11 @@
         )


-@attr.s(**{ATTRS_EQ_FIELD: False})  # type: ignore
+@attr.s(eq=False, auto_attribs=True)
 class ReprFileLocation(TerminalRepr):
-    path = attr.ib(type=str, converter=str)
-    lineno = attr.ib(type=int)
-    message = attr.ib(type=str)
+    path: str = attr.ib(converter=str)
+    lineno: int
+    message: str

     def toterminal(self, tw: TerminalWriter) -> None:
         # Filename and lineno output for each entry, using an output format
@@ -1125,27 +1164,27 @@
         if i != -1:
             msg = msg[:i]
         tw.write(self.path, bold=True, red=True)
-        tw.line(":{}: {}".format(self.lineno, msg))
-
-
-@attr.s(**{ATTRS_EQ_FIELD: False})  # type: ignore
+        tw.line(f":{self.lineno}: {msg}")
+
+
+@attr.s(eq=False, auto_attribs=True)
 class ReprLocals(TerminalRepr):
-    lines = attr.ib(type=Sequence[str])
+    lines: Sequence[str]

     def toterminal(self, tw: TerminalWriter, indent="") -> None:
         for line in self.lines:
             tw.line(indent + line)


-@attr.s(**{ATTRS_EQ_FIELD: False})  # type: ignore
+@attr.s(eq=False, auto_attribs=True)
 class ReprFuncArgs(TerminalRepr):
-    args = attr.ib(type=Sequence[Tuple[str, object]])
+    args: Sequence[Tuple[str, object]]

     def toterminal(self, tw: TerminalWriter) -> None:
         if self.args:
             linesofar = ""
             for name, value in self.args:
-                ns = "{} = {}".format(name, value)
+                ns = f"{name} = {value}"
                 if len(ns) + len(linesofar) + 2 > tw.fullwidth:
                     if linesofar:
                         tw.line(linesofar)
@@ -1160,7 +1199,7 @@
             tw.line("")


-def getfslineno(obj: object) -> Tuple[Union[str, py.path.local], int]:
+def getfslineno(obj: object) -> Tuple[Union[str, Path], int]:
     """Return source location (path, lineno) for the given object.

     If the source cannot be determined return ("", -1).
@@ -1175,14 +1214,14 @@
         obj = obj.place_as  # type: ignore[attr-defined]

     try:
-        code = Code(obj)
+        code = Code.from_function(obj)
     except TypeError:
         try:
             fn = inspect.getsourcefile(obj) or inspect.getfile(obj)  # type: ignore[arg-type]
         except TypeError:
             return "", -1

-        fspath = fn and py.path.local(fn) or ""
+        fspath = fn and absolutepath(fn) or ""
         lineno = -1
         if fspath:
             try:
@@ -1204,7 +1243,6 @@
 if _PLUGGY_DIR.name == "__init__.py":
     _PLUGGY_DIR = _PLUGGY_DIR.parent
 _PYTEST_DIR = Path(_pytest.__file__).parent
-_PY_DIR = Path(py.__file__).parent


 def filter_traceback(entry: TracebackEntry) -> bool:
@@ -1232,7 +1270,5 @@
         return False
     if _PYTEST_DIR in parents:
         return False
-    if _PY_DIR in parents:
-        return False

     return True
('src/_pytest/_code', 'source.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -2,17 +2,17 @@
 import inspect
 import textwrap
 import tokenize
+import types
 import warnings
 from bisect import bisect_right
 from typing import Iterable
 from typing import Iterator
 from typing import List
 from typing import Optional
+from typing import overload
 from typing import Tuple
 from typing import Union

-from _pytest.compat import overload
-

 class Source:
     """An immutable object holding a source code fragment.
@@ -22,7 +22,7 @@

     def __init__(self, obj: object = None) -> None:
         if not obj:
-            self.lines = []  # type: List[str]
+            self.lines: List[str] = []
         elif isinstance(obj, Source):
             self.lines = obj.lines
         elif isinstance(obj, (tuple, list)):
@@ -30,8 +30,11 @@
         elif isinstance(obj, str):
             self.lines = deindent(obj.split("\n"))
         else:
-            rawcode = getrawcode(obj)
-            src = inspect.getsource(rawcode)
+            try:
+                rawcode = getrawcode(obj)
+                src = inspect.getsource(rawcode)
+            except TypeError:
+                src = inspect.getsource(obj)  # type: ignore[arg-type]
             self.lines = deindent(src.split("\n"))

     def __eq__(self, other: object) -> bool:
@@ -46,11 +49,11 @@
     def __getitem__(self, key: int) -> str:
         ...

-    @overload  # noqa: F811
-    def __getitem__(self, key: slice) -> "Source":  # noqa: F811
+    @overload
+    def __getitem__(self, key: slice) -> "Source":
         ...

-    def __getitem__(self, key: Union[int, slice]) -> Union[str, "Source"]:  # noqa: F811
+    def __getitem__(self, key: Union[int, slice]) -> Union[str, "Source"]:
         if isinstance(key, int):
             return self.lines[key]
         else:
@@ -123,19 +126,17 @@
     return source, lineno


-def getrawcode(obj, trycall: bool = True):
+def getrawcode(obj: object, trycall: bool = True) -> types.CodeType:
     """Return code object for given function."""
     try:
-        return obj.__code__
+        return obj.__code__  # type: ignore[attr-defined,no-any-return]
     except AttributeError:
-        obj = getattr(obj, "f_code", obj)
-        obj = getattr(obj, "__code__", obj)
-        if trycall and not hasattr(obj, "co_firstlineno"):
-            if hasattr(obj, "__call__") and not inspect.isclass(obj):
-                x = getrawcode(obj.__call__, trycall=False)
-                if hasattr(x, "co_firstlineno"):
-                    return x
-        return obj
+        pass
+    if trycall:
+        call = getattr(obj, "__call__", None)
+        if call and not isinstance(obj, type):
+            return getrawcode(call, trycall=False)
+    raise TypeError(f"could not get code object for {obj!r}")


 def deindent(lines: Iterable[str]) -> List[str]:
@@ -145,12 +146,17 @@
 def get_statement_startend2(lineno: int, node: ast.AST) -> Tuple[int, Optional[int]]:
     # Flatten all statements and except handlers into one lineno-list.
     # AST's line numbers start indexing at 1.
-    values = []  # type: List[int]
+    values: List[int] = []
     for x in ast.walk(node):
         if isinstance(x, (ast.stmt, ast.ExceptHandler)):
+            # Before Python 3.8, the lineno of a decorated class or function pointed at the decorator.
+            # Since Python 3.8, the lineno points to the class/def, so need to include the decorators.
+            if isinstance(x, (ast.ClassDef, ast.FunctionDef, ast.AsyncFunctionDef)):
+                for d in x.decorator_list:
+                    values.append(d.lineno - 1)
             values.append(x.lineno - 1)
             for name in ("finalbody", "orelse"):
-                val = getattr(x, name, None)  # type: Optional[List[ast.stmt]]
+                val: Optional[List[ast.stmt]] = getattr(x, name, None)
                 if val:
                     # Treat the finally/orelse part as its own statement.
                     values.append(val[0].lineno - 1 - 1)
('src/_pytest/assertion', 'truncate.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -3,10 +3,10 @@
 Current default behaviour is to truncate assertion explanations at
 ~8 terminal lines, unless running in "-vv" mode or running on CI.
 """
-import os
 from typing import List
 from typing import Optional

+from _pytest.assertion import util
 from _pytest.nodes import Item


@@ -27,13 +27,7 @@
 def _should_truncate_item(item: Item) -> bool:
     """Whether or not this test item is eligible for truncation."""
     verbose = item.config.option.verbose
-    return verbose < 2 and not _running_on_ci()
-
-
-def _running_on_ci() -> bool:
-    """Check if we're currently running on a CI system."""
-    env_vars = ["CI", "BUILD_NUMBER"]
-    return any(var in os.environ for var in env_vars)
+    return verbose < 2 and not util.running_on_ci()


 def _truncate_explanation(
@@ -70,10 +64,10 @@
     truncated_line_count += 1  # Account for the part-truncated final line
     msg = "...Full output truncated"
     if truncated_line_count == 1:
-        msg += " ({} line hidden)".format(truncated_line_count)
+        msg += f" ({truncated_line_count} line hidden)"
     else:
-        msg += " ({} lines hidden)".format(truncated_line_count)
-    msg += ", {}".format(USAGE_MSG)
+        msg += f" ({truncated_line_count} lines hidden)"
+    msg += f", {USAGE_MSG}"
     truncated_explanation.extend(["", str(msg)])
     return truncated_explanation

('src/_pytest/assertion', 'util.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -1,5 +1,6 @@
 """Utilities for assertion debugging."""
 import collections.abc
+import os
 import pprint
 from typing import AbstractSet
 from typing import Any
@@ -9,24 +10,26 @@
 from typing import Mapping
 from typing import Optional
 from typing import Sequence
-from typing import Tuple

 import _pytest._code
 from _pytest import outcomes
 from _pytest._io.saferepr import _pformat_dispatch
 from _pytest._io.saferepr import safeformat
 from _pytest._io.saferepr import saferepr
-from _pytest.compat import ATTRS_EQ_FIELD
+from _pytest.config import Config

 # The _reprcompare attribute on the util module is used by the new assertion
 # interpretation code and assertion rewriter to detect this plugin was
 # loaded and in turn call the hooks defined here as part of the
 # DebugInterpreter.
-_reprcompare = None  # type: Optional[Callable[[str, object, object], Optional[str]]]
+_reprcompare: Optional[Callable[[str, object, object], Optional[str]]] = None

 # Works similarly as _reprcompare attribute. Is populated with the hook call
 # when pytest_runtest_setup is called.
-_assertion_pass = None  # type: Optional[Callable[[int, str, str], None]]
+_assertion_pass: Optional[Callable[[int, str, str], None]] = None
+
+# Config object which is assigned during pytest_runtest_protocol.
+_config: Optional[Config] = None


 def format_explanation(explanation: str) -> str:
@@ -112,6 +115,10 @@
     return isinstance(x, (set, frozenset))


+def isnamedtuple(obj: Any) -> bool:
+    return isinstance(obj, tuple) and getattr(obj, "_fields", None) is not None
+
+
 def isdatacls(obj: Any) -> bool:
     return getattr(obj, "__dataclass_fields__", None) is not None

@@ -126,6 +133,27 @@
         return not istext(obj)
     except TypeError:
         return False
+
+
+def has_default_eq(
+    obj: object,
+) -> bool:
+    """Check if an instance of an object contains the default eq
+
+    First, we check if the object's __eq__ attribute has __code__,
+    if so, we check the equally of the method code filename (__code__.co_filename)
+    to the default one generated by the dataclass and attr module
+    for dataclasses the default co_filename is <string>, for attrs class, the __eq__ should contain "attrs eq generated"
+    """
+    # inspired from https://github.com/willmcgugan/rich/blob/07d51ffc1aee6f16bd2e5a25b4e82850fb9ed778/rich/pretty.py#L68
+    if hasattr(obj.__eq__, "__code__") and hasattr(obj.__eq__.__code__, "co_filename"):
+        code_filename = obj.__eq__.__code__.co_filename
+
+        if isattrs(obj):
+            return "attrs generated eq" in code_filename
+
+        return code_filename == "<string>"  # data class
+    return True


 def assertrepr_compare(config, op: str, left: Any, right: Any) -> Optional[List[str]]:
@@ -143,7 +171,7 @@
         left_repr = saferepr(left, maxsize=maxsize)
         right_repr = saferepr(right, maxsize=maxsize)

-    summary = "{} {} {}".format(left_repr, op, right_repr)
+    summary = f"{left_repr} {op} {right_repr}"

     explanation = None
     try:
@@ -173,20 +201,33 @@
     if istext(left) and istext(right):
         explanation = _diff_text(left, right, verbose)
     else:
-        if issequence(left) and issequence(right):
+        from _pytest.python_api import ApproxBase
+
+        if isinstance(left, ApproxBase) or isinstance(right, ApproxBase):
+            # Although the common order should be obtained == expected, this ensures both ways
+            approx_side = left if isinstance(left, ApproxBase) else right
+            other_side = right if isinstance(left, ApproxBase) else left
+
+            explanation = approx_side._repr_compare(other_side)
+        elif type(left) == type(right) and (
+            isdatacls(left) or isattrs(left) or isnamedtuple(left)
+        ):
+            # Note: unlike dataclasses/attrs, namedtuples compare only the
+            # field values, not the type or field names. But this branch
+            # intentionally only handles the same-type case, which was often
+            # used in older code bases before dataclasses/attrs were available.
+            explanation = _compare_eq_cls(left, right, verbose)
+        elif issequence(left) and issequence(right):
             explanation = _compare_eq_sequence(left, right, verbose)
         elif isset(left) and isset(right):
             explanation = _compare_eq_set(left, right, verbose)
         elif isdict(left) and isdict(right):
             explanation = _compare_eq_dict(left, right, verbose)
-        elif type(left) == type(right) and (isdatacls(left) or isattrs(left)):
-            type_fn = (isdatacls, isattrs)
-            explanation = _compare_eq_cls(left, right, verbose, type_fn)
-        elif verbose > 0:
-            explanation = _compare_eq_verbose(left, right)
+
         if isiterable(left) and isiterable(right):
             expl = _compare_eq_iterable(left, right, verbose)
             explanation.extend(expl)
+
     return explanation


@@ -198,7 +239,7 @@
     """
     from difflib import ndiff

-    explanation = []  # type: List[str]
+    explanation: List[str] = []

     if verbose < 1:
         i = 0  # just in case left or right has zero length
@@ -238,18 +279,6 @@
     return explanation


-def _compare_eq_verbose(left: Any, right: Any) -> List[str]:
-    keepends = True
-    left_lines = repr(left).splitlines(keepends)
-    right_lines = repr(right).splitlines(keepends)
-
-    explanation = []  # type: List[str]
-    explanation += ["+" + line for line in left_lines]
-    explanation += ["-" + line for line in right_lines]
-
-    return explanation
-
-
 def _surrounding_parens_on_own_lines(lines: List[str]) -> None:
     """Move opening/closing parenthesis/bracket to own lines."""
     opening = lines[0][:1]
@@ -265,8 +294,8 @@
 def _compare_eq_iterable(
     left: Iterable[Any], right: Iterable[Any], verbose: int = 0
 ) -> List[str]:
-    if not verbose:
-        return ["Use -v to get the full diff"]
+    if verbose <= 0 and not running_on_ci():
+        return ["Use -v to get more diff"]
     # dynamic import to speedup pytest
     import difflib

@@ -297,7 +326,7 @@
     left: Sequence[Any], right: Sequence[Any], verbose: int = 0
 ) -> List[str]:
     comparing_bytes = isinstance(left, bytes) and isinstance(right, bytes)
-    explanation = []  # type: List[str]
+    explanation: List[str] = []
     len_left = len(left)
     len_right = len(right)
     for i in range(min(len_left, len_right)):
@@ -317,9 +346,7 @@
                 left_value = left[i]
                 right_value = right[i]

-            explanation += [
-                "At index {} diff: {!r} != {!r}".format(i, left_value, right_value)
-            ]
+            explanation += [f"At index {i} diff: {left_value!r} != {right_value!r}"]
             break

     if comparing_bytes:
@@ -339,9 +366,7 @@
             extra = saferepr(right[len_left])

         if len_diff == 1:
-            explanation += [
-                "{} contains one more item: {}".format(dir_with_more, extra)
-            ]
+            explanation += [f"{dir_with_more} contains one more item: {extra}"]
         else:
             explanation += [
                 "%s contains %d more items, first extra item: %s"
@@ -370,7 +395,7 @@
 def _compare_eq_dict(
     left: Mapping[Any, Any], right: Mapping[Any, Any], verbose: int = 0
 ) -> List[str]:
-    explanation = []  # type: List[str]
+    explanation: List[str] = []
     set_left = set(left)
     set_right = set(right)
     common = set_left.intersection(set_right)
@@ -408,21 +433,21 @@
     return explanation


-def _compare_eq_cls(
-    left: Any,
-    right: Any,
-    verbose: int,
-    type_fns: Tuple[Callable[[Any], bool], Callable[[Any], bool]],
-) -> List[str]:
-    isdatacls, isattrs = type_fns
+def _compare_eq_cls(left: Any, right: Any, verbose: int) -> List[str]:
+    if not has_default_eq(left):
+        return []
     if isdatacls(left):
-        all_fields = left.__dataclass_fields__
-        fields_to_check = [field for field, info in all_fields.items() if info.compare]
+        import dataclasses
+
+        all_fields = dataclasses.fields(left)
+        fields_to_check = [info.name for info in all_fields if info.compare]
     elif isattrs(left):
         all_fields = left.__attrs_attrs__
-        fields_to_check = [
-            field.name for field in all_fields if getattr(field, ATTRS_EQ_FIELD)
-        ]
+        fields_to_check = [field.name for field in all_fields if getattr(field, "eq")]
+    elif isnamedtuple(left):
+        fields_to_check = left._fields
+    else:
+        assert False

     indent = "  "
     same = []
@@ -476,3 +501,9 @@
         else:
             newdiff.append(line)
     return newdiff
+
+
+def running_on_ci() -> bool:
+    """Check if we're currently running on a CI system."""
+    env_vars = ["CI", "BUILD_NUMBER"]
+    return any(var in os.environ for var in env_vars)
('src/_pytest/assertion', '__init__.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -4,12 +4,12 @@
 from typing import Generator
 from typing import List
 from typing import Optional
+from typing import TYPE_CHECKING

 from _pytest.assertion import rewrite
 from _pytest.assertion import truncate
 from _pytest.assertion import util
 from _pytest.assertion.rewrite import assertstate_key
-from _pytest.compat import TYPE_CHECKING
 from _pytest.config import Config
 from _pytest.config import hookimpl
 from _pytest.config.argparsing import Parser
@@ -83,18 +83,18 @@
     def __init__(self, config: Config, mode) -> None:
         self.mode = mode
         self.trace = config.trace.root.get("assertion")
-        self.hook = None  # type: Optional[rewrite.AssertionRewritingHook]
+        self.hook: Optional[rewrite.AssertionRewritingHook] = None


 def install_importhook(config: Config) -> rewrite.AssertionRewritingHook:
     """Try to install the rewrite hook, raise SystemError if it fails."""
-    config._store[assertstate_key] = AssertionState(config, "rewrite")
-    config._store[assertstate_key].hook = hook = rewrite.AssertionRewritingHook(config)
+    config.stash[assertstate_key] = AssertionState(config, "rewrite")
+    config.stash[assertstate_key].hook = hook = rewrite.AssertionRewritingHook(config)
     sys.meta_path.insert(0, hook)
-    config._store[assertstate_key].trace("installed rewrite import hook")
+    config.stash[assertstate_key].trace("installed rewrite import hook")

     def undo() -> None:
-        hook = config._store[assertstate_key].hook
+        hook = config.stash[assertstate_key].hook
         if hook is not None and hook in sys.meta_path:
             sys.meta_path.remove(hook)

@@ -104,9 +104,9 @@

 def pytest_collection(session: "Session") -> None:
     # This hook is only called when test modules are collected
-    # so for example not in the master process of pytest-xdist
+    # so for example not in the managing process of pytest-xdist
     # (which does not collect test modules).
-    assertstate = session.config._store.get(assertstate_key, None)
+    assertstate = session.config.stash.get(assertstate_key, None)
     if assertstate:
         if assertstate.hook is not None:
             assertstate.hook.set_session(session)
@@ -153,6 +153,7 @@

     saved_assert_hooks = util._reprcompare, util._assertion_pass
     util._reprcompare = callbinrepr
+    util._config = item.config

     if ihook.pytest_assertion_pass.get_hookimpls():

@@ -164,10 +165,11 @@
     yield

     util._reprcompare, util._assertion_pass = saved_assert_hooks
+    util._config = None


 def pytest_sessionfinish(session: "Session") -> None:
-    assertstate = session.config._store.get(assertstate_key, None)
+    assertstate = session.config.stash.get(assertstate_key, None)
     if assertstate:
         if assertstate.hook is not None:
             assertstate.hook.set_session(None)
('src/_pytest/assertion', 'rewrite.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -13,43 +13,43 @@
 import sys
 import tokenize
 import types
+from pathlib import Path
+from pathlib import PurePath
 from typing import Callable
 from typing import Dict
 from typing import IO
 from typing import Iterable
+from typing import Iterator
 from typing import List
 from typing import Optional
 from typing import Sequence
 from typing import Set
 from typing import Tuple
+from typing import TYPE_CHECKING
 from typing import Union

-import py
-
+from _pytest._io.saferepr import DEFAULT_REPR_MAX_SIZE
 from _pytest._io.saferepr import saferepr
 from _pytest._version import version
 from _pytest.assertion import util
 from _pytest.assertion.util import (  # noqa: F401
     format_explanation as _format_explanation,
 )
-from _pytest.compat import fspath
-from _pytest.compat import TYPE_CHECKING
 from _pytest.config import Config
 from _pytest.main import Session
+from _pytest.pathlib import absolutepath
 from _pytest.pathlib import fnmatch_ex
-from _pytest.pathlib import Path
-from _pytest.pathlib import PurePath
-from _pytest.store import StoreKey
+from _pytest.stash import StashKey

 if TYPE_CHECKING:
-    from _pytest.assertion import AssertionState  # noqa: F401
-
-
-assertstate_key = StoreKey["AssertionState"]()
+    from _pytest.assertion import AssertionState
+
+
+assertstate_key = StashKey["AssertionState"]()


 # pytest caches rewritten pycs in pycache dirs
-PYTEST_TAG = "{}-pytest-{}".format(sys.implementation.cache_tag, version)
+PYTEST_TAG = f"{sys.implementation.cache_tag}-pytest-{version}"
 PYC_EXT = ".py" + (__debug__ and "c" or "o")
 PYC_TAIL = "." + PYTEST_TAG + PYC_EXT

@@ -63,14 +63,14 @@
             self.fnpats = config.getini("python_files")
         except ValueError:
             self.fnpats = ["test_*.py", "*_test.py"]
-        self.session = None  # type: Optional[Session]
-        self._rewritten_names = set()  # type: Set[str]
-        self._must_rewrite = set()  # type: Set[str]
+        self.session: Optional[Session] = None
+        self._rewritten_names: Dict[str, Path] = {}
+        self._must_rewrite: Set[str] = set()
         # flag to guard against trying to rewrite a pyc file while we are already writing another pyc file,
         # which might result in infinite recursion (#3506)
         self._writing_pyc = False
         self._basenames_to_check_rewrite = {"conftest"}
-        self._marked_for_rewrite_cache = {}  # type: Dict[str, bool]
+        self._marked_for_rewrite_cache: Dict[str, bool] = {}
         self._session_paths_checked = False

     def set_session(self, session: Optional[Session]) -> None:
@@ -88,7 +88,7 @@
     ) -> Optional[importlib.machinery.ModuleSpec]:
         if self._writing_pyc:
             return None
-        state = self.config._store[assertstate_key]
+        state = self.config.stash[assertstate_key]
         if self._early_rewrite_bailout(name, state):
             return None
         state.trace("find_module called for: %s" % name)
@@ -100,9 +100,6 @@
             spec is None
             # this is a namespace package (without `__init__.py`)
             # there's nothing to rewrite there
-            # python3.5 - python3.6: `namespace`
-            # python3.7+: `None`
-            or spec.origin == "namespace"
             or spec.origin is None
             # we can only rewrite source files
             or not isinstance(spec.loader, importlib.machinery.SourceFileLoader)
@@ -132,9 +129,9 @@
         assert module.__spec__ is not None
         assert module.__spec__.origin is not None
         fn = Path(module.__spec__.origin)
-        state = self.config._store[assertstate_key]
-
-        self._rewritten_names.add(module.__name__)
+        state = self.config.stash[assertstate_key]
+
+        self._rewritten_names[module.__name__] = fn

         # The requested module looks like a test file, so rewrite it. This is
         # the most magical part of the process: load the source, rewrite the
@@ -150,7 +147,7 @@
             ok = try_makedirs(cache_dir)
             if not ok:
                 write = False
-                state.trace("read only directory: {}".format(cache_dir))
+                state.trace(f"read only directory: {cache_dir}")

         cache_name = fn.name[:-3] + PYC_TAIL
         pyc = cache_dir / cache_name
@@ -158,7 +155,7 @@
         # to check for a cached pyc. This may not be optimal...
         co = _read_pyc(fn, pyc, state.trace)
         if co is None:
-            state.trace("rewriting {!r}".format(fn))
+            state.trace(f"rewriting {fn!r}")
             source_stat, co = _rewrite_test(fn, self.config)
             if write:
                 self._writing_pyc = True
@@ -167,7 +164,7 @@
                 finally:
                     self._writing_pyc = False
         else:
-            state.trace("found cached rewritten pyc for {}".format(fn))
+            state.trace(f"found cached rewritten pyc for {fn}")
         exec(co, module.__dict__)

     def _early_rewrite_bailout(self, name: str, state: "AssertionState") -> bool:
@@ -206,20 +203,18 @@
         if self._is_marked_for_rewrite(name, state):
             return False

-        state.trace("early skip of rewriting module: {}".format(name))
+        state.trace(f"early skip of rewriting module: {name}")
         return True

     def _should_rewrite(self, name: str, fn: str, state: "AssertionState") -> bool:
         # always rewrite conftest files
         if os.path.basename(fn) == "conftest.py":
-            state.trace("rewriting conftest file: {!r}".format(fn))
+            state.trace(f"rewriting conftest file: {fn!r}")
             return True

         if self.session is not None:
-            if self.session.isinitpath(py.path.local(fn)):
-                state.trace(
-                    "matched test file (was specified on cmdline): {!r}".format(fn)
-                )
+            if self.session.isinitpath(absolutepath(fn)):
+                state.trace(f"matched test file (was specified on cmdline): {fn!r}")
                 return True

         # modules not passed explicitly on the command line are only
@@ -227,7 +222,7 @@
         fn_path = PurePath(fn)
         for pat in self.fnpats:
             if fnmatch_ex(pat, fn_path):
-                state.trace("matched test file {!r}".format(fn))
+                state.trace(f"matched test file {fn!r}")
                 return True

         return self._is_marked_for_rewrite(name, state)
@@ -238,9 +233,7 @@
         except KeyError:
             for marked in self._must_rewrite:
                 if name == marked or name.startswith(marked + "."):
-                    state.trace(
-                        "matched marked file {!r} (from {!r})".format(name, marked)
-                    )
+                    state.trace(f"matched marked file {name!r} (from {marked!r})")
                     self._marked_for_rewrite_cache[name] = True
                     return True

@@ -280,18 +273,31 @@
         with open(pathname, "rb") as f:
             return f.read()

+    if sys.version_info >= (3, 10):
+
+        def get_resource_reader(self, name: str) -> importlib.abc.TraversableResources:  # type: ignore
+            if sys.version_info < (3, 11):
+                from importlib.readers import FileReader
+            else:
+                from importlib.resources.readers import FileReader
+
+            return FileReader(types.SimpleNamespace(path=self._rewritten_names[name]))
+

 def _write_pyc_fp(
     fp: IO[bytes], source_stat: os.stat_result, co: types.CodeType
 ) -> None:
     # Technically, we don't have to have the same pyc format as
     # (C)Python, since these "pycs" should never be seen by builtin
-    # import. However, there's little reason deviate.
+    # import. However, there's little reason to deviate.
     fp.write(importlib.util.MAGIC_NUMBER)
+    # https://www.python.org/dev/peps/pep-0552/
+    flags = b"\x00\x00\x00\x00"
+    fp.write(flags)
     # as of now, bytecode header expects 32-bit numbers for size and mtime (#4903)
     mtime = int(source_stat.st_mtime) & 0xFFFFFFFF
     size = source_stat.st_size & 0xFFFFFFFF
-    # "<LL" stands for 2 unsigned longs, little-ending
+    # "<LL" stands for 2 unsigned longs, little-endian.
     fp.write(struct.pack("<LL", mtime, size))
     fp.write(marshal.dumps(co))

@@ -306,16 +312,15 @@
         pyc: Path,
     ) -> bool:
         try:
-            with atomic_write(fspath(pyc), mode="wb", overwrite=True) as fp:
+            with atomic_write(os.fspath(pyc), mode="wb", overwrite=True) as fp:
                 _write_pyc_fp(fp, source_stat, co)
         except OSError as e:
-            state.trace("error writing pyc file at {}: {}".format(pyc, e))
+            state.trace(f"error writing pyc file at {pyc}: {e}")
             # we ignore any failure to write the cache file
             # there are many reasons, permission-denied, pycache dir being a
             # file etc.
             return False
         return True
-

 else:

@@ -325,20 +330,18 @@
         source_stat: os.stat_result,
         pyc: Path,
     ) -> bool:
-        proc_pyc = "{}.{}".format(pyc, os.getpid())
+        proc_pyc = f"{pyc}.{os.getpid()}"
         try:
             fp = open(proc_pyc, "wb")
         except OSError as e:
-            state.trace(
-                "error writing pyc file at {}: errno={}".format(proc_pyc, e.errno)
-            )
+            state.trace(f"error writing pyc file at {proc_pyc}: errno={e.errno}")
             return False

         try:
             _write_pyc_fp(fp, source_stat, co)
-            os.rename(proc_pyc, fspath(pyc))
+            os.rename(proc_pyc, pyc)
         except OSError as e:
-            state.trace("error writing pyc file at {}: {}".format(pyc, e))
+            state.trace(f"error writing pyc file at {pyc}: {e}")
             # we ignore any failure to write the cache file
             # there are many reasons, permission-denied, pycache dir being a
             # file etc.
@@ -350,13 +353,12 @@

 def _rewrite_test(fn: Path, config: Config) -> Tuple[os.stat_result, types.CodeType]:
     """Read and rewrite *fn* and return the code object."""
-    fn_ = fspath(fn)
-    stat = os.stat(fn_)
-    with open(fn_, "rb") as f:
-        source = f.read()
-    tree = ast.parse(source, filename=fn_)
-    rewrite_asserts(tree, source, fn_, config)
-    co = compile(tree, fn_, "exec", dont_inherit=True)
+    stat = os.stat(fn)
+    source = fn.read_bytes()
+    strfn = str(fn)
+    tree = ast.parse(source, filename=strfn)
+    rewrite_asserts(tree, source, strfn, config)
+    co = compile(tree, strfn, "exec", dont_inherit=True)
     return stat, co


@@ -368,30 +370,40 @@
     Return rewritten code if successful or None if not.
     """
     try:
-        fp = open(fspath(pyc), "rb")
+        fp = open(pyc, "rb")
     except OSError:
         return None
     with fp:
         try:
-            stat_result = os.stat(fspath(source))
+            stat_result = os.stat(source)
             mtime = int(stat_result.st_mtime)
             size = stat_result.st_size
-            data = fp.read(12)
+            data = fp.read(16)
         except OSError as e:
-            trace("_read_pyc({}): OSError {}".format(source, e))
+            trace(f"_read_pyc({source}): OSError {e}")
             return None
         # Check for invalid or out of date pyc file.
-        if (
-            len(data) != 12
-            or data[:4] != importlib.util.MAGIC_NUMBER
-            or struct.unpack("<LL", data[4:]) != (mtime & 0xFFFFFFFF, size & 0xFFFFFFFF)
-        ):
-            trace("_read_pyc(%s): invalid or out of date pyc" % source)
+        if len(data) != (16):
+            trace("_read_pyc(%s): invalid pyc (too short)" % source)
+            return None
+        if data[:4] != importlib.util.MAGIC_NUMBER:
+            trace("_read_pyc(%s): invalid pyc (bad magic number)" % source)
+            return None
+        if data[4:8] != b"\x00\x00\x00\x00":
+            trace("_read_pyc(%s): invalid pyc (unsupported flags)" % source)
+            return None
+        mtime_data = data[8:12]
+        if int.from_bytes(mtime_data, "little") != mtime & 0xFFFFFFFF:
+            trace("_read_pyc(%s): out of date" % source)
+            return None
+        size_data = data[12:16]
+        if int.from_bytes(size_data, "little") != size & 0xFFFFFFFF:
+            trace("_read_pyc(%s): invalid pyc (incorrect size)" % source)
             return None
         try:
             co = marshal.load(fp)
         except Exception as e:
-            trace("_read_pyc({}): marshal.load error {}".format(source, e))
+            trace(f"_read_pyc({source}): marshal.load error {e}")
             return None
         if not isinstance(co, types.CodeType):
             trace("_read_pyc(%s): not a code object" % source)
@@ -419,7 +431,18 @@
     sequences, especially '\n{' and '\n}' are likely to be present in
     JSON reprs.
     """
-    return saferepr(obj).replace("\n", "\\n")
+    maxsize = _get_maxsize_for_saferepr(util._config)
+    return saferepr(obj, maxsize=maxsize).replace("\n", "\\n")
+
+
+def _get_maxsize_for_saferepr(config: Optional[Config]) -> Optional[int]:
+    """Get `maxsize` configuration for saferepr based on the given config object."""
+    verbosity = config.getoption("verbose") if config is not None else 0
+    if verbosity >= 2:
+        return None
+    if verbosity >= 1:
+        return DEFAULT_REPR_MAX_SIZE * 10
+    return DEFAULT_REPR_MAX_SIZE


 def _format_assertmsg(obj: object) -> str:
@@ -486,7 +509,7 @@

 def _check_if_assertion_pass_impl() -> bool:
     """Check if any plugins implement the pytest_assertion_pass hook
-    in order not to generate explanation unecessarily (might be expensive)."""
+    in order not to generate explanation unnecessarily (might be expensive)."""
     return True if util._assertion_pass else False


@@ -519,29 +542,22 @@
 }


-def set_location(node, lineno, col_offset):
-    """Set node location information recursively."""
-
-    def _fix(node, lineno, col_offset):
-        if "lineno" in node._attributes:
-            node.lineno = lineno
-        if "col_offset" in node._attributes:
-            node.col_offset = col_offset
-        for child in ast.iter_child_nodes(node):
-            _fix(child, lineno, col_offset)
-
-    _fix(node, lineno, col_offset)
-    return node
-
-
+def traverse_node(node: ast.AST) -> Iterator[ast.AST]:
+    """Recursively yield node and all its children in depth-first order."""
+    yield node
+    for child in ast.iter_child_nodes(node):
+        yield from traverse_node(child)
+
+
+@functools.lru_cache(maxsize=1)
 def _get_assertion_exprs(src: bytes) -> Dict[int, str]:
     """Return a mapping from {lineno: "assertion test expression"}."""
-    ret = {}  # type: Dict[int, str]
+    ret: Dict[int, str] = {}

     depth = 0
-    lines = []  # type: List[str]
-    assert_lineno = None  # type: Optional[int]
-    seen_lines = set()  # type: Set[int]
+    lines: List[str] = []
+    assert_lineno: Optional[int] = None
+    seen_lines: Set[int] = set()

     def _write_and_reset() -> None:
         nonlocal depth, lines, assert_lineno, seen_lines
@@ -655,21 +671,14 @@
             self.enable_assertion_pass_hook = False
         self.source = source

-    @functools.lru_cache(maxsize=1)
-    def _assert_expr_to_lineno(self) -> Dict[int, str]:
-        return _get_assertion_exprs(self.source)
-
     def run(self, mod: ast.Module) -> None:
         """Find all assert statements in *mod* and rewrite them."""
         if not mod.body:
             # Nothing to do.
             return
-        # Insert some special imports at the top of the module but after any
-        # docstrings and __future__ imports.
-        aliases = [
-            ast.alias("builtins", "@py_builtins"),
-            ast.alias("_pytest.assertion.rewrite", "@pytest_ar"),
-        ]
+
+        # We'll insert some special imports at the top of the module, but after any
+        # docstrings and __future__ imports, so first figure out where that is.
         doc = getattr(mod, "docstring", None)
         expect_docstring = doc is None
         if doc is not None and self.is_rewrite_disabled(doc):
@@ -701,17 +710,34 @@
             lineno = item.decorator_list[0].lineno
         else:
             lineno = item.lineno
+        # Now actually insert the special imports.
+        if sys.version_info >= (3, 10):
+            aliases = [
+                ast.alias("builtins", "@py_builtins", lineno=lineno, col_offset=0),
+                ast.alias(
+                    "_pytest.assertion.rewrite",
+                    "@pytest_ar",
+                    lineno=lineno,
+                    col_offset=0,
+                ),
+            ]
+        else:
+            aliases = [
+                ast.alias("builtins", "@py_builtins"),
+                ast.alias("_pytest.assertion.rewrite", "@pytest_ar"),
+            ]
         imports = [
             ast.Import([alias], lineno=lineno, col_offset=0) for alias in aliases
         ]
         mod.body[pos:pos] = imports
+
         # Collect asserts.
-        nodes = [mod]  # type: List[ast.AST]
+        nodes: List[ast.AST] = [mod]
         while nodes:
             node = nodes.pop()
             for name, field in ast.iter_fields(node):
                 if isinstance(field, list):
-                    new = []  # type: List[ast.AST]
+                    new: List[ast.AST] = []
                     for i, child in enumerate(field):
                         if isinstance(child, ast.Assert):
                             # Transform assert.
@@ -783,7 +809,7 @@
         to format a string of %-formatted values as added by
         .explanation_param().
         """
-        self.explanation_specifiers = {}  # type: Dict[str, ast.expr]
+        self.explanation_specifiers: Dict[str, ast.expr] = {}
         self.stack.append(self.explanation_specifiers)

     def pop_format_context(self, expl_expr: ast.expr) -> ast.Name:
@@ -831,19 +857,19 @@
                     "assertion is always true, perhaps remove parentheses?"
                 ),
                 category=None,
-                filename=fspath(self.module_path),
+                filename=self.module_path,
                 lineno=assert_.lineno,
             )

-        self.statements = []  # type: List[ast.stmt]
-        self.variables = []  # type: List[str]
+        self.statements: List[ast.stmt] = []
+        self.variables: List[str] = []
         self.variable_counter = itertools.count()

         if self.enable_assertion_pass_hook:
-            self.format_variables = []  # type: List[str]
-
-        self.stack = []  # type: List[Dict[str, ast.expr]]
-        self.expl_stmts = []  # type: List[ast.stmt]
+            self.format_variables: List[str] = []
+
+        self.stack: List[Dict[str, ast.expr]] = []
+        self.expl_stmts: List[ast.stmt] = []
         self.push_format_context()
         # Rewrite assert into a bunch of statements.
         top_condition, explanation = self.visit(assert_.test)
@@ -872,7 +898,7 @@

             # Passed
             fmt_pass = self.helper("_format_explanation", msg)
-            orig = self._assert_expr_to_lineno()[assert_.lineno]
+            orig = _get_assertion_exprs(self.source)[assert_.lineno]
             hook_call_pass = ast.Expr(
                 self.helper(
                     "_call_assertion_pass",
@@ -923,9 +949,10 @@
             variables = [ast.Name(name, ast.Store()) for name in self.variables]
             clear = ast.Assign(variables, ast.NameConstant(None))
             self.statements.append(clear)
-        # Fix line numbers.
+        # Fix locations (line numbers/column offsets).
         for stmt in self.statements:
-            set_location(stmt, assert_.lineno, assert_.col_offset)
+            for node in traverse_node(stmt):
+                ast.copy_location(node, assert_)
         return self.statements

     def visit_Name(self, name: ast.Name) -> Tuple[ast.Name, str]:
@@ -950,7 +977,7 @@
         # Process each operand, short-circuiting if needed.
         for i, v in enumerate(boolop.values):
             if i:
-                fail_inner = []  # type: List[ast.stmt]
+                fail_inner: List[ast.stmt] = []
                 # cond is set in a prior loop iteration below
                 self.expl_stmts.append(ast.If(cond, fail_inner, []))  # noqa
                 self.expl_stmts = fail_inner
@@ -961,10 +988,10 @@
             call = ast.Call(app, [expl_format], [])
             self.expl_stmts.append(ast.Expr(call))
             if i < levels:
-                cond = res  # type: ast.expr
+                cond: ast.expr = res
                 if is_or:
                     cond = ast.UnaryOp(ast.Not(), cond)
-                inner = []  # type: List[ast.stmt]
+                inner: List[ast.stmt] = []
                 self.statements.append(ast.If(cond, inner, []))
                 self.statements = body = inner
         self.statements = save
@@ -983,7 +1010,7 @@
         symbol = BINOP_MAP[binop.op.__class__]
         left_expr, left_expl = self.visit(binop.left)
         right_expr, right_expl = self.visit(binop.right)
-        explanation = "({} {} {})".format(left_expl, symbol, right_expl)
+        explanation = f"({left_expl} {symbol} {right_expl})"
         res = self.assign(ast.BinOp(left_expr, binop.op, right_expr))
         return res, explanation

@@ -1008,11 +1035,11 @@
         new_call = ast.Call(new_func, new_args, new_kwargs)
         res = self.assign(new_call)
         res_expl = self.explanation_param(self.display(res))
-        outer_expl = "{}\n{{{} = {}\n}}".format(res_expl, res_expl, expl)
+        outer_expl = f"{res_expl}\n{{{res_expl} = {expl}\n}}"
         return res, outer_expl

     def visit_Starred(self, starred: ast.Starred) -> Tuple[ast.Starred, str]:
-        # From Python 3.5, a Starred node can appear in a function call.
+        # A Starred node can appear in a function call.
         res, expl = self.visit(starred.value)
         new_starred = ast.Starred(res, starred.ctx)
         return new_starred, "*" + expl
@@ -1031,7 +1058,7 @@
         self.push_format_context()
         left_res, left_expl = self.visit(comp.left)
         if isinstance(comp.left, (ast.Compare, ast.BoolOp)):
-            left_expl = "({})".format(left_expl)
+            left_expl = f"({left_expl})"
         res_variables = [self.variable() for i in range(len(comp.ops))]
         load_names = [ast.Name(v, ast.Load()) for v in res_variables]
         store_names = [ast.Name(v, ast.Store()) for v in res_variables]
@@ -1042,11 +1069,11 @@
         for i, op, next_operand in it:
             next_res, next_expl = self.visit(next_operand)
             if isinstance(next_operand, (ast.Compare, ast.BoolOp)):
-                next_expl = "({})".format(next_expl)
+                next_expl = f"({next_expl})"
             results.append(next_res)
             sym = BINOP_MAP[op.__class__]
             syms.append(ast.Str(sym))
-            expl = "{} {} {}".format(left_expl, sym, next_expl)
+            expl = f"{left_expl} {sym} {next_expl}"
             expls.append(ast.Str(expl))
             res_expr = ast.Compare(left_res, [op], [next_res])
             self.statements.append(ast.Assign([store_names[i]], res_expr))
@@ -1060,7 +1087,7 @@
             ast.Tuple(results, ast.Load()),
         )
         if len(comp.ops) > 1:
-            res = ast.BoolOp(ast.And(), load_names)  # type: ast.expr
+            res: ast.expr = ast.BoolOp(ast.And(), load_names)
         else:
             res = load_names[0]
         return res, self.explanation_param(self.pop_format_context(expl_call))
@@ -1072,7 +1099,7 @@
     Returns True if successful or if it already exists.
     """
     try:
-        os.makedirs(fspath(cache_dir), exist_ok=True)
+        os.makedirs(cache_dir, exist_ok=True)
     except (FileNotFoundError, NotADirectoryError, FileExistsError):
         # One of the path components was not a directory:
         # - we're in a zip file
('src/_pytest/_io', 'saferepr.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -12,7 +12,7 @@
     except (KeyboardInterrupt, SystemExit):
         raise
     except BaseException:
-        return '{}("{}")'.format(type(obj).__name__, obj)
+        return f'{type(obj).__name__}("{obj}")'


 def _format_repr_exception(exc: BaseException, obj: object) -> str:
@@ -21,7 +21,7 @@
     except (KeyboardInterrupt, SystemExit):
         raise
     except BaseException as exc:
-        exc_info = "unpresentable exception ({})".format(_try_repr_or_str(exc))
+        exc_info = f"unpresentable exception ({_try_repr_or_str(exc)})"
     return "<[{} raised in repr()] {} object at 0x{:x}>".format(
         exc_info, type(obj).__name__, id(obj)
     )
@@ -36,12 +36,23 @@


 class SafeRepr(reprlib.Repr):
-    """repr.Repr that limits the resulting size of repr() and includes
-    information on exceptions raised during the call."""
+    """
+    repr.Repr that limits the resulting size of repr() and includes
+    information on exceptions raised during the call.
+    """

-    def __init__(self, maxsize: int) -> None:
+    def __init__(self, maxsize: Optional[int]) -> None:
+        """
+        :param maxsize:
+            If not None, will truncate the resulting repr to that specific size, using ellipsis
+            somewhere in the middle to hide the extra text.
+            If None, will not impose any size limits on the returning repr.
+        """
         super().__init__()
-        self.maxstring = maxsize
+        # ``maxstring`` is used by the superclass, and needs to be an int; using a
+        # very large number in case maxsize is None, meaning we want to disable
+        # truncation.
+        self.maxstring = maxsize if maxsize is not None else 1_000_000_000
         self.maxsize = maxsize

     def repr(self, x: object) -> str:
@@ -51,7 +62,9 @@
             raise
         except BaseException as exc:
             s = _format_repr_exception(exc, x)
-        return _ellipsize(s, self.maxsize)
+        if self.maxsize is not None:
+            s = _ellipsize(s, self.maxsize)
+        return s

     def repr_instance(self, x: object, level: int) -> str:
         try:
@@ -60,7 +73,9 @@
             raise
         except BaseException as exc:
             s = _format_repr_exception(exc, x)
-        return _ellipsize(s, self.maxsize)
+        if self.maxsize is not None:
+            s = _ellipsize(s, self.maxsize)
+        return s


 def safeformat(obj: object) -> str:
@@ -75,7 +90,11 @@
         return _format_repr_exception(exc, obj)


-def saferepr(obj: object, maxsize: int = 240) -> str:
+# Maximum size of overall repr of objects to display during assertion errors.
+DEFAULT_REPR_MAX_SIZE = 240
+
+
+def saferepr(obj: object, maxsize: Optional[int] = DEFAULT_REPR_MAX_SIZE) -> str:
     """Return a size-limited safe repr-string for the given object.

     Failing __repr__ functions of user instances will be represented
@@ -83,7 +102,7 @@
     care to never raise exceptions itself.

     This function is a wrapper around the Repr/reprlib functionality of the
-    standard 2.6 lib.
+    stdlib.
     """
     return SafeRepr(maxsize).repr(obj)

@@ -107,7 +126,12 @@
         if objid in context or p is None:
             # Type ignored because _format is private.
             super()._format(  # type: ignore[misc]
-                object, stream, indent, allowance, context, level,
+                object,
+                stream,
+                indent,
+                allowance,
+                context,
+                level,
             )
             return

@@ -122,7 +146,7 @@
     width: int = 80,
     depth: Optional[int] = None,
     *,
-    compact: bool = False
+    compact: bool = False,
 ) -> str:
     return AlwaysDispatchingPrettyPrinter(
         indent=indent, width=width, depth=depth, compact=compact
('src/_pytest/_io', 'terminalwriter.py')
--- /Users/tshi/researchProjs/pytest/pytest-6.1.2/
+++ /Users/tshi/researchProjs/pytest/pytest-7.1.2/
@@ -76,7 +76,7 @@
         self._file = file
         self.hasmarkup = should_do_markup(file)
         self._current_line = ""
-        self._terminal_width = None  # type: Optional[int]
+        self._terminal_width: Optional[int] = None
         self.code_highlight = True

     @property
@@ -97,7 +97,7 @@
     def markup(self, text: str, **markup: bool) -> str:
         for name in markup:
             if name not in self._esctable:
-                raise ValueError("unknown markup: {!r}".format(name))
+                raise ValueError(f"unknown markup: {name!r}")
         if self.hasmarkup:
             esc = [self._esctable[name] for name, on in markup.items() if on]
             if esc:
@@ -109,7 +109,7 @@
         sepchar: str,
         title: Optional[str] = None,
         fullwidth: Optional[int] = None,
-        **markup: bool
+        **markup: bool,
     ) -> None:
         if fullwidth is None:
             fullwidth = self.fullwidth
@@ -128,7 +128,7 @@
             #         N <= (fullwidth - len(title) - 2) // (2*len(sepchar))
             N = max((fullwidth - len(title) - 2) // (2 * len(sepchar)), 1)
             fill = sepchar * N
-            line = "{} {} {}".format(fill, title, fill)
+            line = f"{fill} {title} {fill}"
         else:
             # we want len(sepchar)*N <= fullwidth
             # i.e.    N <= fullwidth // len(sepchar)
@@ -195,16 +195,39 @@

     def _highlight(self, source: str) -> str:
         """Highlight the given source code if we have markup support."""
+        from _pytest.config.exceptions import UsageError
+
         if not self.hasmarkup or not self.code_highlight:
             return source
         try:
             from pygments.formatters.terminal import TerminalFormatter
             from pygments.lexers.python import PythonLexer
             from pygments import highlight
+            import pygments.util
         except ImportError:
             return source
         else:
-            highlighted = highlight(
-                source, PythonLexer(), TerminalFormatter(bg="dark")
-            )  # type: str
-            return highlighted
+            try:
+                highlighted: str = highlight(
+                    source,
+                    PythonLexer(),
+                    TerminalFormatter(
+                        bg=os.getenv("PYTEST_THEME_MODE", "dark"),
+                        style=os.getenv("PYTEST_THEME"),
+                    ),
+                )
+                return highlighted
+            except pygments.util.ClassNotFound:
+                raise UsageError(
+                    "PYTEST_THEME environment variable had an invalid value: '{}'. "
+                    "Only valid pygment styles are allowed.".format(
+                        os.getenv("PYTEST_THEME")
+                    )
+                )
+            except pygments.util.OptionError:
+                raise UsageError(
+                    "PYTEST_THEME_MODE environment variable had an invalid value: '{}'. "
+                    "The only allowed values are 'dark' and 'light'.".format(
+                        os.getenv("PYTEST_THEME_MODE")
+                    )
+                )
