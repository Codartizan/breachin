('utils', 'bump_version.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -23,19 +23,23 @@
 
 def bump_version(path, version_info, in_develop=True):
     version = stringify_version(version_info, in_develop)
-    release = version
-    if in_develop:
-        version += '+'
 
-    with open(path, 'r+') as f:
-        body = f.read()
-        body = re.sub(r"(?<=__version__ = ')[^']+", version, body)
-        body = re.sub(r"(?<=__released__ = ')[^']+", release, body)
-        body = re.sub(r"(?<=version_info = )\(.*\)", str(version_info), body)
+    with open(path, 'r', encoding='utf-8') as f:
+        lines = f.read().splitlines()
 
-        f.seek(0)
-        f.truncate(0)
-        f.write(body)
+    for i, line in enumerate(lines):
+        if line.startswith('__version__ = '):
+            lines[i] = f"__version__ = '{version}'"
+            continue
+        if line.startswith('version_info = '):
+            lines[i] = f'version_info = {version_info}'
+            continue
+        if line.startswith('_in_development = '):
+            lines[i] = f'_in_development = {in_develop}'
+            continue
+
+    with open(path, 'w', encoding='utf-8') as f:
+        f.write('\n'.join(lines) + '\n')
 
 
 def parse_version(version):
@@ -88,7 +92,7 @@
         self.fetch_version()
 
     def fetch_version(self):
-        with open(self.path) as f:
+        with open(self.path, encoding='utf-8') as f:
             version = f.readline().strip()
             matched = re.search(r'^Release (.*) \((.*)\)$', version)
             if matched is None:
@@ -105,7 +109,7 @@
         release_date = datetime.now().strftime('%b %d, %Y')
         heading = 'Release %s (released %s)' % (self.version, release_date)
 
-        with open(self.path, 'r+') as f:
+        with open(self.path, 'r+', encoding='utf-8') as f:
             f.readline()  # skip first two lines
             f.readline()
             body = f.read()
@@ -126,12 +130,12 @@
                                    version_info[4] or '')
         heading = 'Release %s (in development)' % version
 
-        with open(os.path.join(script_dir, 'CHANGES_template')) as f:
+        with open(os.path.join(script_dir, 'CHANGES_template'), encoding='utf-8') as f:
             f.readline()  # skip first two lines
             f.readline()
             tmpl = f.read()
 
-        with open(self.path, 'r+') as f:
+        with open(self.path, 'r+', encoding='utf-8') as f:
             body = f.read()
 
             f.seek(0)
('sphinx', 'jinja2glue.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,16 +1,9 @@
-"""
-    sphinx.jinja2glue
-    ~~~~~~~~~~~~~~~~~
-
-    Glue code for the jinja2 templating engine.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
-
+"""Glue code for the jinja2 templating engine."""
+
+import pathlib
 from os import path
 from pprint import pformat
-from typing import TYPE_CHECKING, Any, Callable, Dict, Iterator, List, Tuple, Union
+from typing import TYPE_CHECKING, Any, Callable, Dict, Iterator, List, Optional, Tuple, Union
 
 from jinja2 import BaseLoader, FileSystemLoader, TemplateNotFound
 from jinja2.environment import Environment
@@ -124,7 +117,7 @@
 
     def get_source(self, environment: Environment, template: str) -> Tuple[str, str, Callable]:
         for searchpath in self.searchpath:
-            filename = path.join(searchpath, template)
+            filename = str(pathlib.Path(searchpath, template))
             f = open_if_exists(filename)
             if f is None:
                 continue
@@ -149,7 +142,12 @@
 
     # TemplateBridge interface
 
-    def init(self, builder: "Builder", theme: Theme = None, dirs: List[str] = None) -> None:
+    def init(
+        self,
+        builder: "Builder",
+        theme: Optional[Theme] = None,
+        dirs: Optional[List[str]] = None
+    ) -> None:
         # create a chain of paths to search
         if theme:
             # the theme's own dir and its bases' dirs
('sphinx', 'theming.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.theming
-    ~~~~~~~~~~~~~~
-
-    Theming support for HTML builders.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Theming support for HTML builders."""
 
 import configparser
 import os
@@ -16,7 +8,10 @@
 from typing import TYPE_CHECKING, Any, Dict, List
 from zipfile import ZipFile
 
-import pkg_resources
+try:  # Python < 3.10 (backport)
+    from importlib_metadata import entry_points
+except ImportError:
+    from importlib.metadata import entry_points
 
 from sphinx import package_dir
 from sphinx.errors import ThemeError
@@ -69,7 +64,7 @@
             extract_zip(theme_path, self.themedir)
 
         self.config = configparser.RawConfigParser()
-        self.config.read(path.join(self.themedir, THEMECONF))
+        self.config.read(path.join(self.themedir, THEMECONF), encoding='utf-8')
 
         try:
             inherit = self.config.get('theme', 'inherit')
@@ -201,12 +196,13 @@
         Sphinx refers to ``sphinx_themes`` entry_points.
         """
         # look up for new styled entry_points at first
-        entry_points = pkg_resources.iter_entry_points('sphinx.html_themes', name)
-        try:
-            entry_point = next(entry_points)
-            self.app.registry.load_extension(self.app, entry_point.module_name)
+        theme_entry_points = entry_points(group='sphinx.html_themes')
+        try:
+            entry_point = theme_entry_points[name]
+            self.app.registry.load_extension(self.app, entry_point.module)
+            self.app.config.post_init_values()
             return
-        except StopIteration:
+        except KeyError:
             pass
 
     def find_themes(self, theme_path: str) -> Dict[str, str]:
('sphinx', 'config.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.config
-    ~~~~~~~~~~~~~
-
-    Build configuration file handling.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Build configuration file handling."""
 
 import re
 import traceback
@@ -100,18 +92,22 @@
         # the real default is locale-dependent
         'today_fmt': (None, 'env', [str]),
 
-        'language': (None, 'env', [str]),
+        'language': ('en', 'env', [str]),
         'locale_dirs': (['locales'], 'env', []),
         'figure_language_filename': ('{root}.{language}{ext}', 'env', [str]),
+        'gettext_allow_fuzzy_translations': (False, 'gettext', []),
 
         'master_doc': ('index', 'env', []),
         'root_doc': (lambda config: config.master_doc, 'env', []),
         'source_suffix': ({'.rst': 'restructuredtext'}, 'env', Any),
         'source_encoding': ('utf-8-sig', 'env', []),
-        'exclude_patterns': ([], 'env', []),
+        'exclude_patterns': ([], 'env', [str]),
+        'include_patterns': (["**"], 'env', [str]),
         'default_role': (None, 'env', [str]),
         'add_function_parentheses': (True, 'env', []),
         'add_module_names': (True, 'env', []),
+        'toc_object_entries_show_parents': ('domain', 'env',
+                                            ENUM('domain', 'all', 'hide')),
         'trim_footnote_reference_space': (False, 'env', []),
         'show_authors': (False, 'env', []),
         'pygments_style': (None, 'html', [str]),
@@ -147,6 +143,7 @@
         'smartquotes_excludes': ({'languages': ['ja'],
                                   'builders': ['man', 'text']},
                                  'env', []),
+        'option_emphasise_placeholders': (False, 'env', []),
     }
 
     def __init__(self, config: Dict[str, Any] = {}, overrides: Dict[str, Any] = {}) -> None:
@@ -163,13 +160,26 @@
         self.extensions: List[str] = config.get('extensions', [])
 
     @classmethod
-    def read(cls, confdir: str, overrides: Dict = None, tags: Tags = None) -> "Config":
+    def read(
+        cls, confdir: str, overrides: Optional[Dict] = None, tags: Optional[Tags] = None
+    ) -> "Config":
         """Create a Config object from configuration file."""
         filename = path.join(confdir, CONFIG_FILENAME)
         if not path.isfile(filename):
             raise ConfigError(__("config directory doesn't contain a conf.py file (%s)") %
                               confdir)
         namespace = eval_config_file(filename, tags)
+
+        # Note: Old sphinx projects have been configured as "language = None" because
+        #       sphinx-quickstart previously generated this by default.
+        #       To keep compatibility, they should be fallback to 'en' for a while
+        #       (This conversion should not be removed before 2025-01-01).
+        if namespace.get("language", ...) is None:
+            logger.warning(__("Invalid configuration value found: 'language = None'. "
+                              "Update your configuration to a valid language code. "
+                              "Falling back to 'en' (English)."))
+            namespace["language"] = "en"
+
         return cls(namespace, overrides or {})
 
     def convert_overrides(self, name: str, value: Any) -> Any:
@@ -205,7 +215,7 @@
                 except ValueError as exc:
                     raise ValueError(__('invalid number %r for config value %r, ignoring') %
                                      (value, name)) from exc
-            elif hasattr(defvalue, '__call__'):
+            elif callable(defvalue):
                 return value
             elif defvalue is not None and not isinstance(defvalue, str):
                 raise ValueError(__('cannot override config setting %r with unsupported '
@@ -250,13 +260,24 @@
             if name in self.values:
                 self.__dict__[name] = config[name]
 
+    def post_init_values(self) -> None:
+        """
+        Initialize additional config variables that are added after init_values() called.
+        """
+        config = self._raw_config
+        for name in config:
+            if name not in self.__dict__ and name in self.values:
+                self.__dict__[name] = config[name]
+
+        check_confval_types(None, self)
+
     def __getattr__(self, name: str) -> Any:
         if name.startswith('_'):
             raise AttributeError(name)
         if name not in self.values:
             raise AttributeError(__('No such config value: %s') % name)
         default = self.values[name][0]
-        if hasattr(default, '__call__'):
+        if callable(default):
             return default(self)
         return default
 
@@ -401,18 +422,18 @@
     if getenv('SOURCE_DATE_EPOCH') is not None:
         for k in ('copyright', 'epub_copyright'):
             if k in config:
-                replace = r'\g<1>%s' % format_date('%Y')
+                replace = r'\g<1>%s' % format_date('%Y', language='en')
                 config[k] = copyright_year_re.sub(replace, config[k])
 
 
-def check_confval_types(app: "Sphinx", config: Config) -> None:
+def check_confval_types(app: Optional["Sphinx"], config: Config) -> None:
     """Check all values for deviation from the default value's type, since
     that can result in TypeErrors all over the place NB.
     """
     for confval in config:
         default, rebuild, annotations = config.values[confval.name]
 
-        if hasattr(default, '__call__'):
+        if callable(default):
             default = default(config)  # evaluate default value
         if default is None and not annotations:
             continue  # neither inferable nor expliclitly annotated types
@@ -426,7 +447,7 @@
                          "but `{current}` is given.")
                 logger.warning(msg.format(name=confval.name,
                                           current=confval.value,
-                                          candidates=annotations.candidates))
+                                          candidates=annotations.candidates), once=True)
         else:
             if type(confval.value) is type(default):
                 continue
@@ -451,13 +472,13 @@
                     permitted = " or ".join(wrapped_annotations)
                 logger.warning(msg.format(name=confval.name,
                                           current=type(confval.value),
-                                          permitted=permitted))
+                                          permitted=permitted), once=True)
             else:
                 msg = __("The config value `{name}' has type `{current.__name__}', "
                          "defaults to `{default.__name__}'.")
                 logger.warning(msg.format(name=confval.name,
                                           current=type(confval.value),
-                                          default=type(default)))
+                                          default=type(default)), once=True)
 
 
 def check_primary_domain(app: "Sphinx", config: Config) -> None:
('sphinx', 'roles.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,21 +1,16 @@
-"""
-    sphinx.roles
-    ~~~~~~~~~~~~
-
-    Handlers for additional ReST roles.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Handlers for additional ReST roles."""
 
 import re
-from typing import TYPE_CHECKING, Any, Dict, List, Tuple, Type
-
+from typing import TYPE_CHECKING, Any, Dict, List, Optional, Tuple, Type
+
+import docutils.parsers.rst.directives
+import docutils.parsers.rst.roles
+import docutils.parsers.rst.states
 from docutils import nodes, utils
 from docutils.nodes import Element, Node, TextElement, system_message
 
 from sphinx import addnodes
-from sphinx.locale import _
+from sphinx.locale import _, __
 from sphinx.util import ws_re
 from sphinx.util.docutils import ReferenceRole, SphinxRole
 from sphinx.util.typing import RoleFunction
@@ -69,7 +64,8 @@
     innernodeclass: Type[TextElement] = nodes.literal
 
     def __init__(self, fix_parens: bool = False, lowercase: bool = False,
-                 nodeclass: Type[Element] = None, innernodeclass: Type[TextElement] = None,
+                 nodeclass: Optional[Type[Element]] = None,
+                 innernodeclass: Optional[Type[TextElement]] = None,
                  warn_dangling: bool = False) -> None:
         self.fix_parens = fix_parens
         self.lowercase = lowercase
@@ -190,7 +186,7 @@
                 title = "PEP " + self.title
                 reference += nodes.strong(title, title)
         except ValueError:
-            msg = self.inliner.reporter.error('invalid PEP number %s' % self.target,
+            msg = self.inliner.reporter.error(__('invalid PEP number %s') % self.target,
                                               line=self.lineno)
             prb = self.inliner.problematic(self.rawtext, self.rawtext, msg)
             return [prb], [msg]
@@ -201,9 +197,9 @@
         base_url = self.inliner.document.settings.pep_base_url
         ret = self.target.split('#', 1)
         if len(ret) == 2:
-            return base_url + 'pep-%04d#%s' % (int(ret[0]), ret[1])
+            return base_url + 'pep-%04d/#%s' % (int(ret[0]), ret[1])
         else:
-            return base_url + 'pep-%04d' % int(ret[0])
+            return base_url + 'pep-%04d/' % int(ret[0])
 
 
 class RFC(ReferenceRole):
@@ -224,7 +220,7 @@
                 title = "RFC " + self.title
                 reference += nodes.strong(title, title)
         except ValueError:
-            msg = self.inliner.reporter.error('invalid RFC number %s' % self.target,
+            msg = self.inliner.reporter.error(__('invalid RFC number %s') % self.target,
                                               line=self.lineno)
             prb = self.inliner.problematic(self.rawtext, self.rawtext, msg)
             return [prb], [msg]
@@ -301,7 +297,7 @@
                 if len(stack) == 3 and stack[1] == "{" and len(stack[2]) > 0:
                     # emphasized word found
                     if stack[0]:
-                        result.append(nodes.Text(stack[0], stack[0]))
+                        result.append(nodes.Text(stack[0]))
                     result.append(nodes.emphasis(stack[2], stack[2]))
                     stack = ['']
                 else:
@@ -318,7 +314,7 @@
         if ''.join(stack):
             # remaining is treated as Text
             text = ''.join(stack)
-            result.append(nodes.Text(text, text))
+            result.append(nodes.Text(text))
 
         return result
 
@@ -339,6 +335,57 @@
             text = self.text
 
         return [nodes.abbreviation(self.rawtext, text, **options)], []
+
+
+# Sphinx provides the `code-block` directive for highlighting code blocks.
+# Docutils provides the `code` role which in theory can be used similarly by
+# defining a custom role for a given programming language:
+#
+#     .. .. role:: python(code)
+#          :language: python
+#          :class: highlight
+#
+# In practice this does not produce correct highlighting because it uses a
+# separate highlighting mechanism that results in the "long" pygments class
+# names rather than "short" pygments class names produced by the Sphinx
+# `code-block` directive and for which this extension contains CSS rules.
+#
+# In addition, even if that issue is fixed, because the highlighting
+# implementation in docutils, despite being based on pygments, differs from that
+# used by Sphinx, the output does not exactly match that produced by the Sphinx
+# `code-block` directive.
+#
+# This issue is noted here: //github.com/sphinx-doc/sphinx/issues/5157
+#
+# This overrides the docutils `code` role to perform highlighting in the same
+# way as the Sphinx `code-block` directive.
+#
+# TODO: Change to use `SphinxRole` once SphinxRole is fixed to support options.
+def code_role(name: str, rawtext: str, text: str, lineno: int,
+              inliner: docutils.parsers.rst.states.Inliner,
+              options: Dict = {}, content: List[str] = []
+              ) -> Tuple[List[Node], List[system_message]]:
+    options = options.copy()
+    docutils.parsers.rst.roles.set_classes(options)
+    language = options.get('language', '')
+    classes = ['code']
+    if language:
+        classes.append('highlight')
+    if 'classes' in options:
+        classes.extend(options['classes'])
+
+    if language and language not in classes:
+        classes.append(language)
+
+    node = nodes.literal(rawtext, text, classes=classes, language=language)
+
+    return [node], []
+
+
+code_role.options = {  # type: ignore
+    'class': docutils.parsers.rst.directives.class_option,
+    'language': docutils.parsers.rst.directives.unchanged,
+}
 
 
 specific_docroles: Dict[str, RoleFunction] = {
@@ -368,6 +415,10 @@
     for rolename, func in specific_docroles.items():
         roles.register_local_role(rolename, func)
 
+    # Since docutils registers it as a canonical role, override it as a
+    # canonical role as well.
+    roles.register_canonical_role('code', code_role)
+
     return {
         'version': 'builtin',
         'parallel_read_safe': True,
('sphinx', 'deprecation.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.deprecation
-    ~~~~~~~~~~~~~~~~~~
-
-    Sphinx deprecation classes and utilities.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Sphinx deprecation classes and utilities."""
 
 import sys
 import warnings
@@ -14,15 +6,15 @@
 from typing import Any, Dict, Type
 
 
-class RemovedInSphinx50Warning(DeprecationWarning):
+class RemovedInSphinx60Warning(DeprecationWarning):
     pass
 
 
-class RemovedInSphinx60Warning(PendingDeprecationWarning):
+class RemovedInSphinx70Warning(PendingDeprecationWarning):
     pass
 
 
-RemovedInNextVersionWarning = RemovedInSphinx50Warning
+RemovedInNextVersionWarning = RemovedInSphinx60Warning
 
 
 def deprecated_alias(modname: str, objects: Dict[str, object],
('sphinx', 'registry.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.registry
-    ~~~~~~~~~~~~~~~
-
-    Sphinx component registry.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Sphinx component registry."""
 
 import traceback
 import warnings
@@ -16,21 +8,27 @@
                     Union)
 
 from docutils import nodes
+from docutils.core import Publisher
 from docutils.io import Input
 from docutils.nodes import Element, Node, TextElement
 from docutils.parsers import Parser
 from docutils.parsers.rst import Directive
 from docutils.transforms import Transform
-from pkg_resources import iter_entry_points
+
+try:  # Python < 3.10 (backport)
+    from importlib_metadata import entry_points
+except ImportError:
+    from importlib.metadata import entry_points
 
 from sphinx.builders import Builder
 from sphinx.config import Config
-from sphinx.deprecation import RemovedInSphinx60Warning
+from sphinx.deprecation import RemovedInSphinx60Warning, RemovedInSphinx70Warning
 from sphinx.domains import Domain, Index, ObjType
 from sphinx.domains.std import GenericObject, Target
 from sphinx.environment import BuildEnvironment
 from sphinx.errors import ExtensionError, SphinxError, VersionRequirementError
 from sphinx.extension import Extension
+from sphinx.io import create_publisher
 from sphinx.locale import __
 from sphinx.parsers import Parser as SphinxParser
 from sphinx.roles import XRefRole
@@ -128,6 +126,9 @@
 
         #: additional transforms; list of transforms
         self.transforms: List[Type[Transform]] = []
+
+        # private cache of Docutils Publishers (file type -> publisher object)
+        self.publishers: Dict[str, Publisher] = {}
 
     def add_builder(self, builder: Type[Builder], override: bool = False) -> None:
         logger.debug('[app] adding builder: %r', builder)
@@ -143,20 +144,32 @@
             return
 
         if name not in self.builders:
-            entry_points = iter_entry_points('sphinx.builders', name)
+            builder_entry_points = entry_points(group='sphinx.builders')
             try:
-                entry_point = next(entry_points)
-            except StopIteration as exc:
+                entry_point = builder_entry_points[name]
+            except KeyError as exc:
                 raise SphinxError(__('Builder name %s not registered or available'
                                      ' through entry point') % name) from exc
 
-            self.load_extension(app, entry_point.module_name)
-
-    def create_builder(self, app: "Sphinx", name: str) -> Builder:
+            self.load_extension(app, entry_point.module)
+
+    def create_builder(self, app: "Sphinx", name: str,
+                       env: Optional[BuildEnvironment] = None) -> Builder:
         if name not in self.builders:
             raise SphinxError(__('Builder name %s not registered') % name)
 
-        return self.builders[name](app)
+        try:
+            return self.builders[name](app, env)
+        except TypeError:
+            warnings.warn(
+                f"The custom builder {name} defines a custom __init__ method without the "
+                f"'env'argument. Report this bug to the developers of your custom builder, "
+                f"this is likely not a issue with Sphinx. The 'env' argument will be required "
+                f"from Sphinx 7.", RemovedInSphinx70Warning, stacklevel=2)
+            builder = self.builders[name](app)
+            if env is not None:
+                builder.set_environment(env)
+            return builder
 
     def add_domain(self, domain: Type[Domain], override: bool = False) -> None:
         logger.debug('[app] adding domain: %r', domain)
@@ -215,10 +228,17 @@
                                  (index.name, domain))
         indices.append(index)
 
-    def add_object_type(self, directivename: str, rolename: str, indextemplate: str = '',
-                        parse_node: Callable = None, ref_nodeclass: Type[TextElement] = None,
-                        objname: str = '', doc_field_types: List = [], override: bool = False
-                        ) -> None:
+    def add_object_type(
+        self,
+        directivename: str,
+        rolename: str,
+        indextemplate: str = '',
+        parse_node: Optional[Callable] = None,
+        ref_nodeclass: Optional[Type[TextElement]] = None,
+        objname: str = '',
+        doc_field_types: List = [],
+        override: bool = False
+    ) -> None:
         logger.debug('[app] adding object type: %r',
                      (directivename, rolename, indextemplate, parse_node,
                       ref_nodeclass, objname, doc_field_types))
@@ -239,9 +259,15 @@
                                  directivename)
         object_types[directivename] = ObjType(objname or directivename, rolename)
 
-    def add_crossref_type(self, directivename: str, rolename: str, indextemplate: str = '',
-                          ref_nodeclass: Type[TextElement] = None, objname: str = '',
-                          override: bool = False) -> None:
+    def add_crossref_type(
+        self,
+        directivename: str,
+        rolename: str,
+        indextemplate: str = '',
+        ref_nodeclass: Optional[Type[TextElement]] = None,
+        objname: str = '',
+        override: bool = False
+    ) -> None:
         logger.debug('[app] adding crossref type: %r',
                      (directivename, rolename, indextemplate, ref_nodeclass, objname))
 
@@ -383,7 +409,7 @@
 
     def add_latex_package(self, name: str, options: str, after_hyperref: bool = False) -> None:
         if self.has_latex_package(name):
-            logger.warn("latex package '%s' already included" % name)
+            logger.warning("latex package '%s' already included", name)
 
         logger.debug('[app] adding latex package: %r', name)
         if after_hyperref:
@@ -391,8 +417,12 @@
         else:
             self.latex_packages.append((name, options))
 
-    def add_enumerable_node(self, node: Type[Node], figtype: str,
-                            title_getter: TitleGetter = None, override: bool = False) -> None:
+    def add_enumerable_node(
+        self,
+        node: Type[Node],
+        figtype: str,
+        title_getter: Optional[TitleGetter] = None, override: bool = False
+    ) -> None:
         logger.debug('[app] adding enumerable node: (%r, %r, %r)', node, figtype, title_getter)
         if node in self.enumerable_nodes and not override:
             raise ExtensionError(__('enumerable_node %r already registered') % node)
@@ -465,6 +495,15 @@
         envversion['sphinx'] = ENV_VERSION
         return envversion
 
+    def get_publisher(self, app: "Sphinx", filetype: str) -> Publisher:
+        try:
+            return self.publishers[filetype]
+        except KeyError:
+            pass
+        publisher = create_publisher(app, filetype)
+        self.publishers[filetype] = publisher
+        return publisher
+
 
 def merge_source_suffix(app: "Sphinx", config: Config) -> None:
     """Merge any user-specified source_suffix with any added by extensions."""
('sphinx', 'events.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,13 +1,6 @@
-"""
-    sphinx.events
-    ~~~~~~~~~~~~~
+"""Sphinx core events.
 
-    Sphinx core events.
-
-    Gracefully adapted from the TextPress system by Armin.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
+Gracefully adapted from the TextPress system by Armin.
 """
 
 from collections import defaultdict
@@ -105,6 +98,9 @@
             except SphinxError:
                 raise
             except Exception as exc:
+                if self.app.pdb:
+                    # Just pass through the error, so that it can be debugged.
+                    raise
                 modname = safe_getattr(listener.handler, '__module__', None)
                 raise ExtensionError(__("Handler %r for event %r threw an exception") %
                                      (listener.handler, name), exc, modname=modname) from exc
('sphinx', 'io.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,15 +1,9 @@
-"""
-    sphinx.io
-    ~~~~~~~~~
-
-    Input/Output files
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Input/Output files"""
 import codecs
+import warnings
 from typing import TYPE_CHECKING, Any, List, Type
 
+import docutils
 from docutils import nodes
 from docutils.core import Publisher
 from docutils.frontend import Values
@@ -22,6 +16,7 @@
 from docutils.writers import UnfilteredWriter
 
 from sphinx import addnodes
+from sphinx.deprecation import RemovedInSphinx70Warning
 from sphinx.environment import BuildEnvironment
 from sphinx.transforms import (AutoIndexUpgrader, DoctreeReadEvent, FigureAligner,
                                SphinxTransformer)
@@ -163,6 +158,9 @@
 
 def read_doc(app: "Sphinx", env: BuildEnvironment, filename: str) -> nodes.document:
     """Parse a document and convert to doctree."""
+    warnings.warn('sphinx.io.read_doc() is deprecated.',
+                  RemovedInSphinx70Warning, stacklevel=2)
+
     # set up error_handler for the target document
     error_handler = UnicodeDecodeErrorHandler(env.docname)
     codecs.register_error('sphinx', error_handler)  # type: ignore
@@ -184,7 +182,39 @@
                     writer=SphinxDummyWriter(),
                     source_class=SphinxFileInput,
                     destination=NullOutput())
-    pub.process_programmatic_settings(None, env.settings, None)
+    pub.process_programmatic_settings(None, env.settings, None)  # type: ignore[arg-type]
     pub.set_source(source_path=filename)
     pub.publish()
     return pub.document
+
+
+def create_publisher(app: "Sphinx", filetype: str) -> Publisher:
+    reader = SphinxStandaloneReader()
+    reader.setup(app)
+
+    parser = app.registry.create_source_parser(app, filetype)
+    if parser.__class__.__name__ == 'CommonMarkParser' and parser.settings_spec == ():
+        # a workaround for recommonmark
+        #   If recommonmark.AutoStrictify is enabled, the parser invokes reST parser
+        #   internally.  But recommonmark-0.4.0 does not provide settings_spec for reST
+        #   parser.  As a workaround, this copies settings_spec for RSTParser to the
+        #   CommonMarkParser.
+        from docutils.parsers.rst import Parser as RSTParser
+
+        parser.settings_spec = RSTParser.settings_spec
+
+    pub = Publisher(
+        reader=reader,
+        parser=parser,
+        writer=SphinxDummyWriter(),
+        source_class=SphinxFileInput,
+        destination=NullOutput()
+    )
+    # Propagate exceptions by default when used programmatically:
+    defaults = {"traceback": True, **app.env.settings}
+    # Set default settings
+    if docutils.__version_info__[:2] >= (0, 19):
+        pub.get_settings(**defaults)  # type: ignore[arg-type]
+    else:
+        pub.settings = pub.setup_option_parser(**defaults).get_default_values()  # type: ignore
+    return pub
('sphinx', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,21 +1,11 @@
-"""
-    Sphinx
-    ~~~~~~
-
-    The Sphinx documentation toolchain.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""The Sphinx documentation toolchain."""
 
 # Keep this file executable as-is in Python 3!
-# (Otherwise getting the version out of it from setup.py is impossible.)
+# (Otherwise getting the version out of it when packaging is impossible.)
 
 import os
-import subprocess
 import warnings
 from os import path
-from subprocess import PIPE
 
 from .deprecation import RemovedInNextVersionWarning
 
@@ -26,9 +16,11 @@
 # docutils.io using mode='rU' for open
 warnings.filterwarnings('ignore', "'U' mode is deprecated",
                         DeprecationWarning, module='docutils.io')
+warnings.filterwarnings('ignore', 'The frontend.Option class .*',
+                        DeprecationWarning, module='docutils.frontend')
 
-__version__ = '4.2.0'
-__released__ = '4.2.0'  # used when Sphinx builds its own docs
+__version__ = '5.2.0'
+__display_version__ = __version__  # used for command line version
 
 #: Version info for better programmatic use.
 #:
@@ -38,22 +30,26 @@
 #:
 #: .. versionadded:: 1.2
 #:    Before version 1.2, check the string ``sphinx.__version__``.
-version_info = (4, 2, 0, 'final', 0)
+version_info = (5, 2, 0, 'final', 0)
 
 package_dir = path.abspath(path.dirname(__file__))
 
-__display_version__ = __version__  # used for command line version
-if __version__.endswith('+'):
-    # try to find out the commit hash if checked out from git, and append
-    # it to __version__ (since we use this value from setup.py, it gets
-    # automatically propagated to an installed copy as well)
-    __display_version__ = __version__
-    __version__ = __version__[:-1]  # remove '+' for PEP-440 version spec.
+_in_development = False
+if _in_development:
+    # Only import subprocess if needed
+    import subprocess
+
     try:
-        ret = subprocess.run(['git', 'show', '-s', '--pretty=format:%h'],
-                             cwd=package_dir,
-                             stdout=PIPE, stderr=PIPE, encoding='ascii')
-        if ret.stdout:
-            __display_version__ += '/' + ret.stdout.strip()
-    except Exception:
-        pass
+        ret = subprocess.run(
+            ['git', 'show', '-s', '--pretty=format:%h'],
+            cwd=package_dir,
+            stdout=subprocess.PIPE,
+            stderr=subprocess.PIPE,
+            encoding='ascii',
+        ).stdout
+        if ret:
+            __display_version__ += '+/' + ret.strip()
+        del ret
+    finally:
+        del subprocess
+del _in_development
('sphinx', 'addnodes.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,21 +1,21 @@
-"""
-    sphinx.addnodes
-    ~~~~~~~~~~~~~~~
-
-    Additional docutils nodes.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
-
-from typing import TYPE_CHECKING, Any, Dict, List, Sequence
-
+"""Document tree nodes that Sphinx defines on top of those in Docutils."""
+
+from typing import TYPE_CHECKING, Any, Dict, List, Optional, Sequence
+
+import docutils
 from docutils import nodes
 from docutils.nodes import Element
 
 if TYPE_CHECKING:
     from sphinx.application import Sphinx
 
+try:
+    from docutils.nodes import meta as docutils_meta  # type: ignore
+except ImportError:
+    # docutils-0.17 or older
+    from docutils.parsers.rst.directives.html import MetaBody
+    docutils_meta = MetaBody.meta
+
 
 class document(nodes.document):
     """The document root element patched by Sphinx.
@@ -27,9 +27,8 @@
                    in your extensions.  It will be removed without deprecation period.
     """
 
-    def set_id(self, node: Element, msgnode: Element = None,
+    def set_id(self, node: Element, msgnode: Optional[Element] = None,
                suggested_prefix: str = '') -> str:
-        from sphinx.util import docutils
         if docutils.__version_info__ >= (0, 16):
             ret = super().set_id(node, msgnode, suggested_prefix)  # type: ignore
         else:
@@ -85,7 +84,7 @@
     def preserve_original_messages(self) -> None:
         # toctree entries
         rawentries = self.setdefault('rawentries', [])
-        for title, docname in self['entries']:
+        for title, _docname in self['entries']:
             if title:
                 rawentries.append(title)
 
@@ -120,7 +119,7 @@
 #############################################################
 
 class _desc_classes_injector(nodes.Element, not_smartquotable):
-    """Helper base class for injecting a fixes list of classes.
+    """Helper base class for injecting a fixed list of classes.
 
     Use as the first base class.
     """
@@ -391,7 +390,7 @@
 
 
 class centered(nodes.Part, nodes.TextElement):
-    """Deprecated."""
+    """This node is deprecated."""
 
 
 class acks(nodes.Element):
@@ -456,13 +455,18 @@
 
 
 class pending_xref_condition(nodes.Inline, nodes.TextElement):
-    """Node for cross-references that are used to choose appropriate
-    content of the reference by conditions on the resolving phase.
-
-    When the :py:class:`pending_xref` node contains one or more
-    **pending_xref_condition** nodes, the cross-reference resolver
-    should choose the content of the reference using defined conditions
-    in ``condition`` attribute of each pending_xref_condition nodes::
+    """Node representing a potential way to create a cross-reference and the
+    condition in which this way should be used.
+
+    This node is only allowed to be placed under a :py:class:`pending_xref`
+    node.  A **pending_xref** node must contain either no **pending_xref_condition**
+    nodes or it must only contains **pending_xref_condition** nodes.
+
+    The cross-reference resolver will replace a :py:class:`pending_xref` which
+    contains **pending_xref_condition** nodes by the content of exactly one of
+    those **pending_xref_condition** nodes' content. It uses the **condition**
+    attribute to decide which **pending_xref_condition** node's content to
+    use. For example, let us consider how the cross-reference resolver acts on::
 
         <pending_xref refdomain="py" reftarget="io.StringIO ...>
             <pending_xref_condition condition="resolved">
@@ -472,32 +476,26 @@
                 <literal>
                     io.StringIO
 
-    After the processing of cross-reference resolver, one of the content node
-    under pending_xref_condition node is chosen by its condition and to be
-    removed all of pending_xref_condition nodes::
-
-        # When resolved the cross-reference successfully
+    If the cross-reference resolver successfully resolves the cross-reference,
+    then it rewrites the **pending_xref** as::
+
         <reference>
             <literal>
                 StringIO
 
-        # When resolution is failed
+    Otherwise, if the cross-reference resolution failed, it rewrites the
+    **pending_xref** as::
+
         <reference>
             <literal>
                 io.StringIO
 
-    .. note:: This node is only allowed to be placed under pending_xref node.
-              It is not allows to place it under other nodes.  In addition,
-              pending_xref node must contain only pending_xref_condition
-              nodes if it contains one or more pending_xref_condition nodes.
-
-    The pending_xref_condition node should have **condition** attribute.
+    The **pending_xref_condition** node should have **condition** attribute.
     Domains can be store their individual conditions into the attribute to
     filter contents on resolving phase.  As a reserved condition name,
     ``condition="*"`` is used for the fallback of resolution failure.
     Additionally, as a recommended condition name, ``condition="resolved"``
-    is used for the representation of resolstion success in the intersphinx
-    module.
+    represents a resolution success in the intersphinx module.
 
     .. versionadded:: 4.0
     """
@@ -563,7 +561,6 @@
     app.add_node(start_of_file)
     app.add_node(highlightlang)
     app.add_node(tabular_col_spec)
-    app.add_node(meta)
     app.add_node(pending_xref)
     app.add_node(number_reference)
     app.add_node(download_reference)
@@ -571,6 +568,9 @@
     app.add_node(literal_strong)
     app.add_node(manpage)
 
+    if docutils.__version_info__ < (0, 18):
+        app.add_node(meta)
+
     return {
         'version': 'builtin',
         'parallel_read_safe': True,
('sphinx', 'parsers.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,14 +1,5 @@
-"""
-    sphinx.parsers
-    ~~~~~~~~~~~~~~
+"""A Base class for additional parsers."""
 
-    A Base class for additional parsers.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
-
-import warnings
 from typing import TYPE_CHECKING, Any, Dict, List, Type, Union
 
 import docutils.parsers
@@ -19,7 +10,8 @@
 from docutils.transforms import Transform
 from docutils.transforms.universal import SmartQuotes
 
-from sphinx.deprecation import RemovedInSphinx50Warning
+from sphinx.config import Config
+from sphinx.environment import BuildEnvironment
 from sphinx.util.rst import append_epilog, prepend_prolog
 
 if TYPE_CHECKING:
@@ -32,24 +24,14 @@
     of ``docutils.parsers.Parser``.  Compared with ``docutils.parsers.Parser``, this class
     improves accessibility to Sphinx APIs.
 
-    The subclasses can access the following objects and functions:
+    The subclasses can access sphinx core runtime objects (app, config and env).
+    """
 
-    self.app
-        The application object (:class:`sphinx.application.Sphinx`)
-    self.config
-        The config object (:class:`sphinx.config.Config`)
-    self.env
-        The environment object (:class:`sphinx.environment.BuildEnvironment`)
-    self.warn()
-        Emit a warning. (Same as :meth:`sphinx.application.Sphinx.warn()`)
-    self.info()
-        Emit an info message. (Same as :meth:`sphinx.application.Sphinx.info()`)
+    #: The config object
+    config: Config
 
-    .. deprecated:: 1.6
-       ``warn()`` and ``info()`` is deprecated.  Use :mod:`sphinx.util.logging` instead.
-    .. deprecated:: 3.0
-       parser.app is deprecated.
-    """
+    #: The environment object
+    env: BuildEnvironment
 
     def set_application(self, app: "Sphinx") -> None:
         """set_application will be called from Sphinx to set app and other instance variables
@@ -59,11 +41,6 @@
         self._app = app
         self.config = app.config
         self.env = app.env
-
-    @property
-    def app(self) -> "Sphinx":
-        warnings.warn('parser.app is deprecated.', RemovedInSphinx50Warning, stacklevel=2)
-        return self._app
 
 
 class RSTParser(docutils.parsers.rst.Parser, Parser):
('sphinx', 'application.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,18 +1,10 @@
-"""
-    sphinx.application
-    ~~~~~~~~~~~~~~~~~~
-
-    Sphinx application class and extensibility interface.
-
-    Gracefully adapted from the TextPress system by Armin.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
+"""Sphinx application class and extensibility interface.
+
+Gracefully adapted from the TextPress system by Armin.
 """
 
 import os
 import pickle
-import platform
 import sys
 import warnings
 from collections import deque
@@ -136,16 +128,15 @@
     _warncount: int
 
     def __init__(self, srcdir: str, confdir: Optional[str], outdir: str, doctreedir: str,
-                 buildername: str, confoverrides: Dict = None,
-                 status: IO = sys.stdout, warning: IO = sys.stderr,
-                 freshenv: bool = False, warningiserror: bool = False, tags: List[str] = None,
-                 verbosity: int = 0, parallel: int = 0, keep_going: bool = False) -> None:
+                 buildername: str, confoverrides: Optional[Dict] = None,
+                 status: Optional[IO] = sys.stdout, warning: Optional[IO] = sys.stderr,
+                 freshenv: bool = False, warningiserror: bool = False,
+                 tags: Optional[List[str]] = None,
+                 verbosity: int = 0, parallel: int = 0, keep_going: bool = False,
+                 pdb: bool = False) -> None:
         self.phase = BuildPhase.INITIALIZATION
         self.verbosity = verbosity
         self.extensions: Dict[str, Extension] = {}
-        self.builder: Optional[Builder] = None
-        self.env: Optional[BuildEnvironment] = None
-        self.project: Optional[Project] = None
         self.registry = SphinxComponentRegistry()
 
         # validate provided directories
@@ -184,6 +175,7 @@
             self.warningiserror = False
         else:
             self.warningiserror = warningiserror
+        self.pdb = pdb
         logging.setup(self, self._status, self._warning)
 
         self.events = EventManager(self)
@@ -194,12 +186,6 @@
 
         # say hello to the world
         logger.info(bold(__('Running Sphinx v%s') % sphinx.__display_version__))
-
-        # notice for parallel build on macOS and py38+
-        if sys.version_info > (3, 8) and platform.system() == 'Darwin' and parallel > 1:
-            logger.info(bold(__("For security reasons, parallel mode is disabled on macOS and "
-                                "python3.8 and above. For more details, please read "
-                                "https://github.com/sphinx-doc/sphinx/issues/6803")))
 
         # status code for command-line application
         self.statuscode = 0
@@ -262,10 +248,16 @@
 
         # create the project
         self.project = Project(self.srcdir, self.config.source_suffix)
+
+        # set up the build environment
+        self.env = self._init_env(freshenv)
+
         # create the builder
         self.builder = self.create_builder(buildername)
-        # set up the build environment
-        self._init_env(freshenv)
+
+        # build environment post-initialisation, after creating the builder
+        self._post_init_env()
+
         # set up the builder
         self._init_builder()
 
@@ -273,7 +265,7 @@
         """Load translated strings from the configured localedirs if enabled in
         the configuration.
         """
-        if self.config.language is None:
+        if self.config.language == 'en':
             self.translator, has_translation = locale.init([], None)
         else:
             logger.info(bold(__('loading translations [%s]... ') % self.config.language),
@@ -284,33 +276,47 @@
                                      self.config.language, self.config.source_encoding)
             for catalog in repo.catalogs:
                 if catalog.domain == 'sphinx' and catalog.is_outdated():
-                    catalog.write_mo(self.config.language)
+                    catalog.write_mo(self.config.language,
+                                     self.config.gettext_allow_fuzzy_translations)
 
             locale_dirs: List[Optional[str]] = list(repo.locale_dirs)
             locale_dirs += [None]
             locale_dirs += [path.join(package_dir, 'locale')]
 
             self.translator, has_translation = locale.init(locale_dirs, self.config.language)
-            if has_translation or self.config.language == 'en':
-                # "en" never needs to be translated
+            if has_translation:
                 logger.info(__('done'))
             else:
                 logger.info(__('not available for built-in messages'))
 
-    def _init_env(self, freshenv: bool) -> None:
+    def _init_env(self, freshenv: bool) -> BuildEnvironment:
         filename = path.join(self.doctreedir, ENV_PICKLE_FILENAME)
         if freshenv or not os.path.exists(filename):
-            self.env = BuildEnvironment(self)
+            return self._create_fresh_env()
+        else:
+            return self._load_existing_env(filename)
+
+    def _create_fresh_env(self) -> BuildEnvironment:
+        env = BuildEnvironment(self)
+        self._fresh_env_used = True
+        return env
+
+    def _load_existing_env(self, filename: str) -> BuildEnvironment:
+        try:
+            with progress_message(__('loading pickled environment')):
+                with open(filename, 'rb') as f:
+                    env = pickle.load(f)
+                    env.setup(self)
+                    self._fresh_env_used = False
+        except Exception as err:
+            logger.info(__('failed: %s'), err)
+            env = self._create_fresh_env()
+        return env
+
+    def _post_init_env(self) -> None:
+        if self._fresh_env_used:
             self.env.find_files(self.config, self.builder)
-        else:
-            try:
-                with progress_message(__('loading pickled environment')):
-                    with open(filename, 'rb') as f:
-                        self.env = pickle.load(f)
-                        self.env.setup(self)
-            except Exception as err:
-                logger.info(__('failed: %s'), err)
-                self._init_env(freshenv=True)
+        del self._fresh_env_used
 
     def preload_builder(self, name: str) -> None:
         self.registry.preload_builder(self, name)
@@ -320,16 +326,17 @@
             logger.info(__('No builder selected, using default: html'))
             name = 'html'
 
-        return self.registry.create_builder(self, name)
+        return self.registry.create_builder(self, name, self.env)
 
     def _init_builder(self) -> None:
-        self.builder.set_environment(self.env)
+        if not hasattr(self.builder, "env"):
+            self.builder.set_environment(self.env)
         self.builder.init()
         self.events.emit('builder-inited')
 
     # ---- main "build" method -------------------------------------------------
 
-    def build(self, force_all: bool = False, filenames: List[str] = None) -> None:
+    def build(self, force_all: bool = False, filenames: Optional[List[str]] = None) -> None:
         self.phase = BuildPhase.READING
         try:
             if force_all:
@@ -342,33 +349,7 @@
                 self.builder.compile_update_catalogs()
                 self.builder.build_update()
 
-            if self._warncount and self.keep_going:
-                self.statuscode = 1
-
-            status = (__('succeeded') if self.statuscode == 0
-                      else __('finished with problems'))
-            if self._warncount:
-                if self.warningiserror:
-                    if self._warncount == 1:
-                        msg = __('build %s, %s warning (with warnings treated as errors).')
-                    else:
-                        msg = __('build %s, %s warnings (with warnings treated as errors).')
-                else:
-                    if self._warncount == 1:
-                        msg = __('build %s, %s warning.')
-                    else:
-                        msg = __('build %s, %s warnings.')
-
-                logger.info(bold(msg % (status, self._warncount)))
-            else:
-                logger.info(bold(__('build %s.') % status))
-
-            if self.statuscode == 0 and self.builder.epilog:
-                logger.info('')
-                logger.info(self.builder.epilog % {
-                    'outdir': relpath(self.outdir),
-                    'project': self.config.project
-                })
+            self.events.emit('build-finished', None)
         except Exception as err:
             # delete the saved env to force a fresh build next time
             envfile = path.join(self.doctreedir, ENV_PICKLE_FILENAME)
@@ -376,8 +357,35 @@
                 os.unlink(envfile)
             self.events.emit('build-finished', err)
             raise
+
+        if self._warncount and self.keep_going:
+            self.statuscode = 1
+
+        status = (__('succeeded') if self.statuscode == 0
+                  else __('finished with problems'))
+        if self._warncount:
+            if self.warningiserror:
+                if self._warncount == 1:
+                    msg = __('build %s, %s warning (with warnings treated as errors).')
+                else:
+                    msg = __('build %s, %s warnings (with warnings treated as errors).')
+            else:
+                if self._warncount == 1:
+                    msg = __('build %s, %s warning.')
+                else:
+                    msg = __('build %s, %s warnings.')
+
+            logger.info(bold(msg % (status, self._warncount)))
         else:
-            self.events.emit('build-finished', None)
+            logger.info(bold(__('build %s.') % status))
+
+        if self.statuscode == 0 and self.builder.epilog:
+            logger.info('')
+            logger.info(self.builder.epilog % {
+                'outdir': relpath(self.outdir),
+                'project': self.config.project
+            })
+
         self.builder.cleanup()
 
     # ---- general extensibility interface -------------------------------------
@@ -598,7 +606,7 @@
         self.registry.add_translation_handlers(node, **kwargs)
 
     def add_enumerable_node(self, node: Type[Element], figtype: str,
-                            title_getter: TitleGetter = None, override: bool = False,
+                            title_getter: Optional[TitleGetter] = None, override: bool = False,
                             **kwargs: Tuple[Callable, Callable]) -> None:
         """Register a Docutils node class as a numfig target.
 
@@ -631,8 +639,9 @@
 
         :param name: The name of the directive
         :param cls: A directive class
-        :param override: If true, install the directive forcedly even if another directive
+        :param override: If false, do not install it if another directive
                          is already installed as the same name
+                         If true, unconditionally install the directive.
 
         For example, a custom directive named ``my-directive`` would be added
         like this:
@@ -679,8 +688,9 @@
 
         :param name: The name of role
         :param role: A role function
-        :param override: If true, install the role forcedly even if another role is already
-                         installed as the same name
+        :param override: If false, do not install it if another role
+                         is already installed as the same name
+                         If true, unconditionally install the role.
 
         For more details about role functions, see `the Docutils docs
         <https://docutils.sourceforge.io/docs/howto/rst-roles.html>`__ .
@@ -700,8 +710,9 @@
         Register a Docutils role that does nothing but wrap its contents in the
         node given by *nodeclass*.
 
-        If *override* is True, the given *nodeclass* is forcedly installed even if
-        a role named as *name* is already installed.
+        :param override: If false, do not install it if another role
+                         is already installed as the same name
+                         If true, unconditionally install the role.
 
         .. versionadded:: 0.6
         .. versionchanged:: 1.8
@@ -720,8 +731,9 @@
         """Register a domain.
 
         :param domain: A domain class
-        :param override: If true, install the domain forcedly even if another domain
+        :param override: If false, do not install it if another domain
                          is already installed as the same name
+                         If true, unconditionally install the domain.
 
         .. versionadded:: 1.0
         .. versionchanged:: 1.8
@@ -739,8 +751,9 @@
         :param domain: The name of target domain
         :param name: A name of directive
         :param cls: A directive class
-        :param override: If true, install the directive forcedly even if another directive
+        :param override: If false, do not install it if another directive
                          is already installed as the same name
+                         If true, unconditionally install the directive.
 
         .. versionadded:: 1.0
         .. versionchanged:: 1.8
@@ -758,8 +771,9 @@
         :param domain: The name of the target domain
         :param name: The name of the role
         :param role: The role function
-        :param override: If true, install the role forcedly even if another role is already
-                         installed as the same name
+        :param override: If false, do not install it if another role
+                         is already installed as the same name
+                         If true, unconditionally install the role.
 
         .. versionadded:: 1.0
         .. versionchanged:: 1.8
@@ -775,8 +789,9 @@
 
         :param domain: The name of the target domain
         :param index: The index class
-        :param override: If true, install the index forcedly even if another index is
-                         already installed as the same name
+        :param override: If false, do not install it if another index
+                         is already installed as the same name
+                         If true, unconditionally install the index.
 
         .. versionadded:: 1.0
         .. versionchanged:: 1.8
@@ -785,7 +800,8 @@
         self.registry.add_index_to_domain(domain, index)
 
     def add_object_type(self, directivename: str, rolename: str, indextemplate: str = '',
-                        parse_node: Callable = None, ref_nodeclass: Type[TextElement] = None,
+                        parse_node: Optional[Callable] = None,
+                        ref_nodeclass: Optional[Type[TextElement]] = None,
                         objname: str = '', doc_field_types: List = [], override: bool = False
                         ) -> None:
         """Register a new object type.
@@ -852,7 +868,7 @@
                                       override=override)
 
     def add_crossref_type(self, directivename: str, rolename: str, indextemplate: str = '',
-                          ref_nodeclass: Type[TextElement] = None, objname: str = '',
+                          ref_nodeclass: Optional[Type[TextElement]] = None, objname: str = '',
                           override: bool = False) -> None:
         """Register a new crossref object type.
 
@@ -880,8 +896,10 @@
         (Of course, the element following the ``topic`` directive needn't be a
         section.)
 
-        If *override* is True, the given crossref_type is forcedly installed even if
-        a crossref_type having the same name is already installed.
+
+        :param override: If false, do not install it if another cross-reference type
+                         is already installed as the same name
+                         If true, unconditionally install the cross-reference type.
 
         .. versionchanged:: 1.8
            Add *override* keyword.
@@ -936,24 +954,33 @@
         """
         self.registry.add_post_transform(transform)
 
-    def add_js_file(self, filename: str, priority: int = 500, **kwargs: Any) -> None:
+    def add_js_file(self, filename: Optional[str], priority: int = 500,
+                    loading_method: Optional[str] = None, **kwargs: Any) -> None:
         """Register a JavaScript file to include in the HTML output.
 
-        Add *filename* to the list of JavaScript files that the default HTML
-        template will include in order of *priority* (ascending).  The filename
-        must be relative to the HTML static path , or a full URI with scheme.
-        If the priority of the JavaScript file is the same as others, the JavaScript
-        files will be included in order of registration.  If the keyword
-        argument ``body`` is given, its value will be added between the
-        ``<script>`` tags. Extra keyword arguments are included as attributes of
-        the ``<script>`` tag.
+        :param filename: The name of a JavaScript file that the default HTML
+                         template will include. It must be relative to the HTML
+                         static path, or a full URI with scheme, or ``None`` .
+                         The ``None`` value is used to create an inline
+                         ``<script>`` tag.  See the description of *kwargs*
+                         below.
+        :param priority: Files are included in ascending order of priority. If
+                         multiple JavaScript files have the same priority,
+                         those files will be included in order of registration.
+                         See list of "prority range for JavaScript files" below.
+        :param loading_method: The loading method for the JavaScript file.
+                               Either ``'async'`` or ``'defer'`` are allowed.
+        :param kwargs: Extra keyword arguments are included as attributes of the
+                       ``<script>`` tag.  If the special keyword argument
+                       ``body`` is given, its value will be added as the content
+                       of the  ``<script>`` tag.
 
         Example::
 
             app.add_js_file('example.js')
             # => <script src="_static/example.js"></script>
 
-            app.add_js_file('example.js', async="async")
+            app.add_js_file('example.js', loading_method="async")
             # => <script src="_static/example.js" async="async"></script>
 
             app.add_js_file(None, body="var myVariable = 'foo';")
@@ -982,20 +1009,32 @@
 
         .. versionchanged:: 3.5
            Take priority argument.  Allow to add a JavaScript file to the specific page.
-        """
+        .. versionchanged:: 4.4
+           Take loading_method argument.  Allow to change the loading method of the
+           JavaScript file.
+        """
+        if loading_method == 'async':
+            kwargs['async'] = 'async'
+        elif loading_method == 'defer':
+            kwargs['defer'] = 'defer'
+
         self.registry.add_js_file(filename, priority=priority, **kwargs)
-        if hasattr(self.builder, 'add_js_file'):
-            self.builder.add_js_file(filename, priority=priority, **kwargs)  # type: ignore
+        if hasattr(self, 'builder') and hasattr(self.builder, 'add_js_file'):
+            self.builder.add_js_file(filename,  # type: ignore[attr-defined]
+                                     priority=priority, **kwargs)
 
     def add_css_file(self, filename: str, priority: int = 500, **kwargs: Any) -> None:
         """Register a stylesheet to include in the HTML output.
 
-        Add *filename* to the list of CSS files that the default HTML template
-        will include in order of *priority* (ascending).  The filename must be
-        relative to the HTML static path, or a full URI with scheme.  If the
-        priority of the CSS file is the same as others, the CSS files will be
-        included in order of registration.  The keyword arguments are also
-        accepted for attributes of ``<link>`` tag.
+        :param filename: The name of a CSS file that the default HTML
+                         template will include. It must be relative to the HTML
+                         static path, or a full URI with scheme.
+        :param priority: Files are included in ascending order of priority. If
+                         multiple CSS files have the same priority,
+                         those files will be included in order of registration.
+                         See list of "prority range for CSS files" below.
+        :param kwargs: Extra keyword arguments are included as attributes of the
+                       ``<link>`` tag.
 
         Example::
 
@@ -1043,10 +1082,32 @@
         """
         logger.debug('[app] adding stylesheet: %r', filename)
         self.registry.add_css_files(filename, priority=priority, **kwargs)
-        if hasattr(self.builder, 'add_css_file'):
-            self.builder.add_css_file(filename, priority=priority, **kwargs)  # type: ignore
-
-    def add_latex_package(self, packagename: str, options: str = None,
+        if hasattr(self, 'builder') and hasattr(self.builder, 'add_css_file'):
+            self.builder.add_css_file(filename,  # type: ignore[attr-defined]
+                                      priority=priority, **kwargs)
+
+    def add_stylesheet(
+        self, filename: str, alternate: bool = False, title: Optional[str] = None
+    ) -> None:
+        """An alias of :meth:`add_css_file`.
+
+        .. deprecated:: 1.8
+        """
+        logger.warning('The app.add_stylesheet() is deprecated. '
+                       'Please use app.add_css_file() instead.')
+
+        attributes = {}  # type: Dict[str, Any]
+        if alternate:
+            attributes['rel'] = 'alternate stylesheet'
+        else:
+            attributes['rel'] = 'stylesheet'
+
+        if title:
+            attributes['title'] = title
+
+        self.add_css_file(filename, **attributes)
+
+    def add_latex_package(self, packagename: str, options: Optional[str] = None,
                           after_hyperref: bool = False) -> None:
         r"""Register a package to include in the LaTeX source code.
 
@@ -1142,8 +1203,9 @@
         Same as :confval:`source_suffix`.  The users can override this
         using the config setting.
 
-        If *override* is True, the given *suffix* is forcedly installed even if
-        the same suffix is already installed.
+        :param override: If false, do not install it the same suffix
+                         is already installed.
+                         If true, unconditionally install the suffix.
 
         .. versionadded:: 1.8
         """
@@ -1152,8 +1214,9 @@
     def add_source_parser(self, parser: Type[Parser], override: bool = False) -> None:
         """Register a parser class.
 
-        If *override* is True, the given *parser* is forcedly installed even if
-        a parser for the same suffix is already installed.
+        :param override: If false, do not install it if another parser
+                         is already installed for the same suffix.
+                         If true, unconditionally install the parser.
 
         .. versionadded:: 1.4
         .. versionchanged:: 1.8
@@ -1275,7 +1338,12 @@
     that renders templates given a template name and a context.
     """
 
-    def init(self, builder: "Builder", theme: Theme = None, dirs: List[str] = None) -> None:
+    def init(
+        self,
+        builder: "Builder",
+        theme: Optional[Theme] = None,
+        dirs: Optional[List[str]] = None
+    ) -> None:
         """Called by the builder to initialize the template system.
 
         *builder* is the builder object; you'll probably want to look at the
('sphinx', 'extension.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,14 +1,8 @@
-"""
-    sphinx.extension
-    ~~~~~~~~~~~~~~~~
-
-    Utilities for Sphinx extensions.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Utilities for Sphinx extensions."""
 
 from typing import TYPE_CHECKING, Any, Dict
+
+from packaging.version import InvalidVersion, Version
 
 from sphinx.config import Config
 from sphinx.errors import VersionRequirementError
@@ -40,7 +34,14 @@
 
 
 def verify_needs_extensions(app: "Sphinx", config: Config) -> None:
-    """Verify the required Sphinx extensions are loaded."""
+    """Check that extensions mentioned in :confval:`needs_extensions` satisfy the version
+    requirement, and warn if an extension is not loaded.
+
+    Warns if an extension in :confval:`needs_extension` is not loaded.
+
+    :raises VersionRequirementError: if the version of an extension in
+    :confval:`needs_extension` is unknown or older than the required version.
+    """
     if config.needs_extensions is None:
         return
 
@@ -51,7 +52,18 @@
                               'but it is not loaded.'), extname)
             continue
 
-        if extension.version == 'unknown version' or reqversion > extension.version:
+        fulfilled = True
+        if extension.version == 'unknown version':
+            fulfilled = False
+        else:
+            try:
+                if Version(reqversion) > Version(extension.version):
+                    fulfilled = False
+            except InvalidVersion:
+                if reqversion > extension.version:
+                    fulfilled = False
+
+        if not fulfilled:
             raise VersionRequirementError(__('This project needs the extension %s at least in '
                                              'version %s and therefore cannot be built with '
                                              'the loaded version (%s).') %
('sphinx', 'versioning.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,13 +1,4 @@
-"""
-    sphinx.versioning
-    ~~~~~~~~~~~~~~~~~
-
-    Implements the low-level algorithms Sphinx uses for the versioning of
-    doctrees.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Implements the low-level algorithms Sphinx uses for versioning doctrees."""
 import pickle
 from itertools import product, zip_longest
 from operator import itemgetter
@@ -42,7 +33,7 @@
     :param condition:
         A callable which returns either ``True`` or ``False`` for a given node.
     """
-    for node in doctree.traverse(condition):
+    for node in doctree.findall(condition):
         node.uid = uuid4().hex
         yield node
 
@@ -57,8 +48,8 @@
     :param condition:
         A callable which returns either ``True`` or ``False`` for a given node.
     """
-    old_iter = old.traverse(condition)
-    new_iter = new.traverse(condition)
+    old_iter = old.findall(condition)
+    new_iter = new.findall(condition)
     old_nodes = []
     new_nodes = []
     ratios = {}
('sphinx', 'errors.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,15 +1,6 @@
-"""
-    sphinx.errors
-    ~~~~~~~~~~~~~
+"""Contains SphinxError and a few subclasses."""
 
-    Contains SphinxError and a few subclasses (in an extra module to avoid
-    circular import problems).
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
-
-from typing import Any
+from typing import Any, Optional
 
 
 class SphinxError(Exception):
@@ -48,7 +39,9 @@
 class ExtensionError(SphinxError):
     """Extension error."""
 
-    def __init__(self, message: str, orig_exc: Exception = None, modname: str = None) -> None:
+    def __init__(
+        self, message: str, orig_exc: Optional[Exception] = None, modname: Optional[str] = None
+    ) -> None:
         super().__init__(message)
         self.message = message
         self.orig_exc = orig_exc
('sphinx', 'highlighting.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,26 +1,16 @@
-"""
-    sphinx.highlighting
-    ~~~~~~~~~~~~~~~~~~~
+"""Highlight code blocks using Pygments."""
 
-    Highlight code blocks using Pygments.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
-
-from distutils.version import LooseVersion
 from functools import partial
 from importlib import import_module
-from typing import Any, Dict
+from typing import Any, Dict, Optional, Type, Union
 
-from pygments import __version__ as pygmentsversion
 from pygments import highlight
 from pygments.filters import ErrorToken
 from pygments.formatter import Formatter
 from pygments.formatters import HtmlFormatter, LatexFormatter
 from pygments.lexer import Lexer
-from pygments.lexers import (CLexer, Python3Lexer, PythonConsoleLexer, PythonLexer, RstLexer,
-                             TextLexer, get_lexer_by_name, guess_lexer)
+from pygments.lexers import (CLexer, PythonConsoleLexer, PythonLexer, RstLexer, TextLexer,
+                             get_lexer_by_name, guess_lexer)
 from pygments.style import Style
 from pygments.styles import get_style_by_name
 from pygments.util import ClassNotFound
@@ -32,12 +22,10 @@
 logger = logging.getLogger(__name__)
 
 lexers: Dict[str, Lexer] = {}
-lexer_classes: Dict[str, Lexer] = {
+lexer_classes: Dict[str, Union[Type[Lexer], 'partial[Lexer]']] = {
     'none': partial(TextLexer, stripnl=False),
     'python': partial(PythonLexer, stripnl=False),
-    'python3': partial(Python3Lexer, stripnl=False),
     'pycon': partial(PythonConsoleLexer, stripnl=False),
-    'pycon3': partial(PythonConsoleLexer, python3=True, stripnl=False),
     'rest': partial(RstLexer, stripnl=False),
     'c': partial(CLexer, stripnl=False),
 }
@@ -48,24 +36,42 @@
                    ord('}'): '\\PYGZcb{}'}
 
 # used if Pygments is available
-# use textcomp quote to get a true single quote
+# MEMO: no use of \protected here to avoid having to do hyperref extras,
+# (if in future code highlighting in sectioning titles is activated):
+# the definitions here use only robust, protected or chardef tokens,
+# which are all known to the hyperref re-encoding for bookmarks.
+# The " is troublesome because we would like to use \text\textquotedbl
+# but \textquotedbl is *defined to raise an error* (!) if the font
+# encoding is OT1.  This however could happen from 'fontenc' key.
+# MEMO: the Pygments escapes with \char`\<char> syntax, if the document
+# uses old OT1 font encoding, work correctly only in monospace font.
+# MEMO: the Pygmentize output mark-up is always with a {} after.
 _LATEX_ADD_STYLES = r'''
-\renewcommand\PYGZsq{\textquotesingle}
-'''
-# fix extra space between lines when Pygments highlighting uses \fcolorbox
-# add a {..} to limit \fboxsep scope, and force \fcolorbox use correct value
-# cf pygments #1708 which makes this unneeded for Pygments > 2.7.4
-_LATEX_ADD_STYLES_FIXPYG = r'''
+% Sphinx redefinitions
+% Originally to obtain a straight single quote via package textcomp, then
+% to fix problems for the 5.0.0 inline code highlighting (captions!).
+% The \text is from amstext, a dependency of sphinx.sty.  It is here only
+% to avoid build errors if for some reason expansion is in math mode.
+\def\PYGZbs{\text\textbackslash}
+\def\PYGZus{\_}
+\def\PYGZob{\{}
+\def\PYGZcb{\}}
+\def\PYGZca{\text\textasciicircum}
+\def\PYGZam{\&}
+\def\PYGZlt{\text\textless}
+\def\PYGZgt{\text\textgreater}
+\def\PYGZsh{\#}
+\def\PYGZpc{\%}
+\def\PYGZdl{\$}
+\def\PYGZhy{\sphinxhyphen}% defined in sphinxlatexstyletext.sty
+\def\PYGZsq{\text\textquotesingle}
+\def\PYGZdq{"}
+\def\PYGZti{\text\textasciitilde}
 \makeatletter
-% fix for Pygments <= 2.7.4
-\let\spx@original@fcolorbox\fcolorbox
-\def\spx@fixpyg@fcolorbox{\fboxsep-\fboxrule\spx@original@fcolorbox}
-\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+%
-             {\let\fcolorbox\spx@fixpyg@fcolorbox\PYG@do{#2}}}
+% use \protected to allow syntax highlighting in captions
+\protected\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+{\PYG@do{#2}}}
 \makeatother
 '''
-if tuple(LooseVersion(pygmentsversion).version) <= (2, 7, 4):
-    _LATEX_ADD_STYLES += _LATEX_ADD_STYLES_FIXPYG
 
 
 class PygmentsBridge:
@@ -75,7 +81,7 @@
     latex_formatter = LatexFormatter
 
     def __init__(self, dest: str = 'html', stylename: str = 'sphinx',
-                 latex_engine: str = None) -> None:
+                 latex_engine: Optional[str] = None) -> None:
         self.dest = dest
         self.latex_engine = latex_engine
 
@@ -102,23 +108,18 @@
         kwargs.update(self.formatter_args)
         return self.formatter(**kwargs)
 
-    def get_lexer(self, source: str, lang: str, opts: Dict = None,
+    def get_lexer(self, source: str, lang: str, opts: Optional[Dict] = None,
                   force: bool = False, location: Any = None) -> Lexer:
         if not opts:
             opts = {}
 
         # find out which lexer to use
-        if lang in ('py', 'python'):
+        if lang in {'py', 'python', 'py3', 'python3', 'default'}:
             if source.startswith('>>>'):
                 # interactive session
                 lang = 'pycon'
             else:
                 lang = 'python'
-        elif lang in ('py3', 'python3', 'default'):
-            if source.startswith('>>>'):
-                lang = 'pycon3'
-            else:
-                lang = 'python3'
 
         if lang in lexers:
             # just return custom lexers here (without installing raiseonerror filter)
@@ -141,7 +142,7 @@
 
         return lexer
 
-    def highlight_block(self, source: str, lang: str, opts: Dict = None,
+    def highlight_block(self, source: str, lang: str, opts: Optional[Dict] = None,
                         force: bool = False, location: Any = None, **kwargs: Any) -> str:
         if not isinstance(source, str):
             source = source.decode()
('sphinx', 'setup_command.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,28 +1,27 @@
-"""
-    sphinx.setup_command
-    ~~~~~~~~~~~~~~~~~~~~
+"""Setuptools/distutils commands to assist the building of sphinx documentation.
 
-    Setuptools/distutils commands to assist the building of sphinx
-    documentation.
-
-    :author: Sebastian Wiesner
-    :contact: basti.wiesner@gmx.net
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
+:author: Sebastian Wiesner <basti.wiesner@gmx.net>
 """
 
 import os
 import sys
-from distutils.cmd import Command
-from distutils.errors import DistutilsExecError
+import warnings
 from io import StringIO
-from typing import Any, Dict
+from typing import Any, Dict, Optional
 
 from sphinx.application import Sphinx
 from sphinx.cmd.build import handle_exception
+from sphinx.deprecation import RemovedInSphinx70Warning
 from sphinx.util.console import color_terminal, nocolor
 from sphinx.util.docutils import docutils_namespace, patch_docutils
 from sphinx.util.osutil import abspath
+
+try:
+    from setuptools import Command
+    from setuptools.errors import ExecError
+except ImportError:
+    from distutils.cmd import Command
+    from distutils.errors import DistutilsExecError as ExecError
 
 
 class BuildDoc(Command):
@@ -91,19 +90,19 @@
     def initialize_options(self) -> None:
         self.fresh_env = self.all_files = False
         self.pdb = False
-        self.source_dir: str = None
-        self.build_dir: str = None
+        self.source_dir: Optional[str] = None
+        self.build_dir: Optional[str] = None
         self.builder = 'html'
         self.warning_is_error = False
         self.project = ''
         self.version = ''
         self.release = ''
         self.today = ''
-        self.config_dir: str = None
+        self.config_dir: Optional[str] = None
         self.link_index = False
         self.copyright = ''
         # Link verbosity to distutils' (which uses 1 by default).
-        self.verbosity = self.distribution.verbose - 1  # type: ignore
+        self.verbosity = self.distribution.verbose - 1
         self.traceback = False
         self.nitpicky = False
         self.keep_going = False
@@ -112,7 +111,7 @@
         for guess in ('doc', 'docs'):
             if not os.path.isdir(guess):
                 continue
-            for root, dirnames, filenames in os.walk(guess):
+            for root, _dirnames, filenames in os.walk(guess):
                 if 'conf.py' in filenames:
                     return root
         return os.curdir
@@ -131,7 +130,7 @@
 
         if self.build_dir is None:
             build = self.get_finalized_command('build')
-            self.build_dir = os.path.join(abspath(build.build_base), 'sphinx')  # type: ignore
+            self.build_dir = os.path.join(abspath(build.build_base), 'sphinx')
 
         self.doctree_dir = os.path.join(self.build_dir, 'doctrees')
 
@@ -140,9 +139,12 @@
             for builder in self.builder]
 
     def run(self) -> None:
+        warnings.warn('setup.py build_sphinx is deprecated.',
+                      RemovedInSphinx70Warning, stacklevel=2)
+
         if not color_terminal():
             nocolor()
-        if not self.verbose:  # type: ignore
+        if not self.verbose:
             status_stream = StringIO()
         else:
             status_stream = sys.stdout  # type: ignore
@@ -174,8 +176,7 @@
                                  verbosity=self.verbosity, keep_going=self.keep_going)
                     app.build(force_all=self.all_files)
                     if app.statuscode:
-                        raise DistutilsExecError(
-                            'caused by %s builder.' % app.builder.name)
+                        raise ExecError('caused by %s builder.' % app.builder.name)
             except Exception as exc:
                 handle_exception(app, self, exc, sys.stderr)
                 if not self.pdb:
('sphinx', 'pygments_styles.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.pygments_styles
-    ~~~~~~~~~~~~~~~~~~~~~~
-
-    Sphinx theme specific highlighting styles.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Sphinx theme specific highlighting styles."""
 
 from pygments.style import Style
 from pygments.styles.friendly import FriendlyStyle
('sphinx', '__main__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.__main__
-    ~~~~~~~~~~~~~~~
-
-    The Sphinx documentation toolchain.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""The Sphinx documentation toolchain."""
 
 import sys
 
('sphinx', 'project.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,21 +1,13 @@
-"""
-    sphinx.project
-    ~~~~~~~~~~~~~~
-
-    Utility function and classes for Sphinx projects.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Utility function and classes for Sphinx projects."""
 
 import os
 from glob import glob
-from typing import Dict, List, Optional, Set
+from typing import Dict, Iterable, Optional, Set
 
 from sphinx.locale import __
-from sphinx.util import get_matching_files, logging, path_stabilize
-from sphinx.util.matching import compile_matchers
-from sphinx.util.osutil import SEP, relpath
+from sphinx.util import logging
+from sphinx.util.matching import get_matching_files
+from sphinx.util.osutil import SEP, path_stabilize, relpath
 
 logger = logging.getLogger(__name__)
 EXCLUDE_PATHS = ['**/_sources', '.#*', '**/.#*', '*.lproj/**']
@@ -38,13 +30,17 @@
         """Take over a result of last build."""
         self.docnames = other.docnames
 
-    def discover(self, exclude_paths: List[str] = []) -> Set[str]:
+    def discover(self, exclude_paths: Iterable[str] = (),
+                 include_paths: Iterable[str] = ("**",)) -> Set[str]:
         """Find all document files in the source directory and put them in
         :attr:`docnames`.
         """
         self.docnames = set()
-        excludes = compile_matchers(exclude_paths + EXCLUDE_PATHS)
-        for filename in get_matching_files(self.srcdir, excludes):  # type: ignore
+        for filename in get_matching_files(
+            self.srcdir,
+            include_paths,
+            [*exclude_paths] + EXCLUDE_PATHS,
+        ):
             docname = self.path2doc(filename)
             if docname:
                 if docname in self.docnames:
('sphinx/directives', 'code.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,15 +1,7 @@
-"""
-    sphinx.directives.code
-    ~~~~~~~~~~~~~~~~~~~~~~
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
-
 import sys
 import textwrap
 from difflib import unified_diff
-from typing import TYPE_CHECKING, Any, Dict, List, Tuple
+from typing import TYPE_CHECKING, Any, Dict, List, Optional, Tuple
 
 from docutils import nodes
 from docutils.nodes import Element, Node
@@ -56,8 +48,10 @@
                                        linenothreshold=linenothreshold)]
 
 
-def dedent_lines(lines: List[str], dedent: int, location: Tuple[str, int] = None) -> List[str]:
-    if not dedent:
+def dedent_lines(
+    lines: List[str], dedent: Optional[int], location: Optional[Tuple[str, int]] = None
+) -> List[str]:
+    if dedent is None:
         return textwrap.dedent(''.join(lines)).splitlines(True)
 
     if any(s[:dedent].strip() for s in lines):
@@ -138,9 +132,9 @@
 
         if 'dedent' in self.options:
             location = self.state_machine.get_source_and_line(self.lineno)
-            lines = code.split('\n')
+            lines = code.splitlines(True)
             lines = dedent_lines(lines, self.options['dedent'], location=location)
-            code = '\n'.join(lines)
+            code = ''.join(lines)
 
         literal: Element = nodes.literal_block(code, code)
         if 'linenos' in self.options or 'lineno-start' in self.options:
@@ -194,7 +188,7 @@
         ('diff', 'end-at'),
     ]
 
-    def __init__(self, filename: str, options: Dict, config: Config) -> None:
+    def __init__(self, filename: str, options: Dict[str, Any], config: Config) -> None:
         self.filename = filename
         self.options = options
         self.encoding = options.get('encoding', config.source_encoding)
@@ -208,7 +202,9 @@
                 raise ValueError(__('Cannot use both "%s" and "%s" options') %
                                  (option1, option2))
 
-    def read_file(self, filename: str, location: Tuple[str, int] = None) -> List[str]:
+    def read_file(
+        self, filename: str, location: Optional[Tuple[str, int]] = None
+    ) -> List[str]:
         try:
             with open(filename, encoding=self.encoding, errors='strict') as f:
                 text = f.read()
@@ -224,7 +220,7 @@
                                   'be wrong, try giving an :encoding: option') %
                                (self.encoding, filename)) from exc
 
-    def read(self, location: Tuple[str, int] = None) -> Tuple[str, int]:
+    def read(self, location: Optional[Tuple[str, int]] = None) -> Tuple[str, int]:
         if 'diff' in self.options:
             lines = self.show_diff()
         else:
@@ -232,23 +228,25 @@
                        self.start_filter,
                        self.end_filter,
                        self.lines_filter,
+                       self.dedent_filter,
                        self.prepend_filter,
-                       self.append_filter,
-                       self.dedent_filter]
+                       self.append_filter]
             lines = self.read_file(self.filename, location=location)
             for func in filters:
                 lines = func(lines, location=location)
 
         return ''.join(lines), len(lines)
 
-    def show_diff(self, location: Tuple[str, int] = None) -> List[str]:
+    def show_diff(self, location: Optional[Tuple[str, int]] = None) -> List[str]:
         new_lines = self.read_file(self.filename)
-        old_filename = self.options.get('diff')
+        old_filename = self.options['diff']
         old_lines = self.read_file(old_filename)
         diff = unified_diff(old_lines, new_lines, old_filename, self.filename)
         return list(diff)
 
-    def pyobject_filter(self, lines: List[str], location: Tuple[str, int] = None) -> List[str]:
+    def pyobject_filter(
+        self, lines: List[str], location: Optional[Tuple[str, int]] = None
+    ) -> List[str]:
         pyobject = self.options.get('pyobject')
         if pyobject:
             from sphinx.pycode import ModuleAnalyzer
@@ -266,7 +264,9 @@
 
         return lines
 
-    def lines_filter(self, lines: List[str], location: Tuple[str, int] = None) -> List[str]:
+    def lines_filter(
+        self, lines: List[str], location: Optional[Tuple[str, int]] = None
+    ) -> List[str]:
         linespec = self.options.get('lines')
         if linespec:
             linelist = parselinenos(linespec, len(lines))
@@ -290,7 +290,9 @@
 
         return lines
 
-    def start_filter(self, lines: List[str], location: Tuple[str, int] = None) -> List[str]:
+    def start_filter(
+        self, lines: List[str], location: Optional[Tuple[str, int]] = None
+    ) -> List[str]:
         if 'start-at' in self.options:
             start = self.options.get('start-at')
             inclusive = False
@@ -321,7 +323,9 @@
 
         return lines
 
-    def end_filter(self, lines: List[str], location: Tuple[str, int] = None) -> List[str]:
+    def end_filter(
+        self, lines: List[str], location: Optional[Tuple[str, int]] = None
+    ) -> List[str]:
         if 'end-at' in self.options:
             end = self.options.get('end-at')
             inclusive = True
@@ -348,21 +352,27 @@
 
         return lines
 
-    def prepend_filter(self, lines: List[str], location: Tuple[str, int] = None) -> List[str]:
+    def prepend_filter(
+        self, lines: List[str], location: Optional[Tuple[str, int]] = None
+    ) -> List[str]:
         prepend = self.options.get('prepend')
         if prepend:
             lines.insert(0, prepend + '\n')
 
         return lines
 
-    def append_filter(self, lines: List[str], location: Tuple[str, int] = None) -> List[str]:
+    def append_filter(
+        self, lines: List[str], location: Optional[Tuple[str, int]] = None
+    ) -> List[str]:
         append = self.options.get('append')
         if append:
             lines.append(append + '\n')
 
         return lines
 
-    def dedent_filter(self, lines: List[str], location: Tuple[str, int] = None) -> List[str]:
+    def dedent_filter(
+        self, lines: List[str], location: Optional[Tuple[str, int]] = None
+    ) -> List[str]:
         if 'dedent' in self.options:
             return dedent_lines(lines, self.options.get('dedent'), location=location)
         else:
('sphinx/directives', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,15 +1,7 @@
-"""
-    sphinx.directives
-    ~~~~~~~~~~~~~~~~~
-
-    Handlers for additional ReST directives.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Handlers for additional ReST directives."""
 
 import re
-from typing import TYPE_CHECKING, Any, Dict, Generic, List, Tuple, TypeVar, cast
+from typing import TYPE_CHECKING, Any, Dict, Generic, List, Optional, Tuple, TypeVar, cast
 
 from docutils import nodes
 from docutils.nodes import Node
@@ -17,7 +9,6 @@
 
 from sphinx import addnodes
 from sphinx.addnodes import desc_signature
-from sphinx.deprecation import RemovedInSphinx50Warning, deprecated_alias
 from sphinx.util import docutils
 from sphinx.util.docfields import DocFieldTransformer, Field, TypedField
 from sphinx.util.docutils import SphinxDirective
@@ -64,9 +55,9 @@
 
     # types of doc fields that this directive handles, see sphinx.util.docfields
     doc_field_types: List[Field] = []
-    domain: str = None
-    objtype: str = None
-    indexnode: addnodes.index = None
+    domain: Optional[str] = None
+    objtype: Optional[str] = None
+    indexnode: Optional[addnodes.index] = None
 
     # Warning: this might be removed in future version. Don't touch this from extensions.
     _doc_field_type_map: Dict[str, Tuple[Field, bool]] = {}
@@ -139,6 +130,44 @@
         current directive context on the build environment.
         """
         pass
+
+    def _object_hierarchy_parts(self, sig_node: desc_signature) -> Tuple[str, ...]:
+        """
+        Returns a tuple of strings, one entry for each part of the object's
+        hierarchy (e.g. ``('module', 'submodule', 'Class', 'method')``). The
+        returned tuple is used to properly nest children within parents in the
+        table of contents, and can also be used within the
+        :py:meth:`_toc_entry_name` method.
+
+        This method must not be used outwith table of contents generation.
+        """
+        return ()
+
+    def _toc_entry_name(self, sig_node: desc_signature) -> str:
+        """
+        Returns the text of the table of contents entry for the object.
+
+        This function is called once, in :py:meth:`run`, to set the name for the
+        table of contents entry (a special attribute ``_toc_name`` is set on the
+        object node, later used in
+        ``environment.collectors.toctree.TocTreeCollector.process_doc().build_toc()``
+        when the table of contents entries are collected).
+
+        To support table of contents entries for their objects, domains must
+        override this method, also respecting the configuration setting
+        ``toc_object_entries_show_parents``. Domains must also override
+        :py:meth:`_object_hierarchy_parts`, with one (string) entry for each part of the
+        object's hierarchy. The result of this method is set on the signature
+        node, and can be accessed as ``sig_node['_toc_parts']`` for use within
+        this method. The resulting tuple is also used to properly nest children
+        within parents in the table of contents.
+
+        An example implementations of this method is within the python domain
+        (:meth:`PyObject._toc_entry_name`). The python domain sets the
+        ``_toc_parts`` attribute within the :py:meth:`handle_signature()`
+        method.
+        """
+        return ''
 
     def run(self) -> List[Node]:
         """
@@ -166,17 +195,29 @@
 
         node = addnodes.desc()
         node.document = self.state.document
+        source, line = self.get_source_info()
+        # If any options were specified to the directive,
+        # self.state.document.current_line will at this point be set to
+        # None.  To ensure nodes created as part of the signature have a line
+        # number set, set the document's line number correctly.
+        #
+        # Note that we need to subtract one from the line number since
+        # note_source uses 0-based line numbers.
+        if line is not None:
+            line -= 1
+        self.state.document.note_source(source, line)
         node['domain'] = self.domain
         # 'desctype' is a backwards compatible attribute
         node['objtype'] = node['desctype'] = self.objtype
         node['noindex'] = noindex = ('noindex' in self.options)
+        node['noindexentry'] = ('noindexentry' in self.options)
         if self.domain:
             node['classes'].append(self.domain)
         node['classes'].append(node['objtype'])
 
         self.names: List[T] = []
         signatures = self.get_signatures()
-        for i, sig in enumerate(signatures):
+        for sig in signatures:
             # add a signature node for each signature in the current unit
             # and add a reference target for it
             signode = addnodes.desc_signature(sig, '')
@@ -192,6 +233,11 @@
                 signode.clear()
                 signode += addnodes.desc_name(sig, sig)
                 continue  # we don't want an index entry here
+            finally:
+                # Private attributes for ToC generation. Will be modified or removed
+                # without notice.
+                signode['_toc_parts'] = self._object_hierarchy_parts(signode)
+                signode['_toc_name'] = self._toc_entry_name(signode)
             if name not in self.names:
                 self.names.append(name)
                 if not noindex:
@@ -201,6 +247,7 @@
 
         contentnode = addnodes.desc_content()
         node.append(contentnode)
+
         if self.names:
             # needed for association of version{added,changed} directives
             self.env.temp_data['object'] = self.names[0]
@@ -266,16 +313,6 @@
         return []
 
 
-deprecated_alias('sphinx.directives',
-                 {
-                     'DescDirective': ObjectDescription,
-                 },
-                 RemovedInSphinx50Warning,
-                 {
-                     'DescDirective': 'sphinx.directives.ObjectDescription',
-                 })
-
-
 def setup(app: "Sphinx") -> Dict[str, Any]:
     app.add_config_value("strip_signature_backslash", False, 'env')
     directives.register_directive('default-role', DefaultRole)
('sphinx/directives', 'other.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,11 +1,3 @@
-"""
-    sphinx.directives.other
-    ~~~~~~~~~~~~~~~~~~~~~~~
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
-
 import re
 from typing import TYPE_CHECKING, Any, Dict, List, cast
 
@@ -18,8 +10,8 @@
 
 from sphinx import addnodes
 from sphinx.domains.changeset import VersionChange  # NOQA  # for compatibility
-from sphinx.locale import _
-from sphinx.util import docname_join, url_re
+from sphinx.locale import _, __
+from sphinx.util import docname_join, logging, url_re
 from sphinx.util.docutils import SphinxDirective
 from sphinx.util.matching import Matcher, patfilter
 from sphinx.util.nodes import explicit_title_re
@@ -30,6 +22,7 @@
 
 
 glob_re = re.compile(r'.*[*?\[].*')
+logger = logging.getLogger(__name__)
 
 
 def int_or_nothing(argument: str) -> int:
@@ -84,10 +77,11 @@
         return ret
 
     def parse_content(self, toctree: addnodes.toctree) -> List[Node]:
+        generated_docnames = frozenset(self.env.domains['std'].initial_data['labels'].keys())
         suffixes = self.config.source_suffix
 
         # glob target documents
-        all_docnames = self.env.found_docs.copy()
+        all_docnames = self.env.found_docs.copy() | generated_docnames
         all_docnames.remove(self.env.docname)  # remove current document
 
         ret: List[Node] = []
@@ -102,13 +96,15 @@
                 patname = docname_join(self.env.docname, entry)
                 docnames = sorted(patfilter(all_docnames, patname))
                 for docname in docnames:
+                    if docname in generated_docnames:
+                        # don't include generated documents in globs
+                        continue
                     all_docnames.remove(docname)  # don't include it again
                     toctree['entries'].append((None, docname))
                     toctree['includefiles'].append(docname)
                 if not docnames:
-                    ret.append(self.state.document.reporter.warning(
-                        'toctree glob pattern %r didn\'t match any documents'
-                        % entry, line=self.lineno))
+                    logger.warning(__('toctree glob pattern %r didn\'t match any documents'),
+                                   entry, location=toctree)
             else:
                 if explicit:
                     ref = explicit.group(2)
@@ -126,22 +122,23 @@
                 docname = docname_join(self.env.docname, docname)
                 if url_re.match(ref) or ref == 'self':
                     toctree['entries'].append((title, ref))
-                elif docname not in self.env.found_docs:
-                    if excluded(self.env.doc2path(docname, None)):
-                        message = 'toctree contains reference to excluded document %r'
+                elif docname not in self.env.found_docs | generated_docnames:
+                    if excluded(self.env.doc2path(docname, False)):
+                        message = __('toctree contains reference to excluded document %r')
+                        subtype = 'excluded'
                     else:
-                        message = 'toctree contains reference to nonexisting document %r'
-
-                    ret.append(self.state.document.reporter.warning(message % docname,
-                                                                    line=self.lineno))
+                        message = __('toctree contains reference to nonexisting document %r')
+                        subtype = 'not_readable'
+
+                    logger.warning(message, docname, type='toc', subtype=subtype,
+                                   location=toctree)
                     self.env.note_reread()
                 else:
                     if docname in all_docnames:
                         all_docnames.remove(docname)
                     else:
-                        message = 'duplicated entry found in toctree: %s'
-                        ret.append(self.state.document.reporter.warning(message % docname,
-                                                                        line=self.lineno))
+                        logger.warning(__('duplicated entry found in toctree: %s'), docname,
+                                       location=toctree)
 
                     toctree['entries'].append((title, docname))
                     toctree['includefiles'].append(docname)
@@ -179,7 +176,7 @@
             text = _('Code author: ')
         else:
             text = _('Author: ')
-        emph += nodes.Text(text, text)
+        emph += nodes.Text(text)
         inodes, messages = self.state.inline_text(self.arguments[0], self.lineno)
         emph.extend(inodes)
 
@@ -250,8 +247,9 @@
         self.state.nested_parse(self.content, self.content_offset, node)
         if len(node.children) != 1 or not isinstance(node.children[0],
                                                      nodes.bullet_list):
-            reporter = self.state.document.reporter
-            return [reporter.warning('.. acks content is not a list', line=self.lineno)]
+            logger.warning(__('.. acks content is not a list'),
+                           location=(self.env.docname, self.lineno))
+            return []
         return [node]
 
 
@@ -274,8 +272,9 @@
         self.state.nested_parse(self.content, self.content_offset, node)
         if len(node.children) != 1 or not isinstance(node.children[0],
                                                      nodes.bullet_list):
-            reporter = self.state.document.reporter
-            return [reporter.warning('.. hlist content is not a list', line=self.lineno)]
+            logger.warning(__('.. hlist content is not a list'),
+                           location=(self.env.docname, self.lineno))
+            return []
         fulllist = node.children[0]
         # create a hlist node where the items are distributed
         npercol, nmore = divmod(len(fulllist), ncolumns)
@@ -339,7 +338,7 @@
             # be placed in the doctree.
             n_sects_to_raise = current_depth - nested_depth + 1
             parent = cast(nodes.Element, self.state.parent)
-            for i in range(n_sects_to_raise):
+            for _i in range(n_sects_to_raise):
                 if parent.parent:
                     parent = parent.parent
             parent.append(node)
('sphinx/directives', 'patches.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,20 +1,13 @@
-"""
-    sphinx.directives.patches
-    ~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
-
 import os
 import warnings
 from os import path
-from typing import TYPE_CHECKING, Any, Dict, List, Tuple, cast
+from typing import TYPE_CHECKING, Any, Dict, List, Sequence, Tuple, cast
 
 from docutils import nodes
 from docutils.nodes import Node, make_id, system_message
 from docutils.parsers.rst import directives
-from docutils.parsers.rst.directives import html, images, tables
+from docutils.parsers.rst.directives import images, tables
+from docutils.parsers.rst.roles import set_classes
 
 from sphinx import addnodes
 from sphinx.deprecation import RemovedInSphinx60Warning
@@ -27,6 +20,12 @@
 from sphinx.util.osutil import SEP, os_path, relpath
 from sphinx.util.typing import OptionSpec
 
+try:
+    from docutils.parsers.rst.directives.misc import Meta as MetaBase  # type: ignore
+except ImportError:
+    # docutils-0.17 or older
+    from docutils.parsers.rst.directives.html import Meta as MetaBase
+
 if TYPE_CHECKING:
     from sphinx.application import Sphinx
 
@@ -60,19 +59,21 @@
         return [figure_node]
 
 
-class Meta(html.Meta, SphinxDirective):
-    def run(self) -> List[Node]:
+class Meta(MetaBase, SphinxDirective):
+    def run(self) -> Sequence[Node]:
         result = super().run()
         for node in result:
+            # for docutils-0.17 or older.  Since docutils-0.18, patching is no longer needed
+            # because it uses picklable node; ``docutils.nodes.meta``.
             if (isinstance(node, nodes.pending) and
-               isinstance(node.details['nodes'][0], html.MetaBody.meta)):
+               isinstance(node.details['nodes'][0], addnodes.docutils_meta)):
                 meta = node.details['nodes'][0]
                 meta.source = self.env.doc2path(self.env.docname)
                 meta.line = self.lineno
-                meta.rawcontent = meta['content']  # type: ignore
+                meta.rawcontent = meta['content']
 
                 # docutils' meta nodes aren't picklable because the class is nested
-                meta.__class__ = addnodes.meta  # type: ignore
+                meta.__class__ = addnodes.meta
 
         return result
 
@@ -152,6 +153,7 @@
     def run(self) -> List[Node]:
         self.assert_has_content()
 
+        set_classes(self.options)
         code = '\n'.join(self.content)
         node = nodes.literal_block(code, code,
                                    classes=self.options.get('classes', []),
('sphinx/cmd', 'build.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.cmd.build
-    ~~~~~~~~~~~~~~~~
-
-    Build documentation from a provided source.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Build documentation from a provided source."""
 
 import argparse
 import bdb
@@ -16,7 +8,8 @@
 import pdb
 import sys
 import traceback
-from typing import IO, Any, List
+from os import path
+from typing import IO, Any, List, Optional, TextIO
 
 from docutils.utils import SystemMessage
 
@@ -28,9 +21,12 @@
 from sphinx.util import Tee, format_exception_cut_frames, save_traceback
 from sphinx.util.console import color_terminal, nocolor, red, terminal_safe  # type: ignore
 from sphinx.util.docutils import docutils_namespace, patch_docutils
-
-
-def handle_exception(app: Sphinx, args: Any, exception: BaseException, stderr: IO = sys.stderr) -> None:  # NOQA
+from sphinx.util.osutil import abspath, ensuredir
+
+
+def handle_exception(
+    app: Optional[Sphinx], args: Any, exception: BaseException, stderr: IO = sys.stderr
+) -> None:
     if isinstance(exception, bdb.BdbQuit):
         return
 
@@ -228,8 +224,8 @@
     if args.color == 'no' or (args.color == 'auto' and not color_terminal()):
         nocolor()
 
-    status = sys.stdout
-    warning = sys.stderr
+    status: Optional[TextIO] = sys.stdout
+    warning: Optional[TextIO] = sys.stderr
     error = sys.stderr
 
     if args.quiet:
@@ -240,7 +236,9 @@
 
     if warning and args.warnfile:
         try:
-            warnfp = open(args.warnfile, 'w')
+            warnfile = abspath(args.warnfile)
+            ensuredir(path.dirname(warnfile))
+            warnfp = open(args.warnfile, 'w', encoding="utf-8")
         except Exception as exc:
             parser.error(__('cannot open warning file %r: %s') % (
                 args.warnfile, exc))
@@ -276,7 +274,8 @@
             app = Sphinx(args.sourcedir, args.confdir, args.outputdir,
                          args.doctreedir, args.builder, confoverrides, status,
                          warning, args.freshenv, args.warningiserror,
-                         args.tags, args.verbosity, args.jobs, args.keep_going)
+                         args.tags, args.verbosity, args.jobs, args.keep_going,
+                         args.pdb)
             app.build(args.force_all, filenames)
             return app.statuscode
     except (Exception, KeyboardInterrupt) as exc:
('sphinx/cmd', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,9 +1 @@
-"""
-    sphinx.cmd
-    ~~~~~~~~~~
-
-    Modules for command line executables.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Modules for command line executables."""
('sphinx/cmd', 'quickstart.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.cmd.quickstart
-    ~~~~~~~~~~~~~~~~~~~~~
-
-    Quickly setup documentation source to work with Sphinx.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Quickly setup documentation source to work with Sphinx."""
 
 import argparse
 import locale
@@ -15,11 +7,14 @@
 import time
 from collections import OrderedDict
 from os import path
-from typing import Any, Callable, Dict, List, Union
+from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Union
 
 # try to import readline, unix specific enhancement
 try:
     import readline
+    if TYPE_CHECKING and sys.platform == "win32":  # always false, for type checking
+        raise ImportError
+    READLINE_AVAILABLE = True
     if readline.__doc__ and 'libedit' in readline.__doc__:
         readline.parse_and_bind("bind ^I rl_complete")
         USE_LIBEDIT = True
@@ -27,7 +22,7 @@
         readline.parse_and_bind("tab: complete")
         USE_LIBEDIT = False
 except ImportError:
-    readline = None
+    READLINE_AVAILABLE = False
     USE_LIBEDIT = False
 
 from docutils.utils import column_width
@@ -135,7 +130,9 @@
     return x
 
 
-def do_prompt(text: str, default: str = None, validator: Callable[[str], Any] = nonempty) -> Union[str, bool]:  # NOQA
+def do_prompt(
+    text: str, default: Optional[str] = None, validator: Callable[[str], Any] = nonempty
+) -> Union[str, bool]:
     while True:
         if default is not None:
             prompt = PROMPT_PREFIX + '%s [%s]: ' % (text, default)
@@ -146,7 +143,7 @@
             # sequence (see #5335).  To avoid the problem, all prompts are not colored
             # on libedit.
             pass
-        elif readline:
+        elif READLINE_AVAILABLE:
             # pass input_mode=True if readline available
             prompt = colorize(COLOR_QUESTION, prompt, input_mode=True)
         else:
@@ -164,8 +161,8 @@
 
 
 class QuickstartRenderer(SphinxRenderer):
-    def __init__(self, templatedir: str) -> None:
-        self.templatedir = templatedir or ''
+    def __init__(self, templatedir: str = '') -> None:
+        self.templatedir = templatedir
         super().__init__()
 
     def _has_custom_template(self, template_name: str) -> bool:
@@ -188,7 +185,7 @@
             return super().render(template_name, context)
 
 
-def ask_user(d: Dict) -> None:
+def ask_user(d: Dict[str, Any]) -> None:
     """Ask the user for quickstart values missing from *d*.
 
     Values are:
@@ -326,10 +323,11 @@
     print()
 
 
-def generate(d: Dict, overwrite: bool = True, silent: bool = False, templatedir: str = None
-             ) -> None:
+def generate(
+    d: Dict, overwrite: bool = True, silent: bool = False, templatedir: Optional[str] = None
+) -> None:
     """Generate project based on values in *d*."""
-    template = QuickstartRenderer(templatedir=templatedir)
+    template = QuickstartRenderer(templatedir or '')
 
     if 'mastertoctree' not in d:
         d['mastertoctree'] = ''
@@ -362,7 +360,7 @@
     ensuredir(path.join(srcdir, d['dot'] + 'templates'))
     ensuredir(path.join(srcdir, d['dot'] + 'static'))
 
-    def write_file(fpath: str, content: str, newline: str = None) -> None:
+    def write_file(fpath: str, content: str, newline: Optional[str] = None) -> None:
         if overwrite or not path.isfile(fpath):
             if 'quiet' not in d:
                 print(__('Creating file %s.') % fpath)
@@ -375,7 +373,7 @@
     conf_path = os.path.join(templatedir, 'conf.py_t') if templatedir else None
     if not conf_path or not path.isfile(conf_path):
         conf_path = os.path.join(package_dir, 'templates', 'quickstart', 'conf.py_t')
-    with open(conf_path) as f:
+    with open(conf_path, encoding="utf-8") as f:
         conf_text = f.read()
 
     write_file(path.join(srcdir, 'conf.py'), template.render_string(conf_text, d))
('sphinx/cmd', 'make_mode.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,24 +1,17 @@
-"""
-    sphinx.cmd.make_mode
-    ~~~~~~~~~~~~~~~~~~~~
+"""sphinx-build -M command-line handling.
 
-    sphinx-build -M command-line handling.
+This replaces the old, platform-dependent and once-generated content
+of Makefile / make.bat.
 
-    This replaces the old, platform-dependent and once-generated content
-    of Makefile / make.bat.
-
-    This is in its own module so that importing it is fast.  It should not
-    import the main Sphinx modules (like sphinx.applications, sphinx.builders).
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
+This is in its own module so that importing it is fast.  It should not
+import the main Sphinx modules (like sphinx.applications, sphinx.builders).
 """
 
 import os
 import subprocess
 import sys
 from os import path
-from typing import List
+from typing import List, Optional
 
 import sphinx
 from sphinx.cmd.build import build_main
@@ -139,7 +132,7 @@
             return 1
         return 0
 
-    def run_generic_build(self, builder: str, doctreedir: str = None) -> int:
+    def run_generic_build(self, builder: str, doctreedir: Optional[str] = None) -> int:
         # compatibility with old Makefile
         papersize = os.getenv('PAPER', '')
         opts = self.opts
('sphinx/domains', 'citation.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.domains.citation
-    ~~~~~~~~~~~~~~~~~~~~~~~
-
-    The citation domain.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""The citation domain."""
 
 from typing import TYPE_CHECKING, Any, Dict, List, Optional, Set, Tuple, cast
 
@@ -48,7 +40,7 @@
         return self.data.setdefault('citation_refs', {})
 
     def clear_doc(self, docname: str) -> None:
-        for key, (fn, _l, lineno) in list(self.citations.items()):
+        for key, (fn, _l, _lineno) in list(self.citations.items()):
             if fn == docname:
                 del self.citations[key]
         for key, docnames in list(self.citation_refs.items()):
@@ -81,7 +73,7 @@
         docnames.add(self.env.docname)
 
     def check_consistency(self) -> None:
-        for name, (docname, labelid, lineno) in self.citations.items():
+        for name, (docname, _labelid, lineno) in self.citations.items():
             if name not in self.citation_refs:
                 logger.warning(__('Citation [%s] is not referenced.'), name,
                                type='ref', subtype='citation', location=(docname, lineno))
@@ -112,7 +104,7 @@
 
     def apply(self, **kwargs: Any) -> None:
         domain = cast(CitationDomain, self.env.get_domain('citation'))
-        for node in self.document.traverse(nodes.citation):
+        for node in self.document.findall(nodes.citation):
             # register citation node to domain
             node['docname'] = self.env.docname
             domain.note_citation(node)
@@ -131,7 +123,7 @@
 
     def apply(self, **kwargs: Any) -> None:
         domain = cast(CitationDomain, self.env.get_domain('citation'))
-        for node in self.document.traverse(nodes.citation_reference):
+        for node in self.document.findall(nodes.citation_reference):
             target = node.astext()
             ref = pending_xref(target, refdomain='citation', reftype='ref',
                                reftarget=target, refwarn=True,
('sphinx/domains', 'index.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.domains.index
-    ~~~~~~~~~~~~~~~~~~~~
-
-    The index domain.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""The index domain."""
 
 from typing import TYPE_CHECKING, Any, Dict, Iterable, List, Tuple
 
@@ -48,7 +40,7 @@
     def process_doc(self, env: BuildEnvironment, docname: str, document: Node) -> None:
         """Process a document after it is read by the environment."""
         entries = self.entries.setdefault(env.docname, [])
-        for node in document.traverse(addnodes.index):
+        for node in list(document.findall(addnodes.index)):
             try:
                 for entry in node['entries']:
                     split_index_msg(entry[0], entry[1])
@@ -110,7 +102,7 @@
 
         index = addnodes.index(entries=entries)
         target = nodes.target('', '', ids=[target_id])
-        text = nodes.Text(title, title)
+        text = nodes.Text(title)
         self.set_source_info(index)
         return [index, target, text], []
 
('sphinx/domains', 'std.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,16 +1,7 @@
-"""
-    sphinx.domains.std
-    ~~~~~~~~~~~~~~~~~~
-
-    The standard domain.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""The standard domain."""
 
 import re
-import unicodedata
-import warnings
+import sys
 from copy import copy
 from typing import (TYPE_CHECKING, Any, Callable, Dict, Iterable, Iterator, List, Optional,
                     Tuple, Type, Union, cast)
@@ -22,11 +13,10 @@
 
 from sphinx import addnodes
 from sphinx.addnodes import desc_signature, pending_xref
-from sphinx.deprecation import RemovedInSphinx50Warning
 from sphinx.directives import ObjectDescription
 from sphinx.domains import Domain, ObjType
 from sphinx.locale import _, __
-from sphinx.roles import XRefRole
+from sphinx.roles import EmphasizedLiteral, XRefRole
 from sphinx.util import docname_join, logging, ws_re
 from sphinx.util.docutils import SphinxDirective
 from sphinx.util.nodes import clean_astext, make_id, make_refnode
@@ -39,11 +29,17 @@
 
 logger = logging.getLogger(__name__)
 
+if sys.version_info[:2] >= (3, 8):
+    from typing import Final
+else:
+    Final = Any
 
 # RE for option descriptions
 option_desc_re = re.compile(r'((?:/|--|-|\+)?[^\s=]+)(=?\s*.*)')
 # RE for grammar tokens
 token_re = re.compile(r'`((~?\w*:)?\w+)`', re.U)
+
+samp_role = EmphasizedLiteral()
 
 
 class GenericObject(ObjectDescription[str]):
@@ -66,13 +62,6 @@
     def add_target_and_index(self, name: str, sig: str, signode: desc_signature) -> None:
         node_id = make_id(self.env, self.state.document, self.objtype, name)
         signode['ids'].append(node_id)
-
-        # Assign old styled node_id not to break old hyperlinks (if possible)
-        # Note: Will be removed in Sphinx-5.0 (RemovedInSphinx50Warning)
-        old_node_id = self.make_old_id(name)
-        if old_node_id not in self.state.document.ids and old_node_id not in signode['ids']:
-            signode['ids'].append(old_node_id)
-
         self.state.document.note_explicit_target(signode)
 
         if self.indextemplate:
@@ -140,13 +129,6 @@
         node_id = make_id(self.env, self.state.document, self.name, fullname)
         node = nodes.target('', '', ids=[node_id])
         self.set_source_info(node)
-
-        # Assign old styled node_id not to break old hyperlinks (if possible)
-        # Note: Will be removed in Sphinx-5.0 (RemovedInSphinx50Warning)
-        old_node_id = self.make_old_id(fullname)
-        if old_node_id not in self.state.document.ids and old_node_id not in node['ids']:
-            node['ids'].append(old_node_id)
-
         self.state.document.note_explicit_target(node)
         ret: List[Node] = [node]
         if self.indextemplate:
@@ -195,15 +177,40 @@
                                location=signode)
                 continue
             optname, args = m.groups()
-            if optname.endswith('[') and args.endswith(']'):
+            if optname[-1] == '[' and args[-1] == ']':
                 # optional value surrounded by brackets (ex. foo[=bar])
                 optname = optname[:-1]
                 args = '[' + args
 
             if count:
-                signode += addnodes.desc_addname(', ', ', ')
+                if self.env.config.option_emphasise_placeholders:
+                    signode += addnodes.desc_sig_punctuation(',', ',')
+                    signode += addnodes.desc_sig_space()
+                else:
+                    signode += addnodes.desc_addname(', ', ', ')
             signode += addnodes.desc_name(optname, optname)
-            signode += addnodes.desc_addname(args, args)
+            if self.env.config.option_emphasise_placeholders:
+                add_end_bracket = False
+                if args:
+                    if args[0] == '[' and args[-1] == ']':
+                        add_end_bracket = True
+                        signode += addnodes.desc_sig_punctuation('[', '[')
+                        args = args[1:-1]
+                    elif args[0] == ' ':
+                        signode += addnodes.desc_sig_space()
+                        args = args.strip()
+                    elif args[0] == '=':
+                        signode += addnodes.desc_sig_punctuation('=', '=')
+                        args = args[1:]
+                    for part in samp_role.parse(args):
+                        if isinstance(part, nodes.Text):
+                            signode += nodes.Text(part.astext())
+                        else:
+                            signode += part
+                if add_end_bracket:
+                    signode += addnodes.desc_sig_punctuation(']', ']')
+            else:
+                signode += addnodes.desc_addname(args, args)
             if not count:
                 firstname = optname
                 signode['allnames'] = [optname]
@@ -243,7 +250,7 @@
             descr = _('%s command line option') % currprogram
         else:
             descr = _('command line option')
-        for option in sig.split(', '):
+        for option in signode.get('allnames', []):
             entry = '; '.join([descr, option])
             self.indexnode['entries'].append(('pair', entry, signode['ids'][0], '', None))
 
@@ -336,6 +343,7 @@
     def run(self) -> List[Node]:
         node = addnodes.glossary()
         node.document = self.state.document
+        node['sorted'] = ('sorted' in self.options)
 
         # This directive implements a custom format of the reST definition list
         # that allows multiple lines of terms before the definition.  This is
@@ -400,9 +408,8 @@
             was_empty = False
 
         # now, parse all the entries into a big definition list
-        items = []
+        items: List[nodes.definition_list_item] = []
         for terms, definition in entries:
-            termtexts: List[str] = []
             termnodes: List[Node] = []
             system_messages: List[Node] = []
             for line, source, lineno in terms:
@@ -416,7 +423,6 @@
                                           node_id=None, document=self.state.document)
                 term.rawsource = line
                 system_messages.extend(sysmsg)
-                termtexts.append(term.astext())
                 termnodes.append(term)
 
             termnodes.extend(system_messages)
@@ -426,16 +432,10 @@
                 self.state.nested_parse(definition, definition.items[0][1],
                                         defnode)
             termnodes.append(defnode)
-            items.append((termtexts,
-                          nodes.definition_list_item('', *termnodes)))
-
-        if 'sorted' in self.options:
-            items.sort(key=lambda x:
-                       unicodedata.normalize('NFD', x[0][0].lower()))
-
-        dlist = nodes.definition_list()
+            items.append(nodes.definition_list_item('', *termnodes))
+
+        dlist = nodes.definition_list('', *items)
         dlist['classes'].append('glossary')
-        dlist.extend(item[1] for item in items)
         node += dlist
         return messages + [node]
 
@@ -448,7 +448,7 @@
     for m in token_re.finditer(text):
         if m.start() > pos:
             txt = text[pos:m.start()]
-            retnodes.append(nodes.Text(txt, txt))
+            retnodes.append(nodes.Text(txt))
         token = m.group(1)
         if ':' in token:
             if token[0] == '~':
@@ -469,7 +469,7 @@
         retnodes.append(refnode)
         pos = m.end()
     if pos < len(text):
-        retnodes.append(nodes.Text(text[pos:], text[pos:]))
+        retnodes.append(nodes.Text(text[pos:]))
     return retnodes
 
 
@@ -493,12 +493,12 @@
         lines = nl_escape_re.sub('', self.arguments[0]).split('\n')
 
         productionGroup = ""
-        i = 0
+        first_rule_seen = False
         for rule in lines:
-            if i == 0 and ':' not in rule:
+            if not first_rule_seen and ':' not in rule:
                 productionGroup = rule.strip()
                 continue
-            i += 1
+            first_rule_seen = True
             try:
                 name, tokens = rule.split(':', 1)
             except ValueError:
@@ -510,14 +510,6 @@
                 prefix = 'grammar-token-%s' % productionGroup
                 node_id = make_id(self.env, self.state.document, prefix, name)
                 subnode['ids'].append(node_id)
-
-                # Assign old styled node_id not to break old hyperlinks (if possible)
-                # Note: Will be removed in Sphinx-5.0 (RemovedInSphinx50Warning)
-                old_node_id = self.make_old_id(name)
-                if (old_node_id not in self.state.document.ids and
-                        old_node_id not in subnode['ids']):
-                    subnode['ids'].append(old_node_id)
-
                 self.state.document.note_implicit_target(subnode, subnode)
 
                 if len(productionGroup) != 0:
@@ -597,7 +589,7 @@
         'doc':     XRefRole(warn_dangling=True, innernodeclass=nodes.inline),
     }
 
-    initial_data = {
+    initial_data: Final = {
         'progoptions': {},      # (program, name) -> docname, labelid
         'objects': {},          # (type, name) -> docname, labelid
         'labels': {             # labelname -> docname, labelid, sectionname
@@ -613,11 +605,11 @@
     }
 
     dangling_warnings = {
-        'term': 'term not in glossary: %(target)s',
-        'numref':  'undefined label: %(target)s',
-        'keyword': 'unknown keyword: %(target)s',
-        'doc': 'unknown document: %(target)s',
-        'option': 'unknown option: %(target)s',
+        'term': 'term not in glossary: %(target)r',
+        'numref':  'undefined label: %(target)r',
+        'keyword': 'unknown keyword: %(target)r',
+        'doc': 'unknown document: %(target)r',
+        'option': 'unknown option: %(target)r',
     }
 
     # node_class -> (figtype, title_getter)
@@ -674,11 +666,6 @@
             logger.warning(__('duplicate %s description of %s, other instance in %s'),
                            objtype, name, docname, location=location)
         self.objects[objtype, name] = (self.env.docname, labelid)
-
-    def add_object(self, objtype: str, name: str, docname: str, labelid: str) -> None:
-        warnings.warn('StandardDomain.add_object() is deprecated.',
-                      RemovedInSphinx50Warning, stacklevel=2)
-        self.objects[objtype, name] = (docname, labelid)
 
     @property
     def _terms(self) -> Dict[str, Tuple[str, str]]:
@@ -775,12 +762,21 @@
                 if not sectname:
                     continue
             else:
-                toctree = next(iter(node.traverse(addnodes.toctree)), None)
-                if toctree and toctree.get('caption'):
-                    sectname = toctree.get('caption')
+                if (isinstance(node, (nodes.definition_list,
+                                      nodes.field_list)) and
+                        node.children):
+                    node = cast(nodes.Element, node.children[0])
+                if isinstance(node, (nodes.field, nodes.definition_list_item)):
+                    node = cast(nodes.Element, node.children[0])
+                if isinstance(node, (nodes.term, nodes.field_name)):
+                    sectname = clean_astext(node)
                 else:
-                    # anonymous-only labels
-                    continue
+                    toctree = next(node.findall(addnodes.toctree), None)
+                    if toctree and toctree.get('caption'):
+                        sectname = toctree.get('caption')
+                    else:
+                        # anonymous-only labels
+                        continue
             self.labels[name] = docname, labelid, sectname
 
     def add_program_option(self, program: str, name: str, docname: str, labelid: str) -> None:
@@ -1076,7 +1072,7 @@
                       figtype: str, docname: str, target_node: Element) -> Tuple[int, ...]:
         if figtype == 'section':
             if builder.name == 'latex':
-                return tuple()
+                return ()
             elif docname not in env.toc_secnumbers:
                 raise ValueError  # no number assigned
             else:
@@ -1117,9 +1113,9 @@
     else:
         target = node['reftarget']
         if target not in domain.anonlabels:  # type: ignore
-            msg = __('undefined label: %s')
-        else:
-            msg = __('Failed to create a cross reference. A title or caption not found: %s')
+            msg = __('undefined label: %r')
+        else:
+            msg = __('Failed to create a cross reference. A title or caption not found: %r')
 
         logger.warning(msg % target, location=node, type='ref', subtype=node['reftype'])
         return True
('sphinx/domains', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,7 @@
-"""
-    sphinx.domains
-    ~~~~~~~~~~~~~~
-
-    Support for domains, which are groupings of description directives
-    and roles describing e.g. constructs of one programming language.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
+"""Support for domains.
+
+Domains are groupings of description directives
+and roles describing e.g. constructs of one programming language.
 """
 
 import copy
('sphinx/domains', 'changeset.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.domains.changeset
-    ~~~~~~~~~~~~~~~~~~~~~~~~
-
-    The changeset domain.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""The changeset domain."""
 
 from typing import TYPE_CHECKING, Any, Dict, List, NamedTuple, cast
 
@@ -84,7 +76,7 @@
                 content += node[0].children
                 node[0].replace_self(nodes.paragraph('', '', content, translatable=False))
 
-            para = cast(nodes.paragraph, node[0])
+            para = node[0]
             para.insert(0, nodes.inline('', '%s: ' % text, classes=classes))
         elif len(node) > 0:
             # the contents do not starts with a paragraph
@@ -130,7 +122,7 @@
         self.changesets.setdefault(version, []).append(changeset)
 
     def clear_doc(self, docname: str) -> None:
-        for version, changes in self.changesets.items():
+        for changes in self.changesets.values():
             for changeset in changes[:]:
                 if changeset.docname == docname:
                     changes.remove(changeset)
('sphinx/domains', 'cpp.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,16 +1,8 @@
-"""
-    sphinx.domains.cpp
-    ~~~~~~~~~~~~~~~~~~
-
-    The C++ language domain.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""The C++ language domain."""
 
 import re
 from typing import (Any, Callable, Dict, Generator, Iterator, List, Optional, Tuple, TypeVar,
-                    Union, cast)
+                    Union)
 
 from docutils import nodes
 from docutils.nodes import Element, Node, TextElement, system_message
@@ -29,8 +21,8 @@
 from sphinx.transforms import SphinxTransform
 from sphinx.transforms.post_transforms import ReferencesResolver
 from sphinx.util import logging
-from sphinx.util.cfamily import (ASTAttribute, ASTBaseBase, ASTBaseParenExprList, BaseParser,
-                                 DefinitionError, NoOldIdError, StringifyTransform,
+from sphinx.util.cfamily import (ASTAttributeList, ASTBaseBase, ASTBaseParenExprList,
+                                 BaseParser, DefinitionError, NoOldIdError, StringifyTransform,
                                  UnsupportedMultiCharacterCharLiteral, anon_identifier_re,
                                  binary_literal_re, char_literal_re, float_literal_re,
                                  float_literal_suffix_re, hex_literal_re, identifier_re,
@@ -267,7 +259,8 @@
     class_object:
         goal: a class declaration, but with specification of a base class
         grammar:
-              nested-name "final"[opt] (":" base-specifier-list)[opt]
+              attribute-specifier-seq[opt]
+                  nested-name "final"[opt] (":" base-specifier-list)[opt]
             base-specifier-list ->
               base-specifier "..."[opt]
             | base-specifier-list, base-specifier "..."[opt]
@@ -281,7 +274,8 @@
         goal: an unscoped enum or a scoped enum, optionally with the underlying
               type specified
         grammar:
-            ("class" | "struct")[opt] visibility[opt] nested-name (":" type)[opt]
+            ("class" | "struct")[opt] visibility[opt]
+                attribute-specifier-seq[opt] nested-name (":" type)[opt]
     enumerator_object:
         goal: an element in a scoped or unscoped enum. The name should be
               injected according to the scopedness.
@@ -335,27 +329,17 @@
 ]
 
 
-_simple_type_sepcifiers_re = re.compile(r"""(?x)
+_simple_type_specifiers_re = re.compile(r"""(?x)
     \b(
     auto|void|bool
-    # Integer
-    # -------
-    |((signed|unsigned)\s+)?(char|__int128|(
-        ((long\s+long|long|short)\s+)?int
-    ))
-    |wchar_t|char(8|16|32)_t
-    # extensions
-    |((signed|unsigned)\s+)?__int(64|128)
-    # Floating-point
-    # --------------
-    |(float|double|long\s+double)(\s+(_Complex|_Imaginary))?
-    |(_Complex|_Imaginary)\s+(float|double|long\s+double)
-    # extensions
-    |__float80|_Float64x|__float128|_Float128
-    # Integer types that could be prefixes of the previous ones
-    # ---------------------------------------------------------
-    |((signed|unsigned)\s+)?(long\s+long|long|short)
     |signed|unsigned
+    |short|long
+    |char|wchar_t|char(8|16|32)_t
+    |int
+    |__int(64|128)  # extension
+    |float|double
+    |__float80|_Float64x|__float128|_Float128  # extension
+    |_Complex|_Imaginary  # extension
     )\b
 """)
 
@@ -485,12 +469,12 @@
     'long double': 'e',
     '__float80': 'e', '_Float64x': 'e',
     '__float128': 'g', '_Float128': 'g',
-    'float _Complex': 'Cf', '_Complex float': 'Cf',
-    'double _Complex': 'Cd', '_Complex double': 'Cd',
-    'long double _Complex': 'Ce', '_Complex long double': 'Ce',
-    'float _Imaginary': 'f', '_Imaginary float': 'f',
-    'double _Imaginary': 'd', '_Imaginary double': 'd',
-    'long double _Imaginary': 'e', '_Imaginary long double': 'e',
+    '_Complex float': 'Cf',
+    '_Complex double': 'Cd',
+    '_Complex long double': 'Ce',
+    '_Imaginary float': 'f',
+    '_Imaginary double': 'd',
+    '_Imaginary long double': 'e',
     'auto': 'Da',
     'decltype(auto)': 'Dc',
     'std::nullptr_t': 'Dn'
@@ -545,7 +529,8 @@
     '->': 'pt',
     '()': 'cl',
     '[]': 'ix',
-    '.*': 'ds'  # this one is not overloadable, but we need it for expressions
+    '.*': 'ds',  # this one is not overloadable, but we need it for expressions
+    '?': 'qu',
 }
 _id_operator_unary_v2 = {
     '++': 'pp_',
@@ -769,15 +754,15 @@
         # just print the name part, with template args, not template params
         if mode == 'noneIsName':
             if self.rooted:
-                assert False, "Can this happen?"  # TODO
+                raise AssertionError("Can this happen?")  # TODO
                 signode += nodes.Text('::')
             for i in range(len(self.names)):
                 if i != 0:
-                    assert False, "Can this happen?"  # TODO
+                    raise AssertionError("Can this happen?")  # TODO
                     signode += nodes.Text('::blah')
                 n = self.names[i]
                 if self.templates[i]:
-                    assert False, "Can this happen?"  # TODO
+                    raise AssertionError("Can this happen?")  # TODO
                     signode += nodes.Text("template")
                     signode += nodes.Text(" ")
                 n.describe_signature(signode, mode, env, '', symbol)
@@ -786,7 +771,7 @@
             assert len(self.names) == 1
             assert not self.templates[0]
             self.names[0].describe_signature(signode, 'param', env, '', symbol)
-        elif mode == 'markType' or mode == 'lastIsName' or mode == 'markName':
+        elif mode in ('markType', 'lastIsName', 'markName'):
             # Each element should be a pending xref targeting the complete
             # prefix. however, only the identifier part should be a link, such
             # that template args can be a link as well.
@@ -1401,7 +1386,7 @@
         if self.isNewTypeId:
             res.append(transform(self.typ))
         else:
-            assert False
+            raise AssertionError()
         if self.initList is not None:
             res.append(transform(self.initList))
         return ''.join(res)
@@ -1428,7 +1413,7 @@
         if self.isNewTypeId:
             self.typ.describe_signature(signode, mode, env, symbol)
         else:
-            assert False
+            raise AssertionError()
         if self.initList is not None:
             self.initList.describe_signature(signode, mode, env, symbol)
 
@@ -1532,6 +1517,44 @@
                 signode += addnodes.desc_sig_operator(op, op)
             signode += addnodes.desc_sig_space()
             self.exprs[i].describe_signature(signode, mode, env, symbol)
+
+
+class ASTConditionalExpr(ASTExpression):
+    def __init__(self, ifExpr: ASTExpression, thenExpr: ASTExpression,
+                 elseExpr: ASTExpression):
+        self.ifExpr = ifExpr
+        self.thenExpr = thenExpr
+        self.elseExpr = elseExpr
+
+    def _stringify(self, transform: StringifyTransform) -> str:
+        res = []
+        res.append(transform(self.ifExpr))
+        res.append(' ? ')
+        res.append(transform(self.thenExpr))
+        res.append(' : ')
+        res.append(transform(self.elseExpr))
+        return ''.join(res)
+
+    def get_id(self, version: int) -> str:
+        assert version >= 2
+        res = []
+        res.append(_id_operator_v2['?'])
+        res.append(self.ifExpr.get_id(version))
+        res.append(self.thenExpr.get_id(version))
+        res.append(self.elseExpr.get_id(version))
+        return ''.join(res)
+
+    def describe_signature(self, signode: TextElement, mode: str,
+                           env: "BuildEnvironment", symbol: "Symbol") -> None:
+        self.ifExpr.describe_signature(signode, mode, env, symbol)
+        signode += addnodes.desc_sig_space()
+        signode += addnodes.desc_sig_operator('?', '?')
+        signode += addnodes.desc_sig_space()
+        self.thenExpr.describe_signature(signode, mode, env, symbol)
+        signode += addnodes.desc_sig_space()
+        signode += addnodes.desc_sig_operator(':', ':')
+        signode += addnodes.desc_sig_space()
+        self.elseExpr.describe_signature(signode, mode, env, symbol)
 
 
 class ASTBracedInitList(ASTBase):
@@ -1566,42 +1589,39 @@
 
 
 class ASTAssignmentExpr(ASTExpression):
-    def __init__(self, exprs: List[Union[ASTExpression, ASTBracedInitList]], ops: List[str]):
-        assert len(exprs) > 0
-        assert len(exprs) == len(ops) + 1
-        self.exprs = exprs
-        self.ops = ops
+    def __init__(self, leftExpr: ASTExpression, op: str,
+                 rightExpr: Union[ASTExpression, ASTBracedInitList]):
+        self.leftExpr = leftExpr
+        self.op = op
+        self.rightExpr = rightExpr
 
     def _stringify(self, transform: StringifyTransform) -> str:
         res = []
-        res.append(transform(self.exprs[0]))
-        for i in range(1, len(self.exprs)):
-            res.append(' ')
-            res.append(self.ops[i - 1])
-            res.append(' ')
-            res.append(transform(self.exprs[i]))
+        res.append(transform(self.leftExpr))
+        res.append(' ')
+        res.append(self.op)
+        res.append(' ')
+        res.append(transform(self.rightExpr))
         return ''.join(res)
 
     def get_id(self, version: int) -> str:
+        # we end up generating the ID from left to right, instead of right to left
         res = []
-        for i in range(len(self.ops)):
-            res.append(_id_operator_v2[self.ops[i]])
-            res.append(self.exprs[i].get_id(version))
-        res.append(self.exprs[-1].get_id(version))
+        res.append(_id_operator_v2[self.op])
+        res.append(self.leftExpr.get_id(version))
+        res.append(self.rightExpr.get_id(version))
         return ''.join(res)
 
     def describe_signature(self, signode: TextElement, mode: str,
                            env: "BuildEnvironment", symbol: "Symbol") -> None:
-        self.exprs[0].describe_signature(signode, mode, env, symbol)
-        for i in range(1, len(self.exprs)):
-            signode += addnodes.desc_sig_space()
-            op = self.ops[i - 1]
-            if ord(op[0]) >= ord('a') and ord(op[0]) <= ord('z'):
-                signode += addnodes.desc_sig_keyword(op, op)
-            else:
-                signode += addnodes.desc_sig_operator(op, op)
-            signode += addnodes.desc_sig_space()
-            self.exprs[i].describe_signature(signode, mode, env, symbol)
+        self.leftExpr.describe_signature(signode, mode, env, symbol)
+        signode += addnodes.desc_sig_space()
+        if ord(self.op[0]) >= ord('a') and ord(self.op[0]) <= ord('z'):
+            signode += addnodes.desc_sig_keyword(self.op, self.op)
+        else:
+            signode += addnodes.desc_sig_operator(self.op, self.op)
+        signode += addnodes.desc_sig_space()
+        self.rightExpr.describe_signature(signode, mode, env, symbol)
 
 
 class ASTCommaExpr(ASTExpression):
@@ -1853,8 +1873,12 @@
 
 
 class ASTTrailingTypeSpecFundamental(ASTTrailingTypeSpec):
-    def __init__(self, name: str) -> None:
-        self.names = name.split()
+    def __init__(self, names: List[str], canonNames: List[str]) -> None:
+        assert len(names) != 0
+        assert len(names) == len(canonNames), (names, canonNames)
+        self.names = names
+        # the canonical name list is for ID lookup
+        self.canonNames = canonNames
 
     def _stringify(self, transform: StringifyTransform) -> str:
         return ' '.join(self.names)
@@ -1862,14 +1886,14 @@
     def get_id(self, version: int) -> str:
         if version == 1:
             res = []
-            for a in self.names:
+            for a in self.canonNames:
                 if a in _id_fundamental_v1:
                     res.append(_id_fundamental_v1[a])
                 else:
                     res.append(a)
             return '-'.join(res)
 
-        txt = str(self)
+        txt = ' '.join(self.canonNames)
         if txt not in _id_fundamental_v2:
             raise Exception(
                 'Semi-internal error: Fundamental type "%s" can not be mapped '
@@ -1966,7 +1990,7 @@
                 signode += addnodes.desc_sig_keyword('auto', 'auto')
                 signode += addnodes.desc_sig_punctuation(')', ')')
             else:
-                assert False, self.placeholderType
+                raise AssertionError(self.placeholderType)
 
 
 class ASTFunctionParameter(ASTBase):
@@ -2024,7 +2048,7 @@
     def __init__(self, args: List[ASTFunctionParameter], volatile: bool, const: bool,
                  refQual: Optional[str], exceptionSpec: ASTNoexceptSpec,
                  trailingReturn: "ASTType",
-                 override: bool, final: bool, attrs: List[ASTAttribute],
+                 override: bool, final: bool, attrs: ASTAttributeList,
                  initializer: Optional[str]) -> None:
         self.args = args
         self.volatile = volatile
@@ -2094,9 +2118,9 @@
             res.append(' final')
         if self.override:
             res.append(' override')
-        for attr in self.attrs:
+        if len(self.attrs) != 0:
             res.append(' ')
-            res.append(transform(attr))
+            res.append(transform(self.attrs))
         if self.initializer:
             res.append(' = ')
             res.append(self.initializer)
@@ -2147,9 +2171,9 @@
             _add_anno(signode, 'final')
         if self.override:
             _add_anno(signode, 'override')
-        for attr in self.attrs:
+        if len(self.attrs) != 0:
             signode += addnodes.desc_sig_space()
-            attr.describe_signature(signode)
+            self.attrs.describe_signature(signode)
         if self.initializer:
             signode += addnodes.desc_sig_space()
             signode += addnodes.desc_sig_punctuation('=', '=')
@@ -2187,7 +2211,7 @@
                  explicitSpec: Optional[ASTExplicitSpec],
                  consteval: bool, constexpr: bool, constinit: bool,
                  volatile: bool, const: bool, friend: bool,
-                 attrs: List[ASTAttribute]) -> None:
+                 attrs: ASTAttributeList) -> None:
         self.storage = storage
         self.threadLocal = threadLocal
         self.inline = inline
@@ -2219,7 +2243,8 @@
 
     def _stringify(self, transform: StringifyTransform) -> str:
         res: List[str] = []
-        res.extend(transform(attr) for attr in self.attrs)
+        if len(self.attrs) != 0:
+            res.append(transform(self.attrs))
         if self.storage:
             res.append(self.storage)
         if self.threadLocal:
@@ -2246,12 +2271,8 @@
 
     def describe_signature(self, signode: TextElement,
                            env: "BuildEnvironment", symbol: "Symbol") -> None:
-        addSpace = False
-        for attr in self.attrs:
-            if addSpace:
-                signode += addnodes.desc_sig_space()
-            addSpace = True
-            attr.describe_signature(signode)
+        self.attrs.describe_signature(signode)
+        addSpace = len(self.attrs) != 0
 
         def _add(signode: TextElement, text: str) -> bool:
             if addSpace:
@@ -2568,7 +2589,7 @@
 
 class ASTDeclaratorPtr(ASTDeclarator):
     def __init__(self, next: ASTDeclarator, volatile: bool, const: bool,
-                 attrs: List[ASTAttribute]) -> None:
+                 attrs: ASTAttributeList) -> None:
         assert next
         self.next = next
         self.volatile = volatile
@@ -2584,6 +2605,10 @@
         self.next.name = name
 
     @property
+    def isPack(self) -> bool:
+        return self.next.isPack
+
+    @property
     def function_params(self) -> List[ASTFunctionParameter]:
         return self.next.function_params
 
@@ -2596,9 +2621,8 @@
 
     def _stringify(self, transform: StringifyTransform) -> str:
         res = ['*']
-        for a in self.attrs:
-            res.append(transform(a))
-        if len(self.attrs) > 0 and (self.volatile or self.const):
+        res.append(transform(self.attrs))
+        if len(self.attrs) != 0 and (self.volatile or self.const):
             res.append(' ')
         if self.volatile:
             res.append('volatile')
@@ -2653,9 +2677,8 @@
                            env: "BuildEnvironment", symbol: "Symbol") -> None:
         verify_description_mode(mode)
         signode += addnodes.desc_sig_punctuation('*', '*')
-        for a in self.attrs:
-            a.describe_signature(signode)
-        if len(self.attrs) > 0 and (self.volatile or self.const):
+        self.attrs.describe_signature(signode)
+        if len(self.attrs) != 0 and (self.volatile or self.const):
             signode += addnodes.desc_sig_space()
 
         def _add_anno(signode: TextElement, text: str) -> None:
@@ -2673,7 +2696,7 @@
 
 
 class ASTDeclaratorRef(ASTDeclarator):
-    def __init__(self, next: ASTDeclarator, attrs: List[ASTAttribute]) -> None:
+    def __init__(self, next: ASTDeclarator, attrs: ASTAttributeList) -> None:
         assert next
         self.next = next
         self.attrs = attrs
@@ -2688,7 +2711,7 @@
 
     @property
     def isPack(self) -> bool:
-        return True
+        return self.next.isPack
 
     @property
     def function_params(self) -> List[ASTFunctionParameter]:
@@ -2703,9 +2726,8 @@
 
     def _stringify(self, transform: StringifyTransform) -> str:
         res = ['&']
-        for a in self.attrs:
-            res.append(transform(a))
-        if len(self.attrs) > 0 and self.next.require_space_after_declSpecs():
+        res.append(transform(self.attrs))
+        if len(self.attrs) != 0 and self.next.require_space_after_declSpecs():
             res.append(' ')
         res.append(transform(self.next))
         return ''.join(res)
@@ -2734,8 +2756,7 @@
                            env: "BuildEnvironment", symbol: "Symbol") -> None:
         verify_description_mode(mode)
         signode += addnodes.desc_sig_punctuation('&', '&')
-        for a in self.attrs:
-            a.describe_signature(signode)
+        self.attrs.describe_signature(signode)
         if len(self.attrs) > 0 and self.next.require_space_after_declSpecs():
             signode += addnodes.desc_sig_space()
         self.next.describe_signature(signode, mode, env, symbol)
@@ -2761,6 +2782,10 @@
     @property
     def trailingReturn(self) -> "ASTType":
         return self.next.trailingReturn
+
+    @property
+    def isPack(self) -> bool:
+        return True
 
     def require_space_after_declSpecs(self) -> bool:
         return False
@@ -2817,6 +2842,10 @@
     @name.setter
     def name(self, name: ASTNestedName) -> None:
         self.next.name = name
+
+    @property
+    def isPack(self):
+        return self.next.isPack
 
     @property
     def function_params(self) -> List[ASTFunctionParameter]:
@@ -2914,6 +2943,10 @@
     @name.setter
     def name(self, name: ASTNestedName) -> None:
         self.inner.name = name
+
+    @property
+    def isPack(self):
+        return self.inner.isPack or self.next.isPack
 
     @property
     def function_params(self) -> List[ASTFunctionParameter]:
@@ -3078,8 +3111,7 @@
                 elif objectType == 'type':  # just the name
                     res.append(symbol.get_full_nested_name().get_id(version))
                 else:
-                    print(objectType)
-                    assert False
+                    raise AssertionError(objectType)
             else:  # only type encoding
                 if self.decl.is_function_type():
                     raise NoOldIdError()
@@ -3108,8 +3140,7 @@
             elif objectType == 'type':  # just the name
                 res.append(symbol.get_full_nested_name().get_id(version))
             else:
-                print(objectType)
-                assert False
+                raise AssertionError(objectType)
         else:  # only type encoding
             # the 'returnType' of a non-function type is simply just the last
             # type, i.e., for 'int*' it is 'int'
@@ -3324,16 +3355,21 @@
 
 
 class ASTClass(ASTBase):
-    def __init__(self, name: ASTNestedName, final: bool, bases: List[ASTBaseClass]) -> None:
+    def __init__(self, name: ASTNestedName, final: bool, bases: List[ASTBaseClass],
+                 attrs: ASTAttributeList) -> None:
         self.name = name
         self.final = final
         self.bases = bases
+        self.attrs = attrs
 
     def get_id(self, version: int, objectType: str, symbol: "Symbol") -> str:
         return symbol.get_full_nested_name().get_id(version)
 
     def _stringify(self, transform: StringifyTransform) -> str:
         res = []
+        res.append(transform(self.attrs))
+        if len(self.attrs) != 0:
+            res.append(' ')
         res.append(transform(self.name))
         if self.final:
             res.append(' final')
@@ -3350,6 +3386,9 @@
     def describe_signature(self, signode: TextElement, mode: str,
                            env: "BuildEnvironment", symbol: "Symbol") -> None:
         verify_description_mode(mode)
+        self.attrs.describe_signature(signode)
+        if len(self.attrs) != 0:
+            signode += addnodes.desc_sig_space()
         self.name.describe_signature(signode, mode, env, symbol=symbol)
         if self.final:
             signode += addnodes.desc_sig_space()
@@ -3367,8 +3406,9 @@
 
 
 class ASTUnion(ASTBase):
-    def __init__(self, name: ASTNestedName) -> None:
+    def __init__(self, name: ASTNestedName, attrs: ASTAttributeList) -> None:
         self.name = name
+        self.attrs = attrs
 
     def get_id(self, version: int, objectType: str, symbol: "Symbol") -> str:
         if version == 1:
@@ -3376,20 +3416,29 @@
         return symbol.get_full_nested_name().get_id(version)
 
     def _stringify(self, transform: StringifyTransform) -> str:
-        return transform(self.name)
+        res = []
+        res.append(transform(self.attrs))
+        if len(self.attrs) != 0:
+            res.append(' ')
+        res.append(transform(self.name))
+        return ''.join(res)
 
     def describe_signature(self, signode: TextElement, mode: str,
                            env: "BuildEnvironment", symbol: "Symbol") -> None:
         verify_description_mode(mode)
+        self.attrs.describe_signature(signode)
+        if len(self.attrs) != 0:
+            signode += addnodes.desc_sig_space()
         self.name.describe_signature(signode, mode, env, symbol=symbol)
 
 
 class ASTEnum(ASTBase):
-    def __init__(self, name: ASTNestedName, scoped: str,
-                 underlyingType: ASTType) -> None:
+    def __init__(self, name: ASTNestedName, scoped: str, underlyingType: ASTType,
+                 attrs: ASTAttributeList) -> None:
         self.name = name
         self.scoped = scoped
         self.underlyingType = underlyingType
+        self.attrs = attrs
 
     def get_id(self, version: int, objectType: str, symbol: "Symbol") -> str:
         if version == 1:
@@ -3400,6 +3449,9 @@
         res = []
         if self.scoped:
             res.append(self.scoped)
+            res.append(' ')
+        res.append(transform(self.attrs))
+        if len(self.attrs) != 0:
             res.append(' ')
         res.append(transform(self.name))
         if self.underlyingType:
@@ -3411,6 +3463,9 @@
                            env: "BuildEnvironment", symbol: "Symbol") -> None:
         verify_description_mode(mode)
         # self.scoped has been done by the CPPEnumObject
+        self.attrs.describe_signature(signode)
+        if len(self.attrs) != 0:
+            signode += addnodes.desc_sig_space()
         self.name.describe_signature(signode, mode, env, symbol=symbol)
         if self.underlyingType:
             signode += addnodes.desc_sig_space()
@@ -3421,9 +3476,11 @@
 
 
 class ASTEnumerator(ASTBase):
-    def __init__(self, name: ASTNestedName, init: ASTInitializer) -> None:
+    def __init__(self, name: ASTNestedName, init: Optional[ASTInitializer],
+                 attrs: ASTAttributeList) -> None:
         self.name = name
         self.init = init
+        self.attrs = attrs
 
     def get_id(self, version: int, objectType: str, symbol: "Symbol") -> str:
         if version == 1:
@@ -3433,6 +3490,9 @@
     def _stringify(self, transform: StringifyTransform) -> str:
         res = []
         res.append(transform(self.name))
+        if len(self.attrs) != 0:
+            res.append(' ')
+            res.append(transform(self.attrs))
         if self.init:
             res.append(transform(self.init))
         return ''.join(res)
@@ -3441,6 +3501,9 @@
                            env: "BuildEnvironment", symbol: "Symbol") -> None:
         verify_description_mode(mode)
         self.name.describe_signature(signode, mode, env, symbol)
+        if len(self.attrs) != 0:
+            signode += addnodes.desc_sig_space()
+            self.attrs.describe_signature(signode)
         if self.init:
             self.init.describe_signature(signode, 'markType', env, symbol)
 
@@ -3461,6 +3524,14 @@
 
     def describe_signature(self, parentNode: TextElement, mode: str,
                            env: "BuildEnvironment", symbol: "Symbol") -> None:
+        raise NotImplementedError(repr(self))
+
+    @property
+    def isPack(self) -> bool:
+        raise NotImplementedError(repr(self))
+
+    @property
+    def name(self) -> ASTNestedName:
         raise NotImplementedError(repr(self))
 
 
@@ -3575,7 +3646,9 @@
     def get_identifier(self) -> ASTIdentifier:
         return self.data.get_identifier()
 
-    def get_id(self, version: int, objectType: str = None, symbol: "Symbol" = None) -> str:
+    def get_id(
+        self, version: int, objectType: Optional[str] = None, symbol: Optional["Symbol"] = None
+    ) -> str:
         assert version >= 2
         # this is not part of the normal name mangling in C++
         if symbol:
@@ -3597,9 +3670,11 @@
 class ASTTemplateParamNonType(ASTTemplateParam):
     def __init__(self,
                  param: Union[ASTTypeWithInit,
-                              ASTTemplateParamConstrainedTypeWithInit]) -> None:
+                              ASTTemplateParamConstrainedTypeWithInit],
+                 parameterPack: bool = False) -> None:
         assert param
         self.param = param
+        self.parameterPack = parameterPack
 
     @property
     def name(self) -> ASTNestedName:
@@ -3608,7 +3683,7 @@
 
     @property
     def isPack(self) -> bool:
-        return self.param.isPack
+        return self.param.isPack or self.parameterPack
 
     def get_identifier(self) -> ASTIdentifier:
         name = self.param.name
@@ -3629,28 +3704,42 @@
             # the anchor will be our parent
             return symbol.parent.declaration.get_id(version, prefixed=None)
         else:
-            return '_' + self.param.get_id(version)
-
-    def _stringify(self, transform: StringifyTransform) -> str:
-        return transform(self.param)
+            res = '_'
+            if self.parameterPack:
+                res += 'Dp'
+            return res + self.param.get_id(version)
+
+    def _stringify(self, transform: StringifyTransform) -> str:
+        res = transform(self.param)
+        if self.parameterPack:
+            res += '...'
+        return res
 
     def describe_signature(self, signode: TextElement, mode: str,
                            env: "BuildEnvironment", symbol: "Symbol") -> None:
         self.param.describe_signature(signode, mode, env, symbol)
+        if self.parameterPack:
+            signode += addnodes.desc_sig_punctuation('...', '...')
 
 
 class ASTTemplateParams(ASTBase):
-    def __init__(self, params: List[ASTTemplateParam]) -> None:
+    def __init__(self, params: List[ASTTemplateParam],
+                 requiresClause: Optional["ASTRequiresClause"]) -> None:
         assert params is not None
         self.params = params
-
-    def get_id(self, version: int) -> str:
+        self.requiresClause = requiresClause
+
+    def get_id(self, version: int, excludeRequires: bool = False) -> str:
         assert version >= 2
         res = []
         res.append("I")
         for param in self.params:
             res.append(param.get_id(version))
         res.append("E")
+        if not excludeRequires and self.requiresClause:
+            res.append('IQ')
+            res.append(self.requiresClause.expr.get_id(version))
+            res.append('E')
         return ''.join(res)
 
     def _stringify(self, transform: StringifyTransform) -> str:
@@ -3658,6 +3747,9 @@
         res.append("template<")
         res.append(", ".join(transform(a) for a in self.params))
         res.append("> ")
+        if self.requiresClause is not None:
+            res.append(transform(self.requiresClause))
+            res.append(" ")
         return ''.join(res)
 
     def describe_signature(self, signode: TextElement, mode: str,
@@ -3672,6 +3764,9 @@
             first = False
             param.describe_signature(signode, mode, env, symbol)
         signode += addnodes.desc_sig_punctuation('>', '>')
+        if self.requiresClause is not None:
+            signode += addnodes.desc_sig_space()
+            self.requiresClause.describe_signature(signode, mode, env, symbol)
 
     def describe_signature_as_introducer(
             self, parentNode: desc_signature, mode: str, env: "BuildEnvironment",
@@ -3696,6 +3791,11 @@
         if lineSpec and not first:
             lineNode = makeLine(parentNode)
         lineNode += addnodes.desc_sig_punctuation('>', '>')
+        if self.requiresClause:
+            reqNode = addnodes.desc_signature_line()
+            reqNode.sphinx_line_type = 'requiresClause'
+            parentNode += reqNode
+            self.requiresClause.describe_signature(reqNode, 'markType', env, symbol)
 
 
 # Template introducers
@@ -3814,12 +3914,24 @@
         # templates is None means it's an explicit instantiation of a variable
         self.templates = templates
 
-    def get_id(self, version: int) -> str:
+    def get_requires_clause_in_last(self) -> Optional["ASTRequiresClause"]:
+        if self.templates is None:
+            return None
+        lastList = self.templates[-1]
+        if not isinstance(lastList, ASTTemplateParams):
+            return None
+        return lastList.requiresClause  # which may be None
+
+    def get_id_except_requires_clause_in_last(self, version: int) -> str:
         assert version >= 2
-        # this is not part of a normal name mangling system
+        # This is not part of the Itanium ABI mangling system.
         res = []
-        for t in self.templates:
-            res.append(t.get_id(version))
+        lastIndex = len(self.templates) - 1
+        for i, t in enumerate(self.templates):
+            if isinstance(t, ASTTemplateParams):
+                res.append(t.get_id(version, excludeRequires=(i == lastIndex)))
+            else:
+                res.append(t.get_id(version))
         return ''.join(res)
 
     def _stringify(self, transform: StringifyTransform) -> str:
@@ -3842,7 +3954,7 @@
     def _stringify(self, transform: StringifyTransform) -> str:
         return 'requires ' + transform(self.expr)
 
-    def describe_signature(self, signode: addnodes.desc_signature_line, mode: str,
+    def describe_signature(self, signode: nodes.TextElement, mode: str,
                            env: "BuildEnvironment", symbol: "Symbol") -> None:
         signode += addnodes.desc_sig_keyword('requires', 'requires')
         signode += addnodes.desc_sig_space()
@@ -3853,16 +3965,16 @@
 ################################################################################
 
 class ASTDeclaration(ASTBase):
-    def __init__(self, objectType: str, directiveType: str, visibility: str,
-                 templatePrefix: ASTTemplateDeclarationPrefix,
-                 requiresClause: ASTRequiresClause, declaration: Any,
-                 trailingRequiresClause: ASTRequiresClause,
+    def __init__(self, objectType: str, directiveType: Optional[str] = None,
+                 visibility: Optional[str] = None,
+                 templatePrefix: Optional[ASTTemplateDeclarationPrefix] = None,
+                 declaration: Any = None,
+                 trailingRequiresClause: Optional[ASTRequiresClause] = None,
                  semicolon: bool = False) -> None:
         self.objectType = objectType
         self.directiveType = directiveType
         self.visibility = visibility
         self.templatePrefix = templatePrefix
-        self.requiresClause = requiresClause
         self.declaration = declaration
         self.trailingRequiresClause = trailingRequiresClause
         self.semicolon = semicolon
@@ -3873,11 +3985,10 @@
 
     def clone(self) -> "ASTDeclaration":
         templatePrefixClone = self.templatePrefix.clone() if self.templatePrefix else None
-        requiresClasueClone = self.requiresClause.clone() if self.requiresClause else None
         trailingRequiresClasueClone = self.trailingRequiresClause.clone() \
             if self.trailingRequiresClause else None
         return ASTDeclaration(self.objectType, self.directiveType, self.visibility,
-                              templatePrefixClone, requiresClasueClone,
+                              templatePrefixClone,
                               self.declaration.clone(), trailingRequiresClasueClone,
                               self.semicolon)
 
@@ -3893,7 +4004,7 @@
 
     def get_id(self, version: int, prefixed: bool = True) -> str:
         if version == 1:
-            if self.templatePrefix:
+            if self.templatePrefix or self.trailingRequiresClause:
                 raise NoOldIdError()
             if self.objectType == 'enumerator' and self.enumeratorScopedSymbol:
                 return self.enumeratorScopedSymbol.declaration.get_id(version)
@@ -3905,16 +4016,31 @@
             res = [_id_prefix[version]]
         else:
             res = []
-        if self.templatePrefix:
-            res.append(self.templatePrefix.get_id(version))
-        if self.requiresClause or self.trailingRequiresClause:
+        # (See also https://github.com/sphinx-doc/sphinx/pull/10286#issuecomment-1168102147)
+        # The first implementation of requires clauses only supported a single clause after the
+        # template prefix, and no trailing clause. It put the ID after the template parameter
+        # list, i.e.,
+        #    "I" + template_parameter_list_id + "E" + "IQ" + requires_clause_id + "E"
+        # but the second implementation associates the requires clause with each list, i.e.,
+        #    "I" + template_parameter_list_id + "IQ" + requires_clause_id + "E" + "E"
+        # To avoid making a new ID version, we make an exception for the last requires clause
+        # in the template prefix, and still put it in the end.
+        # As we now support trailing requires clauses we add that as if it was a conjunction.
+        if self.templatePrefix is not None:
+            res.append(self.templatePrefix.get_id_except_requires_clause_in_last(version))
+            requiresClauseInLast = self.templatePrefix.get_requires_clause_in_last()
+        else:
+            requiresClauseInLast = None
+
+        if requiresClauseInLast or self.trailingRequiresClause:
             if version < 4:
                 raise NoOldIdError()
             res.append('IQ')
-            if self.requiresClause and self.trailingRequiresClause:
+            if requiresClauseInLast and self.trailingRequiresClause:
+                # make a conjunction of them
                 res.append('aa')
-            if self.requiresClause:
-                res.append(self.requiresClause.expr.get_id(version))
+            if requiresClauseInLast:
+                res.append(requiresClauseInLast.expr.get_id(version))
             if self.trailingRequiresClause:
                 res.append(self.trailingRequiresClause.expr.get_id(version))
             res.append('E')
@@ -3931,9 +4057,6 @@
             res.append(' ')
         if self.templatePrefix:
             res.append(transform(self.templatePrefix))
-        if self.requiresClause:
-            res.append(transform(self.requiresClause))
-            res.append(' ')
         res.append(transform(self.declaration))
         if self.trailingRequiresClause:
             res.append(' ')
@@ -3958,11 +4081,6 @@
             self.templatePrefix.describe_signature(signode, mode, env,
                                                    symbol=self.symbol,
                                                    lineSpec=options.get('tparam-line-spec'))
-        if self.requiresClause:
-            reqNode = addnodes.desc_signature_line()
-            reqNode.sphinx_line_type = 'requiresClause'
-            signode.append(reqNode)
-            self.requiresClause.describe_signature(reqNode, 'markType', env, self.symbol)
         signode += mainDeclNode
         if self.visibility and self.visibility != "public":
             mainDeclNode += addnodes.desc_sig_keyword(self.visibility, self.visibility)
@@ -4000,7 +4118,7 @@
             mainDeclNode += addnodes.desc_sig_keyword('enumerator', 'enumerator')
             mainDeclNode += addnodes.desc_sig_space()
         else:
-            assert False, self.objectType
+            raise AssertionError(self.objectType)
         self.declaration.describe_signature(mainDeclNode, mode, env, self.symbol)
         lastDeclNode = mainDeclNode
         if self.trailingRequiresClause:
@@ -4047,6 +4165,31 @@
         self.data = data
 
 
+def _is_specialization(templateParams: Union[ASTTemplateParams, ASTTemplateIntroduction],
+                       templateArgs: ASTTemplateArgs) -> bool:
+    # Checks if `templateArgs` does not exactly match `templateParams`.
+    # the names of the template parameters must be given exactly as args
+    # and params that are packs must in the args be the name expanded
+    if len(templateParams.params) != len(templateArgs.args):
+        return True
+    # having no template params and no arguments is also a specialization
+    if len(templateParams.params) == 0:
+        return True
+    for i in range(len(templateParams.params)):
+        param = templateParams.params[i]
+        arg = templateArgs.args[i]
+        # TODO: doing this by string manipulation is probably not the most efficient
+        paramName = str(param.name)
+        argTxt = str(arg)
+        isArgPackExpansion = argTxt.endswith('...')
+        if param.isPack != isArgPackExpansion:
+            return True
+        argName = argTxt[:-3] if isArgPackExpansion else argTxt
+        if paramName != argName:
+            return True
+    return False
+
+
 class Symbol:
     debug_indent = 0
     debug_indent_string = "  "
@@ -4054,11 +4197,11 @@
     debug_show_tree = False  # overridden by the corresponding config value
 
     def __copy__(self):
-        assert False  # shouldn't happen
+        raise AssertionError()  # shouldn't happen
 
     def __deepcopy__(self, memo):
         if self.parent:
-            assert False  # shouldn't happen
+            raise AssertionError()  # shouldn't happen
         else:
             # the domain base class makes a copy of the initial data, which is fine
             return Symbol(None, None, None, None, None, None, None)
@@ -4082,19 +4225,30 @@
 
     def __setattr__(self, key: str, value: Any) -> None:
         if key == "children":
-            assert False
+            raise AssertionError()
         else:
             return super().__setattr__(key, value)
 
-    def __init__(self, parent: "Symbol", identOrOp: Union[ASTIdentifier, ASTOperator],
-                 templateParams: Union[ASTTemplateParams, ASTTemplateIntroduction],
-                 templateArgs: Any, declaration: ASTDeclaration,
-                 docname: str, line: int) -> None:
+    def __init__(self, parent: Optional["Symbol"],
+                 identOrOp: Union[ASTIdentifier, ASTOperator, None],
+                 templateParams: Union[ASTTemplateParams, ASTTemplateIntroduction, None],
+                 templateArgs: Any, declaration: Optional[ASTDeclaration],
+                 docname: Optional[str], line: Optional[int]) -> None:
         self.parent = parent
         # declarations in a single directive are linked together
-        self.siblingAbove: Symbol = None
-        self.siblingBelow: Symbol = None
+        self.siblingAbove: Optional[Symbol] = None
+        self.siblingBelow: Optional[Symbol] = None
         self.identOrOp = identOrOp
+        # Ensure the same symbol for `A` is created for:
+        #
+        #     .. cpp:class:: template <typename T> class A
+        #
+        # and
+        #
+        #     .. cpp:function:: template <typename T> int A<T>::foo()
+        if (templateArgs is not None and
+                not _is_specialization(templateParams, templateArgs)):
+            templateArgs = None
         self.templateParams = templateParams  # template<templateParams>
         self.templateArgs = templateArgs  # identifier<templateArgs>
         self.declaration = declaration
@@ -4145,7 +4299,7 @@
                     continue
                 # only add a declaration if we our self are from a declaration
                 if self.declaration:
-                    decl = ASTDeclaration('templateParam', None, None, None, None, tp, None)
+                    decl = ASTDeclaration(objectType='templateParam', declaration=tp)
                 else:
                     decl = None
                 nne = ASTNestedNameElement(tp.get_identifier(), None)
@@ -4160,7 +4314,7 @@
                 if nn is None:
                     continue
                 # (comparing to the template params: we have checked that we are a declaration)
-                decl = ASTDeclaration('functionParam', None, None, None, None, fp, None)
+                decl = ASTDeclaration(objectType='functionParam', declaration=fp)
                 assert not nn.rooted
                 assert len(nn.names) == 1
                 self._add_symbols(nn, [], decl, self.docname, self.line)
@@ -4275,33 +4429,12 @@
             Symbol.debug_print("correctPrimaryTemplateAargs:", correctPrimaryTemplateArgs)
             Symbol.debug_print("searchInSiblings:           ", searchInSiblings)
 
-        def isSpecialization() -> bool:
-            # the names of the template parameters must be given exactly as args
-            # and params that are packs must in the args be the name expanded
-            if len(templateParams.params) != len(templateArgs.args):
-                return True
-            # having no template params and no arguments is also a specialization
-            if len(templateParams.params) == 0:
-                return True
-            for i in range(len(templateParams.params)):
-                param = templateParams.params[i]
-                arg = templateArgs.args[i]
-                # TODO: doing this by string manipulation is probably not the most efficient
-                paramName = str(param.name)
-                argTxt = str(arg)
-                isArgPackExpansion = argTxt.endswith('...')
-                if param.isPack != isArgPackExpansion:
-                    return True
-                argName = argTxt[:-3] if isArgPackExpansion else argTxt
-                if paramName != argName:
-                    return True
-            return False
         if correctPrimaryTemplateArgs:
             if templateParams is not None and templateArgs is not None:
                 # If both are given, but it's not a specialization, then do lookup as if
                 # there is no argument list.
                 # For example: template<typename T> int A<T>::var;
-                if not isSpecialization():
+                if not _is_specialization(templateParams, templateArgs):
                     templateArgs = None
 
         def matches(s: "Symbol") -> bool:
@@ -4730,7 +4863,7 @@
                     if symbol.declaration is None:
                         if Symbol.debug_lookup:
                             Symbol.debug_print("empty candidate")
-                        # if in the end we have non matching, but have an empty one,
+                        # if in the end we have non-matching, but have an empty one,
                         # then just continue with that
                         ourChild = symbol
                         continue
@@ -4757,14 +4890,23 @@
                                  ourChild.declaration.directiveType, name)
                     logger.warning(msg, location=(otherChild.docname, otherChild.line))
                 else:
-                    # Both have declarations, and in the same docname.
-                    # This can apparently happen, it should be safe to
-                    # just ignore it, right?
-                    # Hmm, only on duplicate declarations, right?
-                    msg = "Internal C++ domain error during symbol merging.\n"
-                    msg += "ourChild:\n" + ourChild.to_string(1)
-                    msg += "\notherChild:\n" + otherChild.to_string(1)
-                    logger.warning(msg, location=otherChild.docname)
+                    if (otherChild.declaration.objectType ==
+                            ourChild.declaration.objectType and
+                            otherChild.declaration.objectType in
+                            ('templateParam', 'functionParam') and
+                            ourChild.parent.declaration == otherChild.parent.declaration):
+                        # `ourChild` was just created during merging by the call
+                        # to `_fill_empty` on the parent and can be ignored.
+                        pass
+                    else:
+                        # Both have declarations, and in the same docname.
+                        # This can apparently happen, it should be safe to
+                        # just ignore it, right?
+                        # Hmm, only on duplicate declarations, right?
+                        msg = "Internal C++ domain error during symbol merging.\n"
+                        msg += "ourChild:\n" + ourChild.to_string(1)
+                        msg += "\notherChild:\n" + otherChild.to_string(1)
+                        logger.warning(msg, location=otherChild.docname)
             ourChild.merge_with(otherChild, docnames, env)
         if Symbol.debug_lookup:
             Symbol.debug_indent -= 2
@@ -5024,6 +5166,7 @@
                 res.append(": ")
                 if self.isRedeclaration:
                     res.append('!!duplicate!! ')
+                res.append("{" + self.declaration.objectType + "} ")
                 res.append(str(self.declaration))
         if self.docname:
             res.append('\t(')
@@ -5391,7 +5534,7 @@
         postFixes: List[ASTPostfixOp] = []
         while True:
             self.skip_ws()
-            if prefixType in ['expr', 'cast', 'typeid']:
+            if prefixType in ('expr', 'cast', 'typeid'):
                 if self.skip_string_and_ws('['):
                     expr = self._parse_expression()
                     self.skip_ws()
@@ -5604,50 +5747,60 @@
             return ASTBinOpExpr(exprs, ops)
         return _parse_bin_op_expr(self, 0, inTemplate=inTemplate)
 
-    def _parse_conditional_expression_tail(self, orExprHead: Any) -> None:
+    def _parse_conditional_expression_tail(self, orExprHead: ASTExpression,
+                                           inTemplate: bool) -> Optional[ASTConditionalExpr]:
+        # Consumes the orExprHead on success.
+
         # -> "?" expression ":" assignment-expression
-        return None
+        self.skip_ws()
+        if not self.skip_string("?"):
+            return None
+        thenExpr = self._parse_expression()
+        self.skip_ws()
+        if not self.skip_string(":"):
+            self.fail('Expected ":" after then-expression in conditional expression.')
+        elseExpr = self._parse_assignment_expression(inTemplate)
+        return ASTConditionalExpr(orExprHead, thenExpr, elseExpr)
 
     def _parse_assignment_expression(self, inTemplate: bool) -> ASTExpression:
         # -> conditional-expression
         #  | logical-or-expression assignment-operator initializer-clause
-        #  | throw-expression
-        # TODO: parse throw-expression: "throw" assignment-expression [opt]
-        # if not a throw expression, then:
-        # -> conditional-expression ->
+        #  | yield-expression -> "co_yield" assignment-expression
+        #                      | "co_yield" braced-init-list
+        #  | throw-expression -> "throw" assignment-expression[opt]
+        # TODO: yield-expression
+        # TODO: throw-expression
+
+        # Now we have (after expanding conditional-expression:
         #     logical-or-expression
         #   | logical-or-expression "?" expression ":" assignment-expression
         #   | logical-or-expression assignment-operator initializer-clause
-        exprs: List[Union[ASTExpression, ASTBracedInitList]] = []
-        ops = []
+        leftExpr = self._parse_logical_or_expression(inTemplate=inTemplate)
+        # the ternary operator
+        condExpr = self._parse_conditional_expression_tail(leftExpr, inTemplate)
+        if condExpr is not None:
+            return condExpr
+        # and actual assignment
+        for op in _expression_assignment_ops:
+            if op[0] in 'anox':
+                if not self.skip_word(op):
+                    continue
+            else:
+                if not self.skip_string(op):
+                    continue
+            rightExpr = self._parse_initializer_clause()
+            return ASTAssignmentExpr(leftExpr, op, rightExpr)
+        # just a logical-or-expression
+        return leftExpr
+
+    def _parse_constant_expression(self, inTemplate: bool) -> ASTExpression:
+        # -> conditional-expression ->
+        #    logical-or-expression
+        #  | logical-or-expression "?" expression ":" assignment-expression
         orExpr = self._parse_logical_or_expression(inTemplate=inTemplate)
-        exprs.append(orExpr)
-        # TODO: handle ternary with _parse_conditional_expression_tail
-        while True:
-            oneMore = False
-            self.skip_ws()
-            for op in _expression_assignment_ops:
-                if op[0] in 'anox':
-                    if not self.skip_word(op):
-                        continue
-                else:
-                    if not self.skip_string(op):
-                        continue
-                expr = self._parse_initializer_clause()
-                exprs.append(expr)
-                ops.append(op)
-                oneMore = True
-            if not oneMore:
-                break
-        if len(ops) == 0:
-            return orExpr
-        else:
-            return ASTAssignmentExpr(exprs, ops)
-
-    def _parse_constant_expression(self, inTemplate: bool) -> ASTExpression:
-        # -> conditional-expression
-        orExpr = self._parse_logical_or_expression(inTemplate=inTemplate)
-        # TODO: use _parse_conditional_expression_tail
+        condExpr = self._parse_conditional_expression_tail(orExpr, inTemplate)
+        if condExpr is not None:
+            return condExpr
         return orExpr
 
     def _parse_expression(self) -> ASTExpression:
@@ -5695,7 +5848,7 @@
             while not self.eof:
                 if (len(symbols) == 0 and self.current_char in end):
                     break
-                if self.current_char in brackets.keys():
+                if self.current_char in brackets:
                     symbols.append(brackets[self.current_char])
                 elif len(symbols) > 0 and self.current_char == symbols[-1]:
                     symbols.pop()
@@ -5855,12 +6008,102 @@
 
     # ==========================================================================
 
+    def _parse_simple_type_specifiers(self) -> ASTTrailingTypeSpecFundamental:
+        modifier: Optional[str] = None
+        signedness: Optional[str] = None
+        width: List[str] = []
+        typ: Optional[str] = None
+        names: List[str] = []  # the parsed sequence
+
+        self.skip_ws()
+        while self.match(_simple_type_specifiers_re):
+            t = self.matched_text
+            names.append(t)
+            if t in ('auto', 'void', 'bool',
+                     'char', 'wchar_t', 'char8_t', 'char16_t', 'char32_t',
+                     'int', '__int64', '__int128',
+                     'float', 'double',
+                     '__float80', '_Float64x', '__float128', '_Float128'):
+                if typ is not None:
+                    self.fail("Can not have both {} and {}.".format(t, typ))
+                typ = t
+            elif t in ('signed', 'unsigned'):
+                if signedness is not None:
+                    self.fail("Can not have both {} and {}.".format(t, signedness))
+                signedness = t
+            elif t == 'short':
+                if len(width) != 0:
+                    self.fail("Can not have both {} and {}.".format(t, width[0]))
+                width.append(t)
+            elif t == 'long':
+                if len(width) != 0 and width[0] != 'long':
+                    self.fail("Can not have both {} and {}.".format(t, width[0]))
+                width.append(t)
+            elif t in ('_Imaginary', '_Complex'):
+                if modifier is not None:
+                    self.fail("Can not have both {} and {}.".format(t, modifier))
+                modifier = t
+            self.skip_ws()
+        if len(names) == 0:
+            return None
+
+        if typ in ('auto', 'void', 'bool',
+                   'wchar_t', 'char8_t', 'char16_t', 'char32_t',
+                   '__float80', '_Float64x', '__float128', '_Float128'):
+            if modifier is not None:
+                self.fail("Can not have both {} and {}.".format(typ, modifier))
+            if signedness is not None:
+                self.fail("Can not have both {} and {}.".format(typ, signedness))
+            if len(width) != 0:
+                self.fail("Can not have both {} and {}.".format(typ, ' '.join(width)))
+        elif typ == 'char':
+            if modifier is not None:
+                self.fail("Can not have both {} and {}.".format(typ, modifier))
+            if len(width) != 0:
+                self.fail("Can not have both {} and {}.".format(typ, ' '.join(width)))
+        elif typ == 'int':
+            if modifier is not None:
+                self.fail("Can not have both {} and {}.".format(typ, modifier))
+        elif typ in ('__int64', '__int128'):
+            if modifier is not None:
+                self.fail("Can not have both {} and {}.".format(typ, modifier))
+            if len(width) != 0:
+                self.fail("Can not have both {} and {}.".format(typ, ' '.join(width)))
+        elif typ == 'float':
+            if signedness is not None:
+                self.fail("Can not have both {} and {}.".format(typ, signedness))
+            if len(width) != 0:
+                self.fail("Can not have both {} and {}.".format(typ, ' '.join(width)))
+        elif typ == 'double':
+            if signedness is not None:
+                self.fail("Can not have both {} and {}.".format(typ, signedness))
+            if len(width) > 1:
+                self.fail("Can not have both {} and {}.".format(typ, ' '.join(width)))
+            if len(width) == 1 and width[0] != 'long':
+                self.fail("Can not have both {} and {}.".format(typ, ' '.join(width)))
+        elif typ is None:
+            if modifier is not None:
+                self.fail("Can not have {} without a floating point type.".format(modifier))
+        else:
+            raise AssertionError("Unhandled type {}".format(typ))
+
+        canonNames: List[str] = []
+        if modifier is not None:
+            canonNames.append(modifier)
+        if signedness is not None:
+            canonNames.append(signedness)
+        canonNames.extend(width)
+        if typ is not None:
+            canonNames.append(typ)
+        return ASTTrailingTypeSpecFundamental(names, canonNames)
+
     def _parse_trailing_type_spec(self) -> ASTTrailingTypeSpec:
         # fundamental types, https://en.cppreference.com/w/cpp/language/type
         # and extensions
         self.skip_ws()
-        if self.match(_simple_type_sepcifiers_re):
-            return ASTTrailingTypeSpecFundamental(self.matched_text)
+        res = self._parse_simple_type_specifiers()
+        if res is not None:
+            return res
 
         # decltype
         self.skip_ws()
@@ -5973,12 +6216,7 @@
             override = self.skip_word_and_ws(
                 'override')  # they can be permuted
 
-        attrs = []
-        while True:
-            attr = self._parse_attribute()
-            if attr is None:
-                break
-            attrs.append(attr)
+        attrs = self._parse_attribute_list()
 
         self.skip_ws()
         initializer = None
@@ -6090,7 +6328,7 @@
             break
         return ASTDeclSpecsSimple(storage, threadLocal, inline, virtual,
                                   explicitSpec, consteval, constexpr, constinit,
-                                  volatile, const, friend, attrs)
+                                  volatile, const, friend, ASTAttributeList(attrs))
 
     def _parse_decl_specs(self, outer: str, typed: bool = True) -> ASTDeclSpecs:
         if outer:
@@ -6187,7 +6425,7 @@
             self.skip_ws()
             volatile = False
             const = False
-            attrs = []
+            attrList = []
             while 1:
                 if not volatile:
                     volatile = self.skip_word_and_ws('volatile')
@@ -6199,19 +6437,15 @@
                         continue
                 attr = self._parse_attribute()
                 if attr is not None:
-                    attrs.append(attr)
+                    attrList.append(attr)
                     continue
                 break
             next = self._parse_declarator(named, paramMode, typed)
-            return ASTDeclaratorPtr(next=next, volatile=volatile, const=const, attrs=attrs)
+            return ASTDeclaratorPtr(next=next, volatile=volatile, const=const,
+                                    attrs=ASTAttributeList(attrList))
         # TODO: shouldn't we parse an R-value ref here first?
         if typed and self.skip_string("&"):
-            attrs = []
-            while 1:
-                attr = self._parse_attribute()
-                if attr is None:
-                    break
-                attrs.append(attr)
+            attrs = self._parse_attribute_list()
             next = self._parse_declarator(named, paramMode, typed)
             return ASTDeclaratorRef(next=next, attrs=attrs)
         if typed and self.skip_string("..."):
@@ -6366,14 +6600,21 @@
                 declSpecs = self._parse_decl_specs(outer=outer, typed=False)
                 decl = self._parse_declarator(named=True, paramMode=outer,
                                               typed=False)
-                self.assert_end(allowSemicolon=True)
+                mustEnd = True
+                if outer == 'function':
+                    # Allow trailing requires on functions.
+                    self.skip_ws()
+                    if re.compile(r'requires\b').match(self.definition, self.pos):
+                        mustEnd = False
+                if mustEnd:
+                    self.assert_end(allowSemicolon=True)
             except DefinitionError as exUntyped:
                 if outer == 'type':
                     desc = "If just a name"
                 elif outer == 'function':
                     desc = "If the function has no return type"
                 else:
-                    assert False
+                    raise AssertionError()
                 prevErrors.append((exUntyped, desc))
                 self.pos = startPos
                 try:
@@ -6386,7 +6627,7 @@
                     elif outer == 'function':
                         desc = "If the function has a return type"
                     else:
-                        assert False
+                        raise AssertionError()
                     prevErrors.append((exTyped, desc))
                     # Retain the else branch for easier debugging.
                     # TODO: it would be nice to save the previous stacktrace
@@ -6398,7 +6639,7 @@
                         elif outer == 'function':
                             header = "Error when parsing function declaration."
                         else:
-                            assert False
+                            raise AssertionError()
                         raise self._make_multi_error(prevErrors, header) from exTyped
                     else:
                         # For testing purposes.
@@ -6483,6 +6724,7 @@
         return ASTConcept(nestedName, initializer)
 
     def _parse_class(self) -> ASTClass:
+        attrs = self._parse_attribute_list()
         name = self._parse_nested_name()
         self.skip_ws()
         final = self.skip_word_and_ws('final')
@@ -6510,24 +6752,26 @@
                     continue
                 else:
                     break
-        return ASTClass(name, final, bases)
+        return ASTClass(name, final, bases, attrs)
 
     def _parse_union(self) -> ASTUnion:
+        attrs = self._parse_attribute_list()
         name = self._parse_nested_name()
-        return ASTUnion(name)
+        return ASTUnion(name, attrs)
 
     def _parse_enum(self) -> ASTEnum:
         scoped = None  # is set by CPPEnumObject
-        self.skip_ws()
+        attrs = self._parse_attribute_list()
         name = self._parse_nested_name()
         self.skip_ws()
         underlyingType = None
         if self.skip_string(':'):
             underlyingType = self._parse_type(named=False)
-        return ASTEnum(name, scoped, underlyingType)
+        return ASTEnum(name, scoped, underlyingType, attrs)
 
     def _parse_enumerator(self) -> ASTEnumerator:
         name = self._parse_nested_name()
+        attrs = self._parse_attribute_list()
         self.skip_ws()
         init = None
         if self.skip_string('='):
@@ -6537,14 +6781,14 @@
                 return self._parse_constant_expression(inTemplate=False)
             initVal = self._parse_expression_fallback([], parser)
             init = ASTInitializer(initVal)
-        return ASTEnumerator(name, init)
+        return ASTEnumerator(name, init, attrs)
 
     # ==========================================================================
 
-    def _parse_template_paramter(self) -> ASTTemplateParam:
+    def _parse_template_parameter(self) -> ASTTemplateParam:
         self.skip_ws()
         if self.skip_word('template'):
-            # declare a tenplate template parameter
+            # declare a template template parameter
             nestedParams = self._parse_template_parameter_list()
         else:
             nestedParams = None
@@ -6591,7 +6835,9 @@
                 # non-type parameter or constrained type parameter
                 self.pos = pos
                 param = self._parse_type_with_init('maybe', 'templateParam')
-                return ASTTemplateParamNonType(param)
+                self.skip_ws()
+                parameterPack = self.skip_string('...')
+                return ASTTemplateParamNonType(param, parameterPack)
             except DefinitionError as eNonType:
                 self.pos = pos
                 header = "Error when parsing template parameter."
@@ -6613,14 +6859,15 @@
             pos = self.pos
             err = None
             try:
-                param = self._parse_template_paramter()
+                param = self._parse_template_parameter()
                 templateParams.append(param)
             except DefinitionError as eParam:
                 self.pos = pos
                 err = eParam
             self.skip_ws()
             if self.skip_string('>'):
-                return ASTTemplateParams(templateParams)
+                requiresClause = self._parse_requires_clause()
+                return ASTTemplateParams(templateParams, requiresClause)
             elif self.skip_string(','):
                 continue
             else:
@@ -6742,6 +6989,8 @@
                         return ASTTemplateDeclarationPrefix(None)
                     else:
                         raise e
+                if objectType == 'concept' and params.requiresClause is not None:
+                    self.fail('requires-clause not allowed for concept')
             else:
                 params = self._parse_template_introduction()
                 if not params:
@@ -6789,8 +7038,8 @@
                 self.warn(msg)
 
             newTemplates: List[Union[ASTTemplateParams, ASTTemplateIntroduction]] = []
-            for i in range(numExtra):
-                newTemplates.append(ASTTemplateParams([]))
+            for _i in range(numExtra):
+                newTemplates.append(ASTTemplateParams([], requiresClause=None))
             if templatePrefix and not isMemberInstantiation:
                 newTemplates.extend(templatePrefix.templates)
             templatePrefix = ASTTemplateDeclarationPrefix(newTemplates)
@@ -6806,7 +7055,6 @@
             raise Exception('Internal error, unknown directiveType "%s".' % directiveType)
         visibility = None
         templatePrefix = None
-        requiresClause = None
         trailingRequiresClause = None
         declaration: Any = None
 
@@ -6814,10 +7062,8 @@
         if self.match(_visibility_re):
             visibility = self.matched_text
 
-        if objectType in ('type', 'concept', 'member', 'function', 'class'):
+        if objectType in ('type', 'concept', 'member', 'function', 'class', 'union'):
             templatePrefix = self._parse_template_declaration_prefix(objectType)
-            if objectType == 'function' and templatePrefix is not None:
-                requiresClause = self._parse_requires_clause()
 
         if objectType == 'type':
             prevErrors = []
@@ -6843,8 +7089,7 @@
             declaration = self._parse_type_with_init(named=True, outer='member')
         elif objectType == 'function':
             declaration = self._parse_type(named=True, outer='function')
-            if templatePrefix is not None:
-                trailingRequiresClause = self._parse_requires_clause()
+            trailingRequiresClause = self._parse_requires_clause()
         elif objectType == 'class':
             declaration = self._parse_class()
         elif objectType == 'union':
@@ -6854,7 +7099,7 @@
         elif objectType == 'enumerator':
             declaration = self._parse_enumerator()
         else:
-            assert False
+            raise AssertionError()
         templatePrefix = self._check_template_consistency(declaration.name,
                                                           templatePrefix,
                                                           fullSpecShorthand=False,
@@ -6862,7 +7107,7 @@
         self.skip_ws()
         semicolon = self.skip_string(';')
         return ASTDeclaration(objectType, directiveType, visibility,
-                              templatePrefix, requiresClause, declaration,
+                              templatePrefix, declaration,
                               trailingRequiresClause, semicolon)
 
     def parse_namespace_object(self) -> ASTNamespace:
@@ -6934,21 +7179,14 @@
 class CPPObject(ObjectDescription[ASTDeclaration]):
     """Description of a C++ language object."""
 
-    doc_field_types = [
-        GroupedField('parameter', label=_('Parameters'),
-                     names=('param', 'parameter', 'arg', 'argument'),
-                     can_collapse=True),
+    doc_field_types: List[Field] = [
         GroupedField('template parameter', label=_('Template Parameters'),
                      names=('tparam', 'template parameter'),
                      can_collapse=True),
-        GroupedField('exceptions', label=_('Throws'), rolename='expr',
-                     names=('throws', 'throw', 'exception'),
-                     can_collapse=True),
-        Field('returnvalue', label=_('Returns'), has_arg=False,
-              names=('returns', 'return')),
     ]
 
     option_spec: OptionSpec = {
+        'noindex': directives.flag,
         'noindexentry': directives.flag,
         'tparam-line-spec': directives.flag,
     }
@@ -7181,6 +7419,20 @@
 class CPPFunctionObject(CPPObject):
     object_type = 'function'
 
+    doc_field_types = CPPObject.doc_field_types + [
+        GroupedField('parameter', label=_('Parameters'),
+                     names=('param', 'parameter', 'arg', 'argument'),
+                     can_collapse=True),
+        GroupedField('exceptions', label=_('Throws'), rolename='expr',
+                     names=('throws', 'throw', 'exception'),
+                     can_collapse=True),
+        GroupedField('retval', label=_('Return values'),
+                     names=('retvals', 'retval'),
+                     can_collapse=True),
+        Field('returnvalue', label=_('Returns'), has_arg=False,
+              names=('returns', 'return')),
+    ]
+
 
 class CPPClassObject(CPPObject):
     object_type = 'class'
@@ -7369,8 +7621,7 @@
         return nodes
 
     def apply(self, **kwargs: Any) -> None:
-        for node in self.document.traverse(AliasNode):
-            node = cast(AliasNode, node)
+        for node in self.document.findall(AliasNode):
             sig = node.sig
             parentKey = node.parentKey
             try:
@@ -7489,7 +7740,7 @@
                            " need 'maxdepth' 0 for infinite or at least 2.",
                            location=self.get_location())
         signatures = self.get_signatures()
-        for i, sig in enumerate(signatures):
+        for sig in signatures:
             node.append(AliasNode(sig, aliasOptions, env=self.env))
 
         contentnode = addnodes.desc_content()
@@ -7691,7 +7942,7 @@
                             typ: str, target: str, node: pending_xref,
                             contnode: Element) -> Tuple[Optional[Element], Optional[str]]:
         # add parens again for those that could be functions
-        if typ == 'any' or typ == 'func':
+        if typ in ('any', 'func'):
             target += '()'
         parser = DefinitionParser(target, location=node, config=env.config)
         try:
@@ -7776,7 +8027,7 @@
             if objtypes:
                 return declTyp in objtypes
             print("Type is %s, declaration type is %s" % (typ, declTyp))
-            assert False
+            raise AssertionError()
         if not checkType():
             logger.warning("cpp:%s targets a %s (%s).",
                            typ, s.declaration.objectType,
@@ -7812,7 +8063,7 @@
                     if (env.config.add_function_parentheses and typ == 'func' and
                             title.endswith('operator()')):
                         addParen += 1
-                    if ((typ == 'any' or typ == 'func') and
+                    if (typ in ('any', 'func') and
                             title.endswith('operator') and
                             displayName.endswith('operator()')):
                         addParen += 1
@@ -7902,7 +8153,7 @@
 
     return {
         'version': 'builtin',
-        'env_version': 4,
+        'env_version': 8,
         'parallel_read_safe': True,
         'parallel_write_safe': True,
     }
('sphinx/domains', 'c.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.domains.c
-    ~~~~~~~~~~~~~~~~
-
-    The C language domain.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""The C language domain."""
 
 import re
 from typing import (Any, Callable, Dict, Generator, Iterator, List, Optional, Tuple, TypeVar,
@@ -20,7 +12,7 @@
 from sphinx.addnodes import pending_xref
 from sphinx.application import Sphinx
 from sphinx.builders import Builder
-from sphinx.deprecation import RemovedInSphinx50Warning
+from sphinx.deprecation import RemovedInSphinx60Warning
 from sphinx.directives import ObjectDescription
 from sphinx.domains import Domain, ObjType
 from sphinx.environment import BuildEnvironment
@@ -29,14 +21,14 @@
 from sphinx.transforms import SphinxTransform
 from sphinx.transforms.post_transforms import ReferencesResolver
 from sphinx.util import logging
-from sphinx.util.cfamily import (ASTAttribute, ASTBaseBase, ASTBaseParenExprList, BaseParser,
-                                 DefinitionError, NoOldIdError, StringifyTransform,
+from sphinx.util.cfamily import (ASTAttributeList, ASTBaseBase, ASTBaseParenExprList,
+                                 BaseParser, DefinitionError, NoOldIdError, StringifyTransform,
                                  UnsupportedMultiCharacterCharLiteral, anon_identifier_re,
                                  binary_literal_re, char_literal_re, float_literal_re,
                                  float_literal_suffix_re, hex_literal_re, identifier_re,
                                  integer_literal_re, integers_literal_suffix_re,
                                  octal_literal_re, verify_description_mode)
-from sphinx.util.docfields import Field, TypedField
+from sphinx.util.docfields import Field, GroupedField, TypedField
 from sphinx.util.docutils import SphinxDirective
 from sphinx.util.nodes import make_refnode
 from sphinx.util.typing import OptionSpec
@@ -92,31 +84,22 @@
 _string_re = re.compile(r"[LuU8]?('([^'\\]*(?:\\.[^'\\]*)*)'"
                         r'|"([^"\\]*(?:\\.[^"\\]*)*)")', re.S)
 
-_simple_type_sepcifiers_re = re.compile(r"""(?x)
+# bool, complex, and imaginary are macro "keywords", so they are handled seperately
+_simple_type_specifiers_re = re.compile(r"""(?x)
     \b(
-    void|_Bool|bool
-    # Integer
-    # -------
-    |((signed|unsigned)\s+)?(char|(
-        ((long\s+long|long|short)\s+)?int
-    ))
+    void|_Bool
+    |signed|unsigned
+    |short|long
+    |char
+    |int
     |__uint128|__int128
-    # extensions
-    |((signed|unsigned)\s+)?__int(8|16|32|64|128)
-    # Floating-point
-    # --------------
-    |(float|double|long\s+double)(\s+(_Complex|complex|_Imaginary|imaginary))?
-    |(_Complex|complex|_Imaginary|imaginary)\s+(float|double|long\s+double)
+    |__int(8|16|32|64|128)  # extension
+    |float|double
     |_Decimal(32|64|128)
-    # extensions
-    |__float80|_Float64x|__float128|_Float128|__ibm128
-    |__fp16
-    # Fixed-point, extension
-    |(_Sat\s+)?((signed|unsigned)\s+)?((short|long|long\s+long)\s+)?(_Fract|fract|_Accum|accum)
-    # Integer types that could be prefixes of the previous ones
-    # ---------------------------------------------------------
-    |((signed|unsigned)\s+)?(long\s+long|long|short)
-    |signed|unsigned
+    |_Complex|_Imaginary
+    |__float80|_Float64x|__float128|_Float128|__ibm128  # extension
+    |__fp16  # extension
+    |_Sat|_Fract|fract|_Accum|accum  # extension
     )\b
 """)
 
@@ -214,11 +197,11 @@
         # just print the name part, with template args, not template params
         if mode == 'noneIsName':
             if self.rooted:
-                assert False, "Can this happen?"  # TODO
+                raise AssertionError("Can this happen?")  # TODO
                 signode += nodes.Text('.')
             for i in range(len(self.names)):
                 if i != 0:
-                    assert False, "Can this happen?"  # TODO
+                    raise AssertionError("Can this happen?")  # TODO
                     signode += nodes.Text('.')
                 n = self.names[i]
                 n.describe_signature(signode, mode, env, '', symbol)
@@ -226,7 +209,7 @@
             assert not self.rooted, str(self)
             assert len(self.names) == 1
             self.names[0].describe_signature(signode, 'noneIsName', env, '', symbol)
-        elif mode == 'markType' or mode == 'lastIsName' or mode == 'markName':
+        elif mode in ('markType', 'lastIsName', 'markName'):
             # Each element should be a pending xref targeting the complete
             # prefix.
             prefix = ''
@@ -636,8 +619,9 @@
 
 
 class ASTTrailingTypeSpecFundamental(ASTTrailingTypeSpec):
-    def __init__(self, name: str) -> None:
-        self.names = name.split()
+    def __init__(self, names: List[str]) -> None:
+        assert len(names) != 0
+        self.names = names
 
     def _stringify(self, transform: StringifyTransform) -> str:
         return ' '.join(self.names)
@@ -679,7 +663,7 @@
 
 
 class ASTFunctionParameter(ASTBase):
-    def __init__(self, arg: "ASTTypeWithInit", ellipsis: bool = False) -> None:
+    def __init__(self, arg: Optional["ASTTypeWithInit"], ellipsis: bool = False) -> None:
         self.arg = arg
         self.ellipsis = ellipsis
 
@@ -703,7 +687,7 @@
 
 
 class ASTParameters(ASTBase):
-    def __init__(self, args: List[ASTFunctionParameter], attrs: List[ASTAttribute]) -> None:
+    def __init__(self, args: List[ASTFunctionParameter], attrs: ASTAttributeList) -> None:
         self.args = args
         self.attrs = attrs
 
@@ -721,9 +705,9 @@
             first = False
             res.append(str(a))
         res.append(')')
-        for attr in self.attrs:
+        if len(self.attrs) != 0:
             res.append(' ')
-            res.append(transform(attr))
+            res.append(transform(self.attrs))
         return ''.join(res)
 
     def describe_signature(self, signode: TextElement, mode: str,
@@ -748,14 +732,14 @@
                 arg.describe_signature(signode, 'markType', env, symbol=symbol)
             signode += addnodes.desc_sig_punctuation(')', ')')
 
-        for attr in self.attrs:
+        if len(self.attrs) != 0:
             signode += addnodes.desc_sig_space()
-            attr.describe_signature(signode)
+            self.attrs.describe_signature(signode)
 
 
 class ASTDeclSpecsSimple(ASTBaseBase):
     def __init__(self, storage: str, threadLocal: str, inline: bool,
-                 restrict: bool, volatile: bool, const: bool, attrs: List[Any]) -> None:
+                 restrict: bool, volatile: bool, const: bool, attrs: ASTAttributeList) -> None:
         self.storage = storage
         self.threadLocal = threadLocal
         self.inline = inline
@@ -777,7 +761,8 @@
 
     def _stringify(self, transform: StringifyTransform) -> str:
         res: List[str] = []
-        res.extend(transform(attr) for attr in self.attrs)
+        if len(self.attrs) != 0:
+            res.append(transform(self.attrs))
         if self.storage:
             res.append(self.storage)
         if self.threadLocal:
@@ -794,14 +779,15 @@
 
     def describe_signature(self, modifiers: List[Node]) -> None:
         def _add(modifiers: List[Node], text: str) -> None:
-            if len(modifiers) > 0:
+            if len(modifiers) != 0:
                 modifiers.append(addnodes.desc_sig_space())
             modifiers.append(addnodes.desc_sig_keyword(text, text))
 
-        for attr in self.attrs:
-            if len(modifiers) > 0:
-                modifiers.append(addnodes.desc_sig_space())
-            modifiers.append(attr.describe_signature(modifiers))
+        if len(modifiers) != 0 and len(self.attrs) != 0:
+            modifiers.append(addnodes.desc_sig_space())
+        tempNode = nodes.TextElement()
+        self.attrs.describe_signature(tempNode)
+        modifiers.extend(tempNode.children)
         if self.storage:
             _add(modifiers, self.storage)
         if self.threadLocal:
@@ -1018,7 +1004,7 @@
 
 class ASTDeclaratorPtr(ASTDeclarator):
     def __init__(self, next: ASTDeclarator, restrict: bool, volatile: bool, const: bool,
-                 attrs: Any) -> None:
+                 attrs: ASTAttributeList) -> None:
         assert next
         self.next = next
         self.restrict = restrict
@@ -1041,9 +1027,8 @@
 
     def _stringify(self, transform: StringifyTransform) -> str:
         res = ['*']
-        for a in self.attrs:
-            res.append(transform(a))
-        if len(self.attrs) > 0 and (self.restrict or self.volatile or self.const):
+        res.append(transform(self.attrs))
+        if len(self.attrs) != 0 and (self.restrict or self.volatile or self.const):
             res.append(' ')
         if self.restrict:
             res.append('restrict')
@@ -1065,9 +1050,8 @@
                            env: "BuildEnvironment", symbol: "Symbol") -> None:
         verify_description_mode(mode)
         signode += addnodes.desc_sig_punctuation('*', '*')
-        for a in self.attrs:
-            a.describe_signature(signode)
-        if len(self.attrs) > 0 and (self.restrict or self.volatile or self.const):
+        self.attrs.describe_signature(signode)
+        if len(self.attrs) != 0 and (self.restrict or self.volatile or self.const):
             signode += addnodes.desc_sig_space()
 
         def _add_anno(signode: TextElement, text: str) -> None:
@@ -1390,9 +1374,11 @@
 
 
 class ASTEnumerator(ASTBase):
-    def __init__(self, name: ASTNestedName, init: ASTInitializer) -> None:
+    def __init__(self, name: ASTNestedName, init: Optional[ASTInitializer],
+                 attrs: ASTAttributeList) -> None:
         self.name = name
         self.init = init
+        self.attrs = attrs
 
     def get_id(self, version: int, objectType: str, symbol: "Symbol") -> str:
         return symbol.get_full_nested_name().get_id(version)
@@ -1400,6 +1386,9 @@
     def _stringify(self, transform: StringifyTransform) -> str:
         res = []
         res.append(transform(self.name))
+        if len(self.attrs) != 0:
+            res.append(' ')
+            res.append(transform(self.attrs))
         if self.init:
             res.append(transform(self.init))
         return ''.join(res)
@@ -1408,6 +1397,9 @@
                            env: "BuildEnvironment", symbol: "Symbol") -> None:
         verify_description_mode(mode)
         self.name.describe_signature(signode, mode, env, symbol)
+        if len(self.attrs) != 0:
+            signode += addnodes.desc_sig_space()
+            self.attrs.describe_signature(signode)
         if self.init:
             self.init.describe_signature(signode, 'markType', env, symbol)
 
@@ -1496,7 +1488,7 @@
             mainDeclNode += addnodes.desc_sig_keyword(prefix, prefix)
             mainDeclNode += addnodes.desc_sig_space()
         else:
-            assert False
+            raise AssertionError()
         self.declaration.describe_signature(mainDeclNode, mode, env, self.symbol)
         if self.semicolon:
             mainDeclNode += addnodes.desc_sig_punctuation(';', ';')
@@ -1526,11 +1518,11 @@
     debug_show_tree = False
 
     def __copy__(self):
-        assert False  # shouldn't happen
+        raise AssertionError()  # shouldn't happen
 
     def __deepcopy__(self, memo):
         if self.parent:
-            assert False  # shouldn't happen
+            raise AssertionError()  # shouldn't happen
         else:
             # the domain base class makes a copy of the initial data, which is fine
             return Symbol(None, None, None, None, None)
@@ -1551,7 +1543,7 @@
 
     def __setattr__(self, key: str, value: Any) -> None:
         if key == "children":
-            assert False
+            raise AssertionError()
         else:
             return super().__setattr__(key, value)
 
@@ -1967,7 +1959,7 @@
             if Symbol.debug_lookup:
                 Symbol.debug_print(
                     "no match, but fill an empty declaration, candSybmol is not None?:",
-                    candSymbol is not None)  # NOQA
+                    candSymbol is not None)
                 Symbol.debug_indent -= 2
             if candSymbol is not None:
                 candSymbol.remove()
@@ -2539,7 +2531,7 @@
             while not self.eof:
                 if (len(symbols) == 0 and self.current_char in end):
                     break
-                if self.current_char in brackets.keys():
+                if self.current_char in brackets:
                     symbols.append(brackets[self.current_char])
                 elif len(symbols) > 0 and self.current_char == symbols[-1]:
                     symbols.pop()
@@ -2580,12 +2572,36 @@
                 break
         return ASTNestedName(names, rooted)
 
+    def _parse_simple_type_specifier(self) -> Optional[str]:
+        if self.match(_simple_type_specifiers_re):
+            return self.matched_text
+        for t in ('bool', 'complex', 'imaginary'):
+            if t in self.config.c_extra_keywords:
+                if self.skip_word(t):
+                    return t
+        return None
+
+    def _parse_simple_type_specifiers(self) -> ASTTrailingTypeSpecFundamental:
+        names: List[str] = []
+
+        self.skip_ws()
+        while True:
+            t = self._parse_simple_type_specifier()
+            if t is None:
+                break
+            names.append(t)
+            self.skip_ws()
+        if len(names) == 0:
+            return None
+        return ASTTrailingTypeSpecFundamental(names)
+
     def _parse_trailing_type_spec(self) -> ASTTrailingTypeSpec:
         # fundamental types, https://en.cppreference.com/w/c/language/type
         # and extensions
         self.skip_ws()
-        if self.match(_simple_type_sepcifiers_re):
-            return ASTTrailingTypeSpecFundamental(self.matched_text)
+        res = self._parse_simple_type_specifiers()
+        if res is not None:
+            return res
 
         # prefixed
         prefix = None
@@ -2598,7 +2614,7 @@
         nestedName = self._parse_nested_name()
         return ASTTrailingTypeSpecName(prefix, nestedName)
 
-    def _parse_parameters(self, paramMode: str) -> ASTParameters:
+    def _parse_parameters(self, paramMode: str) -> Optional[ASTParameters]:
         self.skip_ws()
         if not self.skip_string('('):
             if paramMode == 'function':
@@ -2633,13 +2649,7 @@
                         'Expecting "," or ")" in parameters, '
                         'got "%s".' % self.current_char)
 
-        attrs = []
-        while True:
-            attr = self._parse_attribute()
-            if attr is None:
-                break
-            attrs.append(attr)
-
+        attrs = self._parse_attribute_list()
         return ASTParameters(args, attrs)
 
     def _parse_decl_specs_simple(self, outer: str, typed: bool) -> ASTDeclSpecsSimple:
@@ -2698,7 +2708,7 @@
                 continue
             break
         return ASTDeclSpecsSimple(storage, threadLocal, inline,
-                                  restrict, volatile, const, attrs)
+                                  restrict, volatile, const, ASTAttributeList(attrs))
 
     def _parse_decl_specs(self, outer: str, typed: bool = True) -> ASTDeclSpecs:
         if outer:
@@ -2830,7 +2840,7 @@
             next = self._parse_declarator(named, paramMode, typed)
             return ASTDeclaratorPtr(next=next,
                                     restrict=restrict, volatile=volatile, const=const,
-                                    attrs=attrs)
+                                    attrs=ASTAttributeList(attrs))
         if typed and self.current_char == '(':  # note: peeking, not skipping
             # maybe this is the beginning of params, try that first,
             # otherwise assume it's noptr->declarator > ( ptr-declarator )
@@ -2905,7 +2915,7 @@
         value = self._parse_expression_fallback(fallbackEnd, parser, allow=allowFallback)
         return ASTInitializer(value)
 
-    def _parse_type(self, named: Union[bool, str], outer: str = None) -> ASTType:
+    def _parse_type(self, named: Union[bool, str], outer: Optional[str] = None) -> ASTType:
         """
         named=False|'single'|True: 'single' is e.g., for function objects which
         doesn't need to name the arguments, but otherwise is a single name
@@ -3025,6 +3035,7 @@
 
     def _parse_enumerator(self) -> ASTEnumerator:
         name = self._parse_nested_name()
+        attrs = self._parse_attribute_list()
         self.skip_ws()
         init = None
         if self.skip_string('='):
@@ -3035,7 +3046,7 @@
 
             initVal = self._parse_expression_fallback([], parser)
             init = ASTInitializer(initVal)
-        return ASTEnumerator(name, init)
+        return ASTEnumerator(name, init, attrs)
 
     def parse_pre_v3_type_definition(self) -> ASTDeclaration:
         self.skip_ws()
@@ -3080,7 +3091,7 @@
         elif objectType == 'type':
             declaration = self._parse_type(named=True, outer='type')
         else:
-            assert False
+            raise AssertionError()
         if objectType != 'macro':
             self.skip_ws()
             semicolon = self.skip_string(';')
@@ -3130,17 +3141,8 @@
     Description of a C language object.
     """
 
-    doc_field_types = [
-        TypedField('parameter', label=_('Parameters'),
-                   names=('param', 'parameter', 'arg', 'argument'),
-                   typerolename='expr', typenames=('type',)),
-        Field('returnvalue', label=_('Returns'), has_arg=False,
-              names=('returns', 'return')),
-        Field('returntype', label=_('Return type'), has_arg=False,
-              names=('rtype',)),
-    ]
-
     option_spec: OptionSpec = {
+        'noindex': directives.flag,
         'noindexentry': directives.flag,
     }
 
@@ -3270,7 +3272,7 @@
                     msg = "{}: Pre-v3 C type directive '.. c:type:: {}' converted to " \
                           "'.. c:{}:: {}'." \
                           "\nThe original parsing error was:\n{}"
-                    msg = msg.format(RemovedInSphinx50Warning.__name__,
+                    msg = msg.format(RemovedInSphinx60Warning.__name__,
                                      sig, ast.objectType, ast, eOrig)
                     logger.warning(msg, location=signode)
         except DefinitionError as e:
@@ -3342,12 +3344,30 @@
         return self.objtype
 
 
+_function_doc_field_types = [
+    TypedField('parameter', label=_('Parameters'),
+               names=('param', 'parameter', 'arg', 'argument'),
+               typerolename='expr', typenames=('type',)),
+    GroupedField('retval', label=_('Return values'),
+                 names=('retvals', 'retval'),
+                 can_collapse=True),
+    Field('returnvalue', label=_('Returns'), has_arg=False,
+          names=('returns', 'return')),
+    Field('returntype', label=_('Return type'), has_arg=False,
+          names=('rtype',)),
+]
+
+
 class CFunctionObject(CObject):
     object_type = 'function'
 
+    doc_field_types = _function_doc_field_types.copy()
+
 
 class CMacroObject(CObject):
     object_type = 'macro'
+
+    doc_field_types = _function_doc_field_types.copy()
 
 
 class CStructObject(CObject):
@@ -3532,8 +3552,7 @@
         return nodes
 
     def apply(self, **kwargs: Any) -> None:
-        for node in self.document.traverse(AliasNode):
-            node = cast(AliasNode, node)
+        for node in self.document.findall(AliasNode):
             sig = node.sig
             parentKey = node.parentKey
             try:
@@ -3591,7 +3610,7 @@
             nodes = self._render_symbol(s, maxdepth=node.aliasOptions['maxdepth'],
                                         skipThis=node.aliasOptions['noroot'],
                                         aliasOptions=node.aliasOptions,
-                                        renderOptions=dict(), document=node.document)
+                                        renderOptions={}, document=node.document)
             node.replace_self(nodes)
 
 
@@ -3630,8 +3649,7 @@
                            " When skipping the root declaration,"
                            " need 'maxdepth' 0 for infinite or at least 2.",
                            location=self.get_location())
-        signatures = self.get_signatures()
-        for i, sig in enumerate(signatures):
+        for sig in self.get_signatures():
             node.append(AliasNode(sig, aliasOptions, self.state.document, env=self.env))
         return [node]
 
@@ -3686,7 +3704,7 @@
             if self.env.config['c_warn_on_allowed_pre_v3']:
                 msg = "{}: Pre-v3 C type role ':c:type:`{}`' converted to ':c:expr:`{}`'."
                 msg += "\nThe original parsing error was:\n{}"
-                msg = msg.format(RemovedInSphinx50Warning.__name__, text, text, eOrig)
+                msg = msg.format(RemovedInSphinx60Warning.__name__, text, text, eOrig)
                 logger.warning(msg, location=self.get_location())
             return [signode], []
 
('sphinx/domains', 'python.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.domains.python
-    ~~~~~~~~~~~~~~~~~~~~~
-
-    The Python domain.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""The Python domain."""
 
 import builtins
 import inspect
@@ -26,7 +18,7 @@
 from sphinx.addnodes import desc_signature, pending_xref, pending_xref_condition
 from sphinx.application import Sphinx
 from sphinx.builders import Builder
-from sphinx.deprecation import RemovedInSphinx50Warning
+from sphinx.deprecation import RemovedInSphinx60Warning
 from sphinx.directives import ObjectDescription
 from sphinx.domains import Domain, Index, IndexEntry, ObjType
 from sphinx.environment import BuildEnvironment
@@ -36,9 +28,10 @@
 from sphinx.roles import XRefRole
 from sphinx.util import logging
 from sphinx.util.docfields import Field, GroupedField, TypedField
-from sphinx.util.docutils import SphinxDirective
+from sphinx.util.docutils import SphinxDirective, switch_source_input
 from sphinx.util.inspect import signature_from_str
-from sphinx.util.nodes import find_pending_xref_condition, make_id, make_refnode
+from sphinx.util.nodes import (find_pending_xref_condition, make_id, make_refnode,
+                               nested_parse_with_titles)
 from sphinx.util.typing import OptionSpec, TextlikeNode
 
 logger = logging.getLogger(__name__)
@@ -80,34 +73,60 @@
     deprecated: bool
 
 
-def type_to_xref(text: str, env: BuildEnvironment = None) -> addnodes.pending_xref:
-    """Convert a type string to a cross reference node."""
-    if text == 'None':
+def parse_reftarget(reftarget: str, suppress_prefix: bool = False
+                    ) -> Tuple[str, str, str, bool]:
+    """Parse a type string and return (reftype, reftarget, title, refspecific flag)"""
+    refspecific = False
+    if reftarget.startswith('.'):
+        reftarget = reftarget[1:]
+        title = reftarget
+        refspecific = True
+    elif reftarget.startswith('~'):
+        reftarget = reftarget[1:]
+        title = reftarget.split('.')[-1]
+    elif suppress_prefix:
+        title = reftarget.split('.')[-1]
+    elif reftarget.startswith('typing.'):
+        title = reftarget[7:]
+    else:
+        title = reftarget
+
+    if reftarget == 'None' or reftarget.startswith('typing.'):
+        # typing module provides non-class types.  Obj reference is good to refer them.
         reftype = 'obj'
     else:
         reftype = 'class'
 
+    return reftype, reftarget, title, refspecific
+
+
+def type_to_xref(target: str, env: Optional[BuildEnvironment] = None,
+                 suppress_prefix: bool = False) -> addnodes.pending_xref:
+    """Convert a type string to a cross reference node."""
     if env:
         kwargs = {'py:module': env.ref_context.get('py:module'),
                   'py:class': env.ref_context.get('py:class')}
     else:
         kwargs = {}
 
+    reftype, target, title, refspecific = parse_reftarget(target, suppress_prefix)
+
     if env.config.python_use_unqualified_type_names:
         # Note: It would be better to use qualname to describe the object to support support
         # nested classes.  But python domain can't access the real python object because this
         # module should work not-dynamically.
-        shortname = text.split('.')[-1]
+        shortname = title.split('.')[-1]
         contnodes: List[Node] = [pending_xref_condition('', shortname, condition='resolved'),
-                                 pending_xref_condition('', text, condition='*')]
+                                 pending_xref_condition('', title, condition='*')]
     else:
-        contnodes = [nodes.Text(text)]
+        contnodes = [nodes.Text(title)]
 
     return pending_xref('', *contnodes,
-                        refdomain='py', reftype=reftype, reftarget=text, **kwargs)
-
-
-def _parse_annotation(annotation: str, env: BuildEnvironment = None) -> List[Node]:
+                        refdomain='py', reftype=reftype, reftarget=target,
+                        refspecific=refspecific, **kwargs)
+
+
+def _parse_annotation(annotation: str, env: BuildEnvironment) -> List[Node]:
     """Parse type annotation."""
     def unparse(node: ast.AST) -> List[Node]:
         if isinstance(node, ast.Attribute):
@@ -118,16 +137,28 @@
             result.extend(unparse(node.right))
             return result
         elif isinstance(node, ast.BitOr):
-            return [nodes.Text(' '), addnodes.desc_sig_punctuation('', '|'), nodes.Text(' ')]
+            return [addnodes.desc_sig_space(),
+                    addnodes.desc_sig_punctuation('', '|'),
+                    addnodes.desc_sig_space()]
         elif isinstance(node, ast.Constant):  # type: ignore
             if node.value is Ellipsis:
                 return [addnodes.desc_sig_punctuation('', "...")]
-            else:
+            elif isinstance(node.value, bool):
+                return [addnodes.desc_sig_keyword('', repr(node.value))]
+            elif isinstance(node.value, int):
+                return [addnodes.desc_sig_literal_number('', repr(node.value))]
+            elif isinstance(node.value, str):
+                return [addnodes.desc_sig_literal_string('', repr(node.value))]
+            else:
+                # handles None, which is further handled by type_to_xref later
+                # and fallback for other types that should be converted
                 return [nodes.Text(repr(node.value))]
         elif isinstance(node, ast.Expr):
             return unparse(node.value)
         elif isinstance(node, ast.Index):
             return unparse(node.value)
+        elif isinstance(node, ast.Invert):
+            return [addnodes.desc_sig_punctuation('', '~')]
         elif isinstance(node, ast.List):
             result = [addnodes.desc_sig_punctuation('', '[')]
             if node.elts:
@@ -136,7 +167,9 @@
                 # once
                 for elem in node.elts:
                     result.extend(unparse(elem))
-                    result.append(addnodes.desc_sig_punctuation('', ', '))
+                    result.append(addnodes.desc_sig_punctuation('', ','))
+                    result.append(addnodes.desc_sig_space())
+                result.pop()
                 result.pop()
             result.append(addnodes.desc_sig_punctuation('', ']'))
             return result
@@ -156,12 +189,16 @@
                     if isinstance(subnode, nodes.Text):
                         result[i] = nodes.literal('', '', subnode)
             return result
+        elif isinstance(node, ast.UnaryOp):
+            return unparse(node.op) + unparse(node.operand)
         elif isinstance(node, ast.Tuple):
             if node.elts:
                 result = []
                 for elem in node.elts:
                     result.extend(unparse(elem))
-                    result.append(addnodes.desc_sig_punctuation('', ', '))
+                    result.append(addnodes.desc_sig_punctuation('', ','))
+                    result.append(addnodes.desc_sig_space())
+                result.pop()
                 result.pop()
             else:
                 result = [addnodes.desc_sig_punctuation('', '('),
@@ -170,31 +207,42 @@
             return result
         else:
             if sys.version_info < (3, 8):
-                if isinstance(node, ast.Ellipsis):
+                if isinstance(node, ast.Bytes):
+                    return [addnodes.desc_sig_literal_string('', repr(node.s))]
+                elif isinstance(node, ast.Ellipsis):
                     return [addnodes.desc_sig_punctuation('', "...")]
                 elif isinstance(node, ast.NameConstant):
                     return [nodes.Text(node.value)]
+                elif isinstance(node, ast.Num):
+                    return [addnodes.desc_sig_literal_string('', repr(node.n))]
+                elif isinstance(node, ast.Str):
+                    return [addnodes.desc_sig_literal_string('', repr(node.s))]
 
             raise SyntaxError  # unsupported syntax
-
-    if env is None:
-        warnings.warn("The env parameter for _parse_annotation becomes required now.",
-                      RemovedInSphinx50Warning, stacklevel=2)
 
     try:
         tree = ast_parse(annotation)
-        result = unparse(tree)
-        for i, node in enumerate(result):
+        result: List[Node] = []
+        for node in unparse(tree):
             if isinstance(node, nodes.literal):
-                result[i] = node[0]
+                result.append(node[0])
             elif isinstance(node, nodes.Text) and node.strip():
-                result[i] = type_to_xref(str(node), env)
+                if (result and isinstance(result[-1], addnodes.desc_sig_punctuation) and
+                        result[-1].astext() == '~'):
+                    result.pop()
+                    result.append(type_to_xref(str(node), env, suppress_prefix=True))
+                else:
+                    result.append(type_to_xref(str(node), env))
+            else:
+                result.append(node)
         return result
     except SyntaxError:
         return [type_to_xref(annotation, env)]
 
 
-def _parse_arglist(arglist: str, env: BuildEnvironment = None) -> addnodes.desc_parameterlist:
+def _parse_arglist(
+    arglist: str, env: Optional[BuildEnvironment] = None
+) -> addnodes.desc_parameterlist:
     """Parse a list of arguments using AST parser"""
     params = addnodes.desc_parameterlist(arglist)
     sig = signature_from_str('(%s)' % arglist)
@@ -222,13 +270,13 @@
         if param.annotation is not param.empty:
             children = _parse_annotation(param.annotation, env)
             node += addnodes.desc_sig_punctuation('', ':')
-            node += nodes.Text(' ')
+            node += addnodes.desc_sig_space()
             node += addnodes.desc_sig_name('', '', *children)  # type: ignore
         if param.default is not param.empty:
             if param.annotation is not param.empty:
-                node += nodes.Text(' ')
+                node += addnodes.desc_sig_space()
                 node += addnodes.desc_sig_operator('', '=')
-                node += nodes.Text(' ')
+                node += addnodes.desc_sig_space()
             else:
                 node += addnodes.desc_sig_operator('', '=')
             node += nodes.inline('', param.default, classes=['default_value'],
@@ -271,7 +319,8 @@
                 ends_open += 1
                 argument = argument[:-1].strip()
             if argument:
-                stack[-1] += addnodes.desc_parameter(argument, argument)
+                stack[-1] += addnodes.desc_parameter(
+                    '', '', addnodes.desc_sig_name(argument, argument))
             while ends_open:
                 stack.append(addnodes.desc_optional())
                 stack[-2] += stack[-1]
@@ -304,27 +353,27 @@
         result = super().make_xref(rolename, domain, target,  # type: ignore
                                    innernode, contnode,
                                    env, inliner=None, location=None)
-        result['refspecific'] = True
-        result['py:module'] = env.ref_context.get('py:module')
-        result['py:class'] = env.ref_context.get('py:class')
-        if target.startswith(('.', '~')):
-            prefix, result['reftarget'] = target[0], target[1:]
-            if prefix == '.':
-                text = target[1:]
-            elif prefix == '~':
-                text = target.split('.')[-1]
-            for node in result.traverse(nodes.Text):
-                node.parent[node.parent.index(node)] = nodes.Text(text)
-                break
-        elif isinstance(result, pending_xref) and env.config.python_use_unqualified_type_names:
-            children = result.children
-            result.clear()
-
-            shortname = target.split('.')[-1]
-            textnode = innernode('', shortname)
-            contnodes = [pending_xref_condition('', '', textnode, condition='resolved'),
-                         pending_xref_condition('', '', *children, condition='*')]
-            result.extend(contnodes)
+        if isinstance(result, pending_xref):
+            result['refspecific'] = True
+            result['py:module'] = env.ref_context.get('py:module')
+            result['py:class'] = env.ref_context.get('py:class')
+
+            reftype, reftarget, reftitle, _ = parse_reftarget(target)
+            if reftarget != reftitle:
+                result['reftype'] = reftype
+                result['reftarget'] = reftarget
+
+                result.clear()
+                result += innernode(reftitle, reftitle)
+            elif env.config.python_use_unqualified_type_names:
+                children = result.children
+                result.clear()
+
+                shortname = target.split('.')[-1]
+                textnode = innernode('', shortname)
+                contnodes = [pending_xref_condition('', '', textnode, condition='resolved'),
+                             pending_xref_condition('', '', *children, condition='*')]
+                result.extend(contnodes)
 
         return result
 
@@ -332,37 +381,32 @@
                    innernode: Type[TextlikeNode] = nodes.emphasis,
                    contnode: Node = None, env: BuildEnvironment = None,
                    inliner: Inliner = None, location: Node = None) -> List[Node]:
-        delims = r'(\s*[\[\]\(\),](?:\s*or\s)?\s*|\s+or\s+|\s*\|\s*|\.\.\.)'
+        delims = r'(\s*[\[\]\(\),](?:\s*o[rf]\s)?\s*|\s+o[rf]\s+|\s*\|\s*|\.\.\.)'
         delims_re = re.compile(delims)
         sub_targets = re.split(delims, target)
 
         split_contnode = bool(contnode and contnode.astext() == target)
 
+        in_literal = False
         results = []
         for sub_target in filter(None, sub_targets):
             if split_contnode:
                 contnode = nodes.Text(sub_target)
 
-            if delims_re.match(sub_target):
+            if in_literal or delims_re.match(sub_target):
                 results.append(contnode or innernode(sub_target, sub_target))
             else:
                 results.append(self.make_xref(rolename, domain, sub_target,
                                               innernode, contnode, env, inliner, location))
 
+            if sub_target in ('Literal', 'typing.Literal', '~typing.Literal'):
+                in_literal = True
+
         return results
 
 
 class PyField(PyXrefMixin, Field):
-    def make_xref(self, rolename: str, domain: str, target: str,
-                  innernode: Type[TextlikeNode] = nodes.emphasis,
-                  contnode: Node = None, env: BuildEnvironment = None,
-                  inliner: Inliner = None, location: Node = None) -> Node:
-        if rolename == 'class' and target == 'None':
-            # None is not a type, so use obj role instead.
-            rolename = 'obj'
-
-        return super().make_xref(rolename, domain, target, innernode, contnode,
-                                 env, inliner, location)
+    pass
 
 
 class PyGroupedField(PyXrefMixin, GroupedField):
@@ -370,16 +414,7 @@
 
 
 class PyTypedField(PyXrefMixin, TypedField):
-    def make_xref(self, rolename: str, domain: str, target: str,
-                  innernode: Type[TextlikeNode] = nodes.emphasis,
-                  contnode: Node = None, env: BuildEnvironment = None,
-                  inliner: Inliner = None, location: Node = None) -> Node:
-        if rolename == 'class' and target == 'None':
-            # None is not a type, so use obj role instead.
-            rolename = 'obj'
-
-        return super().make_xref(rolename, domain, target, innernode, contnode,
-                                 env, inliner, location)
+    pass
 
 
 class PyObject(ObjectDescription[Tuple[str, str]]):
@@ -418,11 +453,11 @@
 
     allow_nesting = False
 
-    def get_signature_prefix(self, sig: str) -> str:
+    def get_signature_prefix(self, sig: str) -> List[nodes.Node]:
         """May return a prefix to put before the object name in the
         signature.
         """
-        return ''
+        return []
 
     def needs_arglist(self) -> bool:
         """May return true if an empty argument list is to be generated even if
@@ -476,7 +511,17 @@
 
         sig_prefix = self.get_signature_prefix(sig)
         if sig_prefix:
-            signode += addnodes.desc_annotation(sig_prefix, sig_prefix)
+            if type(sig_prefix) is str:
+                warnings.warn(
+                    "Python directive method get_signature_prefix()"
+                    " returning a string is deprecated."
+                    " It must now return a list of nodes."
+                    " Return value was '{}'.".format(sig_prefix),
+                    RemovedInSphinx60Warning)
+                signode += addnodes.desc_annotation(sig_prefix, '',  # type: ignore
+                                                    nodes.Text(sig_prefix))  # type: ignore
+            else:
+                signode += addnodes.desc_annotation(str(sig_prefix), '', *sig_prefix)
 
         if prefix:
             signode += addnodes.desc_addname(prefix, prefix)
@@ -507,9 +552,22 @@
 
         anno = self.options.get('annotation')
         if anno:
-            signode += addnodes.desc_annotation(' ' + anno, ' ' + anno)
+            signode += addnodes.desc_annotation(' ' + anno, '',
+                                                addnodes.desc_sig_space(),
+                                                nodes.Text(anno))
 
         return fullname, prefix
+
+    def _object_hierarchy_parts(self, sig_node: desc_signature) -> Tuple[str, ...]:
+        if 'fullname' not in sig_node:
+            return ()
+        modname = sig_node.get('module')
+        fullname = sig_node['fullname']
+
+        if modname:
+            return (modname, *fullname.split('.'))
+        else:
+            return tuple(fullname.split('.'))
 
     def get_index_text(self, modname: str, name: Tuple[str, str]) -> str:
         """Return the text for the index entry of the object."""
@@ -521,12 +579,6 @@
         fullname = (modname + '.' if modname else '') + name_cls[0]
         node_id = make_id(self.env, self.state.document, '', fullname)
         signode['ids'].append(node_id)
-
-        # Assign old styled node_id(fullname) not to break old hyperlinks (if possible)
-        # Note: Will removed in Sphinx-5.0  (RemovedInSphinx50Warning)
-        if node_id != fullname and fullname not in self.state.document.ids:
-            signode['ids'].append(fullname)
-
         self.state.document.note_explicit_target(signode)
 
         domain = cast(PythonDomain, self.env.get_domain('py'))
@@ -600,6 +652,25 @@
             else:
                 self.env.ref_context.pop('py:module')
 
+    def _toc_entry_name(self, sig_node: desc_signature) -> str:
+        if not sig_node.get('_toc_parts'):
+            return ''
+
+        config = self.env.app.config
+        objtype = sig_node.parent.get('objtype')
+        if config.add_function_parentheses and objtype in {'function', 'method'}:
+            parens = '()'
+        else:
+            parens = ''
+        *parents, name = sig_node['_toc_parts']
+        if config.toc_object_entries_show_parents == 'domain':
+            return sig_node.get('fullname', name) + parens
+        if config.toc_object_entries_show_parents == 'hide':
+            return name + parens
+        if config.toc_object_entries_show_parents == 'all':
+            return '.'.join(parents + [name + parens])
+        return ''
+
 
 class PyFunction(PyObject):
     """Description of a function."""
@@ -609,11 +680,12 @@
         'async': directives.flag,
     })
 
-    def get_signature_prefix(self, sig: str) -> str:
+    def get_signature_prefix(self, sig: str) -> List[nodes.Node]:
         if 'async' in self.options:
-            return 'async '
+            return [addnodes.desc_sig_keyword('', 'async'),
+                    addnodes.desc_sig_space()]
         else:
-            return ''
+            return []
 
     def needs_arglist(self) -> bool:
         return True
@@ -670,11 +742,17 @@
         typ = self.options.get('type')
         if typ:
             annotations = _parse_annotation(typ, self.env)
-            signode += addnodes.desc_annotation(typ, '', nodes.Text(': '), *annotations)
+            signode += addnodes.desc_annotation(typ, '',
+                                                addnodes.desc_sig_punctuation('', ':'),
+                                                addnodes.desc_sig_space(), *annotations)
 
         value = self.options.get('value')
         if value:
-            signode += addnodes.desc_annotation(value, ' = ' + value)
+            signode += addnodes.desc_annotation(value, '',
+                                                addnodes.desc_sig_space(),
+                                                addnodes.desc_sig_punctuation('', '='),
+                                                addnodes.desc_sig_space(),
+                                                nodes.Text(value))
 
         return fullname, prefix
 
@@ -698,11 +776,12 @@
 
     allow_nesting = True
 
-    def get_signature_prefix(self, sig: str) -> str:
+    def get_signature_prefix(self, sig: str) -> List[nodes.Node]:
         if 'final' in self.options:
-            return 'final %s ' % self.objtype
+            return [nodes.Text('final'), addnodes.desc_sig_space(),
+                    nodes.Text(self.objtype), addnodes.desc_sig_space()]
         else:
-            return '%s ' % self.objtype
+            return [nodes.Text(self.objtype), addnodes.desc_sig_space()]
 
     def get_index_text(self, modname: str, name_cls: Tuple[str, str]) -> str:
         if self.objtype == 'class':
@@ -734,25 +813,29 @@
         else:
             return True
 
-    def get_signature_prefix(self, sig: str) -> str:
-        prefix = []
+    def get_signature_prefix(self, sig: str) -> List[nodes.Node]:
+        prefix: List[nodes.Node] = []
         if 'final' in self.options:
-            prefix.append('final')
+            prefix.append(nodes.Text('final'))
+            prefix.append(addnodes.desc_sig_space())
         if 'abstractmethod' in self.options:
-            prefix.append('abstract')
+            prefix.append(nodes.Text('abstract'))
+            prefix.append(addnodes.desc_sig_space())
         if 'async' in self.options:
-            prefix.append('async')
+            prefix.append(nodes.Text('async'))
+            prefix.append(addnodes.desc_sig_space())
         if 'classmethod' in self.options:
-            prefix.append('classmethod')
+            prefix.append(nodes.Text('classmethod'))
+            prefix.append(addnodes.desc_sig_space())
         if 'property' in self.options:
-            prefix.append('property')
+            logger.warning(_('Using the :property: flag with the py:method directive'
+                             'is deprecated, use ".. py:property::" instead.'))
+            prefix.append(nodes.Text('property'))
+            prefix.append(addnodes.desc_sig_space())
         if 'staticmethod' in self.options:
-            prefix.append('static')
-
-        if prefix:
-            return ' '.join(prefix) + ' '
-        else:
-            return ''
+            prefix.append(nodes.Text('static'))
+            prefix.append(addnodes.desc_sig_space())
+        return prefix
 
     def get_index_text(self, modname: str, name_cls: Tuple[str, str]) -> str:
         name, cls = name_cls
@@ -769,7 +852,7 @@
         if 'classmethod' in self.options:
             return _('%s() (%s class method)') % (methname, clsname)
         elif 'property' in self.options:
-            return _('%s() (%s property)') % (methname, clsname)
+            return _('%s (%s property)') % (methname, clsname)
         elif 'staticmethod' in self.options:
             return _('%s() (%s static method)') % (methname, clsname)
         else:
@@ -831,11 +914,18 @@
         typ = self.options.get('type')
         if typ:
             annotations = _parse_annotation(typ, self.env)
-            signode += addnodes.desc_annotation(typ, '', nodes.Text(': '), *annotations)
+            signode += addnodes.desc_annotation(typ, '',
+                                                addnodes.desc_sig_punctuation('', ':'),
+                                                addnodes.desc_sig_space(),
+                                                *annotations)
 
         value = self.options.get('value')
         if value:
-            signode += addnodes.desc_annotation(value, ' = ' + value)
+            signode += addnodes.desc_annotation(value, '',
+                                                addnodes.desc_sig_space(),
+                                                addnodes.desc_sig_punctuation('', '='),
+                                                addnodes.desc_sig_space(),
+                                                nodes.Text(value))
 
         return fullname, prefix
 
@@ -870,19 +960,25 @@
         typ = self.options.get('type')
         if typ:
             annotations = _parse_annotation(typ, self.env)
-            signode += addnodes.desc_annotation(typ, '', nodes.Text(': '), *annotations)
+            signode += addnodes.desc_annotation(typ, '',
+                                                addnodes.desc_sig_punctuation('', ':'),
+                                                addnodes.desc_sig_space(),
+                                                *annotations)
 
         return fullname, prefix
 
-    def get_signature_prefix(self, sig: str) -> str:
-        prefix = []
+    def get_signature_prefix(self, sig: str) -> List[nodes.Node]:
+        prefix: List[nodes.Node] = []
         if 'abstractmethod' in self.options:
-            prefix.append('abstract')
+            prefix.append(nodes.Text('abstract'))
+            prefix.append(addnodes.desc_sig_space())
         if 'classmethod' in self.options:
-            prefix.append('class')
-
-        prefix.append('property')
-        return ' '.join(prefix) + ' '
+            prefix.append(nodes.Text('class'))
+            prefix.append(addnodes.desc_sig_space())
+
+        prefix.append(nodes.Text('property'))
+        prefix.append(addnodes.desc_sig_space())
+        return prefix
 
     def get_index_text(self, modname: str, name_cls: Tuple[str, str]) -> str:
         name, cls = name_cls
@@ -899,35 +995,12 @@
         return _('%s (%s property)') % (attrname, clsname)
 
 
-class PyDecoratorMixin:
-    """
-    Mixin for decorator directives.
-    """
-    def handle_signature(self, sig: str, signode: desc_signature) -> Tuple[str, str]:
-        for cls in self.__class__.__mro__:
-            if cls.__name__ != 'DirectiveAdapter':
-                warnings.warn('PyDecoratorMixin is deprecated. '
-                              'Please check the implementation of %s' % cls,
-                              RemovedInSphinx50Warning, stacklevel=2)
-                break
-        else:
-            warnings.warn('PyDecoratorMixin is deprecated',
-                          RemovedInSphinx50Warning, stacklevel=2)
-
-        ret = super().handle_signature(sig, signode)  # type: ignore
-        signode.insert(0, addnodes.desc_addname('@', '@'))
-        return ret
-
-    def needs_arglist(self) -> bool:
-        return False
-
-
 class PyModule(SphinxDirective):
     """
     Directive to mark description of a new module.
     """
 
-    has_content = False
+    has_content = True
     required_arguments = 1
     optional_arguments = 0
     final_argument_whitespace = False
@@ -944,19 +1017,19 @@
         modname = self.arguments[0].strip()
         noindex = 'noindex' in self.options
         self.env.ref_context['py:module'] = modname
-        ret: List[Node] = []
+
+        content_node: Element = nodes.section()
+        with switch_source_input(self.state, self.content):
+            # necessary so that the child nodes get the right source/line set
+            content_node.document = self.state.document
+            nested_parse_with_titles(self.state, self.content, content_node)
+
+        ret: List[Node] = [*content_node.children]
         if not noindex:
             # note module to the domain
             node_id = make_id(self.env, self.state.document, 'module', modname)
             target = nodes.target('', '', ids=[node_id], ismod=True)
             self.set_source_info(target)
-
-            # Assign old styled node_id not to break old hyperlinks (if possible)
-            # Note: Will removed in Sphinx-5.0  (RemovedInSphinx50Warning)
-            old_node_id = self.make_old_id(modname)
-            if node_id != old_node_id and old_node_id not in self.state.document.ids:
-                target['ids'].append(old_node_id)
-
             self.state.document.note_explicit_target(target)
 
             domain.note_module(modname,
@@ -1037,11 +1110,11 @@
     for node in content:
         if isinstance(node, nodes.field_list):
             fields = cast(List[nodes.field], node)
-            for field in fields:
+            # removing list items while iterating the list needs reversed()
+            for field in reversed(fields):
                 field_name = cast(nodes.field_body, field[0]).astext().strip()
                 if field_name == 'meta' or field_name.startswith('meta '):
                     node.remove(field)
-                    break
 
 
 class PythonModuleIndex(Index):
@@ -1334,7 +1407,14 @@
 
         # always search in "refspecific" mode with the :any: role
         matches = self.find_obj(env, modname, clsname, target, None, 1)
+        multiple_matches = len(matches) > 1
+
         for name, obj in matches:
+
+            if multiple_matches and obj.aliased:
+                # Skip duplicated matches
+                continue
+
             if obj[2] == 'module':
                 results.append(('py:mod',
                                 self._make_module_refnode(builder, fromdocname,
@@ -1395,13 +1475,13 @@
         if s.startswith('typing.'):
             s = s.split('.', 1)[1]
 
-        return s in typing.__all__  # type: ignore
+        return s in typing.__all__
 
     if node.get('refdomain') != 'py':
         return None
     elif node.get('reftype') in ('class', 'obj') and node.get('reftarget') == 'None':
         return contnode
-    elif node.get('reftype') in ('class', 'exc'):
+    elif node.get('reftype') in ('class', 'obj', 'exc'):
         reftarget = node.get('reftarget')
         if inspect.isclass(getattr(builtins, reftarget, None)):
             # built-in class
('sphinx/domains', 'math.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.domains.math
-    ~~~~~~~~~~~~~~~~~~~
-
-    The math domain.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""The math domain."""
 
 from typing import TYPE_CHECKING, Any, Dict, Iterable, List, Optional, Tuple
 
@@ -78,10 +70,10 @@
         def math_node(node: Node) -> bool:
             return isinstance(node, (nodes.math, nodes.math_block))
 
-        self.data['has_equations'][docname] = any(document.traverse(math_node))
+        self.data['has_equations'][docname] = any(document.findall(math_node))
 
     def clear_doc(self, docname: str) -> None:
-        for equation_id, (doc, eqno) in list(self.equations.items()):
+        for equation_id, (doc, _eqno) in list(self.equations.items()):
             if doc == docname:
                 del self.equations[equation_id]
 
('sphinx/domains', 'javascript.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.domains.javascript
-    ~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    The JavaScript domain.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""The JavaScript domain."""
 
 from typing import Any, Dict, Iterator, List, Optional, Tuple, cast
 
@@ -26,8 +18,8 @@
 from sphinx.roles import XRefRole
 from sphinx.util import logging
 from sphinx.util.docfields import Field, GroupedField, TypedField
-from sphinx.util.docutils import SphinxDirective
-from sphinx.util.nodes import make_id, make_refnode
+from sphinx.util.docutils import SphinxDirective, switch_source_input
+from sphinx.util.nodes import make_id, make_refnode, nested_parse_with_titles
 from sphinx.util.typing import OptionSpec
 
 logger = logging.getLogger(__name__)
@@ -41,9 +33,6 @@
     #: added
     has_arguments = False
 
-    #: what is displayed right before the documentation entry
-    display_prefix: str = None
-
     #: If ``allow_nesting`` is ``True``, the object prefixes will be accumulated
     #: based on directive nesting
     allow_nesting = False
@@ -52,6 +41,10 @@
         'noindex': directives.flag,
         'noindexentry': directives.flag,
     }
+
+    def get_display_prefix(self) -> List[Node]:
+        #: what is displayed right before the documentation entry
+        return []
 
     def handle_signature(self, sig: str, signode: desc_signature) -> Tuple[str, str]:
         """Breaks down construct signatures
@@ -71,6 +64,7 @@
         # If construct is nested, prefix the current prefix
         prefix = self.env.ref_context.get('js:object', None)
         mod_name = self.env.ref_context.get('js:module')
+
         name = member
         try:
             member_prefix, member_name = member.rsplit('.', 1)
@@ -91,14 +85,22 @@
         signode['object'] = prefix
         signode['fullname'] = fullname
 
-        if self.display_prefix:
-            signode += addnodes.desc_annotation(self.display_prefix,
-                                                self.display_prefix)
+        display_prefix = self.get_display_prefix()
+        if display_prefix:
+            signode += addnodes.desc_annotation('', '', *display_prefix)
+
+        actual_prefix = None
         if prefix:
-            signode += addnodes.desc_addname(prefix + '.', prefix + '.')
+            actual_prefix = prefix
         elif mod_name:
-            signode += addnodes.desc_addname(mod_name + '.', mod_name + '.')
-        signode += addnodes.desc_name(name, name)
+            actual_prefix = mod_name
+        if actual_prefix:
+            addName = addnodes.desc_addname('', '')
+            for p in actual_prefix.split('.'):
+                addName += addnodes.desc_sig_name(p, p)
+                addName += addnodes.desc_sig_punctuation('.', '.')
+            signode += addName
+        signode += addnodes.desc_name('', '', addnodes.desc_sig_name(name, name))
         if self.has_arguments:
             if not arglist:
                 signode += addnodes.desc_parameterlist()
@@ -106,19 +108,23 @@
                 _pseudo_parse_arglist(signode, arglist)
         return fullname, prefix
 
+    def _object_hierarchy_parts(self, sig_node: desc_signature) -> Tuple[str, ...]:
+        if 'fullname' not in sig_node:
+            return ()
+        modname = sig_node.get('module')
+        fullname = sig_node['fullname']
+
+        if modname:
+            return (modname, *fullname.split('.'))
+        else:
+            return tuple(fullname.split('.'))
+
     def add_target_and_index(self, name_obj: Tuple[str, str], sig: str,
                              signode: desc_signature) -> None:
         mod_name = self.env.ref_context.get('js:module')
         fullname = (mod_name + '.' if mod_name else '') + name_obj[0]
         node_id = make_id(self.env, self.state.document, '', fullname)
         signode['ids'].append(node_id)
-
-        # Assign old styled node_id not to break old hyperlinks (if possible)
-        # Note: Will be removed in Sphinx-5.0 (RemovedInSphinx50Warning)
-        old_node_id = self.make_old_id(fullname)
-        if old_node_id not in self.state.document.ids and old_node_id not in signode['ids']:
-            signode['ids'].append(old_node_id)
-
         self.state.document.note_explicit_target(signode)
 
         domain = cast(JavaScriptDomain, self.env.get_domain('js'))
@@ -206,6 +212,25 @@
         """
         return fullname.replace('$', '_S_')
 
+    def _toc_entry_name(self, sig_node: desc_signature) -> str:
+        if not sig_node.get('_toc_parts'):
+            return ''
+
+        config = self.env.app.config
+        objtype = sig_node.parent.get('objtype')
+        if config.add_function_parentheses and objtype in {'function', 'method'}:
+            parens = '()'
+        else:
+            parens = ''
+        *parents, name = sig_node['_toc_parts']
+        if config.toc_object_entries_show_parents == 'domain':
+            return sig_node.get('fullname', name) + parens
+        if config.toc_object_entries_show_parents == 'hide':
+            return name + parens
+        if config.toc_object_entries_show_parents == 'all':
+            return '.'.join(parents + [name + parens])
+        return ''
+
 
 class JSCallable(JSObject):
     """Description of a JavaScript function, method or constructor."""
@@ -227,8 +252,12 @@
 
 class JSConstructor(JSCallable):
     """Like a callable but with a different prefix."""
-    display_prefix = 'class '
+
     allow_nesting = True
+
+    def get_display_prefix(self) -> List[Node]:
+        return [addnodes.desc_sig_keyword('class', 'class'),
+                addnodes.desc_sig_space()]
 
 
 class JSModule(SphinxDirective):
@@ -250,7 +279,7 @@
     :param mod_name: Module name
     """
 
-    has_content = False
+    has_content = True
     required_arguments = 1
     optional_arguments = 0
     final_argument_whitespace = False
@@ -262,7 +291,14 @@
         mod_name = self.arguments[0].strip()
         self.env.ref_context['js:module'] = mod_name
         noindex = 'noindex' in self.options
-        ret: List[Node] = []
+
+        content_node: Element = nodes.section()
+        with switch_source_input(self.state, self.content):
+            # necessary so that the child nodes get the right source/line set
+            content_node.document = self.state.document
+            nested_parse_with_titles(self.state, self.content, content_node)
+
+        ret: List[Node] = [*content_node.children]
         if not noindex:
             domain = cast(JavaScriptDomain, self.env.get_domain('js'))
 
@@ -274,13 +310,6 @@
                                location=(self.env.docname, self.lineno))
 
             target = nodes.target('', '', ids=[node_id], ismod=True)
-
-            # Assign old styled node_id not to break old hyperlinks (if possible)
-            # Note: Will be removed in Sphinx-5.0 (RemovedInSphinx50Warning)
-            old_node_id = self.make_old_id(mod_name)
-            if old_node_id not in self.state.document.ids and old_node_id not in target['ids']:
-                target['ids'].append(old_node_id)
-
             self.state.document.note_explicit_target(target)
             ret.append(target)
             indextext = _('%s (module)') % mod_name
@@ -371,10 +400,10 @@
         self.modules[modname] = (self.env.docname, node_id)
 
     def clear_doc(self, docname: str) -> None:
-        for fullname, (pkg_docname, node_id, _l) in list(self.objects.items()):
+        for fullname, (pkg_docname, _node_id, _l) in list(self.objects.items()):
             if pkg_docname == docname:
                 del self.objects[fullname]
-        for modname, (pkg_docname, node_id) in list(self.modules.items()):
+        for modname, (pkg_docname, _node_id) in list(self.modules.items()):
             if pkg_docname == docname:
                 del self.modules[modname]
 
('sphinx/domains', 'rst.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.domains.rst
-    ~~~~~~~~~~~~~~~~~~
-
-    The reStructuredText domain.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""The reStructuredText domain."""
 
 import re
 from typing import Any, Dict, Iterator, List, Optional, Tuple, cast
@@ -36,25 +28,23 @@
     """
     Description of generic reST markup.
     """
+    option_spec: OptionSpec = {
+        'noindex': directives.flag,
+        'noindexentry': directives.flag,
+    }
 
     def add_target_and_index(self, name: str, sig: str, signode: desc_signature) -> None:
         node_id = make_id(self.env, self.state.document, self.objtype, name)
         signode['ids'].append(node_id)
-
-        # Assign old styled node_id not to break old hyperlinks (if possible)
-        # Note: Will be removed in Sphinx-5.0 (RemovedInSphinx50Warning)
-        old_node_id = self.make_old_id(name)
-        if old_node_id not in self.state.document.ids and old_node_id not in signode['ids']:
-            signode['ids'].append(old_node_id)
-
         self.state.document.note_explicit_target(signode)
 
         domain = cast(ReSTDomain, self.env.get_domain('rst'))
         domain.note_object(self.objtype, name, node_id, location=signode)
 
-        indextext = self.get_index_text(self.objtype, name)
-        if indextext:
-            self.indexnode['entries'].append(('single', indextext, node_id, '', None))
+        if 'noindexentry' not in self.options:
+            indextext = self.get_index_text(self.objtype, name)
+            if indextext:
+                self.indexnode['entries'].append(('single', indextext, node_id, '', None))
 
     def get_index_text(self, objectname: str, name: str) -> str:
         return ''
@@ -66,6 +56,32 @@
                   This will be removed in Sphinx-5.0.
         """
         return self.objtype + '-' + name
+
+    def _object_hierarchy_parts(self, sig_node: desc_signature) -> Tuple[str, ...]:
+        if 'fullname' not in sig_node:
+            return ()
+        directive_names = []
+        for parent in self.env.ref_context.get('rst:directives', ()):
+            directive_names += parent.split(':')
+        name = sig_node['fullname']
+        return tuple(directive_names + name.split(':'))
+
+    def _toc_entry_name(self, sig_node: desc_signature) -> str:
+        if not sig_node.get('_toc_parts'):
+            return ''
+
+        config = self.env.app.config
+        objtype = sig_node.parent.get('objtype')
+        *parents, name = sig_node['_toc_parts']
+        if objtype == 'directive:option':
+            return f':{name}:'
+        if config.toc_object_entries_show_parents in {'domain', 'all'}:
+            name = ':'.join(sig_node['_toc_parts'])
+        if objtype == 'role':
+            return f':{name}:'
+        if objtype == 'directive':
+            return f'.. {name}::'
+        return ''
 
 
 def parse_directive(d: str) -> Tuple[str, str]:
@@ -94,7 +110,8 @@
     """
     def handle_signature(self, sig: str, signode: desc_signature) -> str:
         name, args = parse_directive(sig)
-        desc_name = '.. %s::' % name
+        desc_name = f'.. {name}::'
+        signode['fullname'] = name.strip()
         signode += addnodes.desc_name(desc_name, desc_name)
         if len(args) > 0:
             signode += addnodes.desc_addname(args, args)
@@ -129,7 +146,9 @@
         except ValueError:
             name, argument = sig, None
 
-        signode += addnodes.desc_name(':%s:' % name, ':%s:' % name)
+        desc_name = f':{name}:'
+        signode['fullname'] = name.strip()
+        signode += addnodes.desc_name(desc_name, desc_name)
         if argument:
             signode += addnodes.desc_annotation(' ' + argument, ' ' + argument)
         if self.options.get('type'):
@@ -150,13 +169,6 @@
 
         node_id = make_id(self.env, self.state.document, prefix, name)
         signode['ids'].append(node_id)
-
-        # Assign old styled node_id not to break old hyperlinks (if possible)
-        # Note: Will be removed in Sphinx-5.0 (RemovedInSphinx50Warning)
-        old_node_id = self.make_old_id(name)
-        if old_node_id not in self.state.document.ids and old_node_id not in signode['ids']:
-            signode['ids'].append(old_node_id)
-
         self.state.document.note_explicit_target(signode)
         domain.note_object(self.objtype, objname, node_id, location=signode)
 
@@ -192,7 +204,9 @@
     Description of a reST role.
     """
     def handle_signature(self, sig: str, signode: desc_signature) -> str:
-        signode += addnodes.desc_name(':%s:' % sig, ':%s:' % sig)
+        desc_name = f':{sig}:'
+        signode['fullname'] = sig.strip()
+        signode += addnodes.desc_name(desc_name, desc_name)
         return sig
 
     def get_index_text(self, objectname: str, name: str) -> str:
@@ -235,7 +249,7 @@
         self.objects[objtype, name] = (self.env.docname, node_id)
 
     def clear_doc(self, docname: str) -> None:
-        for (typ, name), (doc, node_id) in list(self.objects.items()):
+        for (typ, name), (doc, _node_id) in list(self.objects.items()):
             if doc == docname:
                 del self.objects[typ, name]
 
('sphinx/locale', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.locale
-    ~~~~~~~~~~~~~
-
-    Locale utilities.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Locale utilities."""
 
 import gettext
 import locale
@@ -67,19 +59,19 @@
     def __add__(self, other: str) -> str:  # type: ignore
         return self.data + other
 
-    def __radd__(self, other: str) -> str:
+    def __radd__(self, other: str) -> str:  # type: ignore
         return other + self.data
 
     def __mod__(self, other: str) -> str:  # type: ignore
         return self.data % other
 
-    def __rmod__(self, other: str) -> str:
+    def __rmod__(self, other: str) -> str:  # type: ignore
         return other % self.data
 
     def __mul__(self, other: Any) -> str:  # type: ignore
         return self.data * other
 
-    def __rmul__(self, other: Any) -> str:
+    def __rmul__(self, other: Any) -> str:  # type: ignore
         return other * self.data
 
     def __getattr__(self, name: str) -> Any:
@@ -148,7 +140,7 @@
     return translator, has_translation
 
 
-def setlocale(category: int, value: Union[str, Iterable[str]] = None) -> None:
+def setlocale(category: int, value: Union[str, Iterable[str], None] = None) -> None:
     """Update locale settings.
 
     This does not throw any exception even if update fails.
@@ -175,7 +167,7 @@
     """
     try:
         # encoding is ignored
-        language, _ = locale.getlocale(locale.LC_MESSAGES)  # type: Tuple[Optional[str], Any]
+        language, _ = locale.getlocale(locale.LC_MESSAGES)
     except AttributeError:
         # LC_MESSAGES is not always defined. Fallback to the default language
         # in case it is not.
@@ -199,7 +191,7 @@
     return translator.gettext(message)
 
 
-def get_translation(catalog: str, namespace: str = 'general') -> Callable:
+def get_translation(catalog: str, namespace: str = 'general') -> Callable[[str], str]:
     """Get a translation function based on the *catalog* and *namespace*.
 
     The extension can use this API to translate the messages on the
('sphinx/writers', 'texinfo.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,16 +1,7 @@
-"""
-    sphinx.writers.texinfo
-    ~~~~~~~~~~~~~~~~~~~~~~
-
-    Custom docutils writer for Texinfo.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Custom docutils writer for Texinfo."""
 
 import re
 import textwrap
-import warnings
 from os import path
 from typing import (TYPE_CHECKING, Any, Dict, Iterable, Iterator, List, Optional, Pattern, Set,
                     Tuple, Union, cast)
@@ -19,7 +10,6 @@
 from docutils.nodes import Element, Node, Text
 
 from sphinx import __display_version__, addnodes
-from sphinx.deprecation import RemovedInSphinx50Warning
 from sphinx.domains import IndexEntry
 from sphinx.domains.index import IndexDomain
 from sphinx.errors import ExtensionError
@@ -60,8 +50,6 @@
 @exampleindent %(exampleindent)s
 @finalout
 %(direntry)s
-@definfoenclose strong,`,'
-@definfoenclose emph,`,'
 @c %%**end of header
 
 @copying
@@ -103,7 +91,7 @@
     return result
 
 
-def smart_capwords(s: str, sep: str = None) -> str:
+def smart_capwords(s: str, sep: Optional[str] = None) -> str:
     """Like string.capwords() but does not capitalize words that already
     contain a capital letter."""
     words = s.split(sep)
@@ -127,7 +115,7 @@
 
     settings_defaults: Dict = {}
 
-    output: str = None
+    output: Optional[str] = None  # type: ignore[assignment]
 
     visitor_attributes = ('output', 'fragment')
 
@@ -146,8 +134,8 @@
 
 class TexinfoTranslator(SphinxTranslator):
 
-    builder: "TexinfoBuilder" = None
     ignore_missing_images = False
+    builder: "TexinfoBuilder"
 
     default_elements = {
         'author': '',
@@ -185,17 +173,18 @@
         self.body: List[str] = []
         self.context: List[str] = []
         self.descs: List[addnodes.desc] = []
-        self.previous_section: nodes.section = None
+        self.previous_section: Optional[nodes.section] = None
         self.section_level = 0
         self.seen_title = False
         self.next_section_ids: Set[str] = set()
         self.escape_newlines = 0
         self.escape_hyphens = 0
         self.curfilestack: List[str] = []
-        self.footnotestack: List[Dict[str, List[Union[collected_footnote, bool]]]] = []  # NOQA
+        self.footnotestack: List[Dict[str, List[Union[collected_footnote, bool]]]] = []
         self.in_footnote = 0
+        self.in_samp = 0
         self.handled_abbrs: Set[str] = set()
-        self.colwidths: List[int] = None
+        self.colwidths: List[int] = []
 
     def finish(self) -> None:
         if self.previous_section is None:
@@ -285,7 +274,7 @@
         self.indices = [(add_node_name(name), content)
                         for name, content in self.indices]
         # each section is also a node
-        for section in self.document.traverse(nodes.section):
+        for section in self.document.findall(nodes.section):
             title = cast(nodes.TextElement, section.next_node(nodes.Titular))
             name = title.astext() if title else '<untitled>'
             section['node_name'] = add_node_name(name)
@@ -294,7 +283,7 @@
         """Collect the menu entries for each "node" section."""
         node_menus = self.node_menus
         targets: List[Element] = [self.document]
-        targets.extend(self.document.traverse(nodes.section))
+        targets.extend(self.document.findall(nodes.section))
         for node in targets:
             assert 'node_name' in node and node['node_name']
             entries = [s['node_name'] for s in find_subsections(node)]
@@ -311,7 +300,7 @@
             del node_menus[top['node_name']]
             top['node_name'] = 'Top'
         # handle the indices
-        for name, content in self.indices:
+        for name, _content in self.indices:
             node_menus[name] = []
             node_menus['Top'].append(name)
 
@@ -319,7 +308,7 @@
         """Collect the relative links (next, previous, up) for each "node"."""
         rellinks = self.rellinks
         node_menus = self.node_menus
-        for id, entries in node_menus.items():
+        for id in node_menus:
             rellinks[id] = ['', '', '']
         # up's
         for id, entries in node_menus.items():
@@ -465,7 +454,7 @@
     def collect_indices(self) -> None:
         def generate(content: List[Tuple[str, List[IndexEntry]]], collapsed: bool) -> str:
             ret = ['\n@menu\n']
-            for letter, entries in content:
+            for _letter, entries in content:
                 for entry in entries:
                     if not entry[3]:
                         continue
@@ -545,9 +534,12 @@
     def add_xref(self, id: str, name: str, node: Node) -> None:
         name = self.escape_menu(name)
         sid = self.get_short_id(id)
-        self.body.append('@ref{%s,,%s}' % (sid, name))
-        self.referenced_ids.add(sid)
-        self.referenced_ids.add(self.escape_id(id))
+        if self.config.texinfo_cross_references:
+            self.body.append('@ref{%s,,%s}' % (sid, name))
+            self.referenced_ids.add(sid)
+            self.referenced_ids.add(self.escape_id(id))
+        else:
+            self.body.append(name)
 
     # -- Visiting
 
@@ -773,10 +765,10 @@
         self.ensure_eol()
         self.body.append('@end quotation\n')
 
-    def visit_literal_block(self, node: Element) -> None:
+    def visit_literal_block(self, node: Optional[Element]) -> None:
         self.body.append('\n@example\n')
 
-    def depart_literal_block(self, node: Element) -> None:
+    def depart_literal_block(self, node: Optional[Element]) -> None:
         self.ensure_eol()
         self.body.append('@end example\n')
 
@@ -803,21 +795,33 @@
     # -- Inline
 
     def visit_strong(self, node: Element) -> None:
-        self.body.append('@strong{')
+        self.body.append('`')
 
     def depart_strong(self, node: Element) -> None:
-        self.body.append('}')
+        self.body.append("'")
 
     def visit_emphasis(self, node: Element) -> None:
-        self.body.append('@emph{')
+        if self.in_samp:
+            self.body.append('@var{')
+            self.context.append('}')
+        else:
+            self.body.append('`')
+            self.context.append("'")
 
     def depart_emphasis(self, node: Element) -> None:
-        self.body.append('}')
+        self.body.append(self.context.pop())
+
+    def is_samp(self, node: Element) -> bool:
+        return 'samp' in node['classes']
 
     def visit_literal(self, node: Element) -> None:
+        if self.is_samp(node):
+            self.in_samp += 1
         self.body.append('@code{')
 
     def depart_literal(self, node: Element) -> None:
+        if self.is_samp(node):
+            self.in_samp -= 1
         self.body.append('}')
 
     def visit_superscript(self, node: Element) -> None:
@@ -1006,7 +1010,7 @@
         if len(self.colwidths) != self.n_cols:
             return
         self.body.append('\n\n@multitable ')
-        for i, n in enumerate(self.colwidths):
+        for n in self.colwidths:
             self.body.append('{%s} ' % ('x' * (n + 2)))
 
     def depart_colspec(self, node: Element) -> None:
@@ -1042,7 +1046,7 @@
         self.entry_sep = '@tab'
 
     def depart_entry(self, node: Element) -> None:
-        for i in range(node.get('morecols', 0)):
+        for _i in range(node.get('morecols', 0)):
             self.body.append('\n@tab\n')
 
     # -- Field Lists
@@ -1223,7 +1227,11 @@
         self.depart_topic(node)
 
     def visit_label(self, node: Element) -> None:
-        self.body.append('@w{(')
+        # label numbering is automatically generated by Texinfo
+        if self.in_footnote:
+            raise nodes.SkipNode
+        else:
+            self.body.append('@w{(')
 
     def depart_label(self, node: Element) -> None:
         self.body.append(')} ')
@@ -1263,10 +1271,6 @@
 
     def unimplemented_visit(self, node: Element) -> None:
         logger.warning(__("unimplemented node type: %r"), node,
-                       location=node)
-
-    def unknown_visit(self, node: Node) -> None:
-        logger.warning(__("unknown node type: %r"), node,
                        location=node)
 
     def unknown_departure(self, node: Node) -> None:
@@ -1400,7 +1404,7 @@
         category = self.escape_arg(smart_capwords(name))
         self.body.append('\n%s {%s} ' % (self.at_deffnx, category))
         self.at_deffnx = '@deffnx'
-        self.desc_type_name = name
+        self.desc_type_name: Optional[str] = name
 
     def depart_desc_signature(self, node: Element) -> None:
         self.body.append("\n")
@@ -1550,11 +1554,3 @@
         self.body.append('\n\n@example\n%s\n@end example\n\n' %
                          self.escape_arg(node.astext()))
         raise nodes.SkipNode
-
-    @property
-    def desc(self) -> Optional[addnodes.desc]:
-        warnings.warn('TexinfoWriter.desc is deprecated.', RemovedInSphinx50Warning)
-        if len(self.descs):
-            return self.descs[-1]
-        else:
-            return None
('sphinx/writers', 'manpage.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,17 +1,9 @@
-"""
-    sphinx.writers.manpage
-    ~~~~~~~~~~~~~~~~~~~~~~
-
-    Manual page writer, extended for Sphinx custom nodes.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Manual page writer, extended for Sphinx custom nodes."""
 
 from typing import Any, Dict, Iterable, cast
 
 from docutils import nodes
-from docutils.nodes import Element, Node, TextElement
+from docutils.nodes import Element, TextElement
 from docutils.writers.manpage import Translator as BaseTranslator
 from docutils.writers.manpage import Writer
 
@@ -56,7 +48,7 @@
 
     def apply(self, **kwargs: Any) -> None:
         matcher = NodeMatcher(nodes.literal, nodes.emphasis, nodes.strong)
-        for node in self.document.traverse(matcher):  # type: TextElement
+        for node in list(self.document.findall(matcher)):  # type: TextElement
             if any(matcher(subnode) for subnode in node):
                 pos = node.parent.index(node)
                 for subnode in reversed(list(node)):
@@ -107,7 +99,7 @@
 
         # Overwrite admonition label translations with our own
         for label, translation in admonitionlabels.items():
-            self.language.labels[label] = self.deunicode(translation)  # type: ignore
+            self.language.labels[label] = self.deunicode(translation)
 
     # overwritten -- added quotes around all .TH arguments
     def header(self) -> str:
@@ -227,7 +219,7 @@
 
     # overwritten -- don't make whole of term bold if it includes strong node
     def visit_term(self, node: Element) -> None:
-        if node.traverse(nodes.strong):
+        if any(node.findall(nodes.strong)):
             self.body.append('\n')
         else:
             super().visit_term(node)
@@ -462,6 +454,3 @@
 
     def depart_math_block(self, node: Element) -> None:
         self.depart_centered(node)
-
-    def unknown_visit(self, node: Node) -> None:
-        raise NotImplementedError('Unknown node: ' + node.__class__.__name__)
('sphinx/writers', 'html5.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,18 +1,11 @@
-"""
-    sphinx.writers.html5
-    ~~~~~~~~~~~~~~~~~~~~
-
-    Experimental docutils writers for HTML5 handling Sphinx's custom nodes.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Experimental docutils writers for HTML5 handling Sphinx's custom nodes."""
 
 import os
 import posixpath
 import re
+import urllib.parse
 import warnings
-from typing import TYPE_CHECKING, Iterable, Tuple, cast
+from typing import TYPE_CHECKING, Iterable, Optional, Set, Tuple, cast
 
 from docutils import nodes
 from docutils.nodes import Element, Node, Text
@@ -20,7 +13,7 @@
 
 from sphinx import addnodes
 from sphinx.builders import Builder
-from sphinx.deprecation import RemovedInSphinx50Warning, RemovedInSphinx60Warning
+from sphinx.deprecation import RemovedInSphinx60Warning
 from sphinx.locale import _, __, admonitionlabels
 from sphinx.util import logging
 from sphinx.util.docutils import SphinxTranslator
@@ -54,7 +47,11 @@
     Our custom HTML translator.
     """
 
-    builder: "StandaloneHTMLBuilder" = None
+    builder: "StandaloneHTMLBuilder"
+    # Override docutils.writers.html5_polyglot:HTMLTranslator
+    # otherwise, nodes like <inline classes="s">...</inline> will be
+    # converted to <s>...</s> by `visit_inline`.
+    supported_inline_tags: Set[str] = set()
 
     def __init__(self, document: nodes.document, builder: Builder) -> None:
         super().__init__(document, builder)
@@ -66,8 +63,8 @@
         self.secnumber_suffix = self.config.html_secnumber_suffix
         self.param_separator = ''
         self.optional_param_level = 0
-        self._table_row_index = 0
-        self._fieldlist_row_index = 0
+        self._table_row_indices = [0]
+        self._fieldlist_row_indices = [0]
         self.required_params_left = 0
 
     def visit_start_of_file(self, node: Element) -> None:
@@ -254,13 +251,16 @@
         if name:
             node.insert(0, nodes.title(name, admonitionlabels[name]))
 
+    def depart_admonition(self, node: Optional[Element] = None) -> None:
+        self.body.append('</div>\n')
+
     def visit_seealso(self, node: Element) -> None:
         self.visit_admonition(node, 'seealso')
 
     def depart_seealso(self, node: Element) -> None:
         self.depart_admonition(node)
 
-    def get_secnumber(self, node: Element) -> Tuple[int, ...]:
+    def get_secnumber(self, node: Element) -> Optional[Tuple[int, ...]]:
         if node.get('secnumber'):
             return node['secnumber']
 
@@ -384,12 +384,12 @@
                 node.parent.hasattr('ids') and node.parent['ids']):
             # add permalink anchor
             if close_tag.startswith('</h'):
-                self.add_permalink_ref(node.parent, _('Permalink to this headline'))
+                self.add_permalink_ref(node.parent, _('Permalink to this heading'))
             elif close_tag.startswith('</a></h'):
                 self.body.append('</a><a class="headerlink" href="#%s" ' %
                                  node.parent['ids'][0] +
                                  'title="%s">%s' % (
-                                     _('Permalink to this headline'),
+                                     _('Permalink to this heading'),
                                      self.config.html_permalinks_icon))
             elif isinstance(node.parent, nodes.table):
                 self.body.append('</span>')
@@ -462,10 +462,25 @@
         if 'kbd' in node['classes']:
             self.body.append(self.starttag(node, 'kbd', '',
                                            CLASS='docutils literal notranslate'))
-        else:
+            return
+        lang = node.get("language", None)
+        if 'code' not in node['classes'] or not lang:
             self.body.append(self.starttag(node, 'code', '',
                                            CLASS='docutils literal notranslate'))
             self.protect_literal_text += 1
+            return
+
+        opts = self.config.highlight_options.get(lang, {})
+        highlighted = self.highlighter.highlight_block(
+            node.astext(), lang, opts=opts, location=node, nowrap=True)
+        starttag = self.starttag(
+            node,
+            "code",
+            suffix="",
+            CLASS="docutils literal highlight highlight-%s" % lang,
+        )
+        self.body.append(starttag + highlighted.strip() + "</code>")
+        raise nodes.SkipNode
 
     def depart_literal(self, node: Element) -> None:
         if 'kbd' in node['classes']:
@@ -529,7 +544,8 @@
             self.context.append('</a>')
         elif 'filename' in node:
             atts['class'] += ' internal'
-            atts['href'] = posixpath.join(self.builder.dlpath, node['filename'])
+            atts['href'] = posixpath.join(self.builder.dlpath,
+                                          urllib.parse.quote(node['filename']))
             self.body.append(self.starttag(node, 'a', '', **atts))
             self.context.append('</a>')
         else:
@@ -741,7 +757,7 @@
     # overwritten to add even/odd classes
 
     def visit_table(self, node: Element) -> None:
-        self._table_row_index = 0
+        self._table_row_indices.append(0)
 
         atts = {}
         classes = [cls.strip(' \t\n') for cls in self.settings.table_style.split(',')]
@@ -755,9 +771,13 @@
         tag = self.starttag(node, 'table', CLASS=' '.join(classes), **atts)
         self.body.append(tag)
 
+    def depart_table(self, node: Element) -> None:
+        self._table_row_indices.pop()
+        super().depart_table(node)
+
     def visit_row(self, node: Element) -> None:
-        self._table_row_index += 1
-        if self._table_row_index % 2 == 0:
+        self._table_row_indices[-1] += 1
+        if self._table_row_indices[-1] % 2 == 0:
             node['classes'].append('row-even')
         else:
             node['classes'].append('row-odd')
@@ -765,12 +785,16 @@
         node.column = 0  # type: ignore
 
     def visit_field_list(self, node: Element) -> None:
-        self._fieldlist_row_index = 0
+        self._fieldlist_row_indices.append(0)
         return super().visit_field_list(node)
 
+    def depart_field_list(self, node: Element) -> None:
+        self._fieldlist_row_indices.pop()
+        return super().depart_field_list(node)
+
     def visit_field(self, node: Element) -> None:
-        self._fieldlist_row_index += 1
-        if self._fieldlist_row_index % 2 == 0:
+        self._fieldlist_row_indices[-1] += 1
+        if self._fieldlist_row_indices[-1] % 2 == 0:
             node['classes'].append('field-even')
         else:
             node['classes'].append('field-odd')
@@ -796,15 +820,6 @@
         _, depart = self.builder.app.registry.html_block_math_renderers[name]
         if depart:
             depart(self, node)
-
-    def unknown_visit(self, node: Node) -> None:
-        raise NotImplementedError('Unknown node: ' + node.__class__.__name__)
-
-    @property
-    def permalink_text(self) -> str:
-        warnings.warn('HTMLTranslator.permalink_text is deprecated.',
-                      RemovedInSphinx50Warning, stacklevel=2)
-        return self.config.html_permalinks_icon
 
     def generate_targets_for_table(self, node: Element) -> None:
         """Generate hyperlink targets for tables.
@@ -820,3 +835,15 @@
         for id in node['ids'][1:]:
             self.body.append('<span id="%s"></span>' % id)
             node['ids'].remove(id)
+
+    @property
+    def _fieldlist_row_index(self) -> int:
+        warnings.warn('_fieldlist_row_index is deprecated',
+                      RemovedInSphinx60Warning, stacklevel=2)
+        return self._fieldlist_row_indices[-1]
+
+    @property
+    def _table_row_index(self) -> int:
+        warnings.warn('_table_row_index is deprecated',
+                      RemovedInSphinx60Warning, stacklevel=2)
+        return self._table_row_indices[-1]
('sphinx/writers', 'html.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,19 +1,11 @@
-"""
-    sphinx.writers.html
-    ~~~~~~~~~~~~~~~~~~~
-
-    docutils writers handling Sphinx' custom nodes.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
-
-import copy
+"""docutils writers handling Sphinx' custom nodes."""
+
 import os
 import posixpath
 import re
+import urllib.parse
 import warnings
-from typing import TYPE_CHECKING, Iterable, Tuple, cast
+from typing import TYPE_CHECKING, Iterable, Optional, Tuple, cast
 
 from docutils import nodes
 from docutils.nodes import Element, Node, Text
@@ -22,7 +14,7 @@
 
 from sphinx import addnodes
 from sphinx.builders import Builder
-from sphinx.deprecation import RemovedInSphinx50Warning
+from sphinx.deprecation import RemovedInSphinx60Warning
 from sphinx.locale import _, __, admonitionlabels
 from sphinx.util import logging
 from sphinx.util.docutils import SphinxTranslator
@@ -53,11 +45,8 @@
 
 class HTMLWriter(Writer):
 
-    # override embed-stylesheet default value to 0.
-    settings_spec = copy.deepcopy(Writer.settings_spec)
-    for _setting in settings_spec[2]:
-        if '--embed-stylesheet' in _setting[1]:
-            _setting[2]['default'] = 0
+    # override embed-stylesheet default value to False.
+    settings_default_overrides = {"embed_stylesheet": False}
 
     def __init__(self, builder: "StandaloneHTMLBuilder") -> None:
         super().__init__()
@@ -78,12 +67,13 @@
         self.clean_meta = ''.join(self.visitor.meta[2:])
 
 
+# RemovedInSphinx70Warning
 class HTMLTranslator(SphinxTranslator, BaseTranslator):
     """
     Our custom HTML translator.
     """
 
-    builder: "StandaloneHTMLBuilder" = None
+    builder: "StandaloneHTMLBuilder"
 
     def __init__(self, document: nodes.document, builder: Builder) -> None:
         super().__init__(document, builder)
@@ -95,8 +85,8 @@
         self.secnumber_suffix = self.config.html_secnumber_suffix
         self.param_separator = ''
         self.optional_param_level = 0
-        self._table_row_index = 0
-        self._fieldlist_row_index = 0
+        self._table_row_indices = [0]
+        self._fieldlist_row_indices = [0]
         self.required_params_left = 0
 
     def visit_start_of_file(self, node: Element) -> None:
@@ -284,13 +274,16 @@
             node.insert(0, nodes.title(name, admonitionlabels[name]))
         self.set_first_last(node)
 
+    def depart_admonition(self, node: Optional[Element] = None) -> None:
+        self.body.append('</div>\n')
+
     def visit_seealso(self, node: Element) -> None:
         self.visit_admonition(node, 'seealso')
 
     def depart_seealso(self, node: Element) -> None:
         self.depart_admonition(node)
 
-    def get_secnumber(self, node: Element) -> Tuple[int, ...]:
+    def get_secnumber(self, node: Element) -> Optional[Tuple[int, ...]]:
         if node.get('secnumber'):
             return node['secnumber']
         elif isinstance(node.parent, nodes.section):
@@ -433,12 +426,12 @@
            node.parent.hasattr('ids') and node.parent['ids']):
             # add permalink anchor
             if close_tag.startswith('</h'):
-                self.add_permalink_ref(node.parent, _('Permalink to this headline'))
+                self.add_permalink_ref(node.parent, _('Permalink to this heading'))
             elif close_tag.startswith('</a></h'):
                 self.body.append('</a><a class="headerlink" href="#%s" ' %
                                  node.parent['ids'][0] +
                                  'title="%s">%s' % (
-                                     _('Permalink to this headline'),
+                                     _('Permalink to this heading'),
                                      self.config.html_permalinks_icon))
             elif isinstance(node.parent, nodes.table):
                 self.body.append('</span>')
@@ -511,10 +504,25 @@
         if 'kbd' in node['classes']:
             self.body.append(self.starttag(node, 'kbd', '',
                                            CLASS='docutils literal notranslate'))
-        else:
+            return
+        lang = node.get("language", None)
+        if 'code' not in node['classes'] or not lang:
             self.body.append(self.starttag(node, 'code', '',
                                            CLASS='docutils literal notranslate'))
             self.protect_literal_text += 1
+            return
+
+        opts = self.config.highlight_options.get(lang, {})
+        highlighted = self.highlighter.highlight_block(
+            node.astext(), lang, opts=opts, location=node, nowrap=True)
+        starttag = self.starttag(
+            node,
+            "code",
+            suffix="",
+            CLASS="docutils literal highlight highlight-%s" % lang,
+        )
+        self.body.append(starttag + highlighted.strip() + "</code>")
+        raise nodes.SkipNode
 
     def depart_literal(self, node: Element) -> None:
         if 'kbd' in node['classes']:
@@ -589,7 +597,8 @@
             self.context.append('</a>')
         elif 'filename' in node:
             atts['class'] += ' internal'
-            atts['href'] = posixpath.join(self.builder.dlpath, node['filename'])
+            atts['href'] = posixpath.join(self.builder.dlpath,
+                                          urllib.parse.quote(node['filename']))
             self.body.append(self.starttag(node, 'a', '', **atts))
             self.context.append('</a>')
         else:
@@ -805,16 +814,20 @@
     # overwritten to add even/odd classes
 
     def visit_table(self, node: Element) -> None:
-        self._table_row_index = 0
+        self._table_row_indices.append(0)
 
         # set align=default if align not specified to give a default style
         node.setdefault('align', 'default')
 
         return super().visit_table(node)
 
+    def depart_table(self, node: Element) -> None:
+        self._table_row_indices.pop()
+        super().depart_table(node)
+
     def visit_row(self, node: Element) -> None:
-        self._table_row_index += 1
-        if self._table_row_index % 2 == 0:
+        self._table_row_indices[-1] += 1
+        if self._table_row_indices[-1] % 2 == 0:
             node['classes'].append('row-even')
         else:
             node['classes'].append('row-odd')
@@ -827,12 +840,16 @@
             self.body[-1] = '&#160;'
 
     def visit_field_list(self, node: Element) -> None:
-        self._fieldlist_row_index = 0
+        self._fieldlist_row_indices.append(0)
         return super().visit_field_list(node)
 
+    def depart_field_list(self, node: Element) -> None:
+        self._fieldlist_row_indices.pop()
+        return super().depart_field_list(node)
+
     def visit_field(self, node: Element) -> None:
-        self._fieldlist_row_index += 1
-        if self._fieldlist_row_index % 2 == 0:
+        self._fieldlist_row_indices[-1] += 1
+        if self._fieldlist_row_indices[-1] % 2 == 0:
             node['classes'].append('field-even')
         else:
             node['classes'].append('field-odd')
@@ -866,11 +883,14 @@
         if depart:
             depart(self, node)
 
-    def unknown_visit(self, node: Node) -> None:
-        raise NotImplementedError('Unknown node: ' + node.__class__.__name__)
-
     @property
-    def permalink_text(self) -> str:
-        warnings.warn('HTMLTranslator.permalink_text is deprecated.',
-                      RemovedInSphinx50Warning, stacklevel=2)
-        return self.config.html_permalinks_icon
+    def _fieldlist_row_index(self):
+        warnings.warn('_fieldlist_row_index is deprecated',
+                      RemovedInSphinx60Warning, stacklevel=2)
+        return self._fieldlist_row_indices[-1]
+
+    @property
+    def _table_row_index(self):
+        warnings.warn('_table_row_index is deprecated',
+                      RemovedInSphinx60Warning, stacklevel=2)
+        return self._table_row_indices[-1]
('sphinx/writers', 'xml.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.writers.xml
-    ~~~~~~~~~~~~~~~~~~
-
-    Docutils-native XML and pseudo-XML writers.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Docutils-native XML and pseudo-XML writers."""
 
 from typing import Any
 
('sphinx/writers', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,9 +1 @@
-"""
-    sphinx.writers
-    ~~~~~~~~~~~~~~
-
-    Custom docutils writers.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Custom docutils writers."""
('sphinx/writers', 'text.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.writers.text
-    ~~~~~~~~~~~~~~~~~~~
-
-    Custom docutils writer for plain text.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Custom docutils writer for plain text."""
 import math
 import os
 import re
@@ -16,7 +8,7 @@
                     Union, cast)
 
 from docutils import nodes, writers
-from docutils.nodes import Element, Node, Text
+from docutils.nodes import Element, Text
 from docutils.utils import column_width
 
 from sphinx import addnodes
@@ -167,8 +159,8 @@
     @property
     def cells(self) -> Generator[Cell, None, None]:
         seen: Set[Cell] = set()
-        for lineno, line in enumerate(self.lines):
-            for colno, cell in enumerate(line):
+        for line in self.lines:
+            for cell in line:
                 if cell and cell not in seen:
                     yield cell
                     seen.add(cell)
@@ -850,7 +842,7 @@
             self.end_state(first='%s. ' % self.list_counter[-1])
 
     def visit_definition_list_item(self, node: Element) -> None:
-        self._classifier_count_in_li = len(node.traverse(nodes.classifier))
+        self._classifier_count_in_li = len(list(node.findall(nodes.classifier)))
 
     def depart_definition_list_item(self, node: Element) -> None:
         pass
@@ -1189,6 +1181,3 @@
 
     def depart_math_block(self, node: Element) -> None:
         self.end_state()
-
-    def unknown_visit(self, node: Node) -> None:
-        raise NotImplementedError('Unknown node: ' + node.__class__.__name__)
('sphinx/writers', 'latex.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,27 +1,20 @@
-"""
-    sphinx.writers.latex
-    ~~~~~~~~~~~~~~~~~~~~
-
-    Custom docutils writer for LaTeX.
-
-    Much of this code is adapted from Dave Kuhlman's "docpy" writer from his
-    docutils sandbox.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
+"""Custom docutils writer for LaTeX.
+
+Much of this code is adapted from Dave Kuhlman's "docpy" writer from his
+docutils sandbox.
 """
 
 import re
 import warnings
 from collections import defaultdict
 from os import path
-from typing import TYPE_CHECKING, Any, Dict, Iterable, List, Set, Tuple, cast
+from typing import TYPE_CHECKING, Any, Dict, Iterable, List, Optional, Set, Tuple, cast
 
 from docutils import nodes, writers
 from docutils.nodes import Element, Node, Text
 
 from sphinx import addnodes, highlighting
-from sphinx.deprecation import RemovedInSphinx50Warning
+from sphinx.deprecation import RemovedInSphinx70Warning
 from sphinx.domains import IndexEntry
 from sphinx.domains.std import StandardDomain
 from sphinx.errors import SphinxError
@@ -89,13 +82,7 @@
         self.theme: Theme = None
 
     def translate(self) -> None:
-        try:
-            visitor = self.builder.create_translator(self.document, self.builder, self.theme)
-        except TypeError:
-            warnings.warn('LaTeXTranslator now takes 3rd argument; "theme".',
-                          RemovedInSphinx50Warning, stacklevel=2)
-            visitor = self.builder.create_translator(self.document, self.builder)
-
+        visitor = self.builder.create_translator(self.document, self.builder, self.theme)
         self.document.walkabout(visitor)
         self.output = cast(LaTeXTranslator, visitor).astext()
 
@@ -185,7 +172,9 @@
                 assert self.cells[(self.row + row, self.col + col)] == 0
                 self.cells[(self.row + row, self.col + col)] = self.cell_id
 
-    def cell(self, row: int = None, col: int = None) -> "TableCell":
+    def cell(
+        self, row: Optional[int] = None, col: Optional[int] = None
+    ) -> Optional["TableCell"]:
         """Returns a cell object (i.e. rectangular area) containing given position.
 
         If no option arguments: ``row`` or ``col`` are given, the current position;
@@ -270,24 +259,17 @@
 
 
 class LaTeXTranslator(SphinxTranslator):
-    builder: "LaTeXBuilder" = None
+    builder: "LaTeXBuilder"
 
     secnumdepth = 2  # legacy sphinxhowto.cls uses this, whereas article.cls
     # default is originally 3. For book/report, 2 is already LaTeX default.
     ignore_missing_images = False
 
-    # sphinx specific document classes
-    docclasses = ('howto', 'manual')
-
     def __init__(self, document: nodes.document, builder: "LaTeXBuilder",
-                 theme: "Theme" = None) -> None:
+                 theme: "Theme") -> None:
         super().__init__(document, builder)
         self.body: List[str] = []
         self.theme = theme
-
-        if theme is None:
-            warnings.warn('LaTeXTranslator now takes 3rd argument; "theme".',
-                          RemovedInSphinx50Warning, stacklevel=2)
 
         # flags
         self.in_title = 0
@@ -304,6 +286,7 @@
         self.in_parsed_literal = 0
         self.compact_list = 0
         self.first_param = 0
+        self.in_desc_signature = False
 
         sphinxpkgoptions = []
 
@@ -312,30 +295,8 @@
 
         # initial section names
         self.sectionnames = LATEXSECTIONNAMES[:]
-
-        if self.theme:
-            # new style: control sectioning via theme's setting
-            #
-            # .. note:: template variables(elements) are already assigned in builder
-            docclass = self.theme.docclass
-            if self.theme.toplevel_sectioning == 'section':
-                self.sectionnames.remove('chapter')
-        else:
-            # old style: sectioning control is hard-coded
-            # but some have other interface in config file
-            self.elements['wrapperclass'] = self.format_docclass(self.settings.docclass)
-
-            # we assume LaTeX class provides \chapter command except in case
-            # of non-Japanese 'howto' case
-            if document.get('docclass') == 'howto':
-                docclass = self.config.latex_docclass.get('howto', 'article')
-                if docclass[0] == 'j':  # Japanese class...
-                    pass
-                else:
-                    self.sectionnames.remove('chapter')
-            else:
-                docclass = self.config.latex_docclass.get('manual', 'report')
-            self.elements['docclass'] = docclass
+        if self.theme.toplevel_sectioning == 'section':
+            self.sectionnames.remove('chapter')
 
         # determine top section level
         self.top_sectionlevel = 1
@@ -345,7 +306,7 @@
                     self.sectionnames.index(self.config.latex_toplevel_sectioning)
             except ValueError:
                 logger.warning(__('unknown %r toplevel_sectioning for class %r') %
-                               (self.config.latex_toplevel_sectioning, docclass))
+                               (self.config.latex_toplevel_sectioning, self.theme.docclass))
 
         if self.config.numfig:
             self.numfig_secnum_depth = self.config.numfig_secnum_depth
@@ -368,7 +329,7 @@
         if self.config.numfig and self.config.math_numfig:
             sphinxpkgoptions.append('mathnumfig')
 
-        if (self.config.language not in {None, 'en', 'ja'} and
+        if (self.config.language not in {'en', 'ja'} and
                 'fncychap' not in self.config.latex_elements):
             # use Sonny style if any language specified (except English)
             self.elements['fncychap'] = (r'\usepackage[Sonny]{fncychap}' + CR +
@@ -376,7 +337,7 @@
                                          r'\ChTitleVar{\Large\normalfont\sffamily}')
 
         self.babel = self.builder.babel
-        if self.config.language and not self.babel.is_supported_language():
+        if not self.babel.is_supported_language():
             # emit warning if specified language is invalid
             # (only emitting, nothing changed to processing)
             logger.warning(__('no Babel option known for language %r'),
@@ -428,9 +389,9 @@
         self.context: List[Any] = []
         self.descstack: List[str] = []
         self.tables: List[Table] = []
-        self.next_table_colspec: str = None
+        self.next_table_colspec: Optional[str] = None
         self.bodystack: List[List[str]] = []
-        self.footnote_restricted: Element = None
+        self.footnote_restricted: Optional[Element] = None
         self.pending_footnotes: List[nodes.footnote_reference] = []
         self.curfilestack: List[str] = []
         self.handled_abbrs: Set[str] = set()
@@ -443,14 +404,6 @@
         body = self.body
         self.body = self.bodystack.pop()
         return body
-
-    def format_docclass(self, docclass: str) -> str:
-        """Prepends prefix to sphinx document classes"""
-        warnings.warn('LaTeXWriter.format_docclass() is deprecated.',
-                      RemovedInSphinx50Warning, stacklevel=2)
-        if docclass in self.docclasses:
-            docclass = 'sphinx' + docclass
-        return docclass
 
     def astext(self) -> str:
         self.elements.update({
@@ -545,7 +498,7 @@
         return renderer.render(template_name, variables)
 
     @property
-    def table(self) -> Table:
+    def table(self) -> Optional[Table]:
         """Get current table."""
         if self.tables:
             return self.tables[-1]
@@ -571,6 +524,7 @@
 
     def visit_start_of_file(self, node: Element) -> None:
         self.curfilestack.append(node['docname'])
+        self.body.append(CR + r'\sphinxstepscope' + CR)
 
     def depart_start_of_file(self, node: Element) -> None:
         self.curfilestack.pop()
@@ -651,7 +605,7 @@
                 raise nodes.SkipNode
             else:
                 short = ''
-                if node.traverse(nodes.image):
+                if any(node.findall(nodes.image)):
                     short = ('[%s]' % self.escape(' '.join(clean_astext(node).split())))
 
                 try:
@@ -715,6 +669,9 @@
             self.table.has_problematic = True
 
     def depart_desc(self, node: Element) -> None:
+        if self.in_desc_signature:
+            self.body.append(CR + r'\pysigstopsignatures')
+            self.in_desc_signature = False
         if self.config.latex_show_urls == 'footnote':
             self.body.append(CR + r'\end{fulllineitems}\end{savenotes}' + BLANKLINE)
         else:
@@ -723,32 +680,33 @@
     def _visit_signature_line(self, node: Element) -> None:
         for child in node:
             if isinstance(child, addnodes.desc_parameterlist):
-                self.body.append(r'\pysiglinewithargsret{')
+                self.body.append(CR + r'\pysiglinewithargsret{')
                 break
         else:
-            self.body.append(r'\pysigline{')
+            self.body.append(CR + r'\pysigline{')
 
     def _depart_signature_line(self, node: Element) -> None:
         self.body.append('}')
 
     def visit_desc_signature(self, node: Element) -> None:
+        hyper = ''
         if node.parent['objtype'] != 'describe' and node['ids']:
-            hyper = self.hypertarget(node['ids'][0])
-        else:
-            hyper = ''
+            for id in node['ids']:
+                hyper += self.hypertarget(id)
         self.body.append(hyper)
+        if not self.in_desc_signature:
+            self.in_desc_signature = True
+            self.body.append(CR + r'\pysigstartsignatures')
         if not node.get('is_multiline'):
             self._visit_signature_line(node)
         else:
-            self.body.append('%' + CR)
-            self.body.append(r'\pysigstartmultiline' + CR)
+            self.body.append(CR + r'\pysigstartmultiline')
 
     def depart_desc_signature(self, node: Element) -> None:
         if not node.get('is_multiline'):
             self._depart_signature_line(node)
         else:
-            self.body.append('%' + CR)
-            self.body.append(r'\pysigstopmultiline')
+            self.body.append(CR + r'\pysigstopmultiline')
 
     def visit_desc_signature_line(self, node: Element) -> None:
         self._visit_signature_line(node)
@@ -757,9 +715,9 @@
         self._depart_signature_line(node)
 
     def visit_desc_content(self, node: Element) -> None:
-        if node.children and not isinstance(node.children[0], nodes.paragraph):
-            # avoid empty desc environment which causes a formatting bug
-            self.body.append('~')
+        assert self.in_desc_signature
+        self.body.append(CR + r'\pysigstopsignatures')
+        self.in_desc_signature = False
 
     def depart_desc_content(self, node: Element) -> None:
         pass
@@ -858,16 +816,14 @@
     def visit_footnote(self, node: Element) -> None:
         self.in_footnote += 1
         label = cast(nodes.label, node[0])
-        if 'auto' not in node:
-            self.body.append(r'\sphinxstepexplicit ')
         if self.in_parsed_literal:
             self.body.append(r'\begin{footnote}[%s]' % label.astext())
         else:
             self.body.append('%' + CR)
             self.body.append(r'\begin{footnote}[%s]' % label.astext())
-        if 'auto' not in node:
-            self.body.append(r'\phantomsection'
-                             r'\label{\thesphinxscope.%s}%%' % label.astext() + CR)
+        if 'referred' in node:
+            # TODO: in future maybe output a latex macro with backrefs here
+            pass
         self.body.append(r'\sphinxAtStartFootnote' + CR)
 
     def depart_footnote(self, node: Element) -> None:
@@ -912,7 +868,7 @@
         labels = self.hypertarget_to(node)
         table_type = self.table.get_table_type()
         table = self.render(table_type + '.tex_t',
-                            dict(table=self.table, labels=labels))
+                            {'table': self.table, 'labels': labels})
         self.body.append(BLANKLINE)
         self.body.append(table)
         self.body.append(CR)
@@ -1011,7 +967,7 @@
             context = (r'\par' + CR + r'\vskip-\baselineskip'
                        r'\vbox{\hbox{\strut}}\end{varwidth}%' + CR + context)
             self.needs_linetrimming = 1
-        if len(node.traverse(nodes.paragraph)) >= 2:
+        if len(list(node.findall(nodes.paragraph))) >= 2:
             self.table.has_oldproblematic = True
         if isinstance(node.parent.parent, nodes.thead) or (cell.col in self.table.stubs):
             if len(node) == 1 and isinstance(node[0], nodes.paragraph) and node.astext() == '':
@@ -1137,8 +1093,8 @@
             ctx = r'\phantomsection'
             for node_id in node['ids']:
                 ctx += self.hypertarget(node_id, anchor=False)
-        ctx += r'}] \leavevmode'
-        self.body.append(r'\item[{')
+        ctx += r'}'
+        self.body.append(r'\sphinxlineitem{')
         self.context.append(ctx)
 
     def depart_term(self, node: Element) -> None:
@@ -1210,7 +1166,7 @@
         ncolumns = node['ncolumns']
         if self.compact_list > 1:
             self.body.append(r'\setlength{\multicolsep}{0pt}' + CR)
-        self.body.append(r'\begin{multicols}{' + ncolumns + '}\raggedright' + CR)
+        self.body.append(r'\begin{multicols}{' + ncolumns + r'}\raggedright' + CR)
         self.body.append(r'\begin{itemize}\setlength{\itemsep}{0pt}'
                          r'\setlength{\parskip}{0pt}' + CR)
         if self.table:
@@ -1231,7 +1187,7 @@
         # self.body.append(r'\columnbreak\n')
         pass
 
-    def latex_image_length(self, width_str: str, scale: int = 100) -> str:
+    def latex_image_length(self, width_str: str, scale: int = 100) -> Optional[str]:
         try:
             return rstdim_to_latexdim(width_str, scale)
         except ValueError:
@@ -1510,7 +1466,7 @@
         if not node.get('inline', True):
             self.body.append(CR)
         entries = node['entries']
-        for type, string, tid, ismain, key_ in entries:
+        for type, string, _tid, ismain, _key in entries:
             m = ''
             if ismain:
                 m = '|spxpagem'
@@ -1741,10 +1697,22 @@
     def visit_literal(self, node: Element) -> None:
         if self.in_title:
             self.body.append(r'\sphinxstyleliteralintitle{\sphinxupquote{')
+            return
         elif 'kbd' in node['classes']:
             self.body.append(r'\sphinxkeyboard{\sphinxupquote{')
-        else:
+            return
+        lang = node.get("language", None)
+        if 'code' not in node['classes'] or not lang:
             self.body.append(r'\sphinxcode{\sphinxupquote{')
+            return
+
+        opts = self.config.highlight_options.get(lang, {})
+        hlcode = self.highlighter.highlight_block(
+            node.astext(), lang, opts=opts, location=node, nowrap=True)
+        self.body.append(r'\sphinxcode{\sphinxupquote{%' + CR
+                         + hlcode.rstrip() + '%' + CR  # NoQA: W503
+                         + '}}')  # NoQA: W503
+        raise nodes.SkipNode
 
     def depart_literal(self, node: Element) -> None:
         self.body.append('}}')
@@ -1761,9 +1729,7 @@
     def visit_footnotetext(self, node: Element) -> None:
         label = cast(nodes.label, node[0])
         self.body.append('%' + CR)
-        self.body.append(r'\begin{footnotetext}[%s]'
-                         r'\phantomsection\label{\thesphinxscope.%s}%%'
-                         % (label.astext(), label.astext()) + CR)
+        self.body.append(r'\begin{footnotetext}[%s]' % label.astext())
         self.body.append(r'\sphinxAtStartFootnote' + CR)
 
     def depart_footnotetext(self, node: Element) -> None:
@@ -1859,8 +1825,7 @@
         done = 0
         if len(node.children) == 1:
             child = node.children[0]
-            if isinstance(child, nodes.bullet_list) or \
-                    isinstance(child, nodes.enumerated_list):
+            if isinstance(child, (nodes.bullet_list, nodes.enumerated_list)):
                 done = 1
         if not done:
             self.body.append(r'\begin{quote}' + CR)
@@ -1871,8 +1836,7 @@
         done = 0
         if len(node.children) == 1:
             child = node.children[0]
-            if isinstance(child, nodes.bullet_list) or \
-                    isinstance(child, nodes.enumerated_list):
+            if isinstance(child, (nodes.bullet_list, nodes.enumerated_list)):
                 done = 1
         if not done:
             self.body.append(r'\end{quote}' + CR)
@@ -1980,7 +1944,7 @@
 
     def depart_container(self, node: Element) -> None:
         classes = node.get('classes', [])
-        for c in classes:
+        for _c in classes:
             self.body.append('\n\\end{sphinxuseclass}')
 
     def visit_decoration(self, node: Element) -> None:
@@ -2079,8 +2043,12 @@
     def depart_math_reference(self, node: Element) -> None:
         pass
 
-    def unknown_visit(self, node: Node) -> None:
-        raise NotImplementedError('Unknown node: ' + node.__class__.__name__)
+    @property
+    def docclasses(self) -> Tuple[str, str]:
+        """Prepends prefix to sphinx document classes"""
+        warnings.warn('LaTeXWriter.docclasses() is deprecated.',
+                      RemovedInSphinx70Warning, stacklevel=2)
+        return ('howto', 'manual')
 
 
 # FIXME: Workaround to avoid circular import
('sphinx/util', 'tags.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.util.tags
-    ~~~~~~~~~~~~~~~~
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
-
-from typing import Iterator, List
+from typing import Iterator, List, Optional
 
 from jinja2 import nodes
 from jinja2.environment import Environment
@@ -43,7 +35,7 @@
 
 
 class Tags:
-    def __init__(self, tags: List[str] = None) -> None:
+    def __init__(self, tags: Optional[List[str]] = None) -> None:
         self.tags = dict.fromkeys(tags or [], True)
 
     def has(self, tag: str) -> bool:
('sphinx/util', 'logging.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.util.logging
-    ~~~~~~~~~~~~~~~~~~~
-
-    Logging utility functions for Sphinx.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Logging utility functions for Sphinx."""
 
 import logging
 import logging.handlers
@@ -20,6 +12,7 @@
 
 from sphinx.errors import SphinxWarning
 from sphinx.util.console import colorize
+from sphinx.util.osutil import abspath
 
 if TYPE_CHECKING:
     from sphinx.application import Sphinx
@@ -85,7 +78,7 @@
 
         location = getattr(r, 'location', None)
         if isinstance(location, nodes.Node):
-            r.location = get_node_location(location)  # type: ignore
+            r.location = get_node_location(location)
 
 
 class SphinxLogRecord(logging.LogRecord):
@@ -111,14 +104,21 @@
 
 class SphinxWarningLogRecord(SphinxLogRecord):
     """Warning log record class supporting location"""
-    prefix = 'WARNING: '
+    @property
+    def prefix(self) -> str:  # type: ignore
+        if self.levelno >= logging.CRITICAL:
+            return 'CRITICAL: '
+        elif self.levelno >= logging.ERROR:
+            return 'ERROR: '
+        else:
+            return 'WARNING: '
 
 
 class SphinxLoggerAdapter(logging.LoggerAdapter):
     """LoggerAdapter allowing ``type`` and ``subtype`` keywords."""
     KEYWORDS = ['type', 'subtype', 'location', 'nonl', 'color', 'once']
 
-    def log(self, level: Union[int, str], msg: str, *args: Any, **kwargs: Any) -> None:
+    def log(self, level: Union[int, str], msg: str, *args: Any, **kwargs: Any) -> None:  # type: ignore # NOQA
         if isinstance(level, int):
             super().log(level, msg, *args, **kwargs)
         else:
@@ -170,6 +170,11 @@
 
     def shouldFlush(self, record: logging.LogRecord) -> bool:
         return False  # never flush
+
+    def flush(self) -> None:
+        # suppress any flushes triggered by importing packages that flush
+        # all handlers at initialization time
+        pass
 
     def flushTo(self, logger: logging.Logger) -> None:
         self.acquire()
@@ -363,10 +368,8 @@
         else:
             target, subtarget = warning_type, None
 
-        if target == type:
-            if (subtype is None or subtarget is None or
-               subtarget == subtype or subtarget == '*'):
-                return True
+        if target == type and subtarget in (None, subtype, "*"):
+            return True
 
     return False
 
@@ -379,8 +382,8 @@
         super().__init__()
 
     def filter(self, record: logging.LogRecord) -> bool:
-        type = getattr(record, 'type', None)
-        subtype = getattr(record, 'subtype', None)
+        type = getattr(record, 'type', '')
+        subtype = getattr(record, 'subtype', '')
 
         try:
             suppress_warnings = self.app.config.suppress_warnings
@@ -429,7 +432,7 @@
     """Disable WarningIsErrorFilter if this filter installed."""
 
     def filter(self, record: logging.LogRecord) -> bool:
-        record.skip_warningsiserror = True  # type: ignore
+        record.skip_warningsiserror = True
         return True
 
 
@@ -512,6 +515,8 @@
 
 def get_node_location(node: Node) -> Optional[str]:
     (source, line) = get_source_line(node)
+    if source:
+        source = abspath(source)
     if source and line:
         return "%s:%s" % (source, line)
     elif source:
('sphinx/util', 'console.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,15 +1,8 @@
-"""
-    sphinx.util.console
-    ~~~~~~~~~~~~~~~~~~~
-
-    Format colored console output.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Format colored console output."""
 
 import os
 import re
+import shutil
 import sys
 from typing import Dict, Pattern
 
@@ -30,18 +23,8 @@
 
 
 def get_terminal_width() -> int:
-    """Borrowed from the py lib."""
-    try:
-        import fcntl
-        import struct
-        import termios
-        call = fcntl.ioctl(0, termios.TIOCGWINSZ, struct.pack('hhhh', 0, 0, 0, 0))
-        height, width = struct.unpack('hhhh', call)[:2]
-        terminal_width = width
-    except Exception:
-        # FALLBACK
-        terminal_width = int(os.environ.get('COLUMNS', "80")) - 1
-    return terminal_width
+    """Return the width of the terminal in columns."""
+    return shutil.get_terminal_size().columns - 1
 
 
 _tw: int = get_terminal_width()
@@ -57,8 +40,12 @@
 
 
 def color_terminal() -> bool:
+    if 'NO_COLOR' in os.environ:
+        return False
     if sys.platform == 'win32' and colorama is not None:
         colorama.init()
+        return True
+    if 'FORCE_COLOR' in os.environ:
         return True
     if not hasattr(sys.stdout, 'isatty'):
         return False
('sphinx/util', 'compat.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.util.compat
-    ~~~~~~~~~~~~~~~~~~
-
-    modules for backward compatibility
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""modules for backward compatibility"""
 
 import sys
 from typing import TYPE_CHECKING, Any, Dict
('sphinx/util', 'build_phase.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.util.build_phase
-    ~~~~~~~~~~~~~~~~~~~~~~~
-
-    Build phase of Sphinx application.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Build phase of Sphinx application."""
 
 from enum import IntEnum
 
('sphinx/util', 'texescape.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,15 +1,7 @@
-"""
-    sphinx.util.texescape
-    ~~~~~~~~~~~~~~~~~~~~~
-
-    TeX escaping helper.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""TeX escaping helper."""
 
 import re
-from typing import Dict
+from typing import Dict, Optional
 
 tex_replacements = [
     # map TeX special chars
@@ -108,7 +100,7 @@
 _tex_hlescape_map_without_unicode: Dict[int, str] = {}
 
 
-def escape(s: str, latex_engine: str = None) -> str:
+def escape(s: str, latex_engine: Optional[str] = None) -> str:
     """Escape text for LaTeX output."""
     if latex_engine in ('lualatex', 'xelatex'):
         # unicode based LaTeX engine
@@ -117,7 +109,7 @@
         return s.translate(_tex_escape_map)
 
 
-def hlescape(s: str, latex_engine: str = None) -> str:
+def hlescape(s: str, latex_engine: Optional[str] = None) -> str:
     """Escape text for LaTeX highlighter."""
     if latex_engine in ('lualatex', 'xelatex'):
         # unicode based LaTeX engine
('sphinx/util', 'docutils.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,18 +1,10 @@
-"""
-    sphinx.util.docutils
-    ~~~~~~~~~~~~~~~~~~~~
-
-    Utility functions for docutils.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Utility functions for docutils."""
 
 import os
 import re
+import warnings
 from contextlib import contextmanager
 from copy import copy
-from distutils.version import LooseVersion
 from os import path
 from types import ModuleType
 from typing import (IO, TYPE_CHECKING, Any, Callable, Dict, Generator, List, Optional, Set,
@@ -26,9 +18,11 @@
 from docutils.parsers.rst.states import Inliner
 from docutils.statemachine import State, StateMachine, StringList
 from docutils.utils import Reporter, unescape
-
+from docutils.writers._html_base import HTMLTranslator
+
+from sphinx.deprecation import RemovedInSphinx70Warning, deprecated_alias
 from sphinx.errors import SphinxError
-from sphinx.locale import _
+from sphinx.locale import _, __
 from sphinx.util import logging
 from sphinx.util.typing import RoleFunction
 
@@ -36,12 +30,20 @@
 report_re = re.compile('^(.+?:(?:\\d+)?): \\((DEBUG|INFO|WARNING|ERROR|SEVERE)/(\\d+)?\\) ')
 
 if TYPE_CHECKING:
+    from docutils.frontend import Values
+
     from sphinx.builders import Builder
     from sphinx.config import Config
     from sphinx.environment import BuildEnvironment
 
-
-__version_info__ = tuple(LooseVersion(docutils.__version__).version)
+deprecated_alias('sphinx.util.docutils',
+                 {
+                     '__version_info__': docutils.__version_info__,
+                 },
+                 RemovedInSphinx70Warning,
+                 {
+                     '__version_info__': 'docutils.__version_info__',
+                 })
 additional_nodes: Set[Type[Element]] = set()
 
 
@@ -141,6 +143,30 @@
     finally:
         # restore original implementations
         docutils.languages.get_language = get_language
+
+
+@contextmanager
+def patched_rst_get_language() -> Generator[None, None, None]:
+    """Patch docutils.parsers.rst.languages.get_language().
+    Starting from docutils 0.17, get_language() in ``rst.languages``
+    also has a reporter, which needs to be disabled temporarily.
+
+    This should also work for old versions of docutils,
+    because reporter is none by default.
+
+    refs: https://github.com/sphinx-doc/sphinx/issues/10179
+    """
+    from docutils.parsers.rst.languages import get_language
+
+    def patched_get_language(language_code: str, reporter: Reporter = None) -> Any:
+        return get_language(language_code)
+
+    try:
+        docutils.parsers.rst.languages.get_language = patched_get_language
+        yield
+    finally:
+        # restore original implementations
+        docutils.parsers.rst.languages.get_language = get_language
 
 
 @contextmanager
@@ -160,22 +186,56 @@
 
 
 @contextmanager
+def du19_footnotes() -> Generator[None, None, None]:
+    def visit_footnote(self, node):
+        label_style = self.settings.footnote_references
+        if not isinstance(node.previous_sibling(), type(node)):
+            self.body.append(f'<aside class="footnote-list {label_style}">\n')
+        self.body.append(self.starttag(node, 'aside',
+                                       classes=[node.tagname, label_style],
+                                       role="note"))
+
+    def depart_footnote(self, node):
+        self.body.append('</aside>\n')
+        if not isinstance(node.next_node(descend=False, siblings=True),
+                          type(node)):
+            self.body.append('</aside>\n')
+
+    old_visit_footnote = HTMLTranslator.visit_footnote
+    old_depart_footnote = HTMLTranslator.depart_footnote
+
+    # Only apply on Docutils 0.18 or 0.18.1, as 0.17 and earlier used a <dl> based
+    # approach, and 0.19 and later use the fixed approach by default.
+    if docutils.__version_info__[:2] == (0, 18):
+        HTMLTranslator.visit_footnote = visit_footnote  # type: ignore[assignment]
+        HTMLTranslator.depart_footnote = depart_footnote  # type: ignore[assignment]
+
+    try:
+        yield
+    finally:
+        if docutils.__version_info__[:2] == (0, 18):
+            HTMLTranslator.visit_footnote = old_visit_footnote  # type: ignore[assignment]
+            HTMLTranslator.depart_footnote = old_depart_footnote  # type: ignore[assignment]
+
+
+@contextmanager
 def patch_docutils(confdir: Optional[str] = None) -> Generator[None, None, None]:
     """Patch to docutils temporarily."""
-    with patched_get_language(), using_user_docutils_conf(confdir):
+    with patched_get_language(), \
+         patched_rst_get_language(), \
+         using_user_docutils_conf(confdir), \
+         du19_footnotes():
         yield
 
 
-class ElementLookupError(Exception):
-    pass
-
-
-class sphinx_domains:
-    """Monkey-patch directive and role dispatch, so that domain-specific
-    markup takes precedence.
-    """
-    def __init__(self, env: "BuildEnvironment") -> None:
-        self.env = env
+class CustomReSTDispatcher:
+    """Custom reST's mark-up dispatcher.
+
+    This replaces docutils's directives and roles dispatch mechanism for reST parser
+    by original one temporarily.
+    """
+
+    def __init__(self) -> None:
         self.directive_func: Callable = lambda *args: (None, [])
         self.roles_func: Callable = lambda *args: (None, [])
 
@@ -189,12 +249,34 @@
         self.directive_func = directives.directive
         self.role_func = roles.role
 
-        directives.directive = self.lookup_directive
-        roles.role = self.lookup_role
+        directives.directive = self.directive
+        roles.role = self.role
 
     def disable(self) -> None:
         directives.directive = self.directive_func
         roles.role = self.role_func
+
+    def directive(self,
+                  directive_name: str, language_module: ModuleType, document: nodes.document
+                  ) -> Tuple[Optional[Type[Directive]], List[system_message]]:
+        return self.directive_func(directive_name, language_module, document)
+
+    def role(self, role_name: str, language_module: ModuleType, lineno: int, reporter: Reporter
+             ) -> Tuple[RoleFunction, List[system_message]]:
+        return self.role_func(role_name, language_module, lineno, reporter)
+
+
+class ElementLookupError(Exception):
+    pass
+
+
+class sphinx_domains(CustomReSTDispatcher):
+    """Monkey-patch directive and role dispatch, so that domain-specific
+    markup takes precedence.
+    """
+    def __init__(self, env: "BuildEnvironment") -> None:
+        self.env = env
+        super().__init__()
 
     def lookup_domain_element(self, type: str, name: str) -> Any:
         """Lookup a markup element (directive or role), given its name which can
@@ -226,17 +308,20 @@
 
         raise ElementLookupError
 
-    def lookup_directive(self, directive_name: str, language_module: ModuleType, document: nodes.document) -> Tuple[Optional[Type[Directive]], List[system_message]]:  # NOQA
+    def directive(self,
+                  directive_name: str, language_module: ModuleType, document: nodes.document
+                  ) -> Tuple[Optional[Type[Directive]], List[system_message]]:
         try:
             return self.lookup_domain_element('directive', directive_name)
         except ElementLookupError:
-            return self.directive_func(directive_name, language_module, document)
-
-    def lookup_role(self, role_name: str, language_module: ModuleType, lineno: int, reporter: Reporter) -> Tuple[RoleFunction, List[system_message]]:  # NOQA
+            return super().directive(directive_name, language_module, document)
+
+    def role(self, role_name: str, language_module: ModuleType, lineno: int, reporter: Reporter
+             ) -> Tuple[RoleFunction, List[system_message]]:
         try:
             return self.lookup_domain_element('role', role_name)
         except ElementLookupError:
-            return self.role_func(role_name, language_module, lineno, reporter)
+            return super().role(role_name, language_module, lineno, reporter)
 
 
 class WarningStream:
@@ -273,7 +358,9 @@
 
 
 def is_html5_writer_available() -> bool:
-    return __version_info__ > (0, 13, 0)
+    warnings.warn('is_html5_writer_available() is deprecated.',
+                  RemovedInSphinx70Warning)
+    return True
 
 
 @contextmanager
@@ -299,6 +386,7 @@
 
     def __init__(self, **kwargs: Any) -> None:
         self.overwrite_if_changed = kwargs.pop('overwrite_if_changed', False)
+        kwargs.setdefault('encoding', 'utf-8')
         super().__init__(**kwargs)
 
     def write(self, data: str) -> str:
@@ -496,10 +584,23 @@
         else:
             super().dispatch_departure(node)
 
+    def unknown_visit(self, node: Node) -> None:
+        logger.warning(__('unknown node type: %r'), node, location=node)
+
+
+# Node.findall() is a new interface to traverse a doctree since docutils-0.18.
+# This applies a patch to docutils up to 0.18 inclusive to provide Node.findall()
+# method to use it from our codebase.
+if docutils.__version_info__ <= (0, 18):
+    def findall(self, *args, **kwargs):
+        return iter(self.traverse(*args, **kwargs))
+
+    Node.findall = findall  # type: ignore
+
 
 # cache a vanilla instance of nodes.document
 # Used in new_document() function
-__document_cache__: Optional[nodes.document] = None
+__document_cache__: Tuple["Values", Reporter]
 
 
 def new_document(source_path: str, settings: Any = None) -> nodes.document:
@@ -510,15 +611,18 @@
     This makes an instantiation of document nodes much faster.
     """
     global __document_cache__
-    if __document_cache__ is None:
-        __document_cache__ = docutils.utils.new_document(source_path)
+    try:
+        cached_settings, reporter = __document_cache__
+    except NameError:
+        doc = docutils.utils.new_document(source_path)
+        __document_cache__ = cached_settings, reporter = doc.settings, doc.reporter
 
     if settings is None:
-        # Make a copy of ``settings`` from cache to accelerate instantiation
-        settings = copy(__document_cache__.settings)
+        # Make a copy of the cached settings to accelerate instantiation
+        settings = copy(cached_settings)
 
     # Create a new instance of nodes.document using cached reporter
     from sphinx import addnodes
-    document = addnodes.document(settings, __document_cache__.reporter, source=source_path)
+    document = addnodes.document(settings, reporter, source=source_path)
     document.note_source(source_path, -1)
     return document
('sphinx/util', 'fileutil.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,16 +1,8 @@
-"""
-    sphinx.util.fileutil
-    ~~~~~~~~~~~~~~~~~~~~
-
-    File utility functions for Sphinx.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""File utility functions for Sphinx."""
 
 import os
 import posixpath
-from typing import TYPE_CHECKING, Callable, Dict
+from typing import TYPE_CHECKING, Callable, Dict, Optional
 
 from docutils.utils import relative_path
 
@@ -22,7 +14,8 @@
 
 
 def copy_asset_file(source: str, destination: str,
-                    context: Dict = None, renderer: "BaseRenderer" = None) -> None:
+                    context: Optional[Dict] = None,
+                    renderer: Optional["BaseRenderer"] = None) -> None:
     """Copy an asset file to destination.
 
     On copying, it expands the template variables if context argument is given and
@@ -55,8 +48,8 @@
 
 
 def copy_asset(source: str, destination: str, excluded: PathMatcher = lambda path: False,
-               context: Dict = None, renderer: "BaseRenderer" = None,
-               onerror: Callable[[str, Exception], None] = None) -> None:
+               context: Optional[Dict] = None, renderer: Optional["BaseRenderer"] = None,
+               onerror: Optional[Callable[[str, Exception], None]] = None) -> None:
     """Copy asset files to destination recursively.
 
     On copying, it expands the template variables if context argument is given and
('sphinx/util', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.util
-    ~~~~~~~~~~~
-
-    Utility functions for Sphinx.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Utility functions for Sphinx."""
 
 import functools
 import hashlib
@@ -16,17 +8,16 @@
 import sys
 import tempfile
 import traceback
-import unicodedata
 import warnings
 from datetime import datetime
 from importlib import import_module
 from os import path
 from time import mktime, strptime
-from typing import (IO, TYPE_CHECKING, Any, Callable, Dict, Iterable, Iterator, List, Optional,
-                    Pattern, Set, Tuple, Type)
+from typing import (IO, TYPE_CHECKING, Any, Callable, Dict, Generator, Iterable, List,
+                    Optional, Pattern, Set, Tuple, Type, TypeVar)
 from urllib.parse import parse_qsl, quote_plus, urlencode, urlsplit, urlunsplit
 
-from sphinx.deprecation import RemovedInSphinx50Warning
+from sphinx.deprecation import RemovedInSphinx70Warning
 from sphinx.errors import ExtensionError, FiletypeNotFoundError, SphinxParallelError
 from sphinx.locale import __
 from sphinx.util import logging
@@ -37,7 +28,7 @@
 # import other utilities; partly for backwards compatibility, so don't
 # prune unused ones indiscriminately
 from sphinx.util.osutil import (SEP, copyfile, copytimes, ensuredir, make_filename,  # noqa
-                                movefile, mtimes_of_files, os_path, relative_uri)
+                                mtimes_of_files, os_path, relative_uri)
 from sphinx.util.typing import PathMatcher
 
 if TYPE_CHECKING:
@@ -60,22 +51,32 @@
 
 def path_stabilize(filepath: str) -> str:
     "Normalize path separator and unicode string"
-    newpath = filepath.replace(os.path.sep, SEP)
-    return unicodedata.normalize('NFC', newpath)
+    warnings.warn("'sphinx.util.path_stabilize' is deprecated, use "
+                  "'sphinx.util.osutil.path_stabilize' instead.",
+                  RemovedInSphinx70Warning, stacklevel=2)
+    from sphinx.util import osutil
+
+    return osutil.path_stabilize(filepath)
 
 
 def get_matching_files(dirname: str,
-                       exclude_matchers: Tuple[PathMatcher, ...] = ()) -> Iterable[str]:  # NOQA
+                       exclude_matchers: Tuple[PathMatcher, ...] = (),
+                       include_matchers: Tuple[PathMatcher, ...] = ()) -> Iterable[str]:  # NOQA
     """Get all file names in a directory, recursively.
 
     Exclude files and dirs matching some matcher in *exclude_matchers*.
     """
+    warnings.warn("'sphinx.util.get_matching_files' is deprecated, use "
+                  "'sphinx.util.matching.get_matching_files' instead. Note that"
+                  "the types of the arguments have changed from callables to "
+                  "plain string glob patterns.", RemovedInSphinx70Warning, stacklevel=2)
     # dirname is a normalized absolute path.
     dirname = path.normpath(path.abspath(dirname))
-    dirlen = len(dirname) + 1    # exclude final os.path.sep
 
     for root, dirs, files in os.walk(dirname, followlinks=True):
-        relativeroot = root[dirlen:]
+        relativeroot = path.relpath(root, dirname)
+        if relativeroot == ".":
+            relativeroot = ""  # suppress dirname for files on the target dir
 
         qdirs = enumerate(path_stabilize(path.join(relativeroot, dn))
                           for dn in dirs)  # type: Iterable[Tuple[int, str]]
@@ -87,7 +88,7 @@
 
         dirs[:] = sorted(dirs[i] for (i, _) in qdirs)
 
-        for i, filename in sorted(qfiles):
+        for _i, filename in sorted(qfiles):
             yield filename
 
 
@@ -131,7 +132,7 @@
                 self._existing.discard(unique)
 
     def merge_other(self, docnames: Set[str], other: Dict[str, Tuple[Set[str], Any]]) -> None:
-        for filename, (docs, unique) in other.items():
+        for filename, (docs, _unique) in other.items():
             for doc in docs & set(docnames):
                 self.add_file(doc, filename)
 
@@ -153,7 +154,7 @@
     """
 
     try:
-        return hashlib.md5(data, **kwargs)  # type: ignore
+        return hashlib.md5(data, **kwargs)
     except ValueError:
         return hashlib.md5(data, **kwargs, usedforsecurity=False)  # type: ignore
 
@@ -167,7 +168,7 @@
     """
 
     try:
-        return hashlib.sha1(data, **kwargs)  # type: ignore
+        return hashlib.sha1(data, **kwargs)
     except ValueError:
         return hashlib.sha1(data, **kwargs, usedforsecurity=False)  # type: ignore
 
@@ -189,13 +190,13 @@
         return self[filename][1]
 
     def purge_doc(self, docname: str) -> None:
-        for filename, (docs, dest) in list(self.items()):
+        for filename, (docs, _dest) in list(self.items()):
             docs.discard(docname)
             if not docs:
                 del self[filename]
 
     def merge_other(self, docnames: Set[str], other: Dict[str, Tuple[Set[str], Any]]) -> None:
-        for filename, (docs, dest) in other.items():
+        for filename, (docs, _dest) in other.items():
             for docname in docs & set(docnames):
                 self.add_file(docname, filename)
 
@@ -211,7 +212,7 @@
 '''
 
 
-def save_traceback(app: "Sphinx") -> str:
+def save_traceback(app: Optional["Sphinx"]) -> str:
     """Save the current exception's traceback in a temporary file."""
     import platform
 
@@ -248,7 +249,7 @@
     return path
 
 
-def get_full_modname(modname: str, attribute: str) -> str:
+def get_full_modname(modname: str, attribute: str) -> Optional[str]:
     if modname is None:
         # Prevents a TypeError: if the last getattr() call will return None
         # then it's better to return it directly
@@ -314,7 +315,7 @@
     """Parse a line number spec (such as "1,2,4-6") and return a list of
     wanted line numbers.
     """
-    items = list()
+    items = []
     parts = spec.split(',')
     for part in parts:
         try:
@@ -337,32 +338,6 @@
     return items
 
 
-def force_decode(string: str, encoding: str) -> str:
-    """Forcibly get a unicode string out of a bytestring."""
-    warnings.warn('force_decode() is deprecated.',
-                  RemovedInSphinx50Warning, stacklevel=2)
-    if isinstance(string, bytes):
-        try:
-            if encoding:
-                string = string.decode(encoding)
-            else:
-                # try decoding with utf-8, should only work for real UTF-8
-                string = string.decode()
-        except UnicodeError:
-            # last resort -- can't fail
-            string = string.decode('latin1')
-    return string
-
-
-def rpartition(s: str, t: str) -> Tuple[str, str]:
-    """Similar to str.rpartition from 2.5, but doesn't return the separator."""
-    warnings.warn('rpartition() is now deprecated.', RemovedInSphinx50Warning, stacklevel=2)
-    i = s.rfind(t)
-    if i != -1:
-        return s[:i], s[i + len(t):]
-    return '', s
-
-
 def split_into(n: int, type: str, value: str) -> List[str]:
     """Split an index entry into a given number of parts at semicolons."""
     parts = [x.strip() for x in value.split(';', n - 1)]
@@ -403,7 +378,7 @@
     return ''.join(res)
 
 
-def import_object(objname: str, source: str = None) -> Any:
+def import_object(objname: str, source: Optional[str] = None) -> Any:
     """Import python object by qualname."""
     try:
         objpath = objname.split('.')
@@ -429,7 +404,7 @@
     """Split full qualified name to a pair of modname and qualname.
 
     A qualname is an abbreviation for "Qualified name" introduced at PEP-3155
-    (https://www.python.org/dev/peps/pep-3155/).  It is a dotted path name
+    (https://peps.python.org/pep-3155/).  It is a dotted path name
     from the module top-level.
 
     A "full" qualified name means a string containing both module name and
@@ -440,7 +415,7 @@
               calling this function.
     """
     parts = name.split('.')
-    for i, part in enumerate(parts, 1):
+    for i, _part in enumerate(parts, 1):
         try:
             modname = ".".join(parts[:i])
             import_module(modname)
@@ -459,7 +434,7 @@
     split = list(urlsplit(uri))
     split[1] = split[1].encode('idna').decode('ascii')
     split[2] = quote_plus(split[2].encode(), '/')
-    query = list((q, v.encode()) for (q, v) in parse_qsl(split[3]))
+    query = [(q, v.encode()) for (q, v) in parse_qsl(split[3])]
     split[3] = urlencode(query)
     return urlunsplit(split)
 
@@ -480,8 +455,12 @@
     return str(chunk)
 
 
-def old_status_iterator(iterable: Iterable, summary: str, color: str = "darkgreen",
-                        stringify_func: Callable[[Any], str] = display_chunk) -> Iterator:
+T = TypeVar('T')
+
+
+def old_status_iterator(iterable: Iterable[T], summary: str, color: str = "darkgreen",
+                        stringify_func: Callable[[Any], str] = display_chunk
+                        ) -> Generator[T, None, None]:
     l = 0
     for item in iterable:
         if l == 0:
@@ -495,9 +474,10 @@
 
 
 # new version with progress info
-def status_iterator(iterable: Iterable, summary: str, color: str = "darkgreen",
+def status_iterator(iterable: Iterable[T], summary: str, color: str = "darkgreen",
                     length: int = 0, verbosity: int = 0,
-                    stringify_func: Callable[[Any], str] = display_chunk) -> Iterable:
+                    stringify_func: Callable[[Any], str] = display_chunk
+                    ) -> Generator[T, None, None]:
     if length == 0:
         yield from old_status_iterator(iterable, summary, color, stringify_func)
         return
('sphinx/util', 'docfields.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,7 @@
-"""
-    sphinx.util.docfields
-    ~~~~~~~~~~~~~~~~~~~~~
-
-    "Doc fields" are reST field lists in object descriptions that will
-    be domain-specifically transformed to a more appealing presentation.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
+"""Utility code for "Doc fields".
+
+"Doc fields" are reST field lists in object descriptions that will
+be domain-specifically transformed to a more appealing presentation.
 """
 from typing import TYPE_CHECKING, Any, Dict, List, Tuple, Type, Union, cast
 
@@ -21,7 +16,7 @@
 from sphinx.util.typing import TextlikeNode
 
 if TYPE_CHECKING:
-    from sphinx.directive import ObjectDescription
+    from sphinx.directives import ObjectDescription
 
 logger = logging.getLogger(__name__)
 
@@ -78,8 +73,8 @@
         role = env.get_domain(domain).role(rolename)
         if role is None or inliner is None:
             if role is None and inliner is not None:
-                msg = "Problem in %s domain: field is supposed "
-                msg += "to use role '%s', but that role is not in the domain."
+                msg = __("Problem in %s domain: field is supposed "
+                         "to use role '%s', but that role is not in the domain.")
                 logger.warning(__(msg), domain, rolename, location=location)
             refnode = addnodes.pending_xref('', refdomain=domain, refexplicit=False,
                                             reftype=rolename, reftarget=target)
@@ -316,8 +311,7 @@
             if is_typefield:
                 # filter out only inline nodes; others will result in invalid
                 # markup being written out
-                content = [n for n in content if isinstance(n, nodes.Inline) or
-                           isinstance(n, nodes.Text)]
+                content = [n for n in content if isinstance(n, (nodes.Inline, nodes.Text))]
                 if content:
                     types.setdefault(typename, {})[fieldarg] = content
                 continue
('sphinx/util', 'docstrings.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.util.docstrings
-    ~~~~~~~~~~~~~~~~~~~~~~
-
-    Utilities for docstring processing.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Utilities for docstring processing."""
 
 import re
 import sys
@@ -15,7 +7,7 @@
 
 from docutils.parsers.rst.states import Body
 
-from sphinx.deprecation import RemovedInSphinx50Warning, RemovedInSphinx60Warning
+from sphinx.deprecation import RemovedInSphinx60Warning
 
 field_list_item_re = re.compile(Body.patterns['field_marker'])
 
@@ -57,35 +49,27 @@
     return metadata
 
 
-def prepare_docstring(s: str, ignore: int = None, tabsize: int = 8) -> List[str]:
+def prepare_docstring(s: str, tabsize: int = 8) -> List[str]:
     """Convert a docstring into lines of parseable reST.  Remove common leading
-    indentation, where the indentation of a given number of lines (usually just
-    one) is ignored.
+    indentation, where the indentation of the first line is ignored.
 
     Return the docstring as a list of lines usable for inserting into a docutils
     ViewList (used as argument of nested_parse().)  An empty line is added to
     act as a separator between this docstring and following content.
     """
-    if ignore is None:
-        ignore = 1
-    else:
-        warnings.warn("The 'ignore' argument to prepare_docstring() is deprecated.",
-                      RemovedInSphinx50Warning, stacklevel=2)
-
     lines = s.expandtabs(tabsize).splitlines()
     # Find minimum indentation of any non-blank lines after ignored lines.
     margin = sys.maxsize
-    for line in lines[ignore:]:
+    for line in lines[1:]:
         content = len(line.lstrip())
         if content:
             indent = len(line) - content
             margin = min(margin, indent)
-    # Remove indentation from ignored lines.
-    for i in range(ignore):
-        if i < len(lines):
-            lines[i] = lines[i].lstrip()
+    # Remove indentation from the first line.
+    if len(lines):
+        lines[0] = lines[0].lstrip()
     if margin < sys.maxsize:
-        for i in range(ignore, len(lines)):
+        for i in range(1, len(lines)):
             lines[i] = lines[i][margin:]
     # Remove any leading blank lines.
     while lines and not lines[0]:
('sphinx/util', 'matching.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,17 +1,10 @@
-"""
-    sphinx.util.matching
-    ~~~~~~~~~~~~~~~~~~~~
+"""Pattern-matching utility functions for Sphinx."""
 
-    Pattern-matching utility functions for Sphinx.
+import os.path
+import re
+from typing import Callable, Dict, Iterable, Iterator, List, Match, Optional, Pattern
 
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
-
-import re
-from typing import Callable, Dict, Iterable, List, Match, Optional, Pattern
-
-from sphinx.util.osutil import canon_path
+from sphinx.util.osutil import canon_path, path_stabilize
 
 
 def _translate_pattern(pat: str) -> str:
@@ -60,7 +53,7 @@
     return res + '$'
 
 
-def compile_matchers(patterns: List[str]) -> List[Callable[[str], Optional[Match[str]]]]:
+def compile_matchers(patterns: Iterable[str]) -> List[Callable[[str], Optional[Match[str]]]]:
     return [re.compile(_translate_pattern(pat)).match for pat in patterns]
 
 
@@ -71,9 +64,9 @@
           For example, "**/index.rst" matches with "index.rst"
     """
 
-    def __init__(self, patterns: List[str]) -> None:
-        expanded = [pat[3:] for pat in patterns if pat.startswith('**/')]
-        self.patterns = compile_matchers(patterns + expanded)
+    def __init__(self, exclude_patterns: Iterable[str]) -> None:
+        expanded = [pat[3:] for pat in exclude_patterns if pat.startswith('**/')]
+        self.patterns = compile_matchers(list(exclude_patterns) + expanded)
 
     def __call__(self, string: str) -> bool:
         return self.match(string)
@@ -107,3 +100,63 @@
         _pat_cache[pat] = re.compile(_translate_pattern(pat))
     match = _pat_cache[pat].match
     return list(filter(match, names))
+
+
+def get_matching_files(
+    dirname: str,
+    include_patterns: Iterable[str] = ("**",),
+    exclude_patterns: Iterable[str] = (),
+) -> Iterator[str]:
+    """Get all file names in a directory, recursively.
+
+    Filter file names by the glob-style include_patterns and exclude_patterns.
+    The default values include all files ("**") and exclude nothing ("").
+
+    Only files matching some pattern in *include_patterns* are included, and
+    exclusions from *exclude_patterns* take priority over inclusions.
+
+    """
+    # dirname is a normalized absolute path.
+    dirname = os.path.normpath(os.path.abspath(dirname))
+
+    exclude_matchers = compile_matchers(exclude_patterns)
+    include_matchers = compile_matchers(include_patterns)
+
+    for root, dirs, files in os.walk(dirname, followlinks=True):
+        relative_root = os.path.relpath(root, dirname)
+        if relative_root == ".":
+            relative_root = ""  # suppress dirname for files on the target dir
+
+        # Filter files
+        included_files = []
+        for entry in sorted(files):
+            entry = path_stabilize(os.path.join(relative_root, entry))
+            keep = False
+            for matcher in include_matchers:
+                if matcher(entry):
+                    keep = True
+                    break  # break the inner loop
+
+            for matcher in exclude_matchers:
+                if matcher(entry):
+                    keep = False
+                    break  # break the inner loop
+
+            if keep:
+                included_files.append(entry)
+
+        # Filter directories
+        filtered_dirs = []
+        for dir_name in sorted(dirs):
+            normalised = path_stabilize(os.path.join(relative_root, dir_name))
+            for matcher in exclude_matchers:
+                if matcher(normalised):
+                    break  # break the inner loop
+            else:
+                # if the loop didn't break
+                filtered_dirs.append(dir_name)
+
+        dirs[:] = filtered_dirs
+
+        # Yield filtered files
+        yield from included_files
('sphinx/util', 'png.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.util.png
-    ~~~~~~~~~~~~~~~
-
-    PNG image manipulation helpers.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""PNG image manipulation helpers."""
 
 import binascii
 import struct
('sphinx/util', 'inspect.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.util.inspect
-    ~~~~~~~~~~~~~~~~~~~
-
-    Helpers for inspecting Python modules.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Helpers for inspecting Python modules."""
 
 import builtins
 import contextlib
@@ -16,15 +8,13 @@
 import sys
 import types
 import typing
-import warnings
 from functools import partial, partialmethod
 from importlib import import_module
 from inspect import Parameter, isclass, ismethod, ismethoddescriptor, ismodule  # NOQA
 from io import StringIO
-from types import ModuleType
+from types import MethodType, ModuleType
 from typing import Any, Callable, Dict, Mapping, Optional, Sequence, Tuple, Type, cast
 
-from sphinx.deprecation import RemovedInSphinx50Warning
 from sphinx.pycode.ast import ast  # for py36-37
 from sphinx.pycode.ast import unparse as ast_unparse
 from sphinx.util import logging
@@ -38,76 +28,9 @@
     MethodDescriptorType = type(str.join)
     WrapperDescriptorType = type(dict.__dict__['fromkeys'])
 
-if False:
-    # For type annotation
-    from typing import Type  # NOQA
-
 logger = logging.getLogger(__name__)
 
 memory_address_re = re.compile(r' at 0x[0-9a-f]{8,16}(?=>)', re.IGNORECASE)
-
-
-# Copied from the definition of inspect.getfullargspec from Python master,
-# and modified to remove the use of special flags that break decorated
-# callables and bound methods in the name of backwards compatibility. Used
-# under the terms of PSF license v2, which requires the above statement
-# and the following:
-#
-#   Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,
-#   2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017 Python Software
-#   Foundation; All Rights Reserved
-def getargspec(func: Callable) -> Any:
-    """Like inspect.getfullargspec but supports bound methods, and wrapped
-    methods."""
-    warnings.warn('sphinx.ext.inspect.getargspec() is deprecated',
-                  RemovedInSphinx50Warning, stacklevel=2)
-
-    sig = inspect.signature(func)
-
-    args = []
-    varargs = None
-    varkw = None
-    kwonlyargs = []
-    defaults = ()
-    annotations = {}
-    defaults = ()
-    kwdefaults = {}
-
-    if sig.return_annotation is not sig.empty:
-        annotations['return'] = sig.return_annotation
-
-    for param in sig.parameters.values():
-        kind = param.kind
-        name = param.name
-
-        if kind is Parameter.POSITIONAL_ONLY:
-            args.append(name)
-        elif kind is Parameter.POSITIONAL_OR_KEYWORD:
-            args.append(name)
-            if param.default is not param.empty:
-                defaults += (param.default,)  # type: ignore
-        elif kind is Parameter.VAR_POSITIONAL:
-            varargs = name
-        elif kind is Parameter.KEYWORD_ONLY:
-            kwonlyargs.append(name)
-            if param.default is not param.empty:
-                kwdefaults[name] = param.default
-        elif kind is Parameter.VAR_KEYWORD:
-            varkw = name
-
-        if param.annotation is not param.empty:
-            annotations[name] = param.annotation
-
-    if not kwdefaults:
-        # compatibility with 'func.__kwdefaults__'
-        kwdefaults = None
-
-    if not defaults:
-        # compatibility with 'func.__defaults__'
-        defaults = None
-
-    return inspect.FullArgSpec(args, varargs, varkw, defaults,
-                               kwonlyargs, kwdefaults, annotations)
 
 
 def unwrap(obj: Any) -> Any:
@@ -123,7 +46,7 @@
         return obj
 
 
-def unwrap_all(obj: Any, *, stop: Callable = None) -> Any:
+def unwrap_all(obj: Any, *, stop: Optional[Callable] = None) -> Any:
     """
     Get an original object from wrapped object (unwrapping partials, wrapped
     functions, and other decorators).
@@ -134,7 +57,7 @@
         elif ispartial(obj):
             obj = obj.func
         elif inspect.isroutine(obj) and hasattr(obj, '__wrapped__'):
-            obj = obj.__wrapped__
+            obj = obj.__wrapped__  # type: ignore
         elif isclassmethod(obj):
             obj = obj.__func__
         elif isstaticmethod(obj):
@@ -183,7 +106,22 @@
     if isinstance(__mro__, tuple):
         return __mro__
     else:
-        return tuple()
+        return ()
+
+
+def getorigbases(obj: Any) -> Optional[Tuple[Any, ...]]:
+    """Get __orig_bases__ from *obj* safely."""
+    if not inspect.isclass(obj):
+        return None
+
+    # Get __orig_bases__ from obj.__dict__ to avoid accessing the parent's __orig_bases__.
+    # refs: https://github.com/sphinx-doc/sphinx/issues/9607
+    __dict__ = safe_getattr(obj, '__dict__', {})
+    __orig_bases__ = __dict__.get('__orig_bases__')
+    if isinstance(__orig_bases__, tuple) and len(__orig_bases__) > 0:
+        return __orig_bases__
+    else:
+        return None
 
 
 def getslots(obj: Any) -> Optional[Dict]:
@@ -248,7 +186,7 @@
     return isinstance(obj, (partial, partialmethod))
 
 
-def isclassmethod(obj: Any, cls: Any = None, name: str = None) -> bool:
+def isclassmethod(obj: Any, cls: Any = None, name: Optional[str] = None) -> bool:
     """Check if the object is classmethod."""
     if isinstance(obj, classmethod):
         return True
@@ -264,7 +202,7 @@
     return False
 
 
-def isstaticmethod(obj: Any, cls: Any = None, name: str = None) -> bool:
+def isstaticmethod(obj: Any, cls: Any = None, name: Optional[str] = None) -> bool:
     """Check if the object is staticmethod."""
     if isinstance(obj, staticmethod):
         return True
@@ -286,7 +224,7 @@
 def isdescriptor(x: Any) -> bool:
     """Check if the object is some kind of descriptor."""
     for item in '__get__', '__set__', '__delete__':
-        if hasattr(safe_getattr(x, item, None), '__call__'):
+        if callable(safe_getattr(x, item, None)):
             return True
     return False
 
@@ -294,6 +232,11 @@
 def isabstractmethod(obj: Any) -> bool:
     """Check if the object is an abstractmethod."""
     return safe_getattr(obj, '__isabstractmethod__', False) is True
+
+
+def isboundmethod(method: MethodType) -> bool:
+    """Check if the method is a bound method."""
+    return safe_getattr(method, '__self__', None) is not None
 
 
 def is_cython_function_or_method(obj: Any) -> bool:
@@ -340,7 +283,7 @@
     if (inspect.isfunction(obj) and
             hasattr(obj, 'dispatch') and
             hasattr(obj, 'register') and
-            obj.dispatch.__module__ == 'functools'):
+            obj.dispatch.__module__ == 'functools'):  # type: ignore
         return True
     else:
         return False
@@ -387,6 +330,16 @@
     if hasattr(obj, '__code__') and inspect.iscoroutinefunction(obj):
         # check obj.__code__ because iscoroutinefunction() crashes for custom method-like
         # objects (see https://github.com/sphinx-doc/sphinx/issues/6605)
+        return True
+    else:
+        return False
+
+
+def isasyncgenfunction(obj: Any) -> bool:
+    """Check if the object is async-gen function."""
+    if hasattr(obj, '__code__') and inspect.isasyncgenfunction(obj):
+        # check obj.__code__ because isasyncgenfunction() crashes for custom method-like
+        # objects on python3.7 (see https://github.com/sphinx-doc/sphinx/issues/9838)
         return True
     else:
         return False
@@ -529,6 +482,12 @@
 
     def __eq__(self, other: Any) -> bool:
         return self.name == other
+
+    def __hash__(self) -> int:
+        return hash(self.name)
+
+    def __repr__(self) -> str:
+        return self.name
 
 
 class TypeAliasModule:
@@ -598,26 +557,19 @@
     return False
 
 
-def signature(subject: Callable, bound_method: bool = False, follow_wrapped: bool = None,
-              type_aliases: Dict = {}) -> inspect.Signature:
+def signature(subject: Callable, bound_method: bool = False, type_aliases: Dict = {}
+              ) -> inspect.Signature:
     """Return a Signature object for the given *subject*.
 
     :param bound_method: Specify *subject* is a bound method or not
-    :param follow_wrapped: Same as ``inspect.signature()``.
-    """
-
-    if follow_wrapped is None:
-        follow_wrapped = True
-    else:
-        warnings.warn('The follow_wrapped argument of sphinx.util.inspect.signature() is '
-                      'deprecated', RemovedInSphinx50Warning, stacklevel=2)
+    """
 
     try:
         try:
             if _should_unwrap(subject):
                 signature = inspect.signature(subject)
             else:
-                signature = inspect.signature(subject, follow_wrapped=follow_wrapped)
+                signature = inspect.signature(subject, follow_wrapped=True)
         except ValueError:
             # follow built-in wrappers up (ex. functools.lru_cache)
             signature = inspect.signature(subject)
@@ -667,11 +619,12 @@
     #
     # For example, this helps a function having a default value `inspect._empty`.
     # refs: https://github.com/sphinx-doc/sphinx/issues/7935
-    return inspect.Signature(parameters, return_annotation=return_annotation,  # type: ignore
+    return inspect.Signature(parameters, return_annotation=return_annotation,
                              __validate_parameters__=False)
 
 
-def evaluate_signature(sig: inspect.Signature, globalns: Dict = None, localns: Dict = None
+def evaluate_signature(sig: inspect.Signature, globalns: Optional[Dict] = None,
+                       localns: Optional[Dict] = None
                        ) -> inspect.Signature:
     """Evaluate unresolved type annotations in a signature object."""
     def evaluate_forwardref(ref: ForwardRef, globalns: Dict, localns: Dict) -> Any:
@@ -719,11 +672,20 @@
 
 
 def stringify_signature(sig: inspect.Signature, show_annotation: bool = True,
-                        show_return_annotation: bool = True) -> str:
+                        show_return_annotation: bool = True,
+                        unqualified_typehints: bool = False) -> str:
     """Stringify a Signature object.
 
-    :param show_annotation: Show annotation in result
-    """
+    :param show_annotation: If enabled, show annotations on the signature
+    :param show_return_annotation: If enabled, show annotation of the return value
+    :param unqualified_typehints: If enabled, show annotations as unqualified
+                                  (ex. io.StringIO -> StringIO)
+    """
+    if unqualified_typehints:
+        mode = 'smart'
+    else:
+        mode = 'fully-qualified'
+
     args = []
     last_kind = None
     for param in sig.parameters.values():
@@ -746,7 +708,7 @@
 
         if show_annotation and param.annotation is not param.empty:
             arg.write(': ')
-            arg.write(stringify_annotation(param.annotation))
+            arg.write(stringify_annotation(param.annotation, mode))
         if param.default is not param.empty:
             if show_annotation and param.annotation is not param.empty:
                 arg.write(' = ')
@@ -766,7 +728,7 @@
             show_return_annotation is False):
         return '(%s)' % ', '.join(args)
     else:
-        annotation = stringify_annotation(sig.return_annotation)
+        annotation = stringify_annotation(sig.return_annotation, mode)
         return '(%s) -> %s' % (', '.join(args), annotation)
 
 
@@ -792,14 +754,14 @@
         positionals = len(args.args)
 
     for _ in range(len(defaults), positionals):
-        defaults.insert(0, Parameter.empty)
+        defaults.insert(0, Parameter.empty)  # type: ignore
 
     if hasattr(args, "posonlyargs"):
         for i, arg in enumerate(args.posonlyargs):  # type: ignore
             if defaults[i] is Parameter.empty:
                 default = Parameter.empty
             else:
-                default = DefaultValue(ast_unparse(defaults[i], code))
+                default = DefaultValue(ast_unparse(defaults[i], code))  # type: ignore
 
             annotation = ast_unparse(arg.annotation, code) or Parameter.empty
             params.append(Parameter(arg.arg, Parameter.POSITIONAL_ONLY,
@@ -809,7 +771,7 @@
         if defaults[i + posonlyargs] is Parameter.empty:
             default = Parameter.empty
         else:
-            default = DefaultValue(ast_unparse(defaults[i + posonlyargs], code))
+            default = DefaultValue(ast_unparse(defaults[i + posonlyargs], code))  # type: ignore  # NOQA
 
         annotation = ast_unparse(arg.annotation, code) or Parameter.empty
         params.append(Parameter(arg.arg, Parameter.POSITIONAL_OR_KEYWORD,
@@ -821,7 +783,10 @@
                                 annotation=annotation))
 
     for i, arg in enumerate(args.kwonlyargs):
-        default = ast_unparse(args.kw_defaults[i], code) or Parameter.empty
+        if args.kw_defaults[i] is None:
+            default = Parameter.empty
+        else:
+            default = DefaultValue(ast_unparse(args.kw_defaults[i], code))  # type: ignore  # NOQA
         annotation = ast_unparse(arg.annotation, code) or Parameter.empty
         params.append(Parameter(arg.arg, Parameter.KEYWORD_ONLY, default=default,
                                 annotation=annotation))
@@ -836,8 +801,13 @@
     return inspect.Signature(params, return_annotation=return_annotation)
 
 
-def getdoc(obj: Any, attrgetter: Callable = safe_getattr,
-           allow_inherited: bool = False, cls: Any = None, name: str = None) -> str:
+def getdoc(
+    obj: Any,
+    attrgetter: Callable = safe_getattr,
+    allow_inherited: bool = False,
+    cls: Any = None,
+    name: Optional[str] = None
+) -> Optional[str]:
     """Get the docstring for the object.
 
     This tries to obtain the docstring for some kind of objects additionally:
@@ -846,13 +816,22 @@
     * inherited docstring
     * inherited decorated methods
     """
+    def getdoc_internal(obj: Any, attrgetter: Callable = safe_getattr) -> Optional[str]:
+        doc = attrgetter(obj, '__doc__', None)
+        if isinstance(doc, str):
+            return doc
+        else:
+            return None
+
     if cls and name and isclassmethod(obj, cls, name):
         for basecls in getmro(cls):
             meth = basecls.__dict__.get(name)
-            if meth:
-                return getdoc(meth.__func__)
-
-    doc = attrgetter(obj, '__doc__', None)
+            if meth and hasattr(meth, '__func__'):
+                doc: Optional[str] = getdoc(meth.__func__)
+                if doc is not None or not allow_inherited:
+                    return doc
+
+    doc = getdoc_internal(obj)
     if ispartial(obj) and doc == obj.__class__.__doc__:
         return getdoc(obj.func)
     elif doc is None and allow_inherited:
@@ -861,7 +840,7 @@
             for basecls in getmro(cls):
                 meth = safe_getattr(basecls, name, None)
                 if meth is not None:
-                    doc = attrgetter(meth, '__doc__', None)
+                    doc = getdoc_internal(meth)
                     if doc is not None:
                         break
 
('sphinx/util', 'cfamily.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.util.cfamily
-    ~~~~~~~~~~~~~~~~~~~
-
-    Utility functions common to the C and C++ domains.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Utility functions common to the C and C++ domains."""
 
 import re
 from copy import deepcopy
@@ -15,6 +7,7 @@
 from docutils import nodes
 from docutils.nodes import TextElement
 
+from sphinx import addnodes
 from sphinx.config import Config
 from sphinx.util import logging
 
@@ -134,8 +127,9 @@
         return "[[" + self.arg + "]]"
 
     def describe_signature(self, signode: TextElement) -> None:
-        txt = str(self)
-        signode.append(nodes.Text(txt, txt))
+        signode.append(addnodes.desc_sig_punctuation('[[', '[['))
+        signode.append(nodes.Text(self.arg))
+        signode.append(addnodes.desc_sig_punctuation(']]', ']]'))
 
 
 class ASTGnuAttribute(ASTBaseBase):
@@ -167,7 +161,7 @@
 
     def describe_signature(self, signode: TextElement) -> None:
         txt = str(self)
-        signode.append(nodes.Text(txt, txt))
+        signode.append(nodes.Text(txt))
 
 
 class ASTIdAttribute(ASTAttribute):
@@ -180,7 +174,7 @@
         return self.id
 
     def describe_signature(self, signode: TextElement) -> None:
-        signode.append(nodes.Text(self.id, self.id))
+        signode.append(nodes.Text(self.id))
 
 
 class ASTParenAttribute(ASTAttribute):
@@ -195,7 +189,31 @@
 
     def describe_signature(self, signode: TextElement) -> None:
         txt = str(self)
-        signode.append(nodes.Text(txt, txt))
+        signode.append(nodes.Text(txt))
+
+
+class ASTAttributeList(ASTBaseBase):
+    def __init__(self, attrs: List[ASTAttribute]) -> None:
+        self.attrs = attrs
+
+    def __len__(self) -> int:
+        return len(self.attrs)
+
+    def __add__(self, other: "ASTAttributeList") -> "ASTAttributeList":
+        return ASTAttributeList(self.attrs + other.attrs)
+
+    def _stringify(self, transform: StringifyTransform) -> str:
+        return ' '.join(transform(attr) for attr in self.attrs)
+
+    def describe_signature(self, signode: TextElement) -> None:
+        if len(self.attrs) == 0:
+            return
+        self.attrs[0].describe_signature(signode)
+        if len(self.attrs) == 1:
+            return
+        for attr in self.attrs[1:]:
+            signode.append(addnodes.desc_sig_space())
+            attr.describe_signature(signode)
 
 
 ################################################################################
@@ -361,7 +379,7 @@
         while not self.eof:
             if len(symbols) == 0 and self.current_char in end:
                 break
-            if self.current_char in brackets.keys():
+            if self.current_char in brackets:
                 symbols.append(brackets[self.current_char])
             elif len(symbols) > 0 and self.current_char == symbols[-1]:
                 symbols.pop()
@@ -429,5 +447,14 @@
 
         return None
 
+    def _parse_attribute_list(self) -> ASTAttributeList:
+        res = []
+        while True:
+            attr = self._parse_attribute()
+            if attr is None:
+                break
+            res.append(attr)
+        return ASTAttributeList(res)
+
     def _parse_paren_expression_list(self) -> ASTBaseParenExprList:
         raise NotImplementedError
('sphinx/util', 'jsdump.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,16 +1,16 @@
+"""This module implements a simple JavaScript serializer.
+
+Uses the basestring encode function from simplejson by Bob Ippolito.
 """
-    sphinx.util.jsdump
-    ~~~~~~~~~~~~~~~~~~
-
-    This module implements a simple JavaScript serializer.
-    Uses the basestring encode function from simplejson by Bob Ippolito.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
 
 import re
+import warnings
 from typing import IO, Any, Dict, List, Match, Union
+
+from sphinx.deprecation import RemovedInSphinx70Warning
+
+warnings.warn('"sphinx.util.jsdump" has been deprecated. Please use "json" instead.',
+              RemovedInSphinx70Warning)
 
 _str_re = re.compile(r'"(\\\\|\\"|[^"])*"')
 _int_re = re.compile(r'\d+')
('sphinx/util', 'pycompat.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.util.pycompat
-    ~~~~~~~~~~~~~~~~~~~~
-
-    Stuff for Python version compatibility.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Stuff for Python version compatibility."""
 
 import warnings
 from typing import Any, Callable
('sphinx/util', 'images.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.util.images
-    ~~~~~~~~~~~~~~~~~~
-
-    Image utility functions for Sphinx.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Image utility functions for Sphinx."""
 
 import base64
 import imghdr
('sphinx/util', 'osutil.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.util.osutil
-    ~~~~~~~~~~~~~~~~~~
-
-    Operating system-related utility functions for Sphinx.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Operating system-related utility functions for Sphinx."""
 
 import contextlib
 import filecmp
@@ -14,12 +6,10 @@
 import re
 import shutil
 import sys
-import warnings
+import unicodedata
 from io import StringIO
 from os import path
 from typing import Any, Generator, Iterator, List, Optional, Type
-
-from sphinx.deprecation import RemovedInSphinx50Warning
 
 try:
     # for ALT Linux (#6712)
@@ -43,6 +33,12 @@
 def canon_path(nativepath: str) -> str:
     """Return path in OS-independent form"""
     return nativepath.replace(path.sep, SEP)
+
+
+def path_stabilize(filepath: str) -> str:
+    "Normalize path separator and unicode string"
+    new_path = canon_path(filepath)
+    return unicodedata.normalize('NFC', new_path)
 
 
 def relative_uri(base: str, to: str) -> str:
@@ -75,26 +71,13 @@
 
 def mtimes_of_files(dirnames: List[str], suffix: str) -> Iterator[float]:
     for dirname in dirnames:
-        for root, dirs, files in os.walk(dirname):
+        for root, _dirs, files in os.walk(dirname):
             for sfile in files:
                 if sfile.endswith(suffix):
                     try:
                         yield path.getmtime(path.join(root, sfile))
                     except OSError:
                         pass
-
-
-def movefile(source: str, dest: str) -> None:
-    """Move a file, removing the destination if it exists."""
-    warnings.warn('sphinx.util.osutil.movefile() is deprecated for removal. '
-                  'Please use os.replace() instead.',
-                  RemovedInSphinx50Warning, stacklevel=2)
-    if os.path.exists(dest):
-        try:
-            os.unlink(dest)
-        except OSError:
-            pass
-    os.rename(source, dest)
 
 
 def copytimes(source: str, dest: str) -> None:
@@ -129,7 +112,7 @@
     return make_filename(project_suffix_re.sub('', project)).lower()
 
 
-def relpath(path: str, start: str = os.curdir) -> str:
+def relpath(path: str, start: Optional[str] = os.curdir) -> str:
     """Return a relative filepath to *path* either from the current directory or
     from an optional *start* directory.
 
('sphinx/util', 'template.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,17 +1,9 @@
-"""
-    sphinx.util.template
-    ~~~~~~~~~~~~~~~~~~~~
-
-    Templates utility functions for Sphinx.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Templates utility functions for Sphinx."""
 
 import os
 from functools import partial
 from os import path
-from typing import Callable, Dict, List, Tuple, Union
+from typing import Any, Callable, Dict, List, Optional, Tuple, Union
 
 from jinja2 import TemplateNotFound
 from jinja2.environment import Environment
@@ -25,15 +17,15 @@
 
 
 class BaseRenderer:
-    def __init__(self, loader: BaseLoader = None) -> None:
+    def __init__(self, loader: Optional[BaseLoader] = None) -> None:
         self.env = SandboxedEnvironment(loader=loader, extensions=['jinja2.ext.i18n'])
         self.env.filters['repr'] = repr
         self.env.install_gettext_translations(get_translator())
 
-    def render(self, template_name: str, context: Dict) -> str:
+    def render(self, template_name: str, context: Dict[str, Any]) -> str:
         return self.env.get_template(template_name).render(context)
 
-    def render_string(self, source: str, context: Dict) -> str:
+    def render_string(self, source: str, context: Dict[str, Any]) -> str:
         return self.env.from_string(source).render(context)
 
 
@@ -49,25 +41,27 @@
         super().__init__(loader)
 
     @classmethod
-    def render_from_file(cls, filename: str, context: Dict) -> str:
+    def render_from_file(cls, filename: str, context: Dict[str, Any]) -> str:
         dirname = os.path.dirname(filename)
         basename = os.path.basename(filename)
         return cls(dirname).render(basename, context)
 
 
 class SphinxRenderer(FileRenderer):
-    def __init__(self, template_path: Union[str, List[str]] = None) -> None:
+    def __init__(self, template_path: Union[None, str, List[str]] = None) -> None:
         if template_path is None:
             template_path = os.path.join(package_dir, 'templates')
         super().__init__(template_path)
 
     @classmethod
-    def render_from_file(cls, filename: str, context: Dict) -> str:
+    def render_from_file(cls, filename: str, context: Dict[str, Any]) -> str:
         return FileRenderer.render_from_file(filename, context)
 
 
 class LaTeXRenderer(SphinxRenderer):
-    def __init__(self, template_path: str = None, latex_engine: str = None) -> None:
+    def __init__(
+        self, template_path: Optional[str] = None, latex_engine: Optional[str] = None
+    ) -> None:
         if template_path is None:
             template_path = os.path.join(package_dir, 'templates', 'latex')
         super().__init__(template_path)
@@ -89,7 +83,9 @@
 
 
 class ReSTRenderer(SphinxRenderer):
-    def __init__(self, template_path: Union[str, List[str]] = None, language: str = None) -> None:  # NOQA
+    def __init__(
+        self, template_path: Union[None, str, List[str]] = None, language: Optional[str] = None
+    ) -> None:
         super().__init__(template_path)
 
         # add language to environment
('sphinx/util', 'i18n.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,15 +1,8 @@
-"""
-    sphinx.util.i18n
-    ~~~~~~~~~~~~~~~~
-
-    Builder superclass for all builders.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Builder superclass for all builders."""
 
 import os
 import re
+import warnings
 from datetime import datetime, timezone
 from os import path
 from typing import TYPE_CHECKING, Callable, Generator, List, NamedTuple, Optional, Tuple, Union
@@ -18,6 +11,7 @@
 from babel.messages.mofile import write_mo
 from babel.messages.pofile import read_po
 
+from sphinx.deprecation import RemovedInSphinx70Warning
 from sphinx.errors import SphinxError
 from sphinx.locale import __
 from sphinx.util import logging
@@ -59,7 +53,7 @@
             not path.exists(self.mo_path) or
             path.getmtime(self.mo_path) < path.getmtime(self.po_path))
 
-    def write_mo(self, locale: str) -> None:
+    def write_mo(self, locale: str, use_fuzzy: bool = False) -> None:
         with open(self.po_path, encoding=self.charset) as file_po:
             try:
                 po = read_po(file_po, locale)
@@ -69,7 +63,7 @@
 
         with open(self.mo_path, 'wb') as file_mo:
             try:
-                write_mo(file_mo, po)
+                write_mo(file_mo, po, use_fuzzy)
             except Exception as exc:
                 logger.warning(__('writing error: %s, %s'), self.mo_path, exc)
 
@@ -173,9 +167,11 @@
 date_format_re = re.compile('(%s)' % '|'.join(date_format_mappings))
 
 
-def babel_format_date(date: datetime, format: str, locale: Optional[str],
+def babel_format_date(date: datetime, format: str, locale: str,
                       formatter: Callable = babel.dates.format_date) -> str:
     if locale is None:
+        warnings.warn('The locale argument for babel_format_date() becomes required.',
+                      RemovedInSphinx70Warning)
         locale = 'en'
 
     # Check if we have the tzinfo attribute. If not we cannot do any time
@@ -194,7 +190,9 @@
         return format
 
 
-def format_date(format: str, date: datetime = None, language: Optional[str] = None) -> str:
+def format_date(
+    format: str, date: Optional[datetime] = None, language: Optional[str] = None
+) -> str:
     if date is None:
         # If time is not specified, try to use $SOURCE_DATE_EPOCH variable
         # See https://wiki.debian.org/ReproducibleBuilds/TimestampsProposal
@@ -203,6 +201,11 @@
             date = datetime.utcfromtimestamp(float(source_date_epoch))
         else:
             date = datetime.now(timezone.utc).astimezone()
+
+    if language is None:
+        warnings.warn('The language argument for format_date() becomes required.',
+                      RemovedInSphinx70Warning)
+        language = 'en'
 
     result = []
     tokens = date_format_re.split(format)
@@ -229,11 +232,8 @@
 
 
 def get_image_filename_for_language(filename: str, env: "BuildEnvironment") -> str:
-    if not env.config.language:
-        return filename
-
     filename_format = env.config.figure_language_filename
-    d = dict()
+    d = {}
     d['root'], d['ext'] = path.splitext(filename)
     dirname = path.dirname(d['root'])
     if dirname and not dirname.endswith(path.sep):
@@ -252,9 +252,6 @@
 
 
 def search_image_for_language(filename: str, env: "BuildEnvironment") -> str:
-    if not env.config.language:
-        return filename
-
     translated = get_image_filename_for_language(filename, env)
     _, abspath = env.relfn2path(translated)
     if path.exists(abspath):
('sphinx/util', 'math.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,6 @@
-"""
-    sphinx.util.math
-    ~~~~~~~~~~~~~~~~
+"""Utility functions for math."""
 
-    Utility functions for math.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+from typing import Optional
 
 from docutils import nodes
 
@@ -28,7 +22,7 @@
         return node['number']
 
 
-def wrap_displaymath(text: str, label: str, numbering: bool) -> str:
+def wrap_displaymath(text: str, label: Optional[str], numbering: bool) -> str:
     def is_equation(part: str) -> str:
         return part.strip()
 
('sphinx/util', 'nodes.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,17 +1,9 @@
-"""
-    sphinx.util.nodes
-    ~~~~~~~~~~~~~~~~~
-
-    Docutils node-related utility functions for Sphinx.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Docutils node-related utility functions for Sphinx."""
 
 import re
 import unicodedata
 from typing import (TYPE_CHECKING, Any, Callable, Iterable, List, Optional, Set, Tuple, Type,
-                    Union, cast)
+                    Union)
 
 from docutils import nodes
 from docutils.nodes import Element, Node
@@ -38,7 +30,7 @@
 
 
 class NodeMatcher:
-    """A helper class for Node.traverse().
+    """A helper class for Node.findall().
 
     It checks that the given node is an instance of the specified node-classes and
     has the specified node-attributes.
@@ -47,7 +39,7 @@
     and ``reftype`` attributes::
 
         matcher = NodeMatcher(nodes.reference, refdomain='std', reftype='citation')
-        doctree.traverse(matcher)
+        doctree.findall(matcher)
         # => [<reference ...>, <reference ...>, ...]
 
     A special value ``typing.Any`` matches any kind of node-attributes.  For example,
@@ -55,7 +47,7 @@
 
         from typing import Any
         matcher = NodeMatcher(nodes.reference, refdomain=Any)
-        doctree.traverse(matcher)
+        doctree.findall(matcher)
         # => [<reference ...>, <reference ...>, ...]
     """
 
@@ -147,9 +139,14 @@
         logger.debug('[i18n] PATCH: %r to have rawsource: %s',
                      get_full_module_name(node), repr_domxml(node))
         # strip classifier from rawsource of term
-        for classifier in reversed(list(node.parent.traverse(nodes.classifier))):
+        for classifier in reversed(list(node.parent.findall(nodes.classifier))):
             node.rawsource = re.sub(r'\s*:\s*%s' % re.escape(classifier.astext()),
                                     '', node.rawsource)
+    if isinstance(node, nodes.topic) and node.source is None:
+        # docutils-0.18 does not fill the source attribute of topic
+        logger.debug('[i18n] PATCH: %r to have source, line: %s',
+                     get_full_module_name(node), repr_domxml(node))
+        node.source, node.line = node.parent.source, node.parent.line
 
     # workaround: literal_block under bullet list (#4913)
     if isinstance(node, nodes.literal_block) and node.source is None:
@@ -228,9 +225,11 @@
             return False
         return True
 
-    if isinstance(node, addnodes.meta):
+    if is_pending_meta(node) or isinstance(node, addnodes.meta):
+        # docutils-0.17 or older
         return True
-    if is_pending_meta(node):
+    elif isinstance(node, addnodes.docutils_meta):
+        # docutils-0.18+
         return True
 
     return False
@@ -252,7 +251,7 @@
 
 def extract_messages(doctree: Element) -> Iterable[Tuple[Element, str]]:
     """Extract translatable messages from a document tree."""
-    for node in doctree.traverse(is_translatable):  # type: Element
+    for node in doctree.findall(is_translatable):  # type: Element
         if isinstance(node, addnodes.translatable):
             for msg in node.extract_original_messages():
                 yield node, msg
@@ -269,9 +268,14 @@
             else:
                 msg = ''
         elif isinstance(node, META_TYPE_NODES):
+            # docutils-0.17 or older
             msg = node.rawcontent
         elif isinstance(node, nodes.pending) and is_pending_meta(node):
+            # docutils-0.17 or older
             msg = node.details['nodes'][0].rawcontent
+        elif isinstance(node, addnodes.docutils_meta):
+            # docutils-0.18+
+            msg = node["content"]
         else:
             msg = node.rawsource.replace('\n', ' ').strip()
 
@@ -311,7 +315,8 @@
 
 def traverse_translatable_index(doctree: Element) -> Iterable[Tuple[Element, List["IndexEntry"]]]:  # NOQA
     """Traverse translatable index node from a document tree."""
-    for node in doctree.traverse(NodeMatcher(addnodes.index, inline=False)):  # type: addnodes.index  # NOQA
+    matcher = NodeMatcher(addnodes.index, inline=False)
+    for node in doctree.findall(matcher):  # type: addnodes.index
         if 'raw_entries' in node:
             entries = node['raw_entries']
         else:
@@ -341,9 +346,9 @@
 def clean_astext(node: Element) -> str:
     """Like node.astext(), but ignore images."""
     node = node.deepcopy()
-    for img in node.traverse(nodes.image):
+    for img in node.findall(nodes.image):
         img['alt'] = ''
-    for raw in node.traverse(nodes.raw):
+    for raw in list(node.findall(nodes.raw)):
         raw.parent.remove(raw)
     return node.astext()
 
@@ -407,8 +412,8 @@
 
     Record all docnames in *docnameset*, and output docnames with *colorfunc*.
     """
-    tree = cast(nodes.document, tree.deepcopy())
-    for toctreenode in tree.traverse(addnodes.toctree):
+    tree = tree.deepcopy()
+    for toctreenode in list(tree.findall(addnodes.toctree)):
         newnodes = []
         includefiles = map(str, toctreenode['includefiles'])
         for includefile in includefiles:
@@ -426,7 +431,7 @@
                 else:
                     sof = addnodes.start_of_file(docname=includefile)
                     sof.children = subtree.children
-                    for sectionnode in sof.traverse(nodes.section):
+                    for sectionnode in sof.findall(nodes.section):
                         if 'docname' not in sectionnode:
                             sectionnode['docname'] = includefile
                     newnodes.append(sof)
@@ -508,7 +513,7 @@
 
 
 def make_id(env: "BuildEnvironment", document: nodes.document,
-            prefix: str = '', term: str = None) -> str:
+            prefix: str = '', term: Optional[str] = None) -> str:
     """Generate an appropriate node_id for given *prefix* and *term*."""
     node_id = None
     if prefix:
@@ -545,7 +550,8 @@
 
 
 def make_refnode(builder: "Builder", fromdocname: str, todocname: str, targetid: str,
-                 child: Union[Node, List[Node]], title: str = None) -> nodes.reference:
+                 child: Union[Node, List[Node]], title: Optional[str] = None
+                 ) -> nodes.reference:
     """Shortcut to create a reference node."""
     node = nodes.reference('', '', internal=True)
     if fromdocname == todocname and targetid:
@@ -603,7 +609,7 @@
 
 def process_only_nodes(document: Node, tags: "Tags") -> None:
     """Filter ``only`` nodes which do not match *tags*."""
-    for node in document.traverse(addnodes.only):
+    for node in document.findall(addnodes.only):
         try:
             ret = tags.eval_condition(node['expr'])
         except Exception as err:
('sphinx/util', 'requests.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.util.requests
-    ~~~~~~~~~~~~~~~~~~~~
-
-    Simple requests package loader
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Simple requests package loader"""
 
 import sys
 import warnings
@@ -15,47 +7,13 @@
 from urllib.parse import urlsplit
 
 import requests
+from urllib3.exceptions import InsecureRequestWarning
 
 import sphinx
 from sphinx.config import Config
-from sphinx.deprecation import RemovedInSphinx50Warning
-
-try:
-    from requests.packages.urllib3.exceptions import SSLError
-except ImportError:
-    # python-requests package in Debian jessie does not provide ``requests.packages.urllib3``.
-    # So try to import the exceptions from urllib3 package.
-    from urllib3.exceptions import SSLError  # type: ignore
-
-try:
-    from requests.packages.urllib3.exceptions import InsecureRequestWarning
-except ImportError:
-    try:
-        # for Debian-jessie
-        from urllib3.exceptions import InsecureRequestWarning  # type: ignore
-    except ImportError:
-        # for requests < 2.4.0
-        InsecureRequestWarning = None  # type: ignore
-
 
 useragent_header = [('User-Agent',
                      'Mozilla/5.0 (X11; Linux x86_64; rv:25.0) Gecko/20100101 Firefox/25.0')]
-
-
-def is_ssl_error(exc: Exception) -> bool:
-    """Check an exception is SSLError."""
-    warnings.warn(
-        "is_ssl_error() is outdated and likely returns incorrect results "
-        "for modern versions of Requests.",
-        RemovedInSphinx50Warning)
-    if isinstance(exc, SSLError):
-        return True
-    else:
-        args = getattr(exc, 'args', [])
-        if args and isinstance(args[0], SSLError):
-            return True
-        else:
-            return False
 
 
 @contextmanager
('sphinx/util', 'typing.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.util.typing
-    ~~~~~~~~~~~~~~~~~~
-
-    The composite types for Sphinx.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""The composite types for Sphinx."""
 
 import sys
 import typing
@@ -38,11 +30,6 @@
 except ImportError:
     UnionType = None
 
-if False:
-    # For type annotation
-    from typing import Type  # NOQA # for python3.5.1
-
-
 # builtin classes that have incorrect __module__
 INVALID_BUILTIN_CLASSES = {
     Struct: 'struct.Struct',  # Before Python 3.9
@@ -50,6 +37,14 @@
 }
 
 
+def is_invalid_builtin_class(obj: Any) -> bool:
+    """Check *obj* is an invalid built-in class."""
+    try:
+        return obj in INVALID_BUILTIN_CLASSES
+    except TypeError:  # unhashable type
+        return False
+
+
 # Text like nodes which are initialized with text and rawsource
 TextlikeNode = Union[nodes.Text, nodes.TextElement]
 
@@ -70,11 +65,15 @@
 TitleGetter = Callable[[nodes.Node], str]
 
 # inventory data on memory
-Inventory = Dict[str, Dict[str, Tuple[str, str, str, str]]]
-
-
-def get_type_hints(obj: Any, globalns: Dict = None, localns: Dict = None) -> Dict[str, Any]:
-    """Return a dictionary containing type hints for a function, method, module or class object.
+InventoryItem = Tuple[str, str, str, str]
+Inventory = Dict[str, Dict[str, InventoryItem]]
+
+
+def get_type_hints(
+    obj: Any, globalns: Optional[Dict[str, Any]] = None, localns: Optional[Dict] = None
+) -> Dict[str, Any]:
+    """Return a dictionary containing type hints for a function, method, module or class
+    object.
 
     This is a simple wrapper of `typing.get_type_hints()` that does not raise an error on
     runtime.
@@ -104,73 +103,98 @@
     return modname == 'typing' and isinstance(typ, TypeVar)
 
 
-def restify(cls: Optional[Type]) -> str:
-    """Convert python class to a reST reference."""
+def restify(cls: Optional[Type], mode: str = 'fully-qualified-except-typing') -> str:
+    """Convert python class to a reST reference.
+
+    :param mode: Specify a method how annotations will be stringified.
+
+                 'fully-qualified-except-typing'
+                     Show the module name and qualified name of the annotation except
+                     the "typing" module.
+                 'smart'
+                     Show the name of the annotation.
+    """
+    from sphinx.ext.autodoc.mock import ismock, ismockmodule  # lazy loading
     from sphinx.util import inspect  # lazy loading
+
+    if mode == 'smart':
+        modprefix = '~'
+    else:
+        modprefix = ''
 
     try:
         if cls is None or cls is NoneType:
-            return ':obj:`None`'
+            return ':py:obj:`None`'
         elif cls is Ellipsis:
             return '...'
-        elif cls in INVALID_BUILTIN_CLASSES:
-            return ':class:`%s`' % INVALID_BUILTIN_CLASSES[cls]
+        elif isinstance(cls, str):
+            return cls
+        elif ismockmodule(cls):
+            return ':py:class:`%s%s`' % (modprefix, cls.__name__)
+        elif ismock(cls):
+            return ':py:class:`%s%s.%s`' % (modprefix, cls.__module__, cls.__name__)
+        elif is_invalid_builtin_class(cls):
+            return ':py:class:`%s%s`' % (modprefix, INVALID_BUILTIN_CLASSES[cls])
         elif inspect.isNewType(cls):
             if sys.version_info > (3, 10):
                 # newtypes have correct module info since Python 3.10+
-                print(cls, type(cls), dir(cls))
-                return ':class:`%s.%s`' % (cls.__module__, cls.__name__)
-            else:
-                return ':class:`%s`' % cls.__name__
+                return ':py:class:`%s%s.%s`' % (modprefix, cls.__module__, cls.__name__)
+            else:
+                return ':py:class:`%s`' % cls.__name__
         elif UnionType and isinstance(cls, UnionType):
             if len(cls.__args__) > 1 and None in cls.__args__:
-                args = ' | '.join(restify(a) for a in cls.__args__ if a)
+                args = ' | '.join(restify(a, mode) for a in cls.__args__ if a)
                 return 'Optional[%s]' % args
             else:
-                return ' | '.join(restify(a) for a in cls.__args__)
+                return ' | '.join(restify(a, mode) for a in cls.__args__)
         elif cls.__module__ in ('__builtin__', 'builtins'):
             if hasattr(cls, '__args__'):
-                return ':class:`%s`\\ [%s]' % (
+                return ':py:class:`%s`\\ [%s]' % (
                     cls.__name__,
-                    ', '.join(restify(arg) for arg in cls.__args__),
+                    ', '.join(restify(arg, mode) for arg in cls.__args__),
                 )
             else:
-                return ':class:`%s`' % cls.__name__
+                return ':py:class:`%s`' % cls.__name__
         else:
             if sys.version_info >= (3, 7):  # py37+
-                return _restify_py37(cls)
-            else:
-                return _restify_py36(cls)
+                return _restify_py37(cls, mode)
+            else:
+                return _restify_py36(cls, mode)
     except (AttributeError, TypeError):
-        return repr(cls)
-
-
-def _restify_py37(cls: Optional[Type]) -> str:
+        return inspect.object_description(cls)
+
+
+def _restify_py37(cls: Optional[Type], mode: str = 'fully-qualified-except-typing') -> str:
     """Convert python class to a reST reference."""
     from sphinx.util import inspect  # lazy loading
+
+    if mode == 'smart':
+        modprefix = '~'
+    else:
+        modprefix = ''
 
     if (inspect.isgenericalias(cls) and
             cls.__module__ == 'typing' and cls.__origin__ is Union):
         # Union
         if len(cls.__args__) > 1 and cls.__args__[-1] is NoneType:
             if len(cls.__args__) > 2:
-                args = ', '.join(restify(a) for a in cls.__args__[:-1])
-                return ':obj:`~typing.Optional`\\ [:obj:`~typing.Union`\\ [%s]]' % args
-            else:
-                return ':obj:`~typing.Optional`\\ [%s]' % restify(cls.__args__[0])
-        else:
-            args = ', '.join(restify(a) for a in cls.__args__)
-            return ':obj:`~typing.Union`\\ [%s]' % args
+                args = ', '.join(restify(a, mode) for a in cls.__args__[:-1])
+                return ':py:obj:`~typing.Optional`\\ [:obj:`~typing.Union`\\ [%s]]' % args
+            else:
+                return ':py:obj:`~typing.Optional`\\ [%s]' % restify(cls.__args__[0], mode)
+        else:
+            args = ', '.join(restify(a, mode) for a in cls.__args__)
+            return ':py:obj:`~typing.Union`\\ [%s]' % args
     elif inspect.isgenericalias(cls):
         if isinstance(cls.__origin__, typing._SpecialForm):
-            text = restify(cls.__origin__)  # type: ignore
+            text = restify(cls.__origin__, mode)  # type: ignore
         elif getattr(cls, '_name', None):
             if cls.__module__ == 'typing':
-                text = ':class:`~%s.%s`' % (cls.__module__, cls._name)
-            else:
-                text = ':class:`%s.%s`' % (cls.__module__, cls._name)
-        else:
-            text = restify(cls.__origin__)
+                text = ':py:class:`~%s.%s`' % (cls.__module__, cls._name)
+            else:
+                text = ':py:class:`%s%s.%s`' % (modprefix, cls.__module__, cls._name)
+        else:
+            text = restify(cls.__origin__, mode)
 
         origin = getattr(cls, '__origin__', None)
         if not hasattr(cls, '__args__'):
@@ -179,32 +203,40 @@
             # Suppress arguments if all system defined TypeVars (ex. Dict[KT, VT])
             pass
         elif cls.__module__ == 'typing' and cls._name == 'Callable':
-            args = ', '.join(restify(a) for a in cls.__args__[:-1])
-            text += r"\ [[%s], %s]" % (args, restify(cls.__args__[-1]))
+            args = ', '.join(restify(a, mode) for a in cls.__args__[:-1])
+            text += r"\ [[%s], %s]" % (args, restify(cls.__args__[-1], mode))
         elif cls.__module__ == 'typing' and getattr(origin, '_name', None) == 'Literal':
             text += r"\ [%s]" % ', '.join(repr(a) for a in cls.__args__)
         elif cls.__args__:
-            text += r"\ [%s]" % ", ".join(restify(a) for a in cls.__args__)
+            text += r"\ [%s]" % ", ".join(restify(a, mode) for a in cls.__args__)
 
         return text
     elif isinstance(cls, typing._SpecialForm):
-        return ':obj:`~%s.%s`' % (cls.__module__, cls._name)
+        return ':py:obj:`~%s.%s`' % (cls.__module__, cls._name)
+    elif sys.version_info >= (3, 11) and cls is typing.Any:
+        # handle bpo-46998
+        return f':py:obj:`~{cls.__module__}.{cls.__name__}`'
     elif hasattr(cls, '__qualname__'):
         if cls.__module__ == 'typing':
-            return ':class:`~%s.%s`' % (cls.__module__, cls.__qualname__)
-        else:
-            return ':class:`%s.%s`' % (cls.__module__, cls.__qualname__)
+            return ':py:class:`~%s.%s`' % (cls.__module__, cls.__qualname__)
+        else:
+            return ':py:class:`%s%s.%s`' % (modprefix, cls.__module__, cls.__qualname__)
     elif isinstance(cls, ForwardRef):
-        return ':class:`%s`' % cls.__forward_arg__
+        return ':py:class:`%s`' % cls.__forward_arg__
     else:
         # not a class (ex. TypeVar)
         if cls.__module__ == 'typing':
-            return ':obj:`~%s.%s`' % (cls.__module__, cls.__name__)
-        else:
-            return ':obj:`%s.%s`' % (cls.__module__, cls.__name__)
-
-
-def _restify_py36(cls: Optional[Type]) -> str:
+            return ':py:obj:`~%s.%s`' % (cls.__module__, cls.__name__)
+        else:
+            return ':py:obj:`%s%s.%s`' % (modprefix, cls.__module__, cls.__name__)
+
+
+def _restify_py36(cls: Optional[Type], mode: str = 'fully-qualified-except-typing') -> str:
+    if mode == 'smart':
+        modprefix = '~'
+    else:
+        modprefix = ''
+
     module = getattr(cls, '__module__', None)
     if module == 'typing':
         if getattr(cls, '_name', None):
@@ -218,40 +250,40 @@
         else:
             qualname = repr(cls).replace('typing.', '')
     elif hasattr(cls, '__qualname__'):
-        qualname = '%s.%s' % (module, cls.__qualname__)
+        qualname = '%s%s.%s' % (modprefix, module, cls.__qualname__)
     else:
         qualname = repr(cls)
 
     if (isinstance(cls, typing.TupleMeta) and  # type: ignore
             not hasattr(cls, '__tuple_params__')):
         if module == 'typing':
-            reftext = ':class:`~typing.%s`' % qualname
-        else:
-            reftext = ':class:`%s`' % qualname
+            reftext = ':py:class:`~typing.%s`' % qualname
+        else:
+            reftext = ':py:class:`%s%s`' % (modprefix, qualname)
 
         params = cls.__args__
         if params:
-            param_str = ', '.join(restify(p) for p in params)
+            param_str = ', '.join(restify(p, mode) for p in params)
             return reftext + '\\ [%s]' % param_str
         else:
             return reftext
     elif isinstance(cls, typing.GenericMeta):
         if module == 'typing':
-            reftext = ':class:`~typing.%s`' % qualname
-        else:
-            reftext = ':class:`%s`' % qualname
+            reftext = ':py:class:`~typing.%s`' % qualname
+        else:
+            reftext = ':py:class:`%s%s`' % (modprefix, qualname)
 
         if cls.__args__ is None or len(cls.__args__) <= 2:
             params = cls.__args__
         elif cls.__origin__ == Generator:
             params = cls.__args__
         else:  # typing.Callable
-            args = ', '.join(restify(arg) for arg in cls.__args__[:-1])
-            result = restify(cls.__args__[-1])
+            args = ', '.join(restify(arg, mode) for arg in cls.__args__[:-1])
+            result = restify(cls.__args__[-1], mode)
             return reftext + '\\ [[%s], %s]' % (args, result)
 
         if params:
-            param_str = ', '.join(restify(p) for p in params)
+            param_str = ', '.join(restify(p, mode) for p in params)
             return reftext + '\\ [%s]' % (param_str)
         else:
             return reftext
@@ -261,44 +293,61 @@
         if params is not None:
             if len(params) > 1 and params[-1] is NoneType:
                 if len(params) > 2:
-                    param_str = ", ".join(restify(p) for p in params[:-1])
-                    return (':obj:`~typing.Optional`\\ '
-                            '[:obj:`~typing.Union`\\ [%s]]' % param_str)
+                    param_str = ", ".join(restify(p, mode) for p in params[:-1])
+                    return (':py:obj:`~typing.Optional`\\ '
+                            '[:py:obj:`~typing.Union`\\ [%s]]' % param_str)
                 else:
-                    return ':obj:`~typing.Optional`\\ [%s]' % restify(params[0])
-            else:
-                param_str = ', '.join(restify(p) for p in params)
-                return ':obj:`~typing.Union`\\ [%s]' % param_str
-        else:
-            return ':obj:`Union`'
+                    return ':py:obj:`~typing.Optional`\\ [%s]' % restify(params[0], mode)
+            else:
+                param_str = ', '.join(restify(p, mode) for p in params)
+                return ':py:obj:`~typing.Union`\\ [%s]' % param_str
+        else:
+            return ':py:obj:`Union`'
     elif hasattr(cls, '__qualname__'):
         if cls.__module__ == 'typing':
-            return ':class:`~%s.%s`' % (cls.__module__, cls.__qualname__)
-        else:
-            return ':class:`%s.%s`' % (cls.__module__, cls.__qualname__)
+            return ':py:class:`~%s.%s`' % (cls.__module__, cls.__qualname__)
+        else:
+            return ':py:class:`%s%s.%s`' % (modprefix, cls.__module__, cls.__qualname__)
     elif hasattr(cls, '_name'):
         # SpecialForm
         if cls.__module__ == 'typing':
-            return ':obj:`~%s.%s`' % (cls.__module__, cls._name)
-        else:
-            return ':obj:`%s.%s`' % (cls.__module__, cls._name)
+            return ':py:obj:`~%s.%s`' % (cls.__module__, cls._name)
+        else:
+            return ':py:obj:`%s%s.%s`' % (modprefix, cls.__module__, cls._name)
     elif hasattr(cls, '__name__'):
         # not a class (ex. TypeVar)
         if cls.__module__ == 'typing':
-            return ':obj:`~%s.%s`' % (cls.__module__, cls.__name__)
-        else:
-            return ':obj:`%s.%s`' % (cls.__module__, cls.__name__)
+            return ':py:obj:`~%s.%s`' % (cls.__module__, cls.__name__)
+        else:
+            return ':py:obj:`%s%s.%s`' % (modprefix, cls.__module__, cls.__name__)
     else:
         # others (ex. Any)
         if cls.__module__ == 'typing':
-            return ':obj:`~%s.%s`' % (cls.__module__, qualname)
-        else:
-            return ':obj:`%s.%s`' % (cls.__module__, qualname)
-
-
-def stringify(annotation: Any) -> str:
-    """Stringify type annotation object."""
+            return ':py:obj:`~%s.%s`' % (cls.__module__, qualname)
+        else:
+            return ':py:obj:`%s%s.%s`' % (modprefix, cls.__module__, qualname)
+
+
+def stringify(annotation: Any, mode: str = 'fully-qualified-except-typing') -> str:
+    """Stringify type annotation object.
+
+    :param mode: Specify a method how annotations will be stringified.
+
+                 'fully-qualified-except-typing'
+                     Show the module name and qualified name of the annotation except
+                     the "typing" module.
+                 'smart'
+                     Show the name of the annotation.
+                 'fully-qualified'
+                     Show the module name and qualified name of the annotation.
+    """
+    from sphinx.ext.autodoc.mock import ismock, ismockmodule  # lazy loading
     from sphinx.util import inspect  # lazy loading
+
+    if mode == 'smart':
+        modprefix = '~'
+    else:
+        modprefix = ''
 
     if isinstance(annotation, str):
         if annotation.startswith("'") and annotation.endswith("'"):
@@ -307,22 +356,27 @@
         else:
             return annotation
     elif isinstance(annotation, TypeVar):
-        if annotation.__module__ == 'typing':
+        if (annotation.__module__ == 'typing' and
+                mode in ('fully-qualified-except-typing', 'smart')):
             return annotation.__name__
         else:
-            return '.'.join([annotation.__module__, annotation.__name__])
+            return modprefix + '.'.join([annotation.__module__, annotation.__name__])
     elif inspect.isNewType(annotation):
         if sys.version_info > (3, 10):
             # newtypes have correct module info since Python 3.10+
-            return '%s.%s' % (annotation.__module__, annotation.__name__)
+            return modprefix + '%s.%s' % (annotation.__module__, annotation.__name__)
         else:
             return annotation.__name__
     elif not annotation:
         return repr(annotation)
     elif annotation is NoneType:
         return 'None'
-    elif annotation in INVALID_BUILTIN_CLASSES:
-        return INVALID_BUILTIN_CLASSES[annotation]
+    elif ismockmodule(annotation):
+        return modprefix + annotation.__name__
+    elif ismock(annotation):
+        return modprefix + '%s.%s' % (annotation.__module__, annotation.__name__)
+    elif is_invalid_builtin_class(annotation):
+        return modprefix + INVALID_BUILTIN_CLASSES[annotation]
     elif str(annotation).startswith('typing.Annotated'):  # for py310+
         pass
     elif (getattr(annotation, '__module__', None) == 'builtins' and
@@ -335,28 +389,38 @@
         return '...'
 
     if sys.version_info >= (3, 7):  # py37+
-        return _stringify_py37(annotation)
-    else:
-        return _stringify_py36(annotation)
-
-
-def _stringify_py37(annotation: Any) -> str:
+        return _stringify_py37(annotation, mode)
+    else:
+        return _stringify_py36(annotation, mode)
+
+
+def _stringify_py37(annotation: Any, mode: str = 'fully-qualified-except-typing') -> str:
     """stringify() for py37+."""
     module = getattr(annotation, '__module__', None)
-    if module == 'typing':
+    modprefix = ''
+    if module == 'typing' and getattr(annotation, '__forward_arg__', None):
+        qualname = annotation.__forward_arg__
+    elif module == 'typing':
         if getattr(annotation, '_name', None):
             qualname = annotation._name
         elif getattr(annotation, '__qualname__', None):
             qualname = annotation.__qualname__
-        elif getattr(annotation, '__forward_arg__', None):
-            qualname = annotation.__forward_arg__
-        else:
-            qualname = stringify(annotation.__origin__)  # ex. Union
+        else:
+            qualname = stringify(annotation.__origin__).replace('typing.', '')  # ex. Union
+
+        if mode == 'smart':
+            modprefix = '~%s.' % module
+        elif mode == 'fully-qualified':
+            modprefix = '%s.' % module
     elif hasattr(annotation, '__qualname__'):
-        qualname = '%s.%s' % (module, annotation.__qualname__)
+        if mode == 'smart':
+            modprefix = '~%s.' % module
+        else:
+            modprefix = '%s.' % module
+        qualname = annotation.__qualname__
     elif hasattr(annotation, '__origin__'):
         # instantiated generic provided by a user
-        qualname = stringify(annotation.__origin__)
+        qualname = stringify(annotation.__origin__, mode)
     elif UnionType and isinstance(annotation, UnionType):  # types.Union (for py3.10+)
         qualname = 'types.Union'
     else:
@@ -371,54 +435,65 @@
         elif qualname in ('Optional', 'Union'):
             if len(annotation.__args__) > 1 and annotation.__args__[-1] is NoneType:
                 if len(annotation.__args__) > 2:
-                    args = ', '.join(stringify(a) for a in annotation.__args__[:-1])
-                    return 'Optional[Union[%s]]' % args
+                    args = ', '.join(stringify(a, mode) for a in annotation.__args__[:-1])
+                    return '%sOptional[%sUnion[%s]]' % (modprefix, modprefix, args)
                 else:
-                    return 'Optional[%s]' % stringify(annotation.__args__[0])
-            else:
-                args = ', '.join(stringify(a) for a in annotation.__args__)
-                return 'Union[%s]' % args
+                    return '%sOptional[%s]' % (modprefix,
+                                               stringify(annotation.__args__[0], mode))
+            else:
+                args = ', '.join(stringify(a, mode) for a in annotation.__args__)
+                return '%sUnion[%s]' % (modprefix, args)
         elif qualname == 'types.Union':
             if len(annotation.__args__) > 1 and None in annotation.__args__:
                 args = ' | '.join(stringify(a) for a in annotation.__args__ if a)
-                return 'Optional[%s]' % args
+                return '%sOptional[%s]' % (modprefix, args)
             else:
                 return ' | '.join(stringify(a) for a in annotation.__args__)
         elif qualname == 'Callable':
-            args = ', '.join(stringify(a) for a in annotation.__args__[:-1])
-            returns = stringify(annotation.__args__[-1])
-            return '%s[[%s], %s]' % (qualname, args, returns)
+            args = ', '.join(stringify(a, mode) for a in annotation.__args__[:-1])
+            returns = stringify(annotation.__args__[-1], mode)
+            return '%s%s[[%s], %s]' % (modprefix, qualname, args, returns)
         elif qualname == 'Literal':
             args = ', '.join(repr(a) for a in annotation.__args__)
-            return '%s[%s]' % (qualname, args)
+            return '%s%s[%s]' % (modprefix, qualname, args)
         elif str(annotation).startswith('typing.Annotated'):  # for py39+
-            return stringify(annotation.__args__[0])
+            return stringify(annotation.__args__[0], mode)
         elif all(is_system_TypeVar(a) for a in annotation.__args__):
             # Suppress arguments if all system defined TypeVars (ex. Dict[KT, VT])
-            return qualname
-        else:
-            args = ', '.join(stringify(a) for a in annotation.__args__)
-            return '%s[%s]' % (qualname, args)
-
-    return qualname
-
-
-def _stringify_py36(annotation: Any) -> str:
+            return modprefix + qualname
+        else:
+            args = ', '.join(stringify(a, mode) for a in annotation.__args__)
+            return '%s%s[%s]' % (modprefix, qualname, args)
+
+    return modprefix + qualname
+
+
+def _stringify_py36(annotation: Any, mode: str = 'fully-qualified-except-typing') -> str:
     """stringify() for py36."""
     module = getattr(annotation, '__module__', None)
-    if module == 'typing':
+    modprefix = ''
+    if module == 'typing' and getattr(annotation, '__forward_arg__', None):
+        qualname = annotation.__forward_arg__
+    elif module == 'typing':
         if getattr(annotation, '_name', None):
             qualname = annotation._name
         elif getattr(annotation, '__qualname__', None):
             qualname = annotation.__qualname__
-        elif getattr(annotation, '__forward_arg__', None):
-            qualname = annotation.__forward_arg__
         elif getattr(annotation, '__origin__', None):
             qualname = stringify(annotation.__origin__)  # ex. Union
         else:
             qualname = repr(annotation).replace('typing.', '')
+
+        if mode == 'smart':
+            modprefix = '~%s.' % module
+        elif mode == 'fully-qualified':
+            modprefix = '%s.' % module
     elif hasattr(annotation, '__qualname__'):
-        qualname = '%s.%s' % (module, annotation.__qualname__)
+        if mode == 'smart':
+            modprefix = '~%s.' % module
+        else:
+            modprefix = '%s.' % module
+        qualname = annotation.__qualname__
     else:
         qualname = repr(annotation)
 
@@ -426,10 +501,10 @@
             not hasattr(annotation, '__tuple_params__')):  # for Python 3.6
         params = annotation.__args__
         if params:
-            param_str = ', '.join(stringify(p) for p in params)
-            return '%s[%s]' % (qualname, param_str)
-        else:
-            return qualname
+            param_str = ', '.join(stringify(p, mode) for p in params)
+            return '%s%s[%s]' % (modprefix, qualname, param_str)
+        else:
+            return modprefix + qualname
     elif isinstance(annotation, typing.GenericMeta):
         params = None
         if annotation.__args__ is None or len(annotation.__args__) <= 2:  # type: ignore  # NOQA
@@ -437,28 +512,28 @@
         elif annotation.__origin__ == Generator:  # type: ignore
             params = annotation.__args__  # type: ignore
         else:  # typing.Callable
-            args = ', '.join(stringify(arg) for arg
+            args = ', '.join(stringify(arg, mode) for arg
                              in annotation.__args__[:-1])  # type: ignore
             result = stringify(annotation.__args__[-1])  # type: ignore
-            return '%s[[%s], %s]' % (qualname, args, result)
+            return '%s%s[[%s], %s]' % (modprefix, qualname, args, result)
         if params is not None:
-            param_str = ', '.join(stringify(p) for p in params)
-            return '%s[%s]' % (qualname, param_str)
+            param_str = ', '.join(stringify(p, mode) for p in params)
+            return '%s%s[%s]' % (modprefix, qualname, param_str)
     elif (hasattr(annotation, '__origin__') and
           annotation.__origin__ is typing.Union):
         params = annotation.__args__
         if params is not None:
             if len(params) > 1 and params[-1] is NoneType:
                 if len(params) > 2:
-                    param_str = ", ".join(stringify(p) for p in params[:-1])
-                    return 'Optional[Union[%s]]' % param_str
+                    param_str = ", ".join(stringify(p, mode) for p in params[:-1])
+                    return '%sOptional[%sUnion[%s]]' % (modprefix, modprefix, param_str)
                 else:
-                    return 'Optional[%s]' % stringify(params[0])
-            else:
-                param_str = ', '.join(stringify(p) for p in params)
-                return 'Union[%s]' % param_str
-
-    return qualname
+                    return '%sOptional[%s]' % (modprefix, stringify(params[0], mode))
+            else:
+                param_str = ', '.join(stringify(p, mode) for p in params)
+                return '%sUnion[%s]' % (modprefix, param_str)
+
+    return modprefix + qualname
 
 
 deprecated_alias('sphinx.util.typing',
('sphinx/util', 'parallel.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,15 +1,6 @@
-"""
-    sphinx.util.parallel
-    ~~~~~~~~~~~~~~~~~~~~
-
-    Parallel building utilities.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Parallel building utilities."""
 
 import os
-import platform
 import sys
 import time
 import traceback
@@ -18,22 +9,23 @@
 
 try:
     import multiprocessing
+    HAS_MULTIPROCESSING = True
 except ImportError:
-    multiprocessing = None
+    HAS_MULTIPROCESSING = False
 
 from sphinx.errors import SphinxParallelError
 from sphinx.util import logging
 
 logger = logging.getLogger(__name__)
 
+if sys.platform != "win32":
+    ForkProcess = multiprocessing.context.ForkProcess
+else:
+    # For static typing, as ForkProcess doesn't exist on Windows
+    ForkProcess = multiprocessing.process.BaseProcess
 
 # our parallel functionality only works for the forking Process
-#
-# Note: "fork" is not recommended on macOS and py38+.
-#       see https://bugs.python.org/issue33725
-parallel_available = (multiprocessing and
-                      (os.name == 'posix') and
-                      not (sys.version_info > (3, 8) and platform.system() == 'Darwin'))
+parallel_available = multiprocessing and os.name == 'posix'
 
 
 class SerialTasks:
@@ -42,7 +34,9 @@
     def __init__(self, nproc: int = 1) -> None:
         pass
 
-    def add_task(self, task_func: Callable, arg: Any = None, result_func: Callable = None) -> None:  # NOQA
+    def add_task(
+        self, task_func: Callable, arg: Any = None, result_func: Optional[Callable] = None
+    ) -> None:
         if arg is not None:
             res = task_func(arg)
         else:
@@ -64,7 +58,7 @@
         # task arguments
         self._args: Dict[int, Optional[List[Any]]] = {}
         # list of subprocesses (both started and waiting)
-        self._procs: Dict[int, multiprocessing.Process] = {}
+        self._procs: Dict[int, ForkProcess] = {}
         # list of receiving pipe connections of running subprocesses
         self._precvs: Dict[int, Any] = {}
         # list of receiving pipe connections of waiting subprocesses
@@ -90,14 +84,16 @@
         logging.convert_serializable(collector.logs)
         pipe.send((failed, collector.logs, ret))
 
-    def add_task(self, task_func: Callable, arg: Any = None, result_func: Callable = None) -> None:  # NOQA
+    def add_task(
+        self, task_func: Callable, arg: Any = None, result_func: Optional[Callable] = None
+    ) -> None:
         tid = self._taskid
         self._taskid += 1
         self._result_funcs[tid] = result_func or (lambda arg, result: None)
         self._args[tid] = arg
         precv, psend = multiprocessing.Pipe(False)
-        proc = multiprocessing.Process(target=self._process,
-                                       args=(psend, task_func, arg))
+        context = multiprocessing.get_context('fork')
+        proc = context.Process(target=self._process, args=(psend, task_func, arg))
         self._procs[tid] = proc
         self._precvsWaiting[tid] = precv
         self._join_one()
('sphinx/util', 'smartypants.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,27 +1,25 @@
-"""
-    sphinx.util.smartypants
-    ~~~~~~~~~~~~~~~~~~~~~~~
-
-    This is extracted (with minor adaptations for flake8 compliance) from
-    docutils docutils/utils/smartquotes.py as of revision 8097 (30 May 2017),
-    in order to backport for Sphinx usage with Docutils < 0.14 extra language
-    configurations and fixes. Replaces earlier smartypants version as used up
-    to Sphinx 1.5.6.
-
-    :copyright:  2010 Gnter Milde,
-                original `SmartyPants`_:  2003 John Gruber
-                smartypants.py:           2004, 2007 Chad Miller
-    :license: Released under the terms of the `2-Clause BSD license`_, in short:
-
-       Copying and distribution of this file, with or without modification,
-       are permitted in any medium without royalty provided the copyright
-       notices and this notice are preserved.
-       This file is offered as-is, without any warranty.
-
-    .. _SmartyPants: https://daringfireball.net/projects/smartypants/
-    .. _2-Clause BSD license: https://spdx.org/licenses/BSD-2-Clause
-
-    See the LICENSE file and the original docutils code for details.
+"""Deprecated backport of docutils.utils.smartquotes.
+
+This is extracted (with minor adaptations for flake8 compliance) from
+docutils docutils/utils/smartquotes.py as of revision 8097 (30 May 2017),
+in order to backport for Sphinx usage with Docutils < 0.14 extra language
+configurations and fixes. Replaces earlier smartypants version as used up
+to Sphinx 1.5.6.
+
+:copyright:  2010 Gnter Milde,
+            original `SmartyPants`_:  2003 John Gruber
+            smartypants.py:           2004, 2007 Chad Miller
+:license: Released under the terms of the `2-Clause BSD license`_, in short:
+
+   Copying and distribution of this file, with or without modification,
+   are permitted in any medium without royalty provided the copyright
+   notices and this notice are preserved.
+   This file is offered as-is, without any warranty.
+
+.. _SmartyPants: https://daringfireball.net/projects/smartypants/
+.. _2-Clause BSD license: https://spdx.org/licenses/BSD-2-Clause
+
+See the LICENSE file and the original docutils code for details.
 
 """
 
@@ -32,7 +30,6 @@
 from docutils.utils import smartquotes
 
 from sphinx.deprecation import RemovedInSphinx60Warning
-from sphinx.util.docutils import __version_info__ as docutils_version
 
 warnings.warn('sphinx.util.smartypants is deprecated.',
               RemovedInSphinx60Warning)
@@ -375,17 +372,3 @@
         text = smartquotes.processEscapes(text, restore=True)
 
         yield text
-
-
-if docutils_version < (0, 13, 2):
-    # Monkey patch the old docutils versions to fix the issues mentioned
-    # at https://sourceforge.net/p/docutils/bugs/313/
-    # at https://sourceforge.net/p/docutils/bugs/317/
-    # and more
-    smartquotes.educateQuotes = educateQuotes
-    smartquotes.educate_tokens = educate_tokens
-
-    # Fix the issue with French quotes mentioned at
-    # https://sourceforge.net/p/docutils/mailman/message/35760696/
-    # Add/fix other languages as well
-    smartquotes.smartchars.quotes = langquotes
('sphinx/util', 'rst.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.util.rst
-    ~~~~~~~~~~~~~~~
-
-    reST helper functions.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""reST helper functions."""
 
 import re
 from collections import defaultdict
('sphinx/util', 'inventory.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.util.inventory
-    ~~~~~~~~~~~~~~~~~~~~~
-
-    Inventory utility functions for Sphinx.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Inventory utility functions for Sphinx."""
 import os
 import re
 import zlib
('sphinx/util/stemmer', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,45 +1,62 @@
-"""
-    sphinx.util.stemmer
-    ~~~~~~~~~~~~~~~~~~~
+"""Word stemming utilities for Sphinx."""
 
-    Word stemming utilities for Sphinx.
+import warnings
 
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+import snowballstemmer
 
-from sphinx.util.stemmer.porter import PorterStemmer
+from sphinx.deprecation import RemovedInSphinx70Warning
 
-try:
-    from Stemmer import Stemmer as _PyStemmer
-    PYSTEMMER = True
-except ImportError:
-    PYSTEMMER = False
+
+class PorterStemmer:
+    def __init__(self) -> None:
+        warnings.warn(f"{self.__class__.__name__} is deprecated, use "
+                      "snowballstemmer.stemmer('porter') instead.",
+                      RemovedInSphinx70Warning, stacklevel=2)
+        self.stemmer = snowballstemmer.stemmer('porter')
+
+    def stem(self, p: str, i: int, j: int) -> str:
+        warnings.warn(f"{self.__class__.__name__}.stem() is deprecated, use "
+                      "snowballstemmer.stemmer('porter').stemWord() instead.",
+                      RemovedInSphinx70Warning, stacklevel=2)
+        return self.stemmer.stemWord(p)
 
 
 class BaseStemmer:
+    def __init__(self) -> None:
+        warnings.warn(f"{self.__class__.__name__} is deprecated, use "
+                      "snowballstemmer.stemmer('porter') instead.",
+                      RemovedInSphinx70Warning, stacklevel=3)
+
     def stem(self, word: str) -> str:
-        raise NotImplementedError()
+        raise NotImplementedError
 
 
 class PyStemmer(BaseStemmer):
     def __init__(self) -> None:
-        self.stemmer = _PyStemmer('porter')
+        super().__init__()
+        self.stemmer = snowballstemmer.stemmer('porter')
 
     def stem(self, word: str) -> str:
+        warnings.warn(f"{self.__class__.__name__}.stem() is deprecated, use "
+                      "snowballstemmer.stemmer('porter').stemWord() instead.",
+                      RemovedInSphinx70Warning, stacklevel=2)
         return self.stemmer.stemWord(word)
 
 
-class StandardStemmer(PorterStemmer, BaseStemmer):
-    """All those porter stemmer implementations look hideous;
-    make at least the stem method nicer.
-    """
-    def stem(self, word: str) -> str:  # type: ignore
-        return super().stem(word, 0, len(word) - 1)
+class StandardStemmer(BaseStemmer):
+    def __init__(self) -> None:
+        super().__init__()
+        self.stemmer = snowballstemmer.stemmer('porter')
+
+    def stem(self, word: str) -> str:
+        warnings.warn(f"{self.__class__.__name__}.stem() is deprecated, use "
+                      "snowballstemmer.stemmer('porter').stemWord() instead.",
+                      RemovedInSphinx70Warning, stacklevel=2)
+        return self.stemmer.stemWord(word)
 
 
 def get_stemmer() -> BaseStemmer:
-    if PYSTEMMER:
-        return PyStemmer()
-    else:
-        return StandardStemmer()
+    warnings.warn("get_stemmer() is deprecated, use "
+                  "snowballstemmer.stemmer('porter') instead.",
+                  RemovedInSphinx70Warning, stacklevel=2)
+    return PyStemmer()
('sphinx/builders', 'texinfo.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,16 +1,9 @@
-"""
-    sphinx.builders.texinfo
-    ~~~~~~~~~~~~~~~~~~~~~~~
-
-    Texinfo builder.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Texinfo builder."""
 
 import os
+import warnings
 from os import path
-from typing import Any, Dict, Iterable, List, Tuple, Union
+from typing import Any, Dict, Iterable, List, Optional, Tuple, Union
 
 from docutils import nodes
 from docutils.frontend import OptionParser
@@ -59,13 +52,13 @@
     def get_outdated_docs(self) -> Union[str, List[str]]:
         return 'all documents'  # for now
 
-    def get_target_uri(self, docname: str, typ: str = None) -> str:
+    def get_target_uri(self, docname: str, typ: Optional[str] = None) -> str:
         if docname not in self.docnames:
             raise NoUri(docname, typ)
         else:
             return '%' + docname
 
-    def get_relative_uri(self, from_: str, to: str, typ: str = None) -> str:
+    def get_relative_uri(self, from_: str, to: str, typ: Optional[str] = None) -> str:
         # ignore source path
         return self.get_target_uri(to, typ)
 
@@ -109,10 +102,14 @@
             with progress_message(__("writing")):
                 self.post_process_images(doctree)
                 docwriter = TexinfoWriter(self)
-                settings: Any = OptionParser(
-                    defaults=self.env.settings,
-                    components=(docwriter,),
-                    read_config_files=True).get_default_values()
+                with warnings.catch_warnings():
+                    warnings.filterwarnings('ignore', category=DeprecationWarning)
+                    # DeprecationWarning: The frontend.OptionParser class will be replaced
+                    # by a subclass of argparse.ArgumentParser in Docutils 0.21 or later.
+                    settings: Any = OptionParser(
+                        defaults=self.env.settings,
+                        components=(docwriter,),
+                        read_config_files=True).get_default_values()
                 settings.author = author
                 settings.title = title
                 settings.texinfo_filename = targetname[:-5] + '.info'
@@ -138,7 +135,7 @@
             new_sect += nodes.title('<Set title in conf.py>',
                                     '<Set title in conf.py>')
             new_tree += new_sect
-            for node in tree.traverse(addnodes.toctree):
+            for node in tree.findall(addnodes.toctree):
                 new_sect += node
             tree = new_tree
         largetree = inline_all_toctrees(self, self.docnames, indexfile, tree,
@@ -152,15 +149,15 @@
         logger.info(__("resolving references..."))
         self.env.resolve_references(largetree, indexfile, self)
         # TODO: add support for external :ref:s
-        for pendingnode in largetree.traverse(addnodes.pending_xref):
+        for pendingnode in largetree.findall(addnodes.pending_xref):
             docname = pendingnode['refdocname']
             sectname = pendingnode['refsectname']
             newnodes: List[Node] = [nodes.emphasis(sectname, sectname)]
             for subdir, title in self.titles:
                 if docname.startswith(subdir):
-                    newnodes.append(nodes.Text(_(' (in '), _(' (in ')))
+                    newnodes.append(nodes.Text(_(' (in ')))
                     newnodes.append(nodes.emphasis(title, title))
-                    newnodes.append(nodes.Text(')', ')'))
+                    newnodes.append(nodes.Text(')'))
                     break
             else:
                 pass
@@ -205,12 +202,13 @@
 def setup(app: Sphinx) -> Dict[str, Any]:
     app.add_builder(TexinfoBuilder)
 
-    app.add_config_value('texinfo_documents', default_texinfo_documents, None)
-    app.add_config_value('texinfo_appendices', [], None)
-    app.add_config_value('texinfo_elements', {}, None)
-    app.add_config_value('texinfo_domain_indices', True, None, [list])
-    app.add_config_value('texinfo_show_urls', 'footnote', None)
-    app.add_config_value('texinfo_no_detailmenu', False, None)
+    app.add_config_value('texinfo_documents', default_texinfo_documents, False)
+    app.add_config_value('texinfo_appendices', [], False)
+    app.add_config_value('texinfo_elements', {}, False)
+    app.add_config_value('texinfo_domain_indices', True, False, [list])
+    app.add_config_value('texinfo_show_urls', 'footnote', False)
+    app.add_config_value('texinfo_no_detailmenu', False, False)
+    app.add_config_value('texinfo_cross_references', True, False)
 
     return {
         'version': 'builtin',
('sphinx/builders', 'changes.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.builders.changes
-    ~~~~~~~~~~~~~~~~~~~~~~~
-
-    Changelog builder.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Changelog builder."""
 
 import html
 from os import path
@@ -135,7 +127,7 @@
             with open(targetfn, 'w', encoding='utf-8') as f:
                 text = ''.join(hl(i + 1, line) for (i, line) in enumerate(lines))
                 ctx = {
-                    'filename': self.env.doc2path(docname, None),
+                    'filename': self.env.doc2path(docname, False),
                     'text': text
                 }
                 f.write(self.templates.render('changes/rstsource.html', ctx))
@@ -148,7 +140,7 @@
 
     def hl(self, text: str, version: str) -> str:
         text = html.escape(text)
-        for directive in ['versionchanged', 'versionadded', 'deprecated']:
+        for directive in ('versionchanged', 'versionadded', 'deprecated'):
             text = text.replace('.. %s:: %s' % (directive, version),
                                 '<b>.. %s:: %s</b>' % (directive, version))
         return text
('sphinx/builders', 'manpage.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,15 +1,8 @@
-"""
-    sphinx.builders.manpage
-    ~~~~~~~~~~~~~~~~~~~~~~~
+"""Manual pages builder."""
 
-    Manual pages builder.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
-
+import warnings
 from os import path
-from typing import Any, Dict, List, Set, Tuple, Union
+from typing import Any, Dict, List, Optional, Set, Tuple, Union
 
 from docutils.frontend import OptionParser
 from docutils.io import FileOutput
@@ -18,7 +11,6 @@
 from sphinx.application import Sphinx
 from sphinx.builders import Builder
 from sphinx.config import Config
-from sphinx.errors import NoUri
 from sphinx.locale import __
 from sphinx.util import logging, progress_message
 from sphinx.util.console import darkgreen  # type: ignore
@@ -48,18 +40,20 @@
     def get_outdated_docs(self) -> Union[str, List[str]]:
         return 'all manpages'  # for now
 
-    def get_target_uri(self, docname: str, typ: str = None) -> str:
-        if typ == 'token':
-            return ''
-        raise NoUri(docname, typ)
+    def get_target_uri(self, docname: str, typ: Optional[str] = None) -> str:
+        return ''
 
     @progress_message(__('writing'))
     def write(self, *ignored: Any) -> None:
         docwriter = ManualPageWriter(self)
-        docsettings: Any = OptionParser(
-            defaults=self.env.settings,
-            components=(docwriter,),
-            read_config_files=True).get_default_values()
+        with warnings.catch_warnings():
+            warnings.filterwarnings('ignore', category=DeprecationWarning)
+            # DeprecationWarning: The frontend.OptionParser class will be replaced
+            # by a subclass of argparse.ArgumentParser in Docutils 0.21 or later.
+            docsettings: Any = OptionParser(
+                defaults=self.env.settings,
+                components=(docwriter,),
+                read_config_files=True).get_default_values()
 
         for info in self.config.man_pages:
             docname, name, description, authors, section = info
@@ -98,7 +92,7 @@
             logger.info('} ', nonl=True)
             self.env.resolve_references(largetree, docname, self)
             # remove pending_xref nodes
-            for pendingnode in largetree.traverse(addnodes.pending_xref):
+            for pendingnode in largetree.findall(addnodes.pending_xref):
                 pendingnode.replace_self(pendingnode.children)
 
             docwriter.write(largetree, destination)
@@ -117,9 +111,9 @@
 def setup(app: Sphinx) -> Dict[str, Any]:
     app.add_builder(ManualPageBuilder)
 
-    app.add_config_value('man_pages', default_man_pages, None)
-    app.add_config_value('man_show_urls', False, None)
-    app.add_config_value('man_make_section_directory', False, None)
+    app.add_config_value('man_pages', default_man_pages, False)
+    app.add_config_value('man_show_urls', False, False)
+    app.add_config_value('man_make_section_directory', False, False)
 
     return {
         'version': 'builtin',
('sphinx/builders', 'gettext.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,19 +1,12 @@
-"""
-    sphinx.builders.gettext
-    ~~~~~~~~~~~~~~~~~~~~~~~
-
-    The MessageCatalogBuilder class.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""The MessageCatalogBuilder class."""
 
 from codecs import open
 from collections import OrderedDict, defaultdict
 from datetime import datetime, timedelta, tzinfo
 from os import getenv, path, walk
 from time import time
-from typing import Any, DefaultDict, Dict, Generator, Iterable, List, Set, Tuple, Union
+from typing import (Any, DefaultDict, Dict, Generator, Iterable, List, Optional, Set, Tuple,
+                    Union)
 from uuid import uuid4
 
 from docutils import nodes
@@ -61,11 +54,15 @@
         if msg not in self.metadata:  # faster lookup in hash
             self.messages.append(msg)
             self.metadata[msg] = []
-        self.metadata[msg].append((origin.source, origin.line, origin.uid))  # type: ignore
+        line = origin.line
+        if line is None:
+            line = -1
+        self.metadata[msg].append((origin.source, line, origin.uid))  # type: ignore
 
     def __iter__(self) -> Generator[Message, None, None]:
         for message in self.messages:
-            positions = [(source, line) for source, line, uuid in self.metadata[message]]
+            positions = sorted({(source, line) for source, line, uuid
+                               in self.metadata[message]})
             uuids = [uuid for source, line, uuid in self.metadata[message]]
             yield Message(message, positions, uuids)
 
@@ -82,7 +79,9 @@
 
 
 class GettextRenderer(SphinxRenderer):
-    def __init__(self, template_path: str = None, outdir: str = None) -> None:
+    def __init__(
+        self, template_path: Optional[str] = None, outdir: Optional[str] = None
+    ) -> None:
         self.outdir = outdir
         if template_path is None:
             template_path = path.join(package_dir, 'templates', 'gettext')
@@ -97,7 +96,7 @@
         self.env.filters['e'] = escape
         self.env.filters['escape'] = escape
 
-    def render(self, filename: str, context: Dict) -> str:
+    def render(self, filename: str, context: Dict[str, Any]) -> str:
         def _relpath(s: str) -> str:
             return canon_path(relpath(s, self.outdir))
 
@@ -121,7 +120,6 @@
     """
     name = 'i18n'
     versioning_method = 'text'
-    versioning_compare: bool = None  # be set by `gettext_uuid`
     use_message_catalog = False
 
     def init(self) -> None:
@@ -131,7 +129,7 @@
         self.tags = I18nTags()
         self.catalogs: DefaultDict[str, Catalog] = defaultdict(Catalog)
 
-    def get_target_uri(self, docname: str, typ: str = None) -> str:
+    def get_target_uri(self, docname: str, typ: Optional[str] = None) -> str:
         return ''
 
     def get_outdated_docs(self) -> Set[str]:
@@ -146,7 +144,7 @@
     def write_doc(self, docname: str, doctree: nodes.document) -> None:
         catalog = self.catalogs[docname_to_domain(docname, self.config.gettext_compact)]
 
-        for toctree in self.env.tocs[docname].traverse(addnodes.toctree):
+        for toctree in self.env.tocs[docname].findall(addnodes.toctree):
             for node, msg in extract_messages(toctree):
                 node.uid = ''  # type: ignore  # Hack UUID model
                 catalog.add(msg, node)
@@ -157,7 +155,7 @@
         if 'index' in self.env.config.gettext_additional_targets:
             # Extract translatable messages from index entries.
             for node, entries in traverse_translatable_index(doctree):
-                for typ, msg, tid, main, key_ in entries:
+                for typ, msg, _tid, _main, _key in entries:
                     for m in split_index_msg(typ, msg):
                         if typ == 'pair' and m in pairindextypes.values():
                             # avoid built-in translated message was incorporated
@@ -180,13 +178,13 @@
 
 class LocalTimeZone(tzinfo):
     def __init__(self, *args: Any, **kwargs: Any) -> None:
-        super().__init__(*args, **kwargs)  # type: ignore
+        super().__init__(*args, **kwargs)
         self.tzdelta = tzdelta
 
-    def utcoffset(self, dt: datetime) -> timedelta:
+    def utcoffset(self, dt: Optional[datetime]) -> timedelta:
         return self.tzdelta
 
-    def dst(self, dt: datetime) -> timedelta:
+    def dst(self, dt: Optional[datetime]) -> timedelta:
         return timedelta(0)
 
 
@@ -227,7 +225,7 @@
         template_files = set()
         for template_path in self.config.templates_path:
             tmpl_abs_path = path.join(self.app.srcdir, template_path)
-            for dirpath, dirs, files in walk(tmpl_abs_path):
+            for dirpath, _dirs, files in walk(tmpl_abs_path):
                 for fn in files:
                     if fn.endswith('.html'):
                         filename = canon_path(path.join(dirpath, fn))
@@ -247,13 +245,15 @@
             try:
                 with open(template, encoding='utf-8') as f:
                     context = f.read()
-                for line, meth, msg in extract_translations(context):
+                for line, _meth, msg in extract_translations(context):
                     origin = MsgOrigin(template, line)
                     self.catalogs['sphinx'].add(msg, origin)
             except Exception as exc:
                 raise ThemeError('%s: %r' % (template, exc)) from exc
 
-    def build(self, docnames: Iterable[str], summary: str = None, method: str = 'update') -> None:  # NOQA
+    def build(
+        self, docnames: Iterable[str], summary: Optional[str] = None, method: str = 'update'
+    ) -> None:
         self._extract_from_template()
         super().build(docnames, summary, method)
 
('sphinx/builders', 'xml.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,15 +1,7 @@
-"""
-    sphinx.builders.xml
-    ~~~~~~~~~~~~~~~~~~~
-
-    Docutils-native XML and pseudo-XML builders.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Docutils-native XML and pseudo-XML builders."""
 
 from os import path
-from typing import Any, Dict, Iterator, Set, Type, Union
+from typing import Any, Dict, Iterator, Optional, Set, Type, Union
 
 from docutils import nodes
 from docutils.io import StringOutput
@@ -61,7 +53,7 @@
                 # source doesn't exist anymore
                 pass
 
-    def get_target_uri(self, docname: str, typ: str = None) -> str:
+    def get_target_uri(self, docname: str, typ: Optional[str] = None) -> str:
         return docname
 
     def prepare_writing(self, docnames: Set[str]) -> None:
@@ -71,7 +63,10 @@
         # work around multiple string % tuple issues in docutils;
         # replace tuples in attribute values with lists
         doctree = doctree.deepcopy()
-        for node in doctree.traverse(nodes.Element):
+        for domain in self.env.domains.values():
+            xmlns = "xmlns:" + domain.name
+            doctree[xmlns] = "https://www.sphinx-doc.org/"  # type: ignore
+        for node in doctree.findall(nodes.Element):
             for att, value in node.attributes.items():
                 if isinstance(value, tuple):
                     node.attributes[att] = list(value)
('sphinx/builders', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,30 +1,26 @@
-"""
-    sphinx.builders
-    ~~~~~~~~~~~~~~~
-
-    Builder superclass for all builders.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
-
+"""Builder superclass for all builders."""
+
+import codecs
 import pickle
 import time
+import warnings
 from os import path
 from typing import (TYPE_CHECKING, Any, Dict, Iterable, List, Optional, Sequence, Set, Tuple,
                     Type, Union)
 
 from docutils import nodes
 from docutils.nodes import Node
+from docutils.utils import DependencyList
 
 from sphinx.config import Config
+from sphinx.deprecation import RemovedInSphinx70Warning
 from sphinx.environment import CONFIG_CHANGED_REASON, CONFIG_OK, BuildEnvironment
 from sphinx.environment.adapters.asset import ImageAdapter
 from sphinx.errors import SphinxError
 from sphinx.events import EventManager
-from sphinx.io import read_doc
 from sphinx.locale import __
-from sphinx.util import import_object, logging, progress_message, rst, status_iterator
+from sphinx.util import (UnicodeDecodeErrorHandler, get_filetype, import_object, logging,
+                         progress_message, rst, status_iterator)
 from sphinx.util.build_phase import BuildPhase
 from sphinx.util.console import bold  # type: ignore
 from sphinx.util.docutils import sphinx_domains
@@ -32,6 +28,7 @@
 from sphinx.util.osutil import SEP, ensuredir, relative_uri, relpath
 from sphinx.util.parallel import ParallelTasks, SerialTasks, make_chunks, parallel_available
 from sphinx.util.tags import Tags
+from sphinx.util.typing import NoneType
 
 # side effect: registers roles and directives
 from sphinx import directives  # NOQA isort:skip
@@ -68,7 +65,7 @@
     # doctree versioning method
     versioning_method = 'none'
     versioning_compare = False
-    # allow parallel write_doc() calls
+    #: allow parallel write_doc() calls
     allow_parallel = False
     # support translation
     use_message_catalog = True
@@ -81,7 +78,7 @@
     #: The builder supports data URIs or not.
     supported_data_uri_images = False
 
-    def __init__(self, app: "Sphinx") -> None:
+    def __init__(self, app: "Sphinx", env: BuildEnvironment = None) -> None:
         self.srcdir = app.srcdir
         self.confdir = app.confdir
         self.outdir = app.outdir
@@ -89,7 +86,15 @@
         ensuredir(self.doctreedir)
 
         self.app: Sphinx = app
-        self.env: Optional[BuildEnvironment] = None
+        if env is not None:
+            self.env: BuildEnvironment = env
+            self.env.set_versioning_method(self.versioning_method,
+                                           self.versioning_compare)
+        else:
+            # ... is passed by SphinxComponentRegistry.create_builder to not show two warnings.
+            warnings.warn("The 'env' argument to Builder will be required from Sphinx 7.",
+                          RemovedInSphinx70Warning, stacklevel=2)
+            self.env = None
         self.events: EventManager = app.events
         self.config: Config = app.config
         self.tags: Tags = app.tags
@@ -111,6 +116,9 @@
 
     def set_environment(self, env: BuildEnvironment) -> None:
         """Store BuildEnvironment object."""
+        warnings.warn("Builder.set_environment is deprecated, pass env to "
+                      "'Builder.__init__()' instead.",
+                      RemovedInSphinx70Warning, stacklevel=2)
         self.env = env
         self.env.set_versioning_method(self.versioning_method,
                                        self.versioning_compare)
@@ -176,7 +184,7 @@
     def post_process_images(self, doctree: Node) -> None:
         """Pick the best candidate for all image URIs."""
         images = ImageAdapter(self.env)
-        for node in doctree.traverse(nodes.image):
+        for node in doctree.findall(nodes.image):
             if '?' in node['candidates']:
                 # don't rewrite nonlocal image URIs
                 continue
@@ -217,7 +225,8 @@
         for catalog in status_iterator(catalogs, __('writing output... '), "darkgreen",
                                        len(catalogs), self.app.verbosity,
                                        stringify_func=cat2relpath):
-            catalog.write_mo(self.config.language)
+            catalog.write_mo(self.config.language,
+                             self.config.gettext_allow_fuzzy_translations)
 
     def compile_all_catalogs(self) -> None:
         repo = CatalogRepository(self.srcdir, self.config.locale_dirs,
@@ -294,7 +303,9 @@
                        summary=__('targets for %d source files that are out of date') %
                        len(to_build))
 
-    def build(self, docnames: Iterable[str], summary: str = None, method: str = 'update') -> None:  # NOQA
+    def build(
+        self, docnames: Iterable[str], summary: Optional[str] = None, method: str = 'update'
+    ) -> None:
         """Main build method.
 
         First updates the environment, and then calls :meth:`write`.
@@ -435,6 +446,13 @@
             self.read_doc(docname)
 
     def _read_parallel(self, docnames: List[str], nproc: int) -> None:
+        chunks = make_chunks(docnames, nproc)
+
+        # create a status_iterator to step progressbar after reading a document
+        # (see: ``merge()`` function)
+        progress = status_iterator(chunks, __('reading sources... '), "purple",
+                                   len(chunks), self.app.verbosity)
+
         # clear all outdated docs at once
         for docname in docnames:
             self.events.emit('env-purge-doc', self.env, docname)
@@ -451,16 +469,15 @@
             env = pickle.loads(otherenv)
             self.env.merge_info_from(docs, env, self.app)
 
+            next(progress)
+
         tasks = ParallelTasks(nproc)
-        chunks = make_chunks(docnames, nproc)
-
-        for chunk in status_iterator(chunks, __('reading sources... '), "purple",
-                                     len(chunks), self.app.verbosity):
+        for chunk in chunks:
             tasks.add_task(read_process, chunk, merge)
 
         # make sure all threads have finished
-        logger.info(bold(__('waiting for workers...')))
         tasks.join()
+        logger.info('')
 
     def read_doc(self, docname: str) -> None:
         """Parse a file and add/update inventory entries for the doctree."""
@@ -471,8 +488,19 @@
         if path.isfile(docutilsconf):
             self.env.note_dependency(docutilsconf)
 
+        filename = self.env.doc2path(docname)
+        filetype = get_filetype(self.app.config.source_suffix, filename)
+        publisher = self.app.registry.get_publisher(self.app, filetype)
+        # record_dependencies is mutable even though it is in settings,
+        # explicitly re-initialise for each document
+        publisher.settings.record_dependencies = DependencyList()
         with sphinx_domains(self.env), rst.default_role(docname, self.config.default_role):
-            doctree = read_doc(self.app, self.env, self.env.doc2path(docname))
+            # set up error_handler for the target document
+            codecs.register_error('sphinx', UnicodeDecodeErrorHandler(docname))  # type: ignore
+
+            publisher.set_source(source_path=filename)
+            publisher.publish()
+            doctree = publisher.document
 
         # store time of reading, for outdated files detection
         # (Some filesystems have coarse timestamp resolution;
@@ -492,6 +520,10 @@
         # make it picklable
         doctree.reporter = None
         doctree.transformer = None
+
+        # Create a copy of settings object before modification because it is
+        # shared with other documents.
+        doctree.settings = doctree.settings.copy()
         doctree.settings.warning_stream = None
         doctree.settings.env = None
         doctree.settings.record_dependencies = None
@@ -557,19 +589,26 @@
         tasks = ParallelTasks(nproc)
         chunks = make_chunks(docnames, nproc)
 
+        # create a status_iterator to step progressbar after writing a document
+        # (see: ``on_chunk_done()`` function)
+        progress = status_iterator(chunks, __('writing output... '), "darkgreen",
+                                   len(chunks), self.app.verbosity)
+
+        def on_chunk_done(args: List[Tuple[str, NoneType]], result: NoneType) -> None:
+            next(progress)
+
         self.app.phase = BuildPhase.RESOLVING
-        for chunk in status_iterator(chunks, __('writing output... '), "darkgreen",
-                                     len(chunks), self.app.verbosity):
+        for chunk in chunks:
             arg = []
-            for i, docname in enumerate(chunk):
+            for docname in chunk:
                 doctree = self.env.get_and_resolve_doctree(docname, self)
                 self.write_doc_serialized(docname, doctree)
                 arg.append((docname, doctree))
-            tasks.add_task(write_process, arg)
+            tasks.add_task(write_process, arg, on_chunk_done)
 
         # make sure all threads have finished
-        logger.info(bold(__('waiting for workers...')))
         tasks.join()
+        logger.info('')
 
     def prepare_writing(self, docnames: Set[str]) -> None:
         """A place where you can add logic before :meth:`write_doc` is run"""
('sphinx/builders', 'text.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,15 +1,7 @@
-"""
-    sphinx.builders.text
-    ~~~~~~~~~~~~~~~~~~~~
-
-    Plain-text Sphinx builder.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Plain-text Sphinx builder."""
 
 from os import path
-from typing import Any, Dict, Iterator, Set, Tuple
+from typing import Any, Dict, Iterator, Optional, Set, Tuple
 
 from docutils.io import StringOutput
 from docutils.nodes import Node
@@ -33,7 +25,7 @@
     allow_parallel = True
     default_translator_class = TextTranslator
 
-    current_docname: str = None
+    current_docname: Optional[str] = None
 
     def init(self) -> None:
         # section numbers for headings in the currently visited document
@@ -57,7 +49,7 @@
                 # source doesn't exist anymore
                 pass
 
-    def get_target_uri(self, docname: str, typ: str = None) -> str:
+    def get_target_uri(self, docname: str, typ: Optional[str] = None) -> str:
         return ''
 
     def prepare_writing(self, docnames: Set[str]) -> None:
('sphinx/builders', 'linkcheck.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,37 +1,26 @@
-"""
-    sphinx.builders.linkcheck
-    ~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    The CheckExternalLinksBuilder class.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""The CheckExternalLinksBuilder class."""
 
 import json
 import re
 import socket
 import time
-import warnings
+from copy import deepcopy
 from datetime import datetime, timezone
 from email.utils import parsedate_to_datetime
 from html.parser import HTMLParser
 from os import path
 from queue import PriorityQueue, Queue
 from threading import Thread
-from typing import (Any, Dict, Generator, List, NamedTuple, Optional, Pattern, Set, Tuple,
-                    Union, cast)
+from typing import Any, Dict, Generator, List, NamedTuple, Optional, Tuple, Union, cast
 from urllib.parse import unquote, urlparse, urlunparse
 
 from docutils import nodes
-from docutils.nodes import Element
 from requests import Response
 from requests.exceptions import ConnectionError, HTTPError, TooManyRedirects
 
 from sphinx.application import Sphinx
 from sphinx.builders.dummy import DummyBuilder
 from sphinx.config import Config
-from sphinx.deprecation import RemovedInSphinx50Warning
 from sphinx.environment import BuildEnvironment
 from sphinx.locale import __
 from sphinx.transforms.post_transforms import SphinxPostTransform
@@ -43,18 +32,31 @@
 
 uri_re = re.compile('([a-z]+:)?//')  # matches to foo:// and // (a protocol relative URL)
 
-Hyperlink = NamedTuple('Hyperlink', (('uri', str),
-                                     ('docname', str),
-                                     ('lineno', Optional[int])))
-CheckRequest = NamedTuple('CheckRequest', (('next_check', float),
-                                           ('hyperlink', Optional[Hyperlink])))
-CheckResult = NamedTuple('CheckResult', (('uri', str),
-                                         ('docname', str),
-                                         ('lineno', int),
-                                         ('status', str),
-                                         ('message', str),
-                                         ('code', int)))
-RateLimit = NamedTuple('RateLimit', (('delay', float), ('next_check', float)))
+
+class Hyperlink(NamedTuple):
+    uri: str
+    docname: str
+    lineno: Optional[int]
+
+
+class CheckRequest(NamedTuple):
+    next_check: float
+    hyperlink: Optional[Hyperlink]
+
+
+class CheckResult(NamedTuple):
+    uri: str
+    docname: str
+    lineno: int
+    status: str
+    message: str
+    code: int
+
+
+class RateLimit(NamedTuple):
+    delay: float
+    next_check: float
+
 
 # Tuple is old styled CheckRequest
 CheckRequestType = Union[CheckRequest, Tuple[float, str, str, int]]
@@ -65,16 +67,6 @@
 CHECK_IMMEDIATELY = 0
 QUEUE_POLL_SECS = 1
 DEFAULT_DELAY = 60.0
-
-
-def node_line_or_0(node: Element) -> int:
-    """
-    PriorityQueue items must be comparable. The line number is part of the
-    tuple used by the PriorityQueue, keep an homogeneous type for comparison.
-    """
-    warnings.warn('node_line_or_0() is deprecated.',
-                  RemovedInSphinx50Warning, stacklevel=2)
-    return get_node_line(node) or 0
 
 
 class AnchorCheckParser(HTMLParser):
@@ -120,120 +112,17 @@
                 '%(outdir)s/output.txt')
 
     def init(self) -> None:
+        self.broken_hyperlinks = 0
         self.hyperlinks: Dict[str, Hyperlink] = {}
-        self._good: Set[str] = set()
-        self._broken: Dict[str, str] = {}
-        self._redirected: Dict[str, Tuple[str, int]] = {}
         # set a timeout for non-responding servers
         socket.setdefaulttimeout(5.0)
 
-        # create queues and worker threads
-        self._wqueue: PriorityQueue[CheckRequestType] = PriorityQueue()
-        self._rqueue: Queue[CheckResult] = Queue()
-
-    @property
-    def anchors_ignore(self) -> List[Pattern]:
-        warnings.warn(
-            "%s.%s is deprecated." % (self.__class__.__name__, "anchors_ignore"),
-            RemovedInSphinx50Warning,
-            stacklevel=2,
-        )
-        return [re.compile(x) for x in self.config.linkcheck_anchors_ignore]
-
-    @property
-    def auth(self) -> List[Tuple[Pattern, Any]]:
-        warnings.warn(
-            "%s.%s is deprecated." % (self.__class__.__name__, "auth"),
-            RemovedInSphinx50Warning,
-            stacklevel=2,
-        )
-        return [(re.compile(pattern), auth_info) for pattern, auth_info
-                in self.config.linkcheck_auth]
-
-    @property
-    def to_ignore(self) -> List[Pattern]:
-        warnings.warn(
-            "%s.%s is deprecated." % (self.__class__.__name__, "to_ignore"),
-            RemovedInSphinx50Warning,
-            stacklevel=2,
-        )
-        return [re.compile(x) for x in self.config.linkcheck_ignore]
-
-    @property
-    def good(self) -> Set[str]:
-        warnings.warn(
-            "%s.%s is deprecated." % (self.__class__.__name__, "good"),
-            RemovedInSphinx50Warning,
-            stacklevel=2,
-        )
-        return self._good
-
-    @property
-    def broken(self) -> Dict[str, str]:
-        warnings.warn(
-            "%s.%s is deprecated." % (self.__class__.__name__, "broken"),
-            RemovedInSphinx50Warning,
-            stacklevel=2,
-        )
-        return self._broken
-
-    @property
-    def redirected(self) -> Dict[str, Tuple[str, int]]:
-        warnings.warn(
-            "%s.%s is deprecated." % (self.__class__.__name__, "redirected"),
-            RemovedInSphinx50Warning,
-            stacklevel=2,
-        )
-        return self._redirected
-
-    def check_thread(self) -> None:
-        warnings.warn(
-            "%s.%s is deprecated." % (self.__class__.__name__, "check_thread"),
-            RemovedInSphinx50Warning,
-            stacklevel=2,
-        )
-        # do nothing.
-
-    def limit_rate(self, response: Response) -> Optional[float]:
-        warnings.warn(
-            "%s.%s is deprecated." % (self.__class__.__name__, "limit_rate"),
-            RemovedInSphinx50Warning,
-            stacklevel=2,
-        )
-        worker = HyperlinkAvailabilityCheckWorker(self.env, self.config,
-                                                  None, None, {})
-        return worker.limit_rate(response)
-
-    def rqueue(self, response: Response) -> Queue:
-        warnings.warn(
-            "%s.%s is deprecated." % (self.__class__.__name__, "rqueue"),
-            RemovedInSphinx50Warning,
-            stacklevel=2,
-        )
-        return self._rqueue
-
-    def workers(self, response: Response) -> List[Thread]:
-        warnings.warn(
-            "%s.%s is deprecated." % (self.__class__.__name__, "workers"),
-            RemovedInSphinx50Warning,
-            stacklevel=2,
-        )
-        return []
-
-    def wqueue(self, response: Response) -> Queue:
-        warnings.warn(
-            "%s.%s is deprecated." % (self.__class__.__name__, "wqueue"),
-            RemovedInSphinx50Warning,
-            stacklevel=2,
-        )
-        return self._wqueue
-
     def process_result(self, result: CheckResult) -> None:
-        filename = self.env.doc2path(result.docname, None)
-
-        linkstat = dict(filename=filename, lineno=result.lineno,
-                        status=result.status, code=result.code, uri=result.uri,
-                        info=result.message)
+        filename = self.env.doc2path(result.docname, False)
+
+        linkstat = {"filename": filename, "lineno": result.lineno,
+                    "status": result.status, "code": result.code, "uri": result.uri,
+                    "info": result.message}
         self.write_linkstat(linkstat)
 
         if result.status == 'unchecked':
@@ -255,11 +144,12 @@
         elif result.status == 'broken':
             if self.app.quiet or self.app.warningiserror:
                 logger.warning(__('broken link: %s (%s)'), result.uri, result.message,
-                               location=(filename, result.lineno))
+                               location=(result.docname, result.lineno))
             else:
                 logger.info(red('broken    ') + result.uri + red(' - ' + result.message))
             self.write_entry('broken', result.docname, filename, result.lineno,
                              result.uri + ': ' + result.message)
+            self.broken_hyperlinks += 1
         elif result.status == 'redirected':
             try:
                 text, color = {
@@ -274,7 +164,7 @@
             linkstat['text'] = text
             if self.config.linkcheck_allowed_redirects:
                 logger.warning('redirect  ' + result.uri + ' - ' + text + ' to ' +
-                               result.message, location=(filename, result.lineno))
+                               result.message, location=(result.docname, result.lineno))
             else:
                 logger.info(color('redirect  ') + result.uri +
                             color(' - ' + text + ' to ' + result.message))
@@ -292,50 +182,42 @@
         self.json_outfile.write('\n')
 
     def finish(self) -> None:
-        checker = HyperlinkAvailabilityChecker(self.env, self.config, self)
+        checker = HyperlinkAvailabilityChecker(self.env, self.config)
         logger.info('')
 
-        with open(path.join(self.outdir, 'output.txt'), 'w') as self.txt_outfile,\
-             open(path.join(self.outdir, 'output.json'), 'w') as self.json_outfile:
+        output_text = path.join(self.outdir, 'output.txt')
+        output_json = path.join(self.outdir, 'output.json')
+        with open(output_text, 'w', encoding="utf-8") as self.txt_outfile,\
+             open(output_json, 'w', encoding="utf-8") as self.json_outfile:
             for result in checker.check(self.hyperlinks):
                 self.process_result(result)
 
-        if self._broken:
+        if self.broken_hyperlinks:
             self.app.statuscode = 1
 
 
 class HyperlinkAvailabilityChecker:
-    def __init__(self, env: BuildEnvironment, config: Config,
-                 builder: CheckExternalLinksBuilder = None) -> None:
-        # Warning: builder argument will be removed in the sphinx-5.0.
-        # Don't use it from extensions.
-        # tag: RemovedInSphinx50Warning
-        self.builder = builder
+    def __init__(self, env: BuildEnvironment, config: Config) -> None:
         self.config = config
         self.env = env
         self.rate_limits: Dict[str, RateLimit] = {}
+        self.rqueue: Queue = Queue()
         self.workers: List[Thread] = []
+        self.wqueue: PriorityQueue[CheckRequest] = PriorityQueue()
 
         self.to_ignore = [re.compile(x) for x in self.config.linkcheck_ignore]
 
-        if builder:
-            self.rqueue = builder._rqueue
-            self.wqueue = builder._wqueue
-        else:
-            self.rqueue = Queue()
-            self.wqueue = PriorityQueue()
-
     def invoke_threads(self) -> None:
-        for i in range(self.config.linkcheck_workers):
+        for _i in range(self.config.linkcheck_workers):
             thread = HyperlinkAvailabilityCheckWorker(self.env, self.config,
                                                       self.rqueue, self.wqueue,
-                                                      self.rate_limits, self.builder)
+                                                      self.rate_limits)
             thread.start()
             self.workers.append(thread)
 
     def shutdown_threads(self) -> None:
         self.wqueue.join()
-        for worker in self.workers:
+        for _worker in self.workers:
             self.wqueue.put(CheckRequest(CHECK_IMMEDIATELY, None), False)
 
     def check(self, hyperlinks: Dict[str, Hyperlink]) -> Generator[CheckResult, None, None]:
@@ -365,11 +247,7 @@
     """A worker class for checking the availability of hyperlinks."""
 
     def __init__(self, env: BuildEnvironment, config: Config, rqueue: Queue,
-                 wqueue: Queue, rate_limits: Dict[str, RateLimit],
-                 builder: CheckExternalLinksBuilder = None) -> None:
-        # Warning: builder argument will be removed in the sphinx-5.0.
-        # Don't use it from extensions.
-        # tag: RemovedInSphinx50Warning
+                 wqueue: Queue, rate_limits: Dict[str, RateLimit]) -> None:
         self.config = config
         self.env = env
         self.rate_limits = rate_limits
@@ -378,19 +256,10 @@
 
         self.anchors_ignore = [re.compile(x)
                                for x in self.config.linkcheck_anchors_ignore]
+        self.documents_exclude = [re.compile(doc)
+                                  for doc in self.config.linkcheck_exclude_documents]
         self.auth = [(re.compile(pattern), auth_info) for pattern, auth_info
                      in self.config.linkcheck_auth]
-
-        if builder:
-            # if given, fill the result of checks as cache
-            self._good = builder._good
-            self._broken = builder._broken
-            self._redirected = builder._redirected
-        else:
-            # only for compatibility. Will be removed in Sphinx-5.0
-            self._good = set()
-            self._broken = {}
-            self._redirected = {}
 
         super().__init__(daemon=True)
 
@@ -399,7 +268,7 @@
         if self.config.linkcheck_timeout:
             kwargs['timeout'] = self.config.linkcheck_timeout
 
-        def get_request_headers() -> Dict:
+        def get_request_headers() -> Dict[str, str]:
             url = urlparse(uri)
             candidates = ["%s://%s" % (url.scheme, url.netloc),
                           "%s://%s/" % (url.scheme, url.netloc),
@@ -408,7 +277,7 @@
 
             for u in candidates:
                 if u in self.config.linkcheck_request_headers:
-                    headers = dict(DEFAULT_REQUEST_HEADERS)
+                    headers = deepcopy(DEFAULT_REQUEST_HEADERS)
                     headers.update(self.config.linkcheck_request_headers[u])
                     return headers
 
@@ -433,7 +302,7 @@
                 req_url = encode_uri(req_url)
 
             # Get auth info, if any
-            for pattern, auth_info in self.auth:
+            for pattern, auth_info in self.auth:  # noqa: B007 (false positive)
                 if pattern.match(uri):
                     break
             else:
@@ -519,6 +388,15 @@
 
         def check(docname: str) -> Tuple[str, str, int]:
             # check for various conditions without bothering the network
+
+            for doc_matcher in self.documents_exclude:
+                if doc_matcher.match(docname):
+                    info = (
+                        f'{docname} matched {doc_matcher.pattern} from '
+                        'linkcheck_exclude_documents'
+                    )
+                    return 'ignored', info, 0
+
             if len(uri) == 0 or uri.startswith(('#', 'mailto:', 'tel:')):
                 return 'unchecked', '', 0
             elif not uri.startswith(('http:', 'https:')):
@@ -530,27 +408,13 @@
                     if path.exists(path.join(srcdir, uri)):
                         return 'working', '', 0
                     else:
-                        self._broken[uri] = ''
                         return 'broken', '', 0
-            elif uri in self._good:
-                return 'working', 'old', 0
-            elif uri in self._broken:
-                return 'broken', self._broken[uri], 0
-            elif uri in self._redirected:
-                return 'redirected', self._redirected[uri][0], self._redirected[uri][1]
 
             # need to actually check the URI
             for _ in range(self.config.linkcheck_retries):
                 status, info, code = check_uri()
                 if status != "broken":
                     break
-
-            if status == "working":
-                self._good.add(uri)
-            elif status == "broken":
-                self._broken[uri] = info
-            elif status == "redirected":
-                self._redirected[uri] = (info, code)
 
             return (status, info, code)
 
@@ -638,32 +502,34 @@
         builder = cast(CheckExternalLinksBuilder, self.app.builder)
         hyperlinks = builder.hyperlinks
 
+        def add_uri(uri: str, node: nodes.Element) -> None:
+            newuri = self.app.emit_firstresult('linkcheck-process-uri', uri)
+            if newuri:
+                uri = newuri
+
+            lineno = get_node_line(node)
+            uri_info = Hyperlink(uri, self.env.docname, lineno)
+            if uri not in hyperlinks:
+                hyperlinks[uri] = uri_info
+
         # reference nodes
-        for refnode in self.document.traverse(nodes.reference):
+        for refnode in self.document.findall(nodes.reference):
             if 'refuri' not in refnode:
                 continue
             uri = refnode['refuri']
-            newuri = self.app.emit_firstresult('linkcheck-process-uri', uri)
-            if newuri:
-                uri = newuri
-
-            lineno = get_node_line(refnode)
-            uri_info = Hyperlink(uri, self.env.docname, lineno)
-            if uri not in hyperlinks:
-                hyperlinks[uri] = uri_info
+            add_uri(uri, refnode)
 
         # image nodes
-        for imgnode in self.document.traverse(nodes.image):
+        for imgnode in self.document.findall(nodes.image):
             uri = imgnode['candidates'].get('?')
             if uri and '://' in uri:
-                newuri = self.app.emit_firstresult('linkcheck-process-uri', uri)
-                if newuri:
-                    uri = newuri
-
-                lineno = get_node_line(imgnode)
-                uri_info = Hyperlink(uri, self.env.docname, lineno)
-                if uri not in hyperlinks:
-                    hyperlinks[uri] = uri_info
+                add_uri(uri, imgnode)
+
+        # raw nodes
+        for rawnode in self.document.findall(nodes.raw):
+            uri = rawnode.get('source')
+            if uri and '://' in uri:
+                add_uri(uri, rawnode)
 
 
 def rewrite_github_anchor(app: Sphinx, uri: str) -> Optional[str]:
@@ -698,18 +564,19 @@
     app.add_builder(CheckExternalLinksBuilder)
     app.add_post_transform(HyperlinkCollector)
 
-    app.add_config_value('linkcheck_ignore', [], None)
-    app.add_config_value('linkcheck_allowed_redirects', {}, None)
-    app.add_config_value('linkcheck_auth', [], None)
-    app.add_config_value('linkcheck_request_headers', {}, None)
-    app.add_config_value('linkcheck_retries', 1, None)
-    app.add_config_value('linkcheck_timeout', None, None, [int])
-    app.add_config_value('linkcheck_workers', 5, None)
-    app.add_config_value('linkcheck_anchors', True, None)
+    app.add_config_value('linkcheck_ignore', [], False)
+    app.add_config_value('linkcheck_exclude_documents', [], False)
+    app.add_config_value('linkcheck_allowed_redirects', {}, False)
+    app.add_config_value('linkcheck_auth', [], False)
+    app.add_config_value('linkcheck_request_headers', {}, False)
+    app.add_config_value('linkcheck_retries', 1, False)
+    app.add_config_value('linkcheck_timeout', None, False, [int])
+    app.add_config_value('linkcheck_workers', 5, False)
+    app.add_config_value('linkcheck_anchors', True, False)
     # Anchors starting with ! are ignored since they are
     # commonly used for dynamic pages
-    app.add_config_value('linkcheck_anchors_ignore', ["^!"], None)
-    app.add_config_value('linkcheck_rate_limit_timeout', 300.0, None)
+    app.add_config_value('linkcheck_anchors_ignore', ["^!"], False)
+    app.add_config_value('linkcheck_rate_limit_timeout', 300.0, False)
 
     app.add_event('linkcheck-process-uri')
 
('sphinx/builders', 'dirhtml.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,15 +1,7 @@
-"""
-    sphinx.builders.dirhtml
-    ~~~~~~~~~~~~~~~~~~~~~~~
-
-    Directory HTML builders.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Directory HTML builders."""
 
 from os import path
-from typing import Any, Dict
+from typing import Any, Dict, Optional
 
 from sphinx.application import Sphinx
 from sphinx.builders.html import StandaloneHTMLBuilder
@@ -27,7 +19,7 @@
     """
     name = 'dirhtml'
 
-    def get_target_uri(self, docname: str, typ: str = None) -> str:
+    def get_target_uri(self, docname: str, typ: Optional[str] = None) -> str:
         if docname == 'index':
             return ''
         if docname.endswith(SEP + 'index'):
('sphinx/builders', 'singlehtml.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,15 +1,7 @@
-"""
-    sphinx.builders.singlehtml
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    Single HTML builders.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Single HTML builders."""
 
 from os import path
-from typing import Any, Dict, List, Tuple, Union
+from typing import Any, Dict, List, Optional, Tuple, Union
 
 from docutils import nodes
 from docutils.nodes import Node
@@ -35,10 +27,10 @@
 
     copysource = False
 
-    def get_outdated_docs(self) -> Union[str, List[str]]:  # type: ignore
+    def get_outdated_docs(self) -> Union[str, List[str]]:  # type: ignore[override]
         return 'all documents'
 
-    def get_target_uri(self, docname: str, typ: str = None) -> str:
+    def get_target_uri(self, docname: str, typ: Optional[str] = None) -> str:
         if docname in self.env.all_docs:
             # all references are on the same page...
             return self.config.root_doc + self.out_suffix + \
@@ -47,14 +39,14 @@
             # chances are this is a html_additional_page
             return docname + self.out_suffix
 
-    def get_relative_uri(self, from_: str, to: str, typ: str = None) -> str:
+    def get_relative_uri(self, from_: str, to: str, typ: Optional[str] = None) -> str:
         # ignore source
         return self.get_target_uri(to, typ)
 
     def fix_refuris(self, tree: Node) -> None:
         # fix refuris with double anchor
         fname = self.config.root_doc + self.out_suffix
-        for refnode in tree.traverse(nodes.reference):
+        for refnode in tree.findall(nodes.reference):
             if 'refuri' not in refnode:
                 continue
             refuri = refnode['refuri']
@@ -121,7 +113,7 @@
 
         return {self.config.root_doc: new_fignumbers}
 
-    def get_doc_context(self, docname: str, body: str, metatags: str) -> Dict:
+    def get_doc_context(self, docname: str, body: str, metatags: str) -> Dict[str, Any]:
         # no relation links...
         toctree = TocTree(self.env).get_toctree_for(self.config.root_doc, self, False)
         # if there is no toctree, toc is None
('sphinx/builders', 'dummy.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,14 +1,6 @@
-"""
-    sphinx.builders.dummy
-    ~~~~~~~~~~~~~~~~~~~~~
+"""Do syntax checks, but no writing."""
 
-    Do syntax checks, but no writing.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
-
-from typing import Any, Dict, Set
+from typing import Any, Dict, Optional, Set
 
 from docutils.nodes import Node
 
@@ -29,7 +21,7 @@
     def get_outdated_docs(self) -> Set[str]:
         return self.env.found_docs
 
-    def get_target_uri(self, docname: str, typ: str = None) -> str:
+    def get_target_uri(self, docname: str, typ: Optional[str] = None) -> str:
         return ''
 
     def prepare_writing(self, docnames: Set[str]) -> None:
('sphinx/builders', '_epub_base.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,18 +1,10 @@
-"""
-    sphinx.builders._epub_base
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    Base class of epub2/epub3 builders.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Base class of epub2/epub3 builders."""
 
 import html
 import os
 import re
 from os import path
-from typing import Any, Dict, List, NamedTuple, Set, Tuple
+from typing import Any, Dict, List, NamedTuple, Optional, Set, Tuple
 from zipfile import ZIP_DEFLATED, ZIP_STORED, ZipFile
 
 from docutils import nodes
@@ -64,6 +56,7 @@
     '.xhtml': 'application/xhtml+xml',
     '.css': 'text/css',
     '.png': 'image/png',
+    '.webp': 'image/webp',
     '.gif': 'image/gif',
     '.svg': 'image/svg+xml',
     '.jpg': 'image/jpeg',
@@ -277,7 +270,7 @@
                     new_ids.append(new_id)
             node['ids'] = new_ids
 
-        for reference in tree.traverse(nodes.reference):
+        for reference in tree.findall(nodes.reference):
             if 'refuri' in reference:
                 m = self.refuri_re.match(reference['refuri'])
                 if m:
@@ -285,14 +278,14 @@
             if 'refid' in reference:
                 reference['refid'] = self.fix_fragment('', reference['refid'])
 
-        for target in tree.traverse(nodes.target):
+        for target in tree.findall(nodes.target):
             update_node_id(target)
 
             next_node: Node = target.next_node(ascend=True)
             if isinstance(next_node, nodes.Element):
                 update_node_id(next_node)
 
-        for desc_signature in tree.traverse(addnodes.desc_signature):
+        for desc_signature in tree.findall(addnodes.desc_signature):
             update_node_id(desc_signature)
 
     def add_visible_links(self, tree: nodes.document, show_urls: str = 'inline') -> None:
@@ -323,14 +316,14 @@
             # a) place them after the last existing footnote
             # b) place them after an (empty) Footnotes rubric
             # c) create an empty Footnotes rubric at the end of the document
-            fns = tree.traverse(nodes.footnote)
+            fns = list(tree.findall(nodes.footnote))
             if fns:
                 fn = fns[-1]
                 return fn.parent, fn.parent.index(fn) + 1
-            for node in tree.traverse(nodes.rubric):
+            for node in tree.findall(nodes.rubric):
                 if len(node) == 1 and node.astext() == FOOTNOTES_RUBRIC_NAME:
                     return node.parent, node.parent.index(node) + 1
-            doc = tree.traverse(nodes.document)[0]
+            doc = next(tree.findall(nodes.document))
             rub = nodes.rubric()
             rub.append(nodes.Text(FOOTNOTES_RUBRIC_NAME))
             doc.append(rub)
@@ -339,10 +332,10 @@
         if show_urls == 'no':
             return
         if show_urls == 'footnote':
-            doc = tree.traverse(nodes.document)[0]
+            doc = next(tree.findall(nodes.document))
             fn_spot, fn_idx = footnote_spot(tree)
             nr = 1
-        for node in tree.traverse(nodes.reference):
+        for node in list(tree.findall(nodes.reference)):
             uri = node.get('refuri', '')
             if (uri.startswith('http:') or uri.startswith('https:') or
                     uri.startswith('ftp:')) and uri not in node.astext():
@@ -377,14 +370,14 @@
         """Fix href attributes for genindex pages."""
         # XXX: modifies tree inline
         # Logic modeled from themes/basic/genindex.html
-        for key, columns in tree:
-            for entryname, (links, subitems, key_) in columns:
+        for _key, columns in tree:
+            for _entryname, (links, subitems, _key) in columns:
                 for (i, (ismain, link)) in enumerate(links):
                     m = self.refuri_re.match(link)
                     if m:
                         links[i] = (ismain,
                                     self.fix_fragment(m.group(1), m.group(2)))
-                for subentryname, subentrylinks in subitems:
+                for _subentryname, subentrylinks in subitems:
                     for (i, (ismain, link)) in enumerate(subentrylinks):
                         m = self.refuri_re.match(link)
                         if m:
@@ -453,7 +446,7 @@
         pass
 
     def handle_page(self, pagename: str, addctx: Dict, templatename: str = 'page.html',
-                    outfilename: str = None, event_arg: Any = None) -> None:
+                    outfilename: Optional[str] = None, event_arg: Any = None) -> None:
         """Create a rendered page.
 
         This method is overwritten for genindex pages in order to fix href link
@@ -471,7 +464,7 @@
         logger.info(__('writing mimetype file...'))
         copy_asset_file(path.join(self.template_dir, 'mimetype'), self.outdir)
 
-    def build_container(self, outname: str = 'META-INF/container.xml') -> None:  # NOQA
+    def build_container(self, outname: str = 'META-INF/container.xml') -> None:
         """Write the metainfo file META-INF/container.xml."""
         logger.info(__('writing META-INF/container.xml file...'))
         outdir = path.join(self.outdir, 'META-INF')
@@ -491,7 +484,7 @@
         metadata['copyright'] = html.escape(self.config.epub_copyright)
         metadata['scheme'] = html.escape(self.config.epub_scheme)
         metadata['id'] = html.escape(self.config.epub_identifier)
-        metadata['date'] = html.escape(format_date("%Y-%m-%d"))
+        metadata['date'] = html.escape(format_date("%Y-%m-%d", language='en'))
         metadata['manifest_items'] = []
         metadata['spines'] = []
         metadata['guides'] = []
@@ -703,7 +696,7 @@
         epub_filename = path.join(self.outdir, outname)
         with ZipFile(epub_filename, 'w', ZIP_DEFLATED) as epub:
             epub.write(path.join(self.outdir, 'mimetype'), 'mimetype', ZIP_STORED)
-            for filename in ['META-INF/container.xml', 'content.opf', 'toc.ncx']:
+            for filename in ('META-INF/container.xml', 'content.opf', 'toc.ncx'):
                 epub.write(path.join(self.outdir, filename), filename, ZIP_DEFLATED)
             for filename in self.files:
                 epub.write(path.join(self.outdir, filename), filename, ZIP_DEFLATED)
('sphinx/builders', 'epub3.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,6 @@
-"""
-    sphinx.builders.epub3
-    ~~~~~~~~~~~~~~~~~~~~~
-
-    Build epub3 files.
-    Originally derived from epub.py.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
+"""Build epub3 files.
+
+Originally derived from epub.py.
 """
 
 import html
@@ -83,7 +77,7 @@
         self.build_toc()
         self.build_epub()
 
-    def content_metadata(self) -> Dict:
+    def content_metadata(self) -> Dict[str, Any]:
         """Create a dictionary with all metadata for the content.opf
         file properly escaped.
         """
@@ -94,7 +88,7 @@
         metadata['contributor'] = html.escape(self.config.epub_contributor)
         metadata['page_progression_direction'] = PAGE_PROGRESSION_DIRECTIONS.get(writing_mode)
         metadata['ibook_scroll_axis'] = IBOOK_SCROLL_AXIS.get(writing_mode)
-        metadata['date'] = html.escape(format_date("%Y-%m-%dT%H:%M:%SZ"))
+        metadata['date'] = html.escape(format_date("%Y-%m-%dT%H:%M:%SZ", language='en'))
         metadata['version'] = html.escape(self.config.version)
         metadata['epub_version'] = self.config.epub_version
         return metadata
@@ -150,11 +144,11 @@
 
         return navstack[0].children
 
-    def navigation_doc_metadata(self, navlist: List[NavPoint]) -> Dict:
+    def navigation_doc_metadata(self, navlist: List[NavPoint]) -> Dict[str, Any]:
         """Create a dictionary with all metadata for the nav.xhtml file
         properly escaped.
         """
-        metadata: Dict = {}
+        metadata = {}
         metadata['lang'] = html.escape(self.config.epub_language)
         metadata['toc_locale'] = html.escape(self.guide_titles['toc'])
         metadata['navlist'] = navlist
@@ -223,7 +217,7 @@
 
 def convert_epub_css_files(app: Sphinx, config: Config) -> None:
     """This converts string styled epub_css_files to tuple styled one."""
-    epub_css_files: List[Tuple[str, Dict]] = []
+    epub_css_files: List[Tuple[str, Dict[str, Any]]] = []
     for entry in config.epub_css_files:
         if isinstance(entry, str):
             epub_css_files.append((entry, {}))
@@ -242,7 +236,7 @@
     app.add_builder(Epub3Builder)
 
     # config values
-    app.add_config_value('epub_basename', lambda self: make_filename(self.project), None)
+    app.add_config_value('epub_basename', lambda self: make_filename(self.project), False)
     app.add_config_value('epub_version', 3.0, 'epub')  # experimental
     app.add_config_value('epub_theme', 'epub', 'epub')
     app.add_config_value('epub_theme_options', {}, 'epub')
('sphinx/builders/latex', 'transforms.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,14 +1,6 @@
-"""
-    sphinx.builders.latex.transforms
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    Transforms for LaTeX builder.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
-
-from typing import Any, Dict, List, Set, Tuple, cast
+"""Transforms for LaTeX builder."""
+
+from typing import Any, Dict, List, Optional, Set, Tuple, cast
 
 from docutils import nodes
 from docutils.nodes import Element, Node
@@ -33,19 +25,19 @@
 
     def apply(self, **kwargs: Any) -> None:
         matcher = NodeMatcher(*self.TARGET_NODES)
-        for node in self.document.traverse(matcher):  # type: Element
+        for node in self.document.findall(matcher):  # type: Element
             node['docname'] = self.env.docname
 
 
 class SubstitutionDefinitionsRemover(SphinxPostTransform):
-    """Remove ``substitution_definition node from doctrees."""
+    """Remove ``substitution_definition`` nodes from doctrees."""
 
     # should be invoked after Substitutions process
     default_priority = Substitutions.default_priority + 1
     formats = ('latex',)
 
     def run(self, **kwargs: Any) -> None:
-        for node in self.document.traverse(nodes.substitution_definition):
+        for node in list(self.document.findall(nodes.substitution_definition)):
             node.parent.remove(node)
 
 
@@ -81,7 +73,7 @@
         if show_urls is False or show_urls == 'no':
             return
 
-        for node in self.document.traverse(nodes.reference):
+        for node in list(self.document.findall(nodes.reference)):
             uri = node.get('refuri', '')
             if uri.startswith(URI_SCHEMES):
                 if uri.startswith('mailto:'):
@@ -102,13 +94,17 @@
     def get_docname_for_node(self, node: Node) -> str:
         while node:
             if isinstance(node, nodes.document):
-                return self.env.path2doc(node['source'])
+                return self.env.path2doc(node['source']) or ''
             elif isinstance(node, addnodes.start_of_file):
                 return node['docname']
             else:
                 node = node.parent
 
-        return None  # never reached here. only for type hinting
+        try:
+            source = node['source']  # type: ignore[index]
+        except TypeError:
+            raise ValueError('Failed to get a docname!') from None
+        raise ValueError(f'Failed to get a docname for source {source!r}!')
 
     def create_footnote(self, uri: str, docname: str) -> Tuple[nodes.footnote, nodes.footnote_reference]:  # NOQA
         reference = nodes.reference('', nodes.Text(uri), refuri=uri, nolinkurl=True)
@@ -237,7 +233,8 @@
           blah blah blah ...
 
     * Replace second and subsequent footnote references which refers same footnote definition
-      by footnotemark node.
+      by footnotemark node.  Additionally, the footnote definition node is marked as
+      "referred".
 
       Before::
 
@@ -258,7 +255,7 @@
       After::
 
           blah blah blah
-          <footnote ids="id1">
+          <footnote ids="id1" referred=True>
               <label>
                   1
               <paragraph>
@@ -348,7 +345,7 @@
     formats = ('latex',)
 
     def run(self, **kwargs: Any) -> None:
-        footnotes = list(self.document.traverse(nodes.footnote))
+        footnotes = list(self.document.findall(nodes.footnote))
         for node in footnotes:
             node.parent.remove(node)
 
@@ -358,11 +355,11 @@
 
 class LaTeXFootnoteVisitor(nodes.NodeVisitor):
     def __init__(self, document: nodes.document, footnotes: List[nodes.footnote]) -> None:
-        self.appeared: Set[Tuple[str, str]] = set()
+        self.appeared: Dict[Tuple[str, str], nodes.footnote] = {}
         self.footnotes: List[nodes.footnote] = footnotes
         self.pendings: List[nodes.footnote] = []
         self.table_footnotes: List[nodes.footnote] = []
-        self.restricted: Element = None
+        self.restricted: Optional[Element] = None
         super().__init__(document)
 
     def unknown_visit(self, node: Node) -> None:
@@ -423,7 +420,7 @@
         self.unrestrict(node)
 
     def depart_table(self, node: nodes.table) -> None:
-        tbody = list(node.traverse(nodes.tbody))[0]
+        tbody = next(node.findall(nodes.tbody))
         for footnote in reversed(self.table_footnotes):
             fntext = footnotetext('', *footnote.children, ids=footnote['ids'])
             tbody.insert(0, fntext)
@@ -439,22 +436,24 @@
     def visit_footnote_reference(self, node: nodes.footnote_reference) -> None:
         number = node.astext().strip()
         docname = node['docname']
-        if self.restricted:
-            mark = footnotemark('', number, refid=node['refid'])
-            node.replace_self(mark)
-            if (docname, number) not in self.appeared:
-                footnote = self.get_footnote_by_reference(node)
-                self.pendings.append(footnote)
-        elif (docname, number) in self.appeared:
+        if (docname, number) in self.appeared:
+            footnote = self.appeared[(docname, number)]
+            footnote["referred"] = True
+
             mark = footnotemark('', number, refid=node['refid'])
             node.replace_self(mark)
         else:
             footnote = self.get_footnote_by_reference(node)
-            self.footnotes.remove(footnote)
-            node.replace_self(footnote)
-            footnote.walkabout(self)
-
-        self.appeared.add((docname, number))
+            if self.restricted:
+                mark = footnotemark('', number, refid=node['refid'])
+                node.replace_self(mark)
+                self.pendings.append(footnote)
+            else:
+                self.footnotes.remove(footnote)
+                node.replace_self(footnote)
+                footnote.walkabout(self)
+
+            self.appeared[(docname, number)] = footnote
         raise nodes.SkipNode
 
     def get_footnote_by_reference(self, node: nodes.footnote_reference) -> nodes.footnote:
@@ -463,7 +462,7 @@
             if docname == footnote['docname'] and footnote['ids'][0] == node['refid']:
                 return footnote
 
-        return None
+        raise ValueError('No footnote not found for given reference node %r' % node)
 
 
 class BibliographyTransform(SphinxPostTransform):
@@ -501,7 +500,7 @@
 
     def run(self, **kwargs: Any) -> None:
         citations = thebibliography()
-        for node in self.document.traverse(nodes.citation):
+        for node in list(self.document.findall(nodes.citation)):
             node.parent.remove(node)
             citations += node
 
@@ -521,7 +520,7 @@
     def run(self, **kwargs: Any) -> None:
         domain = cast(CitationDomain, self.env.get_domain('citation'))
         matcher = NodeMatcher(addnodes.pending_xref, refdomain='citation', reftype='ref')
-        for node in self.document.traverse(matcher):  # type: addnodes.pending_xref
+        for node in self.document.findall(matcher):  # type: addnodes.pending_xref
             docname, labelid, _ = domain.citations.get(node['reftarget'], ('', '', 0))
             if docname:
                 citation_ref = nodes.citation_reference('', '', *node.children,
@@ -540,7 +539,7 @@
 
     def run(self, **kwargs: Any) -> None:
         equations = self.env.get_domain('math').data['objects']
-        for node in self.document.traverse(addnodes.pending_xref):
+        for node in self.document.findall(addnodes.pending_xref):
             if node['refdomain'] == 'math' and node['reftype'] in ('eq', 'numref'):
                 docname, _ = equations.get(node['reftarget'], (None, None))
                 if docname:
@@ -555,7 +554,7 @@
 
     def run(self, **kwargs: Any) -> None:
         matcher = NodeMatcher(nodes.container, literal_block=True)
-        for node in self.document.traverse(matcher):  # type: nodes.container
+        for node in self.document.findall(matcher):  # type: nodes.container
             newnode = captioned_literal_block('', *node.children, **node.attributes)
             node.replace_self(newnode)
 
@@ -566,7 +565,7 @@
     formats = ('latex',)
 
     def run(self, **kwargs: Any) -> None:
-        for node in self.document.traverse(addnodes.start_of_file):
+        for node in self.document.findall(addnodes.start_of_file):
             section = node.next_node(nodes.section)
             if section:
                 section['ids'].append(':doc')  # special label for :doc:
@@ -602,9 +601,9 @@
     formats = ('latex',)
 
     def run(self, **kwargs: Any) -> None:
-        for node in self.document.traverse(nodes.title):
+        for node in list(self.document.findall(nodes.title)):
             if isinstance(node.parent, nodes.section):
-                for i, index in enumerate(node.traverse(addnodes.index)):
+                for i, index in enumerate(node.findall(addnodes.index)):
                     # move the index node next to the section title
                     node.remove(index)
                     node.parent.insert(i + 1, index)
('sphinx/builders/latex', 'theming.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,16 +1,8 @@
-"""
-    sphinx.builders.latex.theming
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    Theming support for LaTeX builder.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Theming support for LaTeX builder."""
 
 import configparser
 from os import path
-from typing import Dict
+from typing import Dict, Optional
 
 from sphinx.application import Sphinx
 from sphinx.config import Config
@@ -81,7 +73,7 @@
     def __init__(self, name: str, filename: str) -> None:
         super().__init__(name)
         self.config = configparser.RawConfigParser()
-        self.config.read(path.join(filename))
+        self.config.read(path.join(filename), encoding='utf-8')
 
         for key in self.REQUIRED_CONFIG_KEYS:
             try:
@@ -121,14 +113,12 @@
         if name in self.themes:
             theme = self.themes[name]
         else:
-            theme = self.find_user_theme(name)
-            if not theme:
-                theme = Theme(name)
+            theme = self.find_user_theme(name) or Theme(name)
 
         theme.update(self.config)
         return theme
 
-    def find_user_theme(self, name: str) -> Theme:
+    def find_user_theme(self, name: str) -> Optional[Theme]:
         """Find a theme named as *name* from latex_theme_path."""
         for theme_path in self.theme_paths:
             config_path = path.join(theme_path, name, 'theme.conf')
('sphinx/builders/latex', 'util.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.builders.latex.util
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    Utilities for LaTeX builder.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Utilities for LaTeX builder."""
 
 from typing import Optional
 
@@ -20,7 +12,7 @@
         self.language_code = language_code
         self.use_polyglossia = use_polyglossia
         self.supported = True
-        super().__init__(language_code or '')
+        super().__init__(language_code)
 
     def uses_cyrillic(self) -> bool:
         return self.language in self.cyrillic_languages
('sphinx/builders/latex', 'constants.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.builders.latex.constants
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    consntants for LaTeX builder.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""consntants for LaTeX builder."""
 
 from typing import Any, Dict
 
('sphinx/builders/latex', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,17 +1,9 @@
-"""
-    sphinx.builders.latex
-    ~~~~~~~~~~~~~~~~~~~~~
-
-    LaTeX builder.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""LaTeX builder."""
 
 import os
 import warnings
 from os import path
-from typing import Any, Dict, Iterable, List, Tuple, Union
+from typing import Any, Dict, Iterable, List, Optional, Tuple, Union
 
 from docutils.frontend import OptionParser
 from docutils.nodes import Node
@@ -24,7 +16,6 @@
 from sphinx.builders.latex.theming import Theme, ThemeFactory
 from sphinx.builders.latex.util import ExtBabel
 from sphinx.config import ENUM, Config
-from sphinx.deprecation import RemovedInSphinx50Warning
 from sphinx.environment.adapters.asset import ImageAdapter
 from sphinx.errors import NoUri, SphinxError
 from sphinx.locale import _, __
@@ -136,13 +127,13 @@
     def get_outdated_docs(self) -> Union[str, List[str]]:
         return 'all documents'  # for now
 
-    def get_target_uri(self, docname: str, typ: str = None) -> str:
+    def get_target_uri(self, docname: str, typ: Optional[str] = None) -> str:
         if docname not in self.docnames:
             raise NoUri(docname, typ)
         else:
             return '%' + docname
 
-    def get_relative_uri(self, from_: str, to: str, typ: str = None) -> str:
+    def get_relative_uri(self, from_: str, to: str, typ: Optional[str] = None) -> str:
         # ignore source path
         return self.get_target_uri(to, typ)
 
@@ -172,9 +163,8 @@
         self.context.update(ADDITIONAL_SETTINGS.get(self.config.latex_engine, {}))
 
         # Add special settings for (latex_engine, language_code)
-        if self.config.language:
-            key = (self.config.latex_engine, self.config.language[:2])
-            self.context.update(ADDITIONAL_SETTINGS.get(key, {}))
+        key = (self.config.latex_engine, self.config.language[:2])
+        self.context.update(ADDITIONAL_SETTINGS.get(key, {}))
 
         # Apply user settings to context
         self.context.update(self.config.latex_elements)
@@ -205,7 +195,7 @@
 
     def init_babel(self) -> None:
         self.babel = ExtBabel(self.config.language, not self.context['babel'])
-        if self.config.language and not self.babel.is_supported_language():
+        if not self.babel.is_supported_language():
             # emit warning if specified language is invalid
             # (only emitting, nothing changed to processing)
             logger.warning(__('no Babel option known for language %r'),
@@ -234,12 +224,11 @@
             self.context['classoptions'] += ',' + self.babel.get_language()
             # this branch is not taken for xelatex/lualatex if default settings
             self.context['multilingual'] = self.context['babel']
-            if self.config.language:
-                self.context['shorthandoff'] = SHORTHANDOFF
-
-                # Times fonts don't work with Cyrillic languages
-                if self.babel.uses_cyrillic() and 'fontpkg' not in self.config.latex_elements:
-                    self.context['fontpkg'] = ''
+            self.context['shorthandoff'] = SHORTHANDOFF
+
+            # Times fonts don't work with Cyrillic languages
+            if self.babel.uses_cyrillic() and 'fontpkg' not in self.config.latex_elements:
+                self.context['fontpkg'] = ''
         elif self.context['polyglossia']:
             self.context['classoptions'] += ',' + self.babel.get_language()
             options = self.babel.get_mainlanguage_options()
@@ -253,19 +242,23 @@
     def write_stylesheet(self) -> None:
         highlighter = highlighting.PygmentsBridge('latex', self.config.pygments_style)
         stylesheet = path.join(self.outdir, 'sphinxhighlight.sty')
-        with open(stylesheet, 'w') as f:
+        with open(stylesheet, 'w', encoding="utf-8") as f:
             f.write('\\NeedsTeXFormat{LaTeX2e}[1995/12/01]\n')
             f.write('\\ProvidesPackage{sphinxhighlight}'
-                    '[2016/05/29 stylesheet for highlighting with pygments]\n')
+                    '[2022/06/30 stylesheet for highlighting with pygments]\n')
             f.write('% Its contents depend on pygments_style configuration variable.\n\n')
             f.write(highlighter.get_stylesheet())
 
     def write(self, *ignored: Any) -> None:
         docwriter = LaTeXWriter(self)
-        docsettings: Any = OptionParser(
-            defaults=self.env.settings,
-            components=(docwriter,),
-            read_config_files=True).get_default_values()
+        with warnings.catch_warnings():
+            warnings.filterwarnings('ignore', category=DeprecationWarning)
+            # DeprecationWarning: The frontend.OptionParser class will be replaced
+            # by a subclass of argparse.ArgumentParser in Docutils 0.21 or later.
+            docsettings: Any = OptionParser(
+                defaults=self.env.settings,
+                components=(docwriter,),
+                read_config_files=True).get_default_values()
 
         self.init_document_data()
         self.write_stylesheet()
@@ -280,7 +273,7 @@
                                            encoding='utf-8', overwrite_if_changed=True)
             with progress_message(__("processing %s") % targetname):
                 doctree = self.env.get_doctree(docname)
-                toctree = next(iter(doctree.traverse(addnodes.toctree)), None)
+                toctree = next(doctree.findall(addnodes.toctree), None)
                 if toctree and toctree.get('maxdepth') > 0:
                     tocdepth = toctree.get('maxdepth')
                 else:
@@ -310,7 +303,7 @@
     def get_contentsname(self, indexfile: str) -> str:
         tree = self.env.get_doctree(indexfile)
         contentsname = None
-        for toctree in tree.traverse(addnodes.toctree):
+        for toctree in tree.findall(addnodes.toctree):
             if 'caption' in toctree:
                 contentsname = toctree['caption']
                 break
@@ -338,7 +331,7 @@
             new_sect += nodes.title('<Set title in conf.py>',
                                     '<Set title in conf.py>')
             new_tree += new_sect
-            for node in tree.traverse(addnodes.toctree):
+            for node in tree.findall(addnodes.toctree):
                 new_sect += node
             tree = new_tree
         largetree = inline_all_toctrees(self, self.docnames, indexfile, tree,
@@ -353,15 +346,15 @@
         self.env.resolve_references(largetree, indexfile, self)
         # resolve :ref:s to distant tex files -- we can't add a cross-reference,
         # but append the document name
-        for pendingnode in largetree.traverse(addnodes.pending_xref):
+        for pendingnode in largetree.findall(addnodes.pending_xref):
             docname = pendingnode['refdocname']
             sectname = pendingnode['refsectname']
             newnodes: List[Node] = [nodes.emphasis(sectname, sectname)]
             for subdir, title in self.titles:
                 if docname.startswith(subdir):
-                    newnodes.append(nodes.Text(_(' (in '), _(' (in ')))
+                    newnodes.append(nodes.Text(_(' (in ')))
                     newnodes.append(nodes.emphasis(title, title))
-                    newnodes.append(nodes.Text(')', ')'))
+                    newnodes.append(nodes.Text(')'))
                     break
             else:
                 pass
@@ -382,14 +375,10 @@
         # configure usage of xindy (impacts Makefile and latexmkrc)
         # FIXME: convert this rather to a confval with suitable default
         #        according to language ? but would require extra documentation
-        if self.config.language:
-            xindy_lang_option = \
-                XINDY_LANG_OPTIONS.get(self.config.language[:2],
-                                       '-L general -C utf8 ')
-            xindy_cyrillic = self.config.language[:2] in XINDY_CYRILLIC_SCRIPTS
-        else:
-            xindy_lang_option = '-L english -C utf8 '
-            xindy_cyrillic = False
+        xindy_lang_option = XINDY_LANG_OPTIONS.get(self.config.language[:2],
+                                                   '-L general -C utf8 ')
+        xindy_cyrillic = self.config.language[:2] in XINDY_CYRILLIC_SCRIPTS
+
         context = {
             'latex_engine':      self.config.latex_engine,
             'xindy_use':         self.config.latex_use_xindy,
@@ -449,18 +438,6 @@
         filename = path.join(package_dir, 'templates', 'latex', 'sphinxmessages.sty_t')
         copy_asset_file(filename, self.outdir, context=context, renderer=LaTeXRenderer())
 
-    @property
-    def usepackages(self) -> List[Tuple[str, str]]:
-        warnings.warn('LaTeXBuilder.usepackages is deprecated.',
-                      RemovedInSphinx50Warning, stacklevel=2)
-        return self.app.registry.latex_packages
-
-    @property
-    def usepackages_after_hyperref(self) -> List[Tuple[str, str]]:
-        warnings.warn('LaTeXBuilder.usepackages_after_hyperref is deprecated.',
-                      RemovedInSphinx50Warning, stacklevel=2)
-        return self.app.registry.latex_packages_after_hyperref
-
 
 def validate_config_values(app: Sphinx, config: Config) -> None:
     for key in list(config.latex_elements):
@@ -488,7 +465,7 @@
     """ Better default latex_engine settings for specific languages. """
     if config.language == 'ja':
         return 'uplatex'
-    elif (config.language or '').startswith('zh'):
+    elif config.language.startswith('zh'):
         return 'xelatex'
     elif config.language == 'el':
         return 'xelatex'
@@ -533,25 +510,25 @@
     app.connect('config-inited', validate_latex_theme_options, priority=800)
     app.connect('builder-inited', install_packages_for_ja)
 
-    app.add_config_value('latex_engine', default_latex_engine, None,
+    app.add_config_value('latex_engine', default_latex_engine, False,
                          ENUM('pdflatex', 'xelatex', 'lualatex', 'platex', 'uplatex'))
-    app.add_config_value('latex_documents', default_latex_documents, None)
-    app.add_config_value('latex_logo', None, None, [str])
-    app.add_config_value('latex_appendices', [], None)
-    app.add_config_value('latex_use_latex_multicolumn', False, None)
-    app.add_config_value('latex_use_xindy', default_latex_use_xindy, None, [bool])
-    app.add_config_value('latex_toplevel_sectioning', None, None,
+    app.add_config_value('latex_documents', default_latex_documents, False)
+    app.add_config_value('latex_logo', None, False, [str])
+    app.add_config_value('latex_appendices', [], False)
+    app.add_config_value('latex_use_latex_multicolumn', False, False)
+    app.add_config_value('latex_use_xindy', default_latex_use_xindy, False, [bool])
+    app.add_config_value('latex_toplevel_sectioning', None, False,
                          ENUM(None, 'part', 'chapter', 'section'))
-    app.add_config_value('latex_domain_indices', True, None, [list])
-    app.add_config_value('latex_show_urls', 'no', None)
-    app.add_config_value('latex_show_pagerefs', False, None)
-    app.add_config_value('latex_elements', {}, None)
-    app.add_config_value('latex_additional_files', [], None)
-    app.add_config_value('latex_theme', 'manual', None, [str])
-    app.add_config_value('latex_theme_options', {}, None)
-    app.add_config_value('latex_theme_path', [], None, [list])
-
-    app.add_config_value('latex_docclass', default_latex_docclass, None)
+    app.add_config_value('latex_domain_indices', True, False, [list])
+    app.add_config_value('latex_show_urls', 'no', False)
+    app.add_config_value('latex_show_pagerefs', False, False)
+    app.add_config_value('latex_elements', {}, False)
+    app.add_config_value('latex_additional_files', [], False)
+    app.add_config_value('latex_theme', 'manual', False, [str])
+    app.add_config_value('latex_theme_options', {}, False)
+    app.add_config_value('latex_theme_path', [], False, [list])
+
+    app.add_config_value('latex_docclass', default_latex_docclass, False)
 
     return {
         'version': 'builtin',
('sphinx/builders/latex', 'nodes.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.builders.latex.nodes
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    Additional nodes for LaTeX writer.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Additional nodes for LaTeX writer."""
 
 from docutils import nodes
 
('sphinx/builders/html', 'transforms.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.builders.html.transforms
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    Transforms for HTML builder.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Transforms for HTML builder."""
 
 import re
 from typing import Any, Dict, List
@@ -36,7 +28,7 @@
                 x
     """
     default_priority = 400
-    builders = ('html',)
+    formats = ('html',)
     pattern = re.compile(r'(?<=.)(-|\+|\^|\s+)(?=.)')
     multiwords_keys = (('caps', 'lock'),
                        ('page' 'down'),
@@ -48,7 +40,9 @@
 
     def run(self, **kwargs: Any) -> None:
         matcher = NodeMatcher(nodes.literal, classes=["kbd"])
-        for node in self.document.traverse(matcher):  # type: nodes.literal
+        # this list must be pre-created as during iteration new nodes
+        # are added which match the condition in the NodeMatcher.
+        for node in list(self.document.findall(matcher)):  # type: nodes.literal
             parts = self.pattern.split(node[-1].astext())
             if len(parts) == 1 or self.is_multiwords_key(parts):
                 continue
('sphinx/builders/html', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,25 +1,19 @@
-"""
-    sphinx.builders.html
-    ~~~~~~~~~~~~~~~~~~~~
-
-    Several HTML builders.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Several HTML builders."""
 
 import html
 import os
 import posixpath
 import re
 import sys
+import warnings
 from datetime import datetime
 from os import path
-from typing import IO, Any, Dict, Iterable, Iterator, List, Set, Tuple, Type
+from typing import IO, Any, Dict, Iterable, Iterator, List, Optional, Set, Tuple, Type
 from urllib.parse import quote
 
+import docutils.readers.doctree
 from docutils import nodes
-from docutils.core import publish_parts
+from docutils.core import Publisher
 from docutils.frontend import OptionParser
 from docutils.io import DocTreeInput, StringOutput
 from docutils.nodes import Node
@@ -30,7 +24,9 @@
 from sphinx.application import Sphinx
 from sphinx.builders import Builder
 from sphinx.config import ENUM, Config
+from sphinx.deprecation import RemovedInSphinx70Warning, deprecated_alias
 from sphinx.domains import Domain, Index, IndexEntry
+from sphinx.environment import BuildEnvironment
 from sphinx.environment.adapters.asset import ImageAdapter
 from sphinx.environment.adapters.indexentries import IndexEntries
 from sphinx.environment.adapters.toctree import TocTree
@@ -40,7 +36,7 @@
 from sphinx.search import js_index
 from sphinx.theming import HTMLThemeFactory
 from sphinx.util import isurl, logging, md5, progress_message, status_iterator
-from sphinx.util.docutils import is_html5_writer_available, new_document
+from sphinx.util.docutils import new_document
 from sphinx.util.fileutil import copy_asset
 from sphinx.util.i18n import format_date
 from sphinx.util.inventory import InventoryFile
@@ -48,19 +44,24 @@
 from sphinx.util.osutil import copyfile, ensuredir, os_path, relative_uri
 from sphinx.util.tags import Tags
 from sphinx.writers.html import HTMLTranslator, HTMLWriter
-
-# HTML5 Writer is available or not
-if is_html5_writer_available():
-    from sphinx.writers.html5 import HTML5Translator
-    html5_ready = True
-else:
-    html5_ready = False
+from sphinx.writers.html5 import HTML5Translator
 
 #: the filename for the inventory of objects
 INVENTORY_FILENAME = 'objects.inv'
 
 logger = logging.getLogger(__name__)
 return_codes_re = re.compile('[\r\n]+')
+
+DOMAIN_INDEX_TYPE = Tuple[
+    # Index name (e.g. py-modindex)
+    str,
+    # Index class
+    Type[Index],
+    # list of (heading string, list of index entries) pairs.
+    List[Tuple[str, List[IndexEntry]]],
+    # whether sub-entries should start collapsed
+    bool
+]
 
 
 def get_stable_hash(obj: Any) -> str:
@@ -74,6 +75,17 @@
     elif isinstance(obj, (list, tuple)):
         obj = sorted(get_stable_hash(o) for o in obj)
     return md5(str(obj).encode()).hexdigest()
+
+
+def convert_locale_to_language_tag(locale: Optional[str]) -> Optional[str]:
+    """Convert a locale string to a language tag (ex. en_US -> en-US).
+
+    refs: BCP 47 (:rfc:`5646`)
+    """
+    if locale:
+        return locale.replace('_', '-')
+    else:
+        return None
 
 
 class Stylesheet(str):
@@ -197,16 +209,32 @@
     download_support = True  # enable download role
 
     imgpath: str = None
-    domain_indices: List[Tuple[str, Type[Index], List[Tuple[str, List[IndexEntry]]], bool]] = []  # NOQA
-
-    def __init__(self, app: Sphinx) -> None:
-        super().__init__(app)
+    domain_indices: List[DOMAIN_INDEX_TYPE] = []
+
+    def __init__(self, app: Sphinx, env: BuildEnvironment = None) -> None:
+        super().__init__(app, env)
 
         # CSS files
         self.css_files: List[Stylesheet] = []
 
         # JS files
         self.script_files: List[JavaScript] = []
+
+        # Cached Publisher for writing doctrees to HTML
+        reader = docutils.readers.doctree.Reader(parser_name='restructuredtext')
+        pub = Publisher(
+            reader=reader,
+            parser=reader.parser,
+            writer=HTMLWriter(self),
+            source_class=DocTreeInput,
+            destination=StringOutput(encoding='unicode'),
+        )
+        if docutils.__version_info__[:2] >= (0, 19):
+            pub.get_settings(output_encoding='unicode', traceback=True)
+        else:
+            op = pub.setup_option_parser(output_encoding='unicode', traceback=True)
+            pub.settings = op.get_default_values()
+        self._publisher = pub
 
     def init(self) -> None:
         self.build_info = self.create_build_info()
@@ -251,13 +279,16 @@
                 return jsfile
         return None
 
-    def _get_style_filename(self) -> str:
-        if self.config.html_style is not None:
-            return self.config.html_style
+    def _get_style_filenames(self) -> Iterator[str]:
+        if isinstance(self.config.html_style, str):
+            yield self.config.html_style
+        elif self.config.html_style is not None:
+            yield from self.config.html_style
         elif self.theme:
-            return self.theme.get_config('theme', 'stylesheet')
-        else:
-            return 'default.css'
+            stylesheet = self.theme.get_config('theme', 'stylesheet')
+            yield from map(str.strip, stylesheet.split(','))
+        else:
+            yield 'default.css'
 
     def get_theme_config(self) -> Tuple[str, Dict]:
         return self.config.html_theme, self.config.html_theme_options
@@ -296,7 +327,9 @@
     def init_css_files(self) -> None:
         self.css_files = []
         self.add_css_file('pygments.css', priority=200)
-        self.add_css_file(self._get_style_filename(), priority=200)
+
+        for filename in self._get_style_filenames():
+            self.add_css_file(filename, priority=200)
 
         for filename, attrs in self.app.registry.css_files:
             self.add_css_file(filename, **attrs)
@@ -315,9 +348,13 @@
         self.script_files = []
         self.add_js_file('documentation_options.js', id="documentation_options",
                          data_url_root='', priority=200)
+        # Remove frameworks and compatability module below in Sphinx 6.0
+        # xref RemovedInSphinx60Warning
         self.add_js_file('jquery.js', priority=200)
         self.add_js_file('underscore.js', priority=200)
+        self.add_js_file('_sphinx_javascript_frameworks_compat.js', priority=200)
         self.add_js_file('doctools.js', priority=200)
+        self.add_js_file('sphinx_highlight.js', priority=200)
 
         for filename, attrs in self.app.registry.js_files:
             self.add_js_file(filename, **attrs)
@@ -326,7 +363,7 @@
             attrs.setdefault('priority', 800)  # User's JSs are loaded after extensions'
             self.add_js_file(filename, **attrs)
 
-        if self.config.language and self._get_translations_js():
+        if self._get_translations_js():
             self.add_js_file('translations.js')
 
     def add_js_file(self, filename: str, **kwargs: Any) -> None:
@@ -337,8 +374,8 @@
 
     @property
     def default_translator_class(self) -> Type[nodes.NodeVisitor]:  # type: ignore
-        if not html5_ready or self.config.html4_writer:
-            return HTMLTranslator
+        if self.config.html4_writer:
+            return HTMLTranslator  # RemovedInSphinx70Warning
         else:
             return HTML5Translator
 
@@ -364,7 +401,7 @@
 
     def get_outdated_docs(self) -> Iterator[str]:
         try:
-            with open(path.join(self.outdir, '.buildinfo')) as fp:
+            with open(path.join(self.outdir, '.buildinfo'), encoding="utf-8") as fp:
                 buildinfo = BuildInfo.load(fp)
 
             if self.build_info != buildinfo:
@@ -411,19 +448,16 @@
     def get_asset_paths(self) -> List[str]:
         return self.config.html_extra_path + self.config.html_static_path
 
-    def render_partial(self, node: Node) -> Dict[str, str]:
+    def render_partial(self, node: Optional[Node]) -> Dict[str, str]:
         """Utility: Render a lone doctree node."""
         if node is None:
             return {'fragment': ''}
+
         doc = new_document('<partial node>')
         doc.append(node)
-
-        writer = HTMLWriter(self)
-        return publish_parts(reader_name='doctree',
-                             writer=writer,
-                             source_class=DocTreeInput,
-                             settings_overrides={'output_encoding': 'unicode'},
-                             source=doc)
+        self._publisher.set_source(doc)
+        self._publisher.publish()
+        return self._publisher.writer.parts
 
     def prepare_writing(self, docnames: Set[str]) -> None:
         # create the search indexer
@@ -431,18 +465,20 @@
         if self.search:
             from sphinx.search import IndexBuilder
             lang = self.config.html_search_language or self.config.language
-            if not lang:
-                lang = 'en'
             self.indexer = IndexBuilder(self.env, lang,
                                         self.config.html_search_options,
                                         self.config.html_search_scorer)
             self.load_indexer(docnames)
 
         self.docwriter = HTMLWriter(self)
-        self.docsettings: Any = OptionParser(
-            defaults=self.env.settings,
-            components=(self.docwriter,),
-            read_config_files=True).get_default_values()
+        with warnings.catch_warnings():
+            warnings.filterwarnings('ignore', category=DeprecationWarning)
+            # DeprecationWarning: The frontend.OptionParser class will be replaced
+            # by a subclass of argparse.ArgumentParser in Docutils 0.21 or later.
+            self.docsettings: Any = OptionParser(
+                defaults=self.env.settings,
+                components=(self.docwriter,),
+                read_config_files=True).get_default_values()
         self.docsettings.compact_lists = bool(self.config.html_compact_lists)
 
         # determine the additional indices to include
@@ -486,7 +522,7 @@
         rellinks: List[Tuple[str, str, str, str]] = []
         if self.use_index:
             rellinks.append(('genindex', _('General Index'), 'I', _('index')))
-        for indexname, indexcls, content, collapse in self.domain_indices:
+        for indexname, indexcls, _content, _collapse in self.domain_indices:
             # if it has a short name
             if indexcls.shortname:
                 rellinks.append((indexname, indexcls.localname,
@@ -495,6 +531,7 @@
         # back up script_files and css_files to allow adding JS/CSS files to a specific page.
         self._script_files = list(self.script_files)
         self._css_files = list(self.css_files)
+        styles = list(self._get_style_filenames())
 
         self.globalcontext = {
             'embedded': self.embedded,
@@ -509,6 +546,7 @@
             'docstitle': self.config.html_title,
             'shorttitle': self.config.html_short_title,
             'show_copyright': self.config.html_show_copyright,
+            'show_search_summary': self.config.html_show_search_summary,
             'show_sphinx': self.config.html_show_sphinx,
             'has_source': self.config.html_copy_source,
             'show_source': self.config.html_show_sourcelink,
@@ -516,17 +554,19 @@
             'file_suffix': self.out_suffix,
             'link_suffix': self.link_suffix,
             'script_files': self.script_files,
-            'language': self.config.language,
+            'language': convert_locale_to_language_tag(self.config.language),
             'css_files': self.css_files,
             'sphinx_version': __display_version__,
             'sphinx_version_tuple': sphinx_version,
-            'style': self._get_style_filename(),
+            'docutils_version_info': docutils.__version_info__[:5],
+            'styles': styles,
+            'style': styles[-1],  # xref RemovedInSphinx70Warning
             'rellinks': rellinks,
             'builder': self.name,
             'parents': [],
             'logo': logo,
             'favicon': favicon,
-            'html5_doctype': html5_ready and not self.config.html4_writer,
+            'html5_doctype': not self.config.html4_writer,
         }
         if self.theme:
             self.globalcontext.update(
@@ -758,19 +798,20 @@
 
     def create_pygments_style_file(self) -> None:
         """create a style file for pygments."""
-        with open(path.join(self.outdir, '_static', 'pygments.css'), 'w') as f:
+        with open(path.join(self.outdir, '_static', 'pygments.css'), 'w',
+                  encoding="utf-8") as f:
             f.write(self.highlighter.get_stylesheet())
 
         if self.dark_highlighter:
-            with open(path.join(self.outdir, '_static', 'pygments_dark.css'), 'w') as f:
+            with open(path.join(self.outdir, '_static', 'pygments_dark.css'), 'w',
+                      encoding="utf-8") as f:
                 f.write(self.dark_highlighter.get_stylesheet())
 
     def copy_translation_js(self) -> None:
         """Copy a JavaScript file for translations."""
-        if self.config.language is not None:
-            jsfile = self._get_translations_js()
-            if jsfile:
-                copyfile(jsfile, path.join(self.outdir, '_static', 'translations.js'))
+        jsfile = self._get_translations_js()
+        if jsfile:
+            copyfile(jsfile, path.join(self.outdir, '_static', 'translations.js'))
 
     def copy_stemmer_js(self) -> None:
         """Copy a JavaScript file for stemmer."""
@@ -783,7 +824,7 @@
                 if jsfile:
                     copyfile(jsfile, path.join(self.outdir, '_static', '_stemmer.js'))
 
-    def copy_theme_static_files(self, context: Dict) -> None:
+    def copy_theme_static_files(self, context: Dict[str, Any]) -> None:
         def onerror(filename: str, error: Exception) -> None:
             logger.warning(__('Failed to copy a file in html_static_file: %s: %r'),
                            filename, error)
@@ -849,7 +890,7 @@
 
     def write_buildinfo(self) -> None:
         try:
-            with open(path.join(self.outdir, '.buildinfo'), 'w') as fp:
+            with open(path.join(self.outdir, '.buildinfo'), 'w', encoding="utf-8") as fp:
                 self.build_info.dump(fp)
         except OSError as exc:
             logger.warning(__('Failed to write build info file: %r'), exc)
@@ -866,7 +907,7 @@
         Builder.post_process_images(self, doctree)
 
         if self.config.html_scaled_image_link and self.html_scaled_image_link:
-            for node in doctree.traverse(nodes.image):
+            for node in doctree.findall(nodes.image):
                 if not any((key in node) for key in ['scale', 'width', 'height']):
                     # resizing options are not given. scaled image link is available
                     # only for resized images.
@@ -983,7 +1024,7 @@
         return quote(docname) + self.link_suffix
 
     def handle_page(self, pagename: str, addctx: Dict, templatename: str = 'page.html',
-                    outfilename: str = None, event_arg: Any = None) -> None:
+                    outfilename: Optional[str] = None, event_arg: Any = None) -> None:
         ctx = self.globalcontext.copy()
         # current_page_name is backwards compatibility
         ctx['pagename'] = ctx['current_page_name'] = pagename
@@ -1038,7 +1079,7 @@
         # sort JS/CSS before rendering HTML
         try:
             # Convert script_files to list to support non-list script_files (refs: #8889)
-            ctx['script_files'] = sorted(list(ctx['script_files']), key=lambda js: js.priority)
+            ctx['script_files'] = sorted(ctx['script_files'], key=lambda js: js.priority)
         except AttributeError:
             # Skip sorting if users modifies script_files directly (maybe via `html_context`).
             # refs: #8885
@@ -1047,7 +1088,7 @@
             pass
 
         try:
-            ctx['css_files'] = sorted(list(ctx['css_files']), key=lambda css: css.priority)
+            ctx['css_files'] = sorted(ctx['css_files'], key=lambda css: css.priority)
         except AttributeError:
             pass
 
@@ -1298,11 +1339,27 @@
         html_add_permalinks
     )
 
+
+def deprecate_html_4(_app: Sphinx, config: Config) -> None:
+    """Warn on HTML 4."""
+    # RemovedInSphinx70Warning
+    if config.html4_writer:
+        logger.warning(_('Support for emitting HTML 4 output is deprecated and '
+                         'will be removed in Sphinx 7. ("html4_writer=True '
+                         'detected in configuration options)'))
+
+
 # for compatibility
 import sphinxcontrib.serializinghtml  # NOQA
 
 import sphinx.builders.dirhtml  # NOQA
 import sphinx.builders.singlehtml  # NOQA
+
+deprecated_alias('sphinx.builders.html',
+                 {
+                     'html5_ready': True,
+                 },
+                 RemovedInSphinx70Warning)
 
 
 def setup(app: Sphinx) -> Dict[str, Any]:
@@ -1317,7 +1374,7 @@
                          lambda self: _('%s %s documentation') % (self.project, self.release),
                          'html', [str])
     app.add_config_value('html_short_title', lambda self: self.html_title, 'html')
-    app.add_config_value('html_style', None, 'html', [str])
+    app.add_config_value('html_style', None, 'html', [list, str])
     app.add_config_value('html_logo', None, 'html', [str])
     app.add_config_value('html_favicon', None, 'html', [str])
     app.add_config_value('html_css_files', [], 'html')
@@ -1340,6 +1397,7 @@
     app.add_config_value('html_file_suffix', None, 'html', [str])
     app.add_config_value('html_link_suffix', None, 'html', [str])
     app.add_config_value('html_show_copyright', True, 'html')
+    app.add_config_value('html_show_search_summary', True, 'html')
     app.add_config_value('html_show_sphinx', True, 'html')
     app.add_config_value('html_context', {}, 'html')
     app.add_config_value('html_output_encoding', 'utf-8', 'html')
@@ -1367,6 +1425,7 @@
     app.connect('config-inited', validate_html_static_path, priority=800)
     app.connect('config-inited', validate_html_logo, priority=800)
     app.connect('config-inited', validate_html_favicon, priority=800)
+    app.connect('config-inited', deprecate_html_4, priority=800)
     app.connect('builder-inited', validate_math_renderer)
     app.connect('html-page-context', setup_css_tag_helper)
     app.connect('html-page-context', setup_js_tag_helper)
('sphinx/ext', 'imgconverter.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.ext.imgconverter
-    ~~~~~~~~~~~~~~~~~~~~~~~
-
-    Image converter extension for Sphinx
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Image converter extension for Sphinx"""
 
 import subprocess
 import sys
@@ -38,9 +30,13 @@
             subprocess.run(args, stdout=PIPE, stderr=PIPE, check=True)
             return True
         except OSError as exc:
-            logger.warning(__('convert command %r cannot be run, '
-                              'check the image_converter setting: %s'),
-                           self.config.image_converter, exc)
+            logger.warning(__(
+                "Unable to run the image conversion command %r. "
+                "'sphinx.ext.imgconverter' requires ImageMagick by default. "
+                "Ensure it is installed, or set the 'image_converter' option "
+                "to a custom conversion command.\n\n"
+                "Traceback: %s"
+            ), self.config.image_converter, exc)
             return False
         except CalledProcessError as exc:
             logger.warning(__('convert exited with error:\n'
('sphinx/ext', 'extlinks.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,31 +1,24 @@
-"""
-    sphinx.ext.extlinks
-    ~~~~~~~~~~~~~~~~~~~
+"""Extension to save typing and prevent hard-coding of base URLs in reST files.
 
-    Extension to save typing and prevent hard-coding of base URLs in the reST
-    files.
+This adds a new config value called ``extlinks`` that is created like this::
 
-    This adds a new config value called ``extlinks`` that is created like this::
+   extlinks = {'exmpl': ('https://example.invalid/%s.html', caption), ...}
 
-       extlinks = {'exmpl': ('https://example.invalid/%s.html', caption), ...}
+Now you can use e.g. :exmpl:`foo` in your documents.  This will create a
+link to ``https://example.invalid/foo.html``.  The link caption depends on
+the *caption* value given:
 
-    Now you can use e.g. :exmpl:`foo` in your documents.  This will create a
-    link to ``https://example.invalid/foo.html``.  The link caption depends on
-    the *caption* value given:
+- If it is ``None``, the caption will be the full URL.
+- If it is a string, it must contain ``%s`` exactly once.  In this case the
+  caption will be *caption* with the role content substituted for ``%s``.
 
-    - If it is ``None``, the caption will be the full URL.
-    - If it is a string, it must contain ``%s`` exactly once.  In this case the
-      caption will be *caption* with the role content substituted for ``%s``.
+You can also give an explicit caption, e.g. :exmpl:`Foo <foo>`.
 
-    You can also give an explicit caption, e.g. :exmpl:`Foo <foo>`.
-
-    Both, the url string and the caption string must escape ``%`` as ``%%``.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
+Both, the url string and the caption string must escape ``%`` as ``%%``.
 """
 
-import warnings
+import re
+import sys
 from typing import Any, Dict, List, Tuple
 
 from docutils import nodes, utils
@@ -34,9 +27,61 @@
 
 import sphinx
 from sphinx.application import Sphinx
-from sphinx.deprecation import RemovedInSphinx60Warning
+from sphinx.locale import __
+from sphinx.transforms.post_transforms import SphinxPostTransform
+from sphinx.util import logging, rst
 from sphinx.util.nodes import split_explicit_title
 from sphinx.util.typing import RoleFunction
+
+logger = logging.getLogger(__name__)
+
+
+class ExternalLinksChecker(SphinxPostTransform):
+    """
+    For each external link, check if it can be replaced by an extlink.
+
+    We treat each ``reference`` node without ``internal`` attribute as an external link.
+    """
+
+    default_priority = 500
+
+    def run(self, **kwargs: Any) -> None:
+        if not self.config.extlinks_detect_hardcoded_links:
+            return
+
+        for refnode in self.document.findall(nodes.reference):
+            self.check_uri(refnode)
+
+    def check_uri(self, refnode: nodes.reference) -> None:
+        """
+        If the URI in ``refnode`` has a replacement in ``extlinks``,
+        emit a warning with a replacement suggestion.
+        """
+        if 'internal' in refnode or 'refuri' not in refnode:
+            return
+
+        uri = refnode['refuri']
+        title = refnode.astext()
+
+        for alias, (base_uri, _caption) in self.app.config.extlinks.items():
+            if sys.version_info < (3, 7):
+                # Replace a leading backslash because re.escape() inserts a backslash before %
+                # on python 3.6
+                uri_pattern = re.compile(re.escape(base_uri).replace('\\%s', '(?P<value>.+)'))
+            else:
+                uri_pattern = re.compile(re.escape(base_uri).replace('%s', '(?P<value>.+)'))
+
+            match = uri_pattern.match(uri)
+            if match and match.groupdict().get('value'):
+                # build a replacement suggestion
+                msg = __('hardcoded link %r could be replaced by an extlink '
+                         '(try using %r instead)')
+                value = match.groupdict().get('value')
+                if uri != title:
+                    replacement = f":{alias}:`{rst.escape(title)} <{value}>`"
+                else:
+                    replacement = f":{alias}:`{value}`"
+                logger.warning(msg, uri, replacement, location=refnode)
 
 
 def make_link_role(name: str, base_url: str, caption: str) -> RoleFunction:
@@ -48,17 +93,17 @@
     try:
         base_url % 'dummy'
     except (TypeError, ValueError):
-        warnings.warn('extlinks: Sphinx-6.0 will require base URL to '
-                      'contain exactly one \'%s\' and all other \'%\' need '
-                      'to be escaped as \'%%\'.', RemovedInSphinx60Warning)
+        logger.warning(__('extlinks: Sphinx-6.0 will require base URL to '
+                          'contain exactly one \'%s\' and all other \'%\' need '
+                          'to be escaped as \'%%\'.'))  # RemovedInSphinx60Warning
         base_url = base_url.replace('%', '%%') + '%s'
     if caption is not None:
         try:
             caption % 'dummy'
         except (TypeError, ValueError):
-            warnings.warn('extlinks: Sphinx-6.0 will require a caption string to '
-                          'contain exactly one \'%s\' and all other \'%\' need '
-                          'to be escaped as \'%%\'.', RemovedInSphinx60Warning)
+            logger.warning(__('extlinks: Sphinx-6.0 will require a caption string to '
+                              'contain exactly one \'%s\' and all other \'%\' need '
+                              'to be escaped as \'%%\'.'))  # RemovedInSphinx60Warning
             caption = caption.replace('%', '%%') + '%s'
 
     def role(typ: str, rawtext: str, text: str, lineno: int,
@@ -84,5 +129,8 @@
 
 def setup(app: Sphinx) -> Dict[str, Any]:
     app.add_config_value('extlinks', {}, 'env')
+    app.add_config_value('extlinks_detect_hardcoded_links', False, 'env')
+
     app.connect('builder-inited', setup_link_roles)
+    app.add_post_transform(ExternalLinksChecker)
     return {'version': sphinx.__display_version__, 'parallel_read_safe': True}
('sphinx/ext', 'apidoc.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,17 +1,12 @@
-"""
-    sphinx.ext.apidoc
-    ~~~~~~~~~~~~~~~~~
-
-    Parses a directory tree looking for Python modules and packages and creates
-    ReST files appropriately to create code documentation with Sphinx.  It also
-    creates a modules index (named modules.<suffix>).
-
-    This is derived from the "sphinx-autopackage" script, which is:
-    Copyright 2008 Socit des arts technologiques (SAT),
-    https://sat.qc.ca/
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
+"""Creates reST files corresponding to Python modules for code documentation.
+
+Parses a directory tree looking for Python modules and packages and creates
+ReST files appropriately to create code documentation with Sphinx.  It also
+creates a modules index (named modules.<suffix>).
+
+This is derived from the "sphinx-autopackage" script, which is:
+Copyright 2008 Socit des arts technologiques (SAT),
+https://sat.qc.ca/
 """
 
 import argparse
@@ -23,7 +18,7 @@
 from fnmatch import fnmatch
 from importlib.machinery import EXTENSION_SUFFIXES
 from os import path
-from typing import Any, Generator, List, Tuple
+from typing import Any, Generator, List, Optional, Tuple
 
 import sphinx.locale
 from sphinx import __display_version__, package_dir
@@ -63,7 +58,7 @@
     return '.'.join(filter(None, modnames))
 
 
-def is_packagedir(dirname: str = None, files: List[str] = None) -> bool:
+def is_packagedir(dirname: Optional[str] = None, files: Optional[List[str]] = None) -> bool:
     """Check given *files* contains __init__ file."""
     if files is None and dirname is None:
         return False
@@ -93,7 +88,7 @@
 
 
 def create_module_file(package: str, basename: str, opts: Any,
-                       user_template_dir: str = None) -> None:
+                       user_template_dir: Optional[str] = None) -> None:
     """Build the text of the file and write the file."""
     options = copy(OPTIONS)
     if opts.includeprivate and 'private-members' not in options:
@@ -112,7 +107,8 @@
 
 def create_package_file(root: str, master_package: str, subroot: str, py_files: List[str],
                         opts: Any, subs: List[str], is_namespace: bool,
-                        excludes: List[str] = [], user_template_dir: str = None) -> None:
+                        excludes: List[str] = [], user_template_dir: Optional[str] = None
+                        ) -> None:
     """Build the text of the file and write the file."""
     # build a list of sub packages (directories containing an __init__ file)
     subpackages = [module_join(master_package, subroot, pkgname)
@@ -122,6 +118,7 @@
     submodules = [sub.split('.')[0] for sub in py_files
                   if not is_skipped_module(path.join(root, sub), opts, excludes) and
                   not is_initpy(sub)]
+    submodules = sorted(set(submodules))
     submodules = [module_join(master_package, subroot, modname)
                   for modname in submodules]
     options = copy(OPTIONS)
@@ -149,7 +146,7 @@
 
 
 def create_modules_toc_file(modules: List[str], opts: Any, name: str = 'modules',
-                            user_template_dir: str = None) -> None:
+                            user_template_dir: Optional[str] = None) -> None:
     """Create the module's index."""
     modules.sort()
     prev_module = ''
@@ -227,7 +224,7 @@
 
 def has_child_module(rootpath: str, excludes: List[str], opts: Any) -> bool:
     """Check the given directory contains child module/s (at least one)."""
-    for root, subs, files in walk(rootpath, excludes, opts):
+    for _root, _subs, files in walk(rootpath, excludes, opts):
         if files:
             return True
 
@@ -235,7 +232,7 @@
 
 
 def recurse_tree(rootpath: str, excludes: List[str], opts: Any,
-                 user_template_dir: str = None) -> List[str]:
+                 user_template_dir: Optional[str] = None) -> List[str]:
     """
     Look for every file in the directory tree and create the corresponding
     ReST files.
('sphinx/ext', 'mathjax.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,13 +1,8 @@
-"""
-    sphinx.ext.mathjax
-    ~~~~~~~~~~~~~~~~~~
+"""Allow `MathJax`_ to be used to display math in Sphinx's HTML writer.
 
-    Allow `MathJax <https://www.mathjax.org/>`_ to be used to display math in
-    Sphinx's HTML writer -- requires the MathJax JavaScript library on your
-    webserver/computer.
+This requires the MathJax JavaScript library on your webserver/computer.
 
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
+.. _MathJax: https://www.mathjax.org/
 """
 
 import json
@@ -70,7 +65,7 @@
     raise nodes.SkipNode
 
 
-def install_mathjax(app: Sphinx, pagename: str, templatename: str, context: Dict,
+def install_mathjax(app: Sphinx, pagename: str, templatename: str, context: Dict[str, Any],
                     event_arg: Any) -> None:
     if app.builder.format != 'html' or app.builder.math_renderer_name != 'mathjax':  # type: ignore  # NOQA
         return
@@ -81,11 +76,6 @@
     domain = cast(MathDomain, app.env.get_domain('math'))
     if app.registry.html_assets_policy == 'always' or domain.has_equations(pagename):
         # Enable mathjax only if equations exists
-        options = {'async': 'async'}
-        if app.config.mathjax_options:
-            options.update(app.config.mathjax_options)
-        app.add_js_file(app.config.mathjax_path, **options)  # type: ignore
-
         if app.config.mathjax2_config:
             if app.config.mathjax_path == MATHJAX_URL:
                 logger.warning(
@@ -96,6 +86,18 @@
         if app.config.mathjax3_config:
             body = 'window.MathJax = %s' % json.dumps(app.config.mathjax3_config)
             app.add_js_file(None, body=body)
+
+        options = {}
+        if app.config.mathjax_options:
+            options.update(app.config.mathjax_options)
+        if 'async' not in options and 'defer' not in options:
+            if app.config.mathjax3_config:
+                # Load MathJax v3 via "defer" method
+                options['defer'] = 'defer'
+            else:
+                # Load other MathJax via "async" method
+                options['async'] = 'async'
+        app.add_js_file(app.config.mathjax_path, **options)
 
 
 def setup(app: Sphinx) -> Dict[str, Any]:
('sphinx/ext', 'graphviz.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.ext.graphviz
-    ~~~~~~~~~~~~~~~~~~~
-
-    Allow graphviz-formatted graphs to be included in Sphinx-generated
-    documents inline.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
+"""Allow graphviz-formatted graphs to be included inline in generated documents.
 """
 
 import posixpath
@@ -14,7 +6,7 @@
 import subprocess
 from os import path
 from subprocess import PIPE, CalledProcessError
-from typing import Any, Dict, List, Tuple
+from typing import Any, Dict, List, Optional, Tuple
 
 from docutils import nodes
 from docutils.nodes import Node
@@ -50,14 +42,14 @@
     href_re = re.compile('href=".*?"')
 
     def __init__(self, filename: str, content: str, dot: str = '') -> None:
-        self.id: str = None
+        self.id: Optional[str] = None
         self.filename = filename
         self.content = content.splitlines()
         self.clickable: List[str] = []
 
         self.parse(dot=dot)
 
-    def parse(self, dot: str = None) -> None:
+    def parse(self, dot: str) -> None:
         matched = self.maptag_re.match(self.content[0])
         if not matched:
             raise GraphvizError('Invalid clickable map file found: %s' % self.filename)
@@ -218,7 +210,8 @@
 
 
 def render_dot(self: SphinxTranslator, code: str, options: Dict, format: str,
-               prefix: str = 'graphviz', filename: str = None) -> Tuple[str, str]:
+               prefix: str = 'graphviz', filename: Optional[str] = None
+               ) -> Tuple[Optional[str], Optional[str]]:
     """Render graphviz code into a PNG or PDF output file."""
     graphviz_dot = options.get('graphviz_dot', self.builder.config.graphviz_dot)
     hashkey = (code + str(options) + str(graphviz_dot) +
@@ -232,7 +225,7 @@
         return relfn, outfn
 
     if (hasattr(self.builder, '_graphviz_warned_dot') and
-       self.builder._graphviz_warned_dot.get(graphviz_dot)):  # type: ignore  # NOQA
+       self.builder._graphviz_warned_dot.get(graphviz_dot)):  # type: ignore[attr-defined]
         return None, None
 
     ensuredir(path.dirname(outfn))
@@ -270,8 +263,9 @@
 
 
 def render_dot_html(self: HTMLTranslator, node: graphviz, code: str, options: Dict,
-                    prefix: str = 'graphviz', imgcls: str = None, alt: str = None,
-                    filename: str = None) -> Tuple[str, str]:
+                    prefix: str = 'graphviz', imgcls: Optional[str] = None,
+                    alt: Optional[str] = None, filename: Optional[str] = None
+                    ) -> Tuple[str, str]:
     format = self.builder.config.graphviz_output_format
     try:
         if format not in ('png', 'svg'):
@@ -326,7 +320,7 @@
 
 
 def render_dot_latex(self: LaTeXTranslator, node: graphviz, code: str,
-                     options: Dict, prefix: str = 'graphviz', filename: str = None
+                     options: Dict, prefix: str = 'graphviz', filename: Optional[str] = None
                      ) -> None:
     try:
         fname, outfn = render_dot(self, code, options, 'pdf', prefix, filename)
('sphinx/ext', 'intersphinx.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,51 +1,50 @@
-"""
-    sphinx.ext.intersphinx
-    ~~~~~~~~~~~~~~~~~~~~~~
-
-    Insert links to objects documented in remote Sphinx documentation.
-
-    This works as follows:
-
-    * Each Sphinx HTML build creates a file named "objects.inv" that contains a
-      mapping from object names to URIs relative to the HTML set's root.
-
-    * Projects using the Intersphinx extension can specify links to such mapping
-      files in the `intersphinx_mapping` config value.  The mapping will then be
-      used to resolve otherwise missing references to objects into links to the
-      other documentation.
-
-    * By default, the mapping file is assumed to be at the same location as the
-      rest of the documentation; however, the location of the mapping file can
-      also be specified individually, e.g. if the docs should be buildable
-      without Internet access.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
+"""Insert links to objects documented in remote Sphinx documentation.
+
+This works as follows:
+
+* Each Sphinx HTML build creates a file named "objects.inv" that contains a
+  mapping from object names to URIs relative to the HTML set's root.
+
+* Projects using the Intersphinx extension can specify links to such mapping
+  files in the `intersphinx_mapping` config value.  The mapping will then be
+  used to resolve otherwise missing references to objects into links to the
+  other documentation.
+
+* By default, the mapping file is assumed to be at the same location as the
+  rest of the documentation; however, the location of the mapping file can
+  also be specified individually, e.g. if the docs should be buildable
+  without Internet access.
 """
 
 import concurrent.futures
 import functools
 import posixpath
+import re
 import sys
 import time
 from os import path
-from typing import IO, Any, Dict, List, Tuple
+from types import ModuleType
+from typing import IO, Any, Dict, List, Optional, Tuple, cast
 from urllib.parse import urlsplit, urlunsplit
 
 from docutils import nodes
-from docutils.nodes import TextElement
-from docutils.utils import relative_path
+from docutils.nodes import Element, Node, TextElement, system_message
+from docutils.utils import Reporter, relative_path
 
 import sphinx
 from sphinx.addnodes import pending_xref
 from sphinx.application import Sphinx
 from sphinx.builders.html import INVENTORY_FILENAME
 from sphinx.config import Config
+from sphinx.domains import Domain
 from sphinx.environment import BuildEnvironment
+from sphinx.errors import ExtensionError
 from sphinx.locale import _, __
+from sphinx.transforms.post_transforms import ReferencesResolver
 from sphinx.util import logging, requests
+from sphinx.util.docutils import CustomReSTDispatcher, SphinxRole
 from sphinx.util.inventory import InventoryFile
-from sphinx.util.typing import Inventory
+from sphinx.util.typing import Inventory, InventoryItem, RoleFunction
 
 logger = logging.getLogger(__name__)
 
@@ -99,7 +98,7 @@
     return urlunsplit(frags)
 
 
-def _read_from_url(url: str, config: Config = None) -> IO:
+def _read_from_url(url: str, config: Optional[Config] = None) -> IO:
     """Reads data from *url* with an HTTP *GET*.
 
     This function supports fetching from resources which use basic HTTP auth as
@@ -258,105 +257,349 @@
                 inventories.main_inventory.setdefault(type, {}).update(objects)
 
 
-def missing_reference(app: Sphinx, env: BuildEnvironment, node: pending_xref,
-                      contnode: TextElement) -> nodes.reference:
-    """Attempt to resolve a missing reference via intersphinx references."""
-    target = node['reftarget']
-    inventories = InventoryAdapter(env)
-    objtypes: List[str] = None
-    if node['reftype'] == 'any':
-        # we search anything!
-        objtypes = ['%s:%s' % (domain.name, objtype)
-                    for domain in env.domains.values()
-                    for objtype in domain.object_types]
-        domain = None
+def _create_element_from_result(domain: Domain, inv_name: Optional[str],
+                                data: InventoryItem,
+                                node: pending_xref, contnode: TextElement) -> Element:
+    proj, version, uri, dispname = data
+    if '://' not in uri and node.get('refdoc'):
+        # get correct path in case of subdirectories
+        uri = path.join(relative_path(node['refdoc'], '.'), uri)
+    if version:
+        reftitle = _('(in %s v%s)') % (proj, version)
     else:
-        domain = node.get('refdomain')
-        if not domain:
+        reftitle = _('(in %s)') % (proj,)
+    newnode = nodes.reference('', '', internal=False, refuri=uri, reftitle=reftitle)
+    if node.get('refexplicit'):
+        # use whatever title was given
+        newnode.append(contnode)
+    elif dispname == '-' or \
+            (domain.name == 'std' and node['reftype'] == 'keyword'):
+        # use whatever title was given, but strip prefix
+        title = contnode.astext()
+        if inv_name is not None and title.startswith(inv_name + ':'):
+            newnode.append(contnode.__class__(title[len(inv_name) + 1:],
+                                              title[len(inv_name) + 1:]))
+        else:
+            newnode.append(contnode)
+    else:
+        # else use the given display name (used for :ref:)
+        newnode.append(contnode.__class__(dispname, dispname))
+    return newnode
+
+
+def _resolve_reference_in_domain_by_target(
+        inv_name: Optional[str], inventory: Inventory,
+        domain: Domain, objtypes: List[str],
+        target: str,
+        node: pending_xref, contnode: TextElement) -> Optional[Element]:
+    for objtype in objtypes:
+        if objtype not in inventory:
+            # Continue if there's nothing of this kind in the inventory
+            continue
+
+        if target in inventory[objtype]:
+            # Case sensitive match, use it
+            data = inventory[objtype][target]
+        elif objtype == 'std:term':
+            # Check for potential case insensitive matches for terms only
+            target_lower = target.lower()
+            insensitive_matches = list(filter(lambda k: k.lower() == target_lower,
+                                              inventory[objtype].keys()))
+            if insensitive_matches:
+                data = inventory[objtype][insensitive_matches[0]]
+            else:
+                # No case insensitive match either, continue to the next candidate
+                continue
+        else:
+            # Could reach here if we're not a term but have a case insensitive match.
+            # This is a fix for terms specifically, but potentially should apply to
+            # other types.
+            continue
+        return _create_element_from_result(domain, inv_name, data, node, contnode)
+    return None
+
+
+def _resolve_reference_in_domain(env: BuildEnvironment,
+                                 inv_name: Optional[str], inventory: Inventory,
+                                 honor_disabled_refs: bool,
+                                 domain: Domain, objtypes: List[str],
+                                 node: pending_xref, contnode: TextElement
+                                 ) -> Optional[Element]:
+    # we adjust the object types for backwards compatibility
+    if domain.name == 'std' and 'cmdoption' in objtypes:
+        # until Sphinx-1.6, cmdoptions are stored as std:option
+        objtypes.append('option')
+    if domain.name == 'py' and 'attribute' in objtypes:
+        # Since Sphinx-2.1, properties are stored as py:method
+        objtypes.append('method')
+
+    # the inventory contains domain:type as objtype
+    objtypes = ["{}:{}".format(domain.name, t) for t in objtypes]
+
+    # now that the objtypes list is complete we can remove the disabled ones
+    if honor_disabled_refs:
+        disabled = env.config.intersphinx_disabled_reftypes
+        objtypes = [o for o in objtypes if o not in disabled]
+
+    # without qualification
+    res = _resolve_reference_in_domain_by_target(inv_name, inventory, domain, objtypes,
+                                                 node['reftarget'], node, contnode)
+    if res is not None:
+        return res
+
+    # try with qualification of the current scope instead
+    full_qualified_name = domain.get_full_qualified_name(node)
+    if full_qualified_name is None:
+        return None
+    return _resolve_reference_in_domain_by_target(inv_name, inventory, domain, objtypes,
+                                                  full_qualified_name, node, contnode)
+
+
+def _resolve_reference(env: BuildEnvironment, inv_name: Optional[str], inventory: Inventory,
+                       honor_disabled_refs: bool,
+                       node: pending_xref, contnode: TextElement) -> Optional[Element]:
+    # disabling should only be done if no inventory is given
+    honor_disabled_refs = honor_disabled_refs and inv_name is None
+
+    if honor_disabled_refs and '*' in env.config.intersphinx_disabled_reftypes:
+        return None
+
+    typ = node['reftype']
+    if typ == 'any':
+        for domain_name, domain in env.domains.items():
+            if honor_disabled_refs \
+                    and (domain_name + ":*") in env.config.intersphinx_disabled_reftypes:
+                continue
+            objtypes = list(domain.object_types)
+            res = _resolve_reference_in_domain(env, inv_name, inventory,
+                                               honor_disabled_refs,
+                                               domain, objtypes,
+                                               node, contnode)
+            if res is not None:
+                return res
+        return None
+    else:
+        domain_name = node.get('refdomain')
+        if not domain_name:
             # only objects in domains are in the inventory
             return None
-        objtypes = env.get_domain(domain).objtypes_for_role(node['reftype'])
+        if honor_disabled_refs \
+                and (domain_name + ":*") in env.config.intersphinx_disabled_reftypes:
+            return None
+        domain = env.get_domain(domain_name)
+        objtypes = domain.objtypes_for_role(typ)
         if not objtypes:
             return None
-        objtypes = ['%s:%s' % (domain, objtype) for objtype in objtypes]
-    if 'std:cmdoption' in objtypes:
-        # until Sphinx-1.6, cmdoptions are stored as std:option
-        objtypes.append('std:option')
-    if 'py:attribute' in objtypes:
-        # Since Sphinx-2.1, properties are stored as py:method
-        objtypes.append('py:method')
-
-    to_try = [(inventories.main_inventory, target)]
-    if domain:
-        full_qualified_name = env.get_domain(domain).get_full_qualified_name(node)
-        if full_qualified_name:
-            to_try.append((inventories.main_inventory, full_qualified_name))
-    in_set = None
-    if ':' in target:
-        # first part may be the foreign doc set name
-        setname, newtarget = target.split(':', 1)
-        if setname in inventories.named_inventory:
-            in_set = setname
-            to_try.append((inventories.named_inventory[setname], newtarget))
-            if domain:
-                node['reftarget'] = newtarget
-                full_qualified_name = env.get_domain(domain).get_full_qualified_name(node)
-                if full_qualified_name:
-                    to_try.append((inventories.named_inventory[setname], full_qualified_name))
-    for inventory, target in to_try:
-        for objtype in objtypes:
-            if objtype not in inventory:
-                # Continue if there's nothing of this kind in the inventory
+        return _resolve_reference_in_domain(env, inv_name, inventory,
+                                            honor_disabled_refs,
+                                            domain, objtypes,
+                                            node, contnode)
+
+
+def inventory_exists(env: BuildEnvironment, inv_name: str) -> bool:
+    return inv_name in InventoryAdapter(env).named_inventory
+
+
+def resolve_reference_in_inventory(env: BuildEnvironment,
+                                   inv_name: str,
+                                   node: pending_xref, contnode: TextElement
+                                   ) -> Optional[Element]:
+    """Attempt to resolve a missing reference via intersphinx references.
+
+    Resolution is tried in the given inventory with the target as is.
+
+    Requires ``inventory_exists(env, inv_name)``.
+    """
+    assert inventory_exists(env, inv_name)
+    return _resolve_reference(env, inv_name, InventoryAdapter(env).named_inventory[inv_name],
+                              False, node, contnode)
+
+
+def resolve_reference_any_inventory(env: BuildEnvironment,
+                                    honor_disabled_refs: bool,
+                                    node: pending_xref, contnode: TextElement
+                                    ) -> Optional[Element]:
+    """Attempt to resolve a missing reference via intersphinx references.
+
+    Resolution is tried with the target as is in any inventory.
+    """
+    return _resolve_reference(env, None, InventoryAdapter(env).main_inventory,
+                              honor_disabled_refs,
+                              node, contnode)
+
+
+def resolve_reference_detect_inventory(env: BuildEnvironment,
+                                       node: pending_xref, contnode: TextElement
+                                       ) -> Optional[Element]:
+    """Attempt to resolve a missing reference via intersphinx references.
+
+    Resolution is tried first with the target as is in any inventory.
+    If this does not succeed, then the target is split by the first ``:``,
+    to form ``inv_name:newtarget``. If ``inv_name`` is a named inventory, then resolution
+    is tried in that inventory with the new target.
+    """
+
+    # ordinary direct lookup, use data as is
+    res = resolve_reference_any_inventory(env, True, node, contnode)
+    if res is not None:
+        return res
+
+    # try splitting the target into 'inv_name:target'
+    target = node['reftarget']
+    if ':' not in target:
+        return None
+    inv_name, newtarget = target.split(':', 1)
+    if not inventory_exists(env, inv_name):
+        return None
+    node['reftarget'] = newtarget
+    res_inv = resolve_reference_in_inventory(env, inv_name, node, contnode)
+    node['reftarget'] = target
+    return res_inv
+
+
+def missing_reference(app: Sphinx, env: BuildEnvironment, node: pending_xref,
+                      contnode: TextElement) -> Optional[Element]:
+    """Attempt to resolve a missing reference via intersphinx references."""
+
+    return resolve_reference_detect_inventory(env, node, contnode)
+
+
+class IntersphinxDispatcher(CustomReSTDispatcher):
+    """Custom dispatcher for external role.
+
+    This enables :external:***:/:external+***: roles on parsing reST document.
+    """
+
+    def role(self, role_name: str, language_module: ModuleType, lineno: int, reporter: Reporter
+             ) -> Tuple[RoleFunction, List[system_message]]:
+        if len(role_name) > 9 and role_name.startswith(('external:', 'external+')):
+            return IntersphinxRole(role_name), []
+        else:
+            return super().role(role_name, language_module, lineno, reporter)
+
+
+class IntersphinxRole(SphinxRole):
+    # group 1: just for the optionality of the inventory name
+    # group 2: the inventory name (optional)
+    # group 3: the domain:role or role part
+    _re_inv_ref = re.compile(r"(\+([^:]+))?:(.*)")
+
+    def __init__(self, orig_name: str) -> None:
+        self.orig_name = orig_name
+
+    def run(self) -> Tuple[List[Node], List[system_message]]:
+        assert self.name == self.orig_name.lower()
+        inventory, name_suffix = self.get_inventory_and_name_suffix(self.orig_name)
+        if inventory and not inventory_exists(self.env, inventory):
+            logger.warning(__('inventory for external cross-reference not found: %s'),
+                           inventory, location=(self.env.docname, self.lineno))
+            return [], []
+
+        role_name = self.get_role_name(name_suffix)
+        if role_name is None:
+            logger.warning(__('role for external cross-reference not found: %s'), name_suffix,
+                           location=(self.env.docname, self.lineno))
+            return [], []
+
+        result, messages = self.invoke_role(role_name)
+        for node in result:
+            if isinstance(node, pending_xref):
+                node['intersphinx'] = True
+                node['inventory'] = inventory
+
+        return result, messages
+
+    def get_inventory_and_name_suffix(self, name: str) -> Tuple[Optional[str], str]:
+        assert name.startswith('external'), name
+        assert name[8] in ':+', name
+        # either we have an explicit inventory name, i.e,
+        # :external+inv:role:        or
+        # :external+inv:domain:role:
+        # or we look in all inventories, i.e.,
+        # :external:role:            or
+        # :external:domain:role:
+        inv, suffix = IntersphinxRole._re_inv_ref.fullmatch(name, 8).group(2, 3)
+        return inv, suffix
+
+    def get_role_name(self, name: str) -> Optional[Tuple[str, str]]:
+        names = name.split(':')
+        if len(names) == 1:
+            # role
+            default_domain = self.env.temp_data.get('default_domain')
+            domain = default_domain.name if default_domain else None
+            role = names[0]
+        elif len(names) == 2:
+            # domain:role:
+            domain = names[0]
+            role = names[1]
+        else:
+            return None
+
+        if domain and self.is_existent_role(domain, role):
+            return (domain, role)
+        elif self.is_existent_role('std', role):
+            return ('std', role)
+        else:
+            return None
+
+    def is_existent_role(self, domain_name: str, role_name: str) -> bool:
+        try:
+            domain = self.env.get_domain(domain_name)
+            if role_name in domain.roles:
+                return True
+            else:
+                return False
+        except ExtensionError:
+            return False
+
+    def invoke_role(self, role: Tuple[str, str]) -> Tuple[List[Node], List[system_message]]:
+        domain = self.env.get_domain(role[0])
+        if domain:
+            role_func = domain.role(role[1])
+
+            return role_func(':'.join(role), self.rawtext, self.text, self.lineno,
+                             self.inliner, self.options, self.content)
+        else:
+            return [], []
+
+
+class IntersphinxRoleResolver(ReferencesResolver):
+    """pending_xref node resolver for intersphinx role.
+
+    This resolves pending_xref nodes generated by :intersphinx:***: role.
+    """
+
+    default_priority = ReferencesResolver.default_priority - 1
+
+    def run(self, **kwargs: Any) -> None:
+        for node in self.document.findall(pending_xref):
+            if 'intersphinx' not in node:
                 continue
-            if target in inventory[objtype]:
-                # Case sensitive match, use it
-                proj, version, uri, dispname = inventory[objtype][target]
-            elif objtype == 'std:term':
-                # Check for potential case insensitive matches for terms only
-                target_lower = target.lower()
-                insensitive_matches = list(filter(lambda k: k.lower() == target_lower,
-                                                  inventory[objtype].keys()))
-                if insensitive_matches:
-                    proj, version, uri, dispname = inventory[objtype][insensitive_matches[0]]
-                else:
-                    # No case insensitive match either, continue to the next candidate
-                    continue
+            contnode = cast(nodes.TextElement, node[0].deepcopy())
+            inv_name = node['inventory']
+            if inv_name is not None:
+                assert inventory_exists(self.env, inv_name)
+                newnode = resolve_reference_in_inventory(self.env, inv_name, node, contnode)
             else:
-                # Could reach here if we're not a term but have a case insensitive match.
-                # This is a fix for terms specifically, but potentially should apply to
-                # other types.
-                continue
-
-            if '://' not in uri and node.get('refdoc'):
-                # get correct path in case of subdirectories
-                uri = path.join(relative_path(node['refdoc'], '.'), uri)
-            if version:
-                reftitle = _('(in %s v%s)') % (proj, version)
+                newnode = resolve_reference_any_inventory(self.env, False, node, contnode)
+            if newnode is None:
+                typ = node['reftype']
+                msg = (__('external %s:%s reference target not found: %s') %
+                       (node['refdomain'], typ, node['reftarget']))
+                logger.warning(msg, location=node, type='ref', subtype=typ)
+                node.replace_self(contnode)
             else:
-                reftitle = _('(in %s)') % (proj,)
-            newnode = nodes.reference('', '', internal=False, refuri=uri, reftitle=reftitle)
-            if node.get('refexplicit'):
-                # use whatever title was given
-                newnode.append(contnode)
-            elif dispname == '-' or \
-                    (domain == 'std' and node['reftype'] == 'keyword'):
-                # use whatever title was given, but strip prefix
-                title = contnode.astext()
-                if in_set and title.startswith(in_set + ':'):
-                    newnode.append(contnode.__class__(title[len(in_set) + 1:],
-                                                      title[len(in_set) + 1:]))
-                else:
-                    newnode.append(contnode)
-            else:
-                # else use the given display name (used for :ref:)
-                newnode.append(contnode.__class__(dispname, dispname))
-            return newnode
-    # at least get rid of the ':' in the target if no explicit title given
-    if in_set is not None and not node.get('refexplicit', True):
-        if len(contnode) and isinstance(contnode[0], nodes.Text):
-            contnode[0] = nodes.Text(newtarget, contnode[0].rawsource)
-
-    return None
+                node.replace_self(newnode)
+
+
+def install_dispatcher(app: Sphinx, docname: str, source: List[str]) -> None:
+    """Enable IntersphinxDispatcher.
+
+    .. note:: The installed dispatcher will be uninstalled on disabling sphinx_domain
+              automatically.
+    """
+    dispatcher = IntersphinxDispatcher()
+    dispatcher.enable()
 
 
 def normalize_intersphinx_mapping(app: Sphinx, config: Config) -> None:
@@ -387,9 +630,12 @@
     app.add_config_value('intersphinx_mapping', {}, True)
     app.add_config_value('intersphinx_cache_limit', 5, False)
     app.add_config_value('intersphinx_timeout', None, False)
+    app.add_config_value('intersphinx_disabled_reftypes', ['std:doc'], True)
     app.connect('config-inited', normalize_intersphinx_mapping, priority=800)
     app.connect('builder-inited', load_mappings)
+    app.connect('source-read', install_dispatcher)
     app.connect('missing-reference', missing_reference)
+    app.add_post_transform(IntersphinxRoleResolver)
     return {
         'version': sphinx.__display_version__,
         'env_version': 1,
@@ -406,7 +652,7 @@
         sys.exit(1)
 
     class MockConfig:
-        intersphinx_timeout: int = None
+        intersphinx_timeout: Optional[int] = None
         tls_verify = False
         user_agent = None
 
('sphinx/ext', 'githubpages.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.ext.githubpages
-    ~~~~~~~~~~~~~~~~~~~~~~
-
-    To publish HTML docs at GitHub Pages, create .nojekyll file.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""To publish HTML docs at GitHub Pages, create .nojekyll file."""
 
 import os
 import urllib
@@ -19,13 +11,14 @@
 
 def create_nojekyll_and_cname(app: Sphinx, env: BuildEnvironment) -> None:
     if app.builder.format == 'html':
-        open(os.path.join(app.builder.outdir, '.nojekyll'), 'wt').close()
+        open(os.path.join(app.builder.outdir, '.nojekyll'), 'wb').close()
 
         html_baseurl = app.config.html_baseurl
         if html_baseurl:
             domain = urllib.parse.urlparse(html_baseurl).hostname
             if domain and not domain.endswith(".github.io"):
-                with open(os.path.join(app.builder.outdir, 'CNAME'), 'wt') as f:
+                with open(os.path.join(app.builder.outdir, 'CNAME'), 'w',
+                          encoding="utf-8") as f:
                     # NOTE: don't write a trailing newline. The `CNAME` file that's
                     # auto-generated by the Github UI doesn't have one.
                     f.write(domain)
('sphinx/ext', 'duration.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.ext.duration
-    ~~~~~~~~~~~~~~~~~~~
-
-    Measure durations of Sphinx processing.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Measure durations of Sphinx processing."""
 
 from datetime import datetime, timedelta
 from itertools import islice
('sphinx/ext', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,9 +1 @@
-"""
-    sphinx.ext
-    ~~~~~~~~~~
-
-    Contains Sphinx features not activated by default.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Contains Sphinx features not activated by default."""
('sphinx/ext', 'linkcode.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.ext.linkcode
-    ~~~~~~~~~~~~~~~~~~~
-
-    Add external links to module code in Python object descriptions.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Add external links to module code in Python object descriptions."""
 
 from typing import Any, Dict, Set
 
@@ -39,7 +31,7 @@
         'js': ['object', 'fullname'],
     }
 
-    for objnode in doctree.traverse(addnodes.desc):
+    for objnode in list(doctree.findall(addnodes.desc)):
         domain = objnode.get('domain')
         uris: Set[str] = set()
         for signode in objnode:
('sphinx/ext', 'coverage.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,7 @@
-"""
-    sphinx.ext.coverage
-    ~~~~~~~~~~~~~~~~~~~
-
-    Check Python modules and C API for coverage.  Mostly written by Josip
-    Dzolonga for the Google Highly Open Participation contest.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
+"""Check Python modules and C API for coverage.
+
+Mostly written by Josip Dzolonga for the Google Highly Open Participation
+contest.
 """
 
 import glob
@@ -29,12 +24,12 @@
 
 
 # utility
-def write_header(f: IO, text: str, char: str = '-') -> None:
+def write_header(f: IO[str], text: str, char: str = '-') -> None:
     f.write(text + '\n')
     f.write(char * len(text) + '\n')
 
 
-def compile_regex_list(name: str, exps: str) -> List[Pattern]:
+def compile_regex_list(name: str, exps: str) -> List[Pattern[str]]:
     lst = []
     for exp in exps:
         try:
@@ -58,14 +53,14 @@
             pattern = path.join(self.srcdir, pattern)
             self.c_sourcefiles.extend(glob.glob(pattern))
 
-        self.c_regexes: List[Tuple[str, Pattern]] = []
+        self.c_regexes: List[Tuple[str, Pattern[str]]] = []
         for (name, exp) in self.config.coverage_c_regexes.items():
             try:
                 self.c_regexes.append((name, re.compile(exp)))
             except Exception:
                 logger.warning(__('invalid regex %r in coverage_c_regexes'), exp)
 
-        self.c_ignorexps: Dict[str, List[Pattern]] = {}
+        self.c_ignorexps: Dict[str, List[Pattern[str]]] = {}
         for (name, exps) in self.config.coverage_ignore_c_items.items():
             self.c_ignorexps[name] = compile_regex_list('coverage_ignore_c_items',
                                                         exps)
@@ -95,7 +90,7 @@
         c_objects = self.env.domaindata['c']['objects']
         for filename in self.c_sourcefiles:
             undoc: Set[Tuple[str, str]] = set()
-            with open(filename) as f:
+            with open(filename, encoding="utf-8") as f:
                 for line in f:
                     for key, regex in self.c_regexes:
                         match = regex.match(line)
@@ -113,7 +108,7 @@
 
     def write_c_coverage(self) -> None:
         output_file = path.join(self.outdir, 'c.txt')
-        with open(output_file, 'w') as op:
+        with open(output_file, 'w', encoding="utf-8") as op:
             if self.config.coverage_write_headline:
                 write_header(op, 'Undocumented C API elements', '=')
             op.write('\n')
@@ -232,7 +227,7 @@
     def write_py_coverage(self) -> None:
         output_file = path.join(self.outdir, 'python.txt')
         failed = []
-        with open(output_file, 'w') as op:
+        with open(output_file, 'w', encoding="utf-8") as op:
             if self.config.coverage_write_headline:
                 write_header(op, 'Undocumented Python objects', '=')
             keys = sorted(self.py_undoc.keys())
('sphinx/ext', 'imgmath.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,22 +1,14 @@
-"""
-    sphinx.ext.imgmath
-    ~~~~~~~~~~~~~~~~~~
-
-    Render math in HTML via dvipng or dvisvgm.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
-
+"""Render math in HTML via dvipng or dvisvgm."""
+
+import base64
 import posixpath
 import re
 import shutil
 import subprocess
-import sys
 import tempfile
 from os import path
 from subprocess import PIPE, CalledProcessError
-from typing import Any, Dict, List, Tuple
+from typing import Any, Dict, List, Optional, Tuple
 
 from docutils import nodes
 from docutils.nodes import Element
@@ -39,15 +31,19 @@
 
 templates_path = path.join(package_dir, 'templates', 'imgmath')
 
+__all__ = ()
+
 
 class MathExtError(SphinxError):
     category = 'Math extension error'
 
-    def __init__(self, msg: str, stderr: bytes = None, stdout: bytes = None) -> None:
+    def __init__(
+        self, msg: str, stderr: Optional[str] = None, stdout: Optional[str] = None
+    ) -> None:
         if stderr:
-            msg += '\n[stderr]\n' + stderr.decode(sys.getdefaultencoding(), 'replace')
+            msg += '\n[stderr]\n' + stderr
         if stdout:
-            msg += '\n[stdout]\n' + stdout.decode(sys.getdefaultencoding(), 'replace')
+            msg += '\n[stdout]\n' + stdout
         super().__init__(msg)
 
 
@@ -62,11 +58,11 @@
 depthsvgcomment_re = re.compile(r'<!-- DEPTH=(-?\d+) -->')
 
 
-def read_svg_depth(filename: str) -> int:
+def read_svg_depth(filename: str) -> Optional[int]:
     """Read the depth from comment at last line of SVG file
     """
-    with open(filename) as f:
-        for line in f:
+    with open(filename, encoding="utf-8") as f:
+        for line in f:  # noqa: B007
             pass
         # Only last line is checked
         matched = depthsvgcomment_re.match(line)
@@ -78,7 +74,7 @@
 def write_svg_depth(filename: str, depth: int) -> None:
     """Write the depth to SVG file as a comment at end of file
     """
-    with open(filename, 'a') as f:
+    with open(filename, 'a', encoding="utf-8") as f:
         f.write('\n<!-- DEPTH=%s -->' % depth)
 
 
@@ -135,7 +131,8 @@
     command.append('math.tex')
 
     try:
-        subprocess.run(command, stdout=PIPE, stderr=PIPE, cwd=tempdir, check=True)
+        subprocess.run(command, stdout=PIPE, stderr=PIPE, cwd=tempdir, check=True,
+                       encoding='ascii')
         return path.join(tempdir, 'math.dvi')
     except OSError as exc:
         logger.warning(__('LaTeX command %r cannot be run (needed for math '
@@ -160,7 +157,7 @@
         raise MathExtError('%s exited with error' % name, exc.stderr, exc.stdout) from exc
 
 
-def convert_dvi_to_png(dvipath: str, builder: Builder) -> Tuple[str, int]:
+def convert_dvi_to_png(dvipath: str, builder: Builder) -> Tuple[str, Optional[int]]:
     """Convert DVI file to PNG image."""
     tempdir = ensure_tempdir(builder)
     filename = path.join(tempdir, 'math.png')
@@ -186,7 +183,7 @@
     return filename, depth
 
 
-def convert_dvi_to_svg(dvipath: str, builder: Builder) -> Tuple[str, int]:
+def convert_dvi_to_svg(dvipath: str, builder: Builder) -> Tuple[str, Optional[int]]:
     """Convert DVI file to SVG image."""
     tempdir = ensure_tempdir(builder)
     filename = path.join(tempdir, 'math.svg')
@@ -210,13 +207,17 @@
     return filename, depth
 
 
-def render_math(self: HTMLTranslator, math: str) -> Tuple[str, int]:
+def render_math(
+    self: HTMLTranslator,
+    math: str,
+) -> Tuple[Optional[str], Optional[int], Optional[str], Optional[str]]:
     """Render the LaTeX math expression *math* using latex and dvipng or
     dvisvgm.
 
     Return the filename relative to the built document and the "depth",
     that is, the distance of image bottom and baseline in pixels, if the
     option to use preview_latex is switched on.
+    Also return the temporary and destination files.
 
     Error handling may seem strange, but follows a pattern: if LaTeX or dvipng
     (dvisvgm) aren't available, only a warning is generated (since that enables
@@ -241,19 +242,19 @@
             depth = read_png_depth(outfn)
         elif image_format == 'svg':
             depth = read_svg_depth(outfn)
-        return relfn, depth
+        return relfn, depth, None, outfn
 
     # if latex or dvipng (dvisvgm) has failed once, don't bother to try again
     if hasattr(self.builder, '_imgmath_warned_latex') or \
        hasattr(self.builder, '_imgmath_warned_image_translator'):
-        return None, None
+        return None, None, None, None
 
     # .tex -> .dvi
     try:
         dvipath = compile_math(latex, self.builder)
     except InvokeError:
         self.builder._imgmath_warned_latex = True  # type: ignore
-        return None, None
+        return None, None, None, None
 
     # .dvi -> .png/.svg
     try:
@@ -263,13 +264,19 @@
             imgpath, depth = convert_dvi_to_svg(dvipath, self.builder)
     except InvokeError:
         self.builder._imgmath_warned_image_translator = True  # type: ignore
-        return None, None
-
-    # Move generated image on tempdir to build dir
-    ensuredir(path.dirname(outfn))
-    shutil.move(imgpath, outfn)
-
-    return relfn, depth
+        return None, None, None, None
+
+    return relfn, depth, imgpath, outfn
+
+
+def render_maths_to_base64(image_format: str, outfn: Optional[str]) -> str:
+    with open(outfn, "rb") as f:
+        encoded = base64.b64encode(f.read()).decode(encoding='utf-8')
+    if image_format == 'png':
+        return f'data:image/png;base64,{encoded}'
+    if image_format == 'svg':
+        return f'data:image/svg+xml;base64,{encoded}'
+    raise MathExtError('imgmath_image_format must be either "png" or "svg"')
 
 
 def cleanup_tempdir(app: Sphinx, exc: Exception) -> None:
@@ -291,7 +298,7 @@
 
 def html_visit_math(self: HTMLTranslator, node: nodes.math) -> None:
     try:
-        fname, depth = render_math(self, '$' + node.astext() + '$')
+        fname, depth, imgpath, outfn = render_math(self, '$' + node.astext() + '$')
     except MathExtError as exc:
         msg = str(exc)
         sm = nodes.system_message(msg, type='WARNING', level=2,
@@ -299,14 +306,23 @@
         sm.walkabout(self)
         logger.warning(__('display latex %r: %s'), node.astext(), msg)
         raise nodes.SkipNode from exc
-    if fname is None:
+    if self.builder.config.imgmath_embed:
+        image_format = self.builder.config.imgmath_image_format.lower()
+        img_src = render_maths_to_base64(image_format, outfn)
+    else:
+        # Move generated image on tempdir to build dir
+        if imgpath is not None:
+            ensuredir(path.dirname(outfn))
+            shutil.move(imgpath, outfn)
+        img_src = fname
+    if img_src is None:
         # something failed -- use text-only as a bad substitute
         self.body.append('<span class="math">%s</span>' %
                          self.encode(node.astext()).strip())
     else:
-        c = ('<img class="math" src="%s"' % fname) + get_tooltip(self, node)
+        c = f'<img class="math" src="{img_src}"' + get_tooltip(self, node)
         if depth is not None:
-            c += ' style="vertical-align: %dpx"' % (-depth)
+            c += f' style="vertical-align: {-depth:d}px"'
         self.body.append(c + '/>')
     raise nodes.SkipNode
 
@@ -317,7 +333,7 @@
     else:
         latex = wrap_displaymath(node.astext(), None, False)
     try:
-        fname, depth = render_math(self, latex)
+        fname, depth, imgpath, outfn = render_math(self, latex)
     except MathExtError as exc:
         msg = str(exc)
         sm = nodes.system_message(msg, type='WARNING', level=2,
@@ -332,12 +348,21 @@
         self.body.append('<span class="eqno">(%s)' % number)
         self.add_permalink_ref(node, _('Permalink to this equation'))
         self.body.append('</span>')
-    if fname is None:
+    if self.builder.config.imgmath_embed:
+        image_format = self.builder.config.imgmath_image_format.lower()
+        img_src = render_maths_to_base64(image_format, outfn)
+    else:
+        # Move generated image on tempdir to build dir
+        if imgpath is not None:
+            ensuredir(path.dirname(outfn))
+            shutil.move(imgpath, outfn)
+        img_src = fname
+    if img_src is None:
         # something failed -- use text-only as a bad substitute
         self.body.append('<span class="math">%s</span></p>\n</div>' %
                          self.encode(node.astext()).strip())
     else:
-        self.body.append(('<img src="%s"' % fname) + get_tooltip(self, node) +
+        self.body.append(f'<img src="{img_src}"' + get_tooltip(self, node) +
                          '/></p>\n</div>')
     raise nodes.SkipNode
 
@@ -360,5 +385,6 @@
     app.add_config_value('imgmath_latex_preamble', '', 'html')
     app.add_config_value('imgmath_add_tooltips', True, 'html')
     app.add_config_value('imgmath_font_size', 12, 'html')
+    app.add_config_value('imgmath_embed', False, 'html', [bool])
     app.connect('build-finished', cleanup_tempdir)
     return {'version': sphinx.__display_version__, 'parallel_read_safe': True}
('sphinx/ext', 'inheritance_diagram.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,45 +1,38 @@
-r"""
-    sphinx.ext.inheritance_diagram
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    Defines a docutils directive for inserting inheritance diagrams.
-
-    Provide the directive with one or more classes or modules (separated
-    by whitespace).  For modules, all of the classes in that module will
-    be used.
-
-    Example::
-
-       Given the following classes:
-
-       class A: pass
-       class B(A): pass
-       class C(A): pass
-       class D(B, C): pass
-       class E(B): pass
-
-       .. inheritance-diagram: D E
-
-       Produces a graph like the following:
-
-                   A
-                  / \
-                 B   C
-                / \ /
-               E   D
-
-    The graph is inserted as a PNG+image map into HTML and a PDF in
-    LaTeX.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
+r"""Defines a docutils directive for inserting inheritance diagrams.
+
+Provide the directive with one or more classes or modules (separated
+by whitespace).  For modules, all of the classes in that module will
+be used.
+
+Example::
+
+   Given the following classes:
+
+   class A: pass
+   class B(A): pass
+   class C(A): pass
+   class D(B, C): pass
+   class E(B): pass
+
+   .. inheritance-diagram: D E
+
+   Produces a graph like the following:
+
+               A
+              / \
+             B   C
+            / \ /
+           E   D
+
+The graph is inserted as a PNG+image map into HTML and a PDF in
+LaTeX.
 """
 
 import builtins
 import inspect
 import re
 from importlib import import_module
-from typing import Any, Dict, Iterable, List, Tuple, cast
+from typing import Any, Dict, Iterable, List, Optional, Tuple, cast
 
 from docutils import nodes
 from docutils.nodes import Node
@@ -138,8 +131,9 @@
     graphviz dot graph from them.
     """
     def __init__(self, class_names: List[str], currmodule: str, show_builtins: bool = False,
-                 private_bases: bool = False, parts: int = 0, aliases: Dict[str, str] = None,
-                 top_classes: List[Any] = []) -> None:
+                 private_bases: bool = False, parts: int = 0,
+                 aliases: Optional[Dict[str, str]] = None, top_classes: List[Any] = []
+                 ) -> None:
         """*class_names* is a list of child classes to show bases from.
 
         If *show_builtins* is True, then Python builtins will be shown
@@ -219,7 +213,9 @@
 
         return list(all_classes.values())
 
-    def class_name(self, cls: Any, parts: int = 0, aliases: Dict[str, str] = None) -> str:
+    def class_name(
+        self, cls: Any, parts: int = 0, aliases: Optional[Dict[str, str]] = None
+    ) -> str:
         """Given a class object, return a fully-qualified name.
 
         This works for things I've tested in matplotlib so far, but may not be
@@ -263,13 +259,14 @@
         'style': '"setlinewidth(0.5)"',
     }
 
-    def _format_node_attrs(self, attrs: Dict) -> str:
+    def _format_node_attrs(self, attrs: Dict[str, Any]) -> str:
         return ','.join(['%s=%s' % x for x in sorted(attrs.items())])
 
-    def _format_graph_attrs(self, attrs: Dict) -> str:
+    def _format_graph_attrs(self, attrs: Dict[str, Any]) -> str:
         return ''.join(['%s=%s;\n' % x for x in sorted(attrs.items())])
 
-    def generate_dot(self, name: str, urls: Dict = {}, env: BuildEnvironment = None,
+    def generate_dot(self, name: str, urls: Dict[str, str] = {},
+                     env: Optional[BuildEnvironment] = None,
                      graph_attrs: Dict = {}, node_attrs: Dict = {}, edge_attrs: Dict = {}
                      ) -> str:
         """Generate a graphviz dot graph from the classes that were passed in
('sphinx/ext', 'doctest.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,6 @@
-"""
-    sphinx.ext.doctest
-    ~~~~~~~~~~~~~~~~~~
-
-    Mimic doctest by automatically executing code snippets and checking
-    their results.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
+"""Mimic doctest in Sphinx.
+
+The extension automatically execute code snippets and checks their results.
 """
 
 import doctest
@@ -15,8 +9,8 @@
 import time
 from io import StringIO
 from os import path
-from typing import (TYPE_CHECKING, Any, Callable, Dict, Iterable, List, Sequence, Set, Tuple,
-                    Type)
+from typing import (TYPE_CHECKING, Any, Callable, Dict, Iterable, List, Optional, Sequence,
+                    Set, Tuple, Type)
 
 from docutils import nodes
 from docutils.nodes import Element, Node, TextElement
@@ -47,15 +41,15 @@
     """Check `spec` satisfies `version` or not.
 
     This obeys PEP-440 specifiers:
-    https://www.python.org/dev/peps/pep-0440/#version-specifiers
+    https://peps.python.org/pep-0440/#version-specifiers
 
     Some examples:
 
-        >>> is_allowed_version('3.3', '<=3.5')
+        >>> is_allowed_version('<=3.5', '3.3')
         True
-        >>> is_allowed_version('3.3', '<=3.2')
+        >>> is_allowed_version('<=3.2', '3.3')
         False
-        >>> is_allowed_version('3.3', '>3.2, <4.0')
+        >>> is_allowed_version('>3.2, <4.0', '3.3')
         True
     """
     return Version(version) in SpecifierSet(spec)
@@ -231,7 +225,7 @@
 
 class TestCode:
     def __init__(self, code: str, type: str, filename: str,
-                 lineno: int, options: Dict = None) -> None:
+                 lineno: int, options: Optional[Dict] = None) -> None:
         self.code = code
         self.type = type
         self.filename = filename
@@ -323,7 +317,7 @@
             logger.info(text, nonl=True)
         self.outfile.write(text)
 
-    def get_target_uri(self, docname: str, typ: str = None) -> str:
+    def get_target_uri(self, docname: str, typ: Optional[str] = None) -> str:
         return ''
 
     def get_outdated_docs(self) -> Set[str]:
@@ -368,11 +362,11 @@
             filename = relpath(node.source, self.env.srcdir)\
                 .rsplit(':docstring of ', maxsplit=1)[0]
         except Exception:
-            filename = self.env.doc2path(docname, base=None)
+            filename = self.env.doc2path(docname, False)
         return filename
 
     @staticmethod
-    def get_line_number(node: Node) -> int:
+    def get_line_number(node: Node) -> Optional[int]:
         """Get the real line number or admit we don't know."""
         # TODO:  Work out how to store or calculate real (file-relative)
         #       line numbers for doctest blocks in docstrings.
@@ -422,7 +416,7 @@
             def condition(node: Node) -> bool:
                 return isinstance(node, (nodes.literal_block, nodes.comment)) \
                     and 'testnodetype' in node
-        for node in doctree.traverse(condition):  # type: Element
+        for node in doctree.findall(condition):  # type: Element
             if self.skipped(node):
                 continue
 
('sphinx/ext', 'ifconfig.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,22 +1,17 @@
-"""
-    sphinx.ext.ifconfig
-    ~~~~~~~~~~~~~~~~~~~
+"""Provides the ``ifconfig`` directive.
 
-    Provides the ``ifconfig`` directive that allows to write documentation
-    that is included depending on configuration variables.
+The ``ifconfig`` directive enables writing documentation
+that is included depending on configuration variables.
 
-    Usage::
+Usage::
 
-        .. ifconfig:: releaselevel in ('alpha', 'beta', 'rc')
+    .. ifconfig:: releaselevel in ('alpha', 'beta', 'rc')
 
-           This stuff is only included in the built docs for unstable versions.
+       This stuff is only included in the built docs for unstable versions.
 
-    The argument for ``ifconfig`` is a plain Python expression, evaluated in the
-    namespace of the project configuration (that is, all variables from
-    ``conf.py`` are available.)
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
+The argument for ``ifconfig`` is a plain Python expression, evaluated in the
+namespace of the project configuration (that is, all variables from
+``conf.py`` are available.)
 """
 
 from typing import Any, Dict, List
@@ -56,7 +51,7 @@
     ns = {confval.name: confval.value for confval in app.config}
     ns.update(app.config.__dict__.copy())
     ns['builder'] = app.builder.name
-    for node in doctree.traverse(ifconfig):
+    for node in list(doctree.findall(ifconfig)):
         try:
             res = eval(node['expr'], ns)
         except Exception as err:
('sphinx/ext', 'todo.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,14 +1,8 @@
-"""
-    sphinx.ext.todo
-    ~~~~~~~~~~~~~~~
-
-    Allow todos to be inserted into your documentation.  Inclusion of todos can
-    be switched of by a configuration variable.  The todolist directive collects
-    all todos of your project and lists them along with a backlink to the
-    original location.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
+"""Allow todos to be inserted into your documentation.
+
+Inclusion of todos can be switched of by a configuration variable.
+The todolist directive collects all todos of your project and lists them along
+with a backlink to the original location.
 """
 
 from typing import Any, Dict, List, Tuple, cast
@@ -93,7 +87,7 @@
     def process_doc(self, env: BuildEnvironment, docname: str,
                     document: nodes.document) -> None:
         todos = self.todos.setdefault(docname, [])
-        for todo in document.traverse(todo_node):
+        for todo in document.findall(todo_node):
             env.app.emit('todo-defined', todo)
             todos.append(todo)
 
@@ -131,7 +125,7 @@
 
     def process(self, doctree: nodes.document, docname: str) -> None:
         todos: List[todo_node] = sum(self.domain.todos.values(), [])
-        for node in doctree.traverse(todolist):
+        for node in list(doctree.findall(todolist)):
             if not self.config.todo_include_todos:
                 node.parent.remove(node)
                 continue
@@ -165,7 +159,7 @@
         suffix = description[description.find('>>') + 2:]
 
         para = nodes.paragraph(classes=['todo-source'])
-        para += nodes.Text(prefix, prefix)
+        para += nodes.Text(prefix)
 
         # Create a reference
         linktext = nodes.emphasis(_('original entry'), _('original entry'))
@@ -178,13 +172,13 @@
             pass
 
         para += reference
-        para += nodes.Text(suffix, suffix)
+        para += nodes.Text(suffix)
 
         return para
 
     def resolve_reference(self, todo: todo_node, docname: str) -> None:
         """Resolve references in the todo content."""
-        for node in todo.traverse(addnodes.pending_xref):
+        for node in todo.findall(addnodes.pending_xref):
             if 'refdoc' in node:
                 node['refdoc'] = docname
 
('sphinx/ext', 'viewcode.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,16 +1,7 @@
-"""
-    sphinx.ext.viewcode
-    ~~~~~~~~~~~~~~~~~~~
-
-    Add links to module code in Python object descriptions.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Add links to module code in Python object descriptions."""
 
 import posixpath
 import traceback
-import warnings
 from os import path
 from typing import Any, Dict, Generator, Iterable, Optional, Set, Tuple, cast
 
@@ -22,7 +13,6 @@
 from sphinx.application import Sphinx
 from sphinx.builders import Builder
 from sphinx.builders.html import StandaloneHTMLBuilder
-from sphinx.deprecation import RemovedInSphinx50Warning
 from sphinx.environment import BuildEnvironment
 from sphinx.locale import _, __
 from sphinx.pycode import ModuleAnalyzer
@@ -108,7 +98,7 @@
 
         return False
 
-    for objnode in doctree.traverse(addnodes.desc):
+    for objnode in list(doctree.findall(addnodes.desc)):
         if objnode.get('domain') != 'py':
             continue
         names: Set[str] = set()
@@ -184,27 +174,15 @@
             self.remove_viewcode_anchors()
 
     def convert_viewcode_anchors(self) -> None:
-        for node in self.document.traverse(viewcode_anchor):
+        for node in self.document.findall(viewcode_anchor):
             anchor = nodes.inline('', _('[source]'), classes=['viewcode-link'])
             refnode = make_refnode(self.app.builder, node['refdoc'], node['reftarget'],
                                    node['refid'], anchor)
             node.replace_self(refnode)
 
     def remove_viewcode_anchors(self) -> None:
-        for node in self.document.traverse(viewcode_anchor):
+        for node in list(self.document.findall(viewcode_anchor)):
             node.parent.remove(node)
-
-
-def missing_reference(app: Sphinx, env: BuildEnvironment, node: Element, contnode: Node
-                      ) -> Optional[Node]:
-    # resolve our "viewcode" reference nodes -- they need special treatment
-    if node['reftype'] == 'viewcode':
-        warnings.warn('viewcode extension is no longer use pending_xref node. '
-                      'Please update your extension.', RemovedInSphinx50Warning)
-        return make_refnode(app.builder, node['refdoc'], node['reftarget'],
-                            node['refid'], contnode)
-
-    return None
 
 
 def get_module_filename(app: Sphinx, modname: str) -> Optional[str]:
@@ -349,7 +327,6 @@
     app.connect('env-merge-info', env_merge_info)
     app.connect('env-purge-doc', env_purge_doc)
     app.connect('html-collect-pages', collect_pages)
-    app.connect('missing-reference', missing_reference)
     # app.add_config_value('viewcode_include_modules', [], 'env')
     # app.add_config_value('viewcode_exclude_modules', [], 'env')
     app.add_event('viewcode-find-source')
('sphinx/ext', 'autosectionlabel.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.ext.autosectionlabel
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    Allow reference sections by :ref: role using its title.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Allow reference sections by :ref: role using its title."""
 
 from typing import Any, Dict, cast
 
@@ -33,7 +25,7 @@
 
 def register_sections_as_label(app: Sphinx, document: Node) -> None:
     domain = cast(StandardDomain, app.env.get_domain('std'))
-    for node in document.traverse(nodes.section):
+    for node in document.findall(nodes.section):
         if (app.config.autosectionlabel_maxdepth and
                 get_node_depth(node) >= app.config.autosectionlabel_maxdepth):
             continue
('sphinx/ext/napoleon', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.ext.napoleon
-    ~~~~~~~~~~~~~~~~~~~
-
-    Support for NumPy and Google style docstrings.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Support for NumPy and Google style docstrings."""
 
 from typing import Any, Dict, List
 
@@ -49,7 +41,7 @@
     .. _Google style:
        https://google.github.io/styleguide/pyguide.html
     .. _NumPy style:
-       https://github.com/numpy/numpy/blob/master/doc/HOWTO_DOCUMENT.rst.txt
+       https://numpydoc.readthedocs.io/en/latest/format.html#docstring-standard
 
     Attributes
     ----------
@@ -288,7 +280,7 @@
     }
 
     def __init__(self, **settings: Any) -> None:
-        for name, (default, rebuild) in self._config_values.items():
+        for name, (default, _rebuild) in self._config_values.items():
             setattr(self, name, default)
         for name, value in settings.items():
             setattr(self, name, value)
@@ -444,10 +436,10 @@
 
     """
     has_doc = getattr(obj, '__doc__', False)
-    is_member = (what == 'class' or what == 'exception' or what == 'module')
+    is_member = what in ('class', 'exception', 'module')
     if name != '__weakref__' and has_doc and is_member:
         cls_is_owner = False
-        if what == 'class' or what == 'exception':
+        if what in ('class', 'exception'):
             qualname = getattr(obj, '__qualname__', '')
             cls_path, _, _ = qualname.rpartition('.')
             if cls_path:
('sphinx/ext/napoleon', 'docstring.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,24 +1,15 @@
-"""
-    sphinx.ext.napoleon.docstring
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-
-    Classes for docstring parsing and formatting.
-
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Classes for docstring parsing and formatting."""
 
 import collections
 import inspect
 import re
+import warnings
 from functools import partial
 from typing import Any, Callable, Dict, List, Tuple, Type, Union
 
 from sphinx.application import Sphinx
 from sphinx.config import Config as SphinxConfig
-from sphinx.ext.napoleon.iterators import modify_iter
+from sphinx.deprecation import RemovedInSphinx60Warning
 from sphinx.locale import _, __
 from sphinx.util import logging
 from sphinx.util.inspect import stringify_annotation
@@ -52,6 +43,29 @@
     r"^default[^_0-9A-Za-z].*$",
 )
 _SINGLETONS = ("None", "True", "False", "Ellipsis")
+
+
+class Deque(collections.deque):
+    """
+    A subclass of deque that mimics ``pockets.iterators.modify_iter``.
+
+    The `.Deque.get` and `.Deque.next` methods are added.
+    """
+
+    sentinel = object()
+
+    def get(self, n: int) -> Any:
+        """
+        Return the nth element of the stack, or ``self.sentinel`` if n is
+        greater than the stack size.
+        """
+        return self[n] if n < len(self) else self.sentinel
+
+    def next(self) -> Any:
+        if self:
+            return super().popleft()
+        else:
+            raise StopIteration
 
 
 def _convert_type_spec(_type: str, translations: Dict[str, str] = {}) -> str:
@@ -161,7 +175,7 @@
             lines = docstring.splitlines()
         else:
             lines = docstring
-        self._line_iter = modify_iter(lines, modifier=lambda s: s.rstrip())
+        self._lines = Deque(map(str.rstrip, lines))
         self._parsed_lines: List[str] = []
         self._is_in_section = False
         self._section_indent = 0
@@ -233,32 +247,34 @@
 
     def _consume_indented_block(self, indent: int = 1) -> List[str]:
         lines = []
-        line = self._line_iter.peek()
-        while(not self._is_section_break() and
-              (not line or self._is_indented(line, indent))):
-            lines.append(next(self._line_iter))
-            line = self._line_iter.peek()
+        line = self._lines.get(0)
+        while (
+            not self._is_section_break() and
+            (not line or self._is_indented(line, indent))
+        ):
+            lines.append(self._lines.next())
+            line = self._lines.get(0)
         return lines
 
     def _consume_contiguous(self) -> List[str]:
         lines = []
-        while (self._line_iter.has_next() and
-               self._line_iter.peek() and
+        while (self._lines and
+               self._lines.get(0) and
                not self._is_section_header()):
-            lines.append(next(self._line_iter))
+            lines.append(self._lines.next())
         return lines
 
     def _consume_empty(self) -> List[str]:
         lines = []
-        line = self._line_iter.peek()
-        while self._line_iter.has_next() and not line:
-            lines.append(next(self._line_iter))
-            line = self._line_iter.peek()
+        line = self._lines.get(0)
+        while self._lines and not line:
+            lines.append(self._lines.next())
+            line = self._lines.get(0)
         return lines
 
     def _consume_field(self, parse_type: bool = True, prefer_type: bool = False
                        ) -> Tuple[str, str, List[str]]:
-        line = next(self._line_iter)
+        line = self._lines.next()
 
         before, colon, after = self._partition_field_on_colon(line)
         _name, _type, _desc = before, '', after
@@ -296,7 +312,7 @@
         return fields
 
     def _consume_inline_attribute(self) -> Tuple[str, List[str]]:
-        line = next(self._line_iter)
+        line = self._lines.next()
         _type, colon, _desc = self._partition_field_on_colon(line)
         if not colon or not _desc:
             _type, _desc = _desc, _type
@@ -334,7 +350,7 @@
         return lines
 
     def _consume_section_header(self) -> str:
-        section = next(self._line_iter)
+        section = self._lines.next()
         stripped_section = section.strip(':')
         if stripped_section.lower() in self._sections:
             section = stripped_section
@@ -342,15 +358,15 @@
 
     def _consume_to_end(self) -> List[str]:
         lines = []
-        while self._line_iter.has_next():
-            lines.append(next(self._line_iter))
+        while self._lines:
+            lines.append(self._lines.next())
         return lines
 
     def _consume_to_next_section(self) -> List[str]:
         self._consume_empty()
         lines = []
         while not self._is_section_break():
-            lines.append(next(self._line_iter))
+            lines.append(self._lines.next())
         return lines + self._consume_empty()
 
     def _dedent(self, lines: List[str], full: bool = False) -> List[str]:
@@ -476,12 +492,12 @@
         return lines
 
     def _get_current_indent(self, peek_ahead: int = 0) -> int:
-        line = self._line_iter.peek(peek_ahead + 1)[peek_ahead]
-        while line != self._line_iter.sentinel:
+        line = self._lines.get(peek_ahead)
+        while line is not self._lines.sentinel:
             if line:
                 return self._get_indent(line)
             peek_ahead += 1
-            line = self._line_iter.peek(peek_ahead + 1)[peek_ahead]
+            line = self._lines.get(peek_ahead)
         return 0
 
     def _get_indent(self, line: str) -> int:
@@ -536,7 +552,7 @@
         return next_indent > indent
 
     def _is_section_header(self) -> bool:
-        section = self._line_iter.peek().lower()
+        section = self._lines.get(0).lower()
         match = _google_section_regex.match(section)
         if match and section.strip(':') in self._sections:
             header_indent = self._get_indent(section)
@@ -550,8 +566,8 @@
         return False
 
     def _is_section_break(self) -> bool:
-        line = self._line_iter.peek()
-        return (not self._line_iter.has_next() or
+        line = self._lines.get(0)
+        return (not self._lines or
                 self._is_section_header() or
                 (self._is_in_section and
                     line and
@@ -593,7 +609,7 @@
             self._parsed_lines.extend(res)
             return
 
-        while self._line_iter.has_next():
+        while self._lines:
             if self._is_section_header():
                 try:
                     section = self._consume_section_header()
@@ -631,7 +647,6 @@
             if not _type:
                 _type = self._lookup_annotation(_name)
             if self._config.napoleon_use_ivar:
-                _name = self._qualify_name(_name, self._obj)
                 field = ':ivar %s: ' % _name
                 lines.extend(self._format_block(field, _desc))
                 if _type:
@@ -769,12 +784,9 @@
     def _parse_returns_section(self, section: str) -> List[str]:
         fields = self._consume_returns_section()
         multi = len(fields) > 1
-        if multi:
-            use_rtype = False
-        else:
-            use_rtype = self._config.napoleon_use_rtype
-
+        use_rtype = False if multi else self._config.napoleon_use_rtype
         lines: List[str] = []
+
         for _name, _type, _desc in fields:
             if use_rtype:
                 field = self._format_field(_name, '', _desc)
@@ -787,7 +799,8 @@
                 else:
                     lines.extend(self._format_block(':returns: * ', field))
             else:
-                lines.extend(self._format_block(':returns: ', field))
+                if any(field):  # only add :returns: if there's something to say
+                    lines.extend(self._format_block(':returns: ', field))
                 if _type and use_rtype:
                     lines.extend([':rtype: %s' % _type, ''])
         if lines and lines[-1]:
@@ -827,6 +840,8 @@
                 "".join(after_colon).strip())
 
     def _qualify_name(self, attr_name: str, klass: Type) -> str:
+        warnings.warn('%s._qualify_name() is deprecated.' %
+                      self.__class__.__name__, RemovedInSphinx60Warning)
         if klass and '.' not in attr_name:
             if attr_name.startswith('~'):
                 attr_name = attr_name[1:]
@@ -940,12 +955,12 @@
         else:
             return [item]
 
-    tokens = list(
+    tokens = [
         item
         for raw_token in _token_regex.split(spec)
         for item in postprocess(raw_token)
         if item
-    )
+    ]
     return tokens
 
 
@@ -1167,7 +1182,7 @@
 
     def _consume_field(self, parse_type: bool = True, prefer_type: bool = False
                        ) -> Tuple[str, str, List[str]]:
-        line = next(self._line_iter)
+        line = self._lines.next()
         if parse_type:
             _name, _, _type = self._partition_field_on_colon(line)
         else:
@@ -1198,15 +1213,15 @@
         return self._consume_fields(prefer_type=True)
 
     def _consume_section_header(self) -> str:
-        section = next(self._line_iter)
+        section = self._lines.next()
         if not _directive_regex.match(section):
             # Consume the header underline
-            next(self._line_iter)
+            self._lines.next()
         return section
 
     def _is_section_break(self) -> bool:
-        line1, line2 = self._line_iter.peek(2)
-        return (not self._line_iter.has_next() or
+        line1, line2 = self._lines.get(0), self._lines.get(1)
+        return (not self._lines or
                 self._is_section_header() or
                 ['', ''] == [line1, line2] or
                 (self._is_in_section and
@@ -1214,7 +1229,7 @@
                     not self._is_indented(line1, self._section_indent)))
 
     def _is_section_header(self) -> bool:
-        section, underline = self._line_iter.peek(2)
+        section, underline = self._lines.get(0), self._lines.get(1)
         section = section.lower()
         if section in self._sections and isinstance(underline, str):
             return bool(_numpy_section_regex.match(underline))
('sphinx/ext/napoleon', 'iterators.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,17 +1,13 @@
-"""
-    sphinx.ext.napoleon.iterators
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-
-    A collection of helpful iterators.
-
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""A collection of helpful iterators."""
 
 import collections
+import warnings
 from typing import Any, Iterable, Optional
+
+from sphinx.deprecation import RemovedInSphinx70Warning
+
+warnings.warn('sphinx.ext.napoleon.iterators is deprecated.',
+              RemovedInSphinx70Warning)
 
 
 class peek_iter:
@@ -59,7 +55,7 @@
     def __iter__(self) -> "peek_iter":
         return self
 
-    def __next__(self, n: int = None) -> Any:
+    def __next__(self, n: Optional[int] = None) -> Any:
         return self.next(n)
 
     def _fillcache(self, n: Optional[int]) -> None:
@@ -88,7 +84,7 @@
         """
         return self.peek() != self.sentinel
 
-    def next(self, n: int = None) -> Any:
+    def next(self, n: Optional[int] = None) -> Any:
         """Get the next item or `n` items of the iterator.
 
         Parameters
('sphinx/ext/autosummary', 'generate.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,20 +1,15 @@
-"""
-    sphinx.ext.autosummary.generate
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    Usable as a library or script to generate automatic RST source files for
-    items referred to in autosummary:: directives.
-
-    Each generated RST file contains a single auto*:: directive which
-    extracts the docstring of the referred item.
-
-    Example Makefile rule::
-
-       generate:
-               sphinx-autogen -o source/generated source/*.rst
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
+"""Generates reST source files for autosummary.
+
+Usable as a library or script to generate automatic RST source files for
+items referred to in autosummary:: directives.
+
+Each generated RST file contains a single auto*:: directive which
+extracts the docstring of the referred item.
+
+Example Makefile rule::
+
+   generate:
+           sphinx-autogen -o source/generated source/*.rst
 """
 
 import argparse
@@ -25,10 +20,9 @@
 import pydoc
 import re
 import sys
-import warnings
 from gettext import NullTranslations
 from os import path
-from typing import Any, Dict, List, NamedTuple, Set, Tuple, Type, Union
+from typing import Any, Dict, List, NamedTuple, Optional, Sequence, Set, Tuple, Type
 
 from jinja2 import TemplateNotFound
 from jinja2.sandbox import SandboxedEnvironment
@@ -38,15 +32,15 @@
 from sphinx.application import Sphinx
 from sphinx.builders import Builder
 from sphinx.config import Config
-from sphinx.deprecation import RemovedInSphinx50Warning
 from sphinx.ext.autodoc import Documenter
 from sphinx.ext.autodoc.importer import import_module
-from sphinx.ext.autosummary import get_documenter, import_by_name, import_ivar_by_name
+from sphinx.ext.autosummary import (ImportExceptionGroup, get_documenter, import_by_name,
+                                    import_ivar_by_name)
 from sphinx.locale import __
 from sphinx.pycode import ModuleAnalyzer, PycodeError
 from sphinx.registry import SphinxComponentRegistry
 from sphinx.util import logging, rst, split_full_qualified_name
-from sphinx.util.inspect import safe_getattr
+from sphinx.util.inspect import getall, safe_getattr
 from sphinx.util.osutil import ensuredir
 from sphinx.util.template import SphinxTemplateLoader
 
@@ -68,6 +62,7 @@
 
         self.config.add('autosummary_context', {}, True, None)
         self.config.add('autosummary_filename_map', {}, True, None)
+        self.config.add('autosummary_ignore_module_all', True, 'env', bool)
         self.config.init_values()
 
     def emit_firstresult(self, *args: Any) -> None:
@@ -96,18 +91,6 @@
         app.registry.add_documenter(documenter.objtype, documenter)
 
 
-def _simple_info(msg: str) -> None:
-    warnings.warn('_simple_info() is deprecated.',
-                  RemovedInSphinx50Warning, stacklevel=2)
-    print(msg)
-
-
-def _simple_warn(msg: str) -> None:
-    warnings.warn('_simple_warn() is deprecated.',
-                  RemovedInSphinx50Warning, stacklevel=2)
-    print('WARNING: ' + msg, file=sys.stderr)
-
-
 def _underline(title: str, line: str = '=') -> str:
     if '\n' in title:
         raise ValueError('Can only underline single lines')
@@ -117,14 +100,9 @@
 class AutosummaryRenderer:
     """A helper class for rendering."""
 
-    def __init__(self, app: Union[Builder, Sphinx], template_dir: str = None) -> None:
+    def __init__(self, app: Sphinx) -> None:
         if isinstance(app, Builder):
-            warnings.warn('The first argument for AutosummaryRenderer has been '
-                          'changed to Sphinx object',
-                          RemovedInSphinx50Warning, stacklevel=2)
-        if template_dir:
-            warnings.warn('template_dir argument for AutosummaryRenderer is deprecated.',
-                          RemovedInSphinx50Warning, stacklevel=2)
+            raise ValueError('Expected a Sphinx application object!')
 
         system_templates_path = [os.path.join(package_dir, 'ext', 'autosummary', 'templates')]
         loader = SphinxTemplateLoader(app.srcdir, app.config.templates_path,
@@ -135,24 +113,9 @@
         self.env.filters['e'] = rst.escape
         self.env.filters['underline'] = _underline
 
-        if isinstance(app, (Sphinx, DummyApplication)):
-            if app.translator:
-                self.env.add_extension("jinja2.ext.i18n")
-                self.env.install_gettext_translations(app.translator)
-        elif isinstance(app, Builder):
-            if app.app.translator:
-                self.env.add_extension("jinja2.ext.i18n")
-                self.env.install_gettext_translations(app.app.translator)
-
-    def exists(self, template_name: str) -> bool:
-        """Check if template file exists."""
-        warnings.warn('AutosummaryRenderer.exists() is deprecated.',
-                      RemovedInSphinx50Warning, stacklevel=2)
-        try:
-            self.env.get_template(template_name)
-            return True
-        except TemplateNotFound:
-            return False
+        if app.translator:
+            self.env.add_extension("jinja2.ext.i18n")
+            self.env.install_gettext_translations(app.translator)
 
     def render(self, template_name: str, context: Dict) -> str:
         """Render a template file."""
@@ -192,7 +155,13 @@
 
     def scan(self, imported_members: bool) -> List[str]:
         members = []
-        for name in dir(self.object):
+        try:
+            analyzer = ModuleAnalyzer.for_module(self.object.__name__)
+            attr_docs = analyzer.find_attr_docs()
+        except PycodeError:
+            attr_docs = {}
+
+        for name in members_of(self.object, self.app.config):
             try:
                 value = safe_getattr(self.object, name)
             except AttributeError:
@@ -203,7 +172,9 @@
                 continue
 
             try:
-                if inspect.ismodule(value):
+                if ('', name) in attr_docs:
+                    imported = False
+                elif inspect.ismodule(value):
                     imported = True
                 elif safe_getattr(value, '__module__') != self.object.__name__:
                     imported = True
@@ -212,21 +183,37 @@
             except AttributeError:
                 imported = False
 
+            respect_module_all = not self.app.config.autosummary_ignore_module_all
             if imported_members:
                 # list all members up
                 members.append(name)
             elif imported is False:
-                # list not-imported members up
+                # list not-imported members
                 members.append(name)
+            elif '__all__' in dir(self.object) and respect_module_all:
+                # list members that have __all__ set
+                members.append(name)
 
         return members
+
+
+def members_of(obj: Any, conf: Config) -> Sequence[str]:
+    """Get the members of ``obj``, possibly ignoring the ``__all__`` module attribute
+
+    Follows the ``conf.autosummary_ignore_module_all`` setting."""
+
+    if conf.autosummary_ignore_module_all:
+        return dir(obj)
+    else:
+        return getall(obj) or dir(obj)
 
 
 def generate_autosummary_content(name: str, obj: Any, parent: Any,
                                  template: AutosummaryRenderer, template_name: str,
                                  imported_members: bool, app: Any,
                                  recursive: bool, context: Dict,
-                                 modname: str = None, qualname: str = None) -> str:
+                                 modname: Optional[str] = None,
+                                 qualname: Optional[str] = None) -> str:
     doc = get_documenter(app, obj, parent)
 
     def skip_member(obj: Any, name: str, objtype: str) -> bool:
@@ -245,7 +232,7 @@
 
     def get_module_members(obj: Any) -> Dict[str, Any]:
         members = {}
-        for name in dir(obj):
+        for name in members_of(obj, app.config):
             try:
                 members[name] = safe_getattr(obj, name)
             except AttributeError:
@@ -301,7 +288,7 @@
 
     def get_modules(obj: Any) -> Tuple[List[str], List[str]]:
         items: List[str] = []
-        for _, modname, ispkg in pkgutil.iter_modules(obj.__path__):
+        for _, modname, _ispkg in pkgutil.iter_modules(obj.__path__):
             fullname = name + '.' + modname
             try:
                 module = import_module(fullname)
@@ -365,20 +352,11 @@
         return template.render(doc.objtype, ns)
 
 
-def generate_autosummary_docs(sources: List[str], output_dir: str = None,
-                              suffix: str = '.rst', base_path: str = None,
-                              builder: Builder = None, template_dir: str = None,
+def generate_autosummary_docs(sources: List[str], output_dir: Optional[str] = None,
+                              suffix: str = '.rst', base_path: Optional[str] = None,
                               imported_members: bool = False, app: Any = None,
                               overwrite: bool = True, encoding: str = 'utf-8') -> None:
-    if builder:
-        warnings.warn('builder argument for generate_autosummary_docs() is deprecated.',
-                      RemovedInSphinx50Warning, stacklevel=2)
-
-    if template_dir:
-        warnings.warn('template_dir argument for generate_autosummary_docs() is deprecated.',
-                      RemovedInSphinx50Warning, stacklevel=2)
-
-    showed_sources = list(sorted(sources))
+    showed_sources = sorted(sources)
     if len(showed_sources) > 20:
         showed_sources = showed_sources[:10] + ['...'] + showed_sources[-10:]
     logger.info(__('[autosummary] generating autosummary for: %s') %
@@ -416,13 +394,20 @@
         try:
             name, obj, parent, modname = import_by_name(entry.name)
             qualname = name.replace(modname + ".", "")
-        except ImportError as e:
+        except ImportExceptionGroup as exc:
             try:
-                # try to importl as an instance attribute
+                # try to import as an instance attribute
                 name, obj, parent, modname = import_ivar_by_name(entry.name)
                 qualname = name.replace(modname + ".", "")
-            except ImportError:
-                logger.warning(__('[autosummary] failed to import %r: %s') % (entry.name, e))
+            except ImportError as exc2:
+                if exc2.__cause__:
+                    exceptions: List[BaseException] = exc.exceptions + [exc2.__cause__]
+                else:
+                    exceptions = exc.exceptions + [exc2]
+
+                errors = list({"* %s: %s" % (type(e).__name__, e) for e in exceptions})
+                logger.warning(__('[autosummary] failed to import %s.\nPossible hints:\n%s'),
+                               entry.name, '\n'.join(errors))
                 continue
 
         context: Dict[str, Any] = {}
@@ -453,7 +438,6 @@
     if new_files:
         generate_autosummary_docs(new_files, output_dir=output_dir,
                                   suffix=suffix, base_path=base_path,
-                                  builder=builder, template_dir=template_dir,
                                   imported_members=imported_members, app=app,
                                   overwrite=overwrite)
 
@@ -473,32 +457,31 @@
     return documented
 
 
-def find_autosummary_in_docstring(name: str, module: str = None, filename: str = None
-                                  ) -> List[AutosummaryEntry]:
+def find_autosummary_in_docstring(
+    name: str, filename: Optional[str] = None
+) -> List[AutosummaryEntry]:
     """Find out what items are documented in the given object's docstring.
 
     See `find_autosummary_in_lines`.
     """
-    if module:
-        warnings.warn('module argument for find_autosummary_in_docstring() is deprecated.',
-                      RemovedInSphinx50Warning, stacklevel=2)
-
     try:
         real_name, obj, parent, modname = import_by_name(name)
         lines = pydoc.getdoc(obj).splitlines()
         return find_autosummary_in_lines(lines, module=name, filename=filename)
     except AttributeError:
         pass
-    except ImportError as e:
-        print("Failed to import '%s': %s" % (name, e))
+    except ImportExceptionGroup as exc:
+        errors = list({"* %s: %s" % (type(e).__name__, e) for e in exc.exceptions})
+        print('Failed to import %s.\nPossible hints:\n%s' % (name, '\n'.join(errors)))
     except SystemExit:
         print("Failed to import '%s'; the module executes module level "
               "statement and it might call sys.exit()." % name)
     return []
 
 
-def find_autosummary_in_lines(lines: List[str], module: str = None, filename: str = None
-                              ) -> List[AutosummaryEntry]:
+def find_autosummary_in_lines(
+    lines: List[str], module: Optional[str] = None, filename: Optional[str] = None
+) -> List[AutosummaryEntry]:
     """Find out what items appear in autosummary:: directives in the
     given lines.
 
@@ -522,7 +505,7 @@
     documented: List[AutosummaryEntry] = []
 
     recursive = False
-    toctree: str = None
+    toctree: Optional[str] = None
     template = None
     current_module = module
     in_autosummary = False
@@ -630,6 +613,10 @@
                         dest='imported_members', default=False,
                         help=__('document imported members (default: '
                                 '%(default)s)'))
+    parser.add_argument('-a', '--respect-module-all', action='store_true',
+                        dest='respect_module_all', default=False,
+                        help=__('document exactly the members in module __all__ attribute. '
+                                '(default: %(default)s)'))
 
     return parser
 
@@ -646,6 +633,7 @@
 
     if args.templates:
         app.config.templates_path.append(path.abspath(args.templates))
+    app.config.autosummary_ignore_module_all = not args.respect_module_all  # type: ignore
 
     generate_autosummary_docs(args.source_file, args.output_dir,
                               '.' + args.suffix,
('sphinx/ext/autosummary', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,55 +1,49 @@
-"""
-    sphinx.ext.autosummary
-    ~~~~~~~~~~~~~~~~~~~~~~
-
-    Sphinx extension that adds an autosummary:: directive, which can be
-    used to generate function/method/attribute/etc. summary lists, similar
-    to those output eg. by Epydoc and other API doc generation tools.
-
-    An :autolink: role is also provided.
-
-    autosummary directive
-    ---------------------
-
-    The autosummary directive has the form::
-
-        .. autosummary::
-           :nosignatures:
-           :toctree: generated/
-
-           module.function_1
-           module.function_2
-           ...
-
-    and it generates an output table (containing signatures, optionally)
-
-        ========================  =============================================
-        module.function_1(args)   Summary line from the docstring of function_1
-        module.function_2(args)   Summary line from the docstring
-        ...
-        ========================  =============================================
-
-    If the :toctree: option is specified, files matching the function names
-    are inserted to the toctree with the given prefix:
-
-        generated/module.function_1
-        generated/module.function_2
-        ...
-
-    Note: The file names contain the module:: or currentmodule:: prefixes.
-
-    .. seealso:: autosummary_generate.py
-
-
-    autolink role
-    -------------
-
-    The autolink role functions as ``:obj:`` when the name referred can be
-    resolved to a Python object, and otherwise it becomes simple emphasis.
-    This can be used as the default role to make links 'smart'.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
+"""Extension that adds an autosummary:: directive.
+
+The directive can be used to generate function/method/attribute/etc. summary
+lists, similar to those output eg. by Epydoc and other API doc generation tools.
+
+An :autolink: role is also provided.
+
+autosummary directive
+---------------------
+
+The autosummary directive has the form::
+
+    .. autosummary::
+       :nosignatures:
+       :toctree: generated/
+
+       module.function_1
+       module.function_2
+       ...
+
+and it generates an output table (containing signatures, optionally)
+
+    ========================  =============================================
+    module.function_1(args)   Summary line from the docstring of function_1
+    module.function_2(args)   Summary line from the docstring
+    ...
+    ========================  =============================================
+
+If the :toctree: option is specified, files matching the function names
+are inserted to the toctree with the given prefix:
+
+    generated/module.function_1
+    generated/module.function_2
+    ...
+
+Note: The file names contain the module:: or currentmodule:: prefixes.
+
+.. seealso:: autosummary_generate.py
+
+
+autolink role
+-------------
+
+The autolink role functions as ``:obj:`` when the name referred can be
+resolved to a Python object, and otherwise it becomes simple emphasis.
+This can be used as the default role to make links 'smart'.
 """
 
 import inspect
@@ -61,10 +55,10 @@
 from inspect import Parameter
 from os import path
 from types import ModuleType
-from typing import Any, Dict, List, Optional, Tuple, Type, cast
+from typing import Any, Dict, List, Optional, Sequence, Tuple, Type, cast
 
 from docutils import nodes
-from docutils.nodes import Element, Node, system_message
+from docutils.nodes import Node, system_message
 from docutils.parsers.rst import directives
 from docutils.parsers.rst.states import RSTStateMachine, Struct, state_classes
 from docutils.statemachine import StringList
@@ -73,14 +67,14 @@
 from sphinx import addnodes
 from sphinx.application import Sphinx
 from sphinx.config import Config
-from sphinx.deprecation import (RemovedInSphinx50Warning, RemovedInSphinx60Warning,
+from sphinx.deprecation import (RemovedInSphinx60Warning, RemovedInSphinx70Warning,
                                 deprecated_alias)
 from sphinx.environment import BuildEnvironment
-from sphinx.environment.adapters.toctree import TocTree
 from sphinx.ext.autodoc import INSTANCEATTR, Documenter
 from sphinx.ext.autodoc.directive import DocumenterBridge, Options
 from sphinx.ext.autodoc.importer import import_module
 from sphinx.ext.autodoc.mock import mock
+from sphinx.extension import Extension
 from sphinx.locale import __
 from sphinx.project import Project
 from sphinx.pycode import ModuleAnalyzer, PycodeError
@@ -106,32 +100,6 @@
 
 class autosummary_toc(nodes.comment):
     pass
-
-
-def process_autosummary_toc(app: Sphinx, doctree: nodes.document) -> None:
-    """Insert items described in autosummary:: to the TOC tree, but do
-    not generate the toctree:: list.
-    """
-    warnings.warn('process_autosummary_toc() is deprecated',
-                  RemovedInSphinx50Warning, stacklevel=2)
-    env = app.builder.env
-    crawled = {}
-
-    def crawl_toc(node: Element, depth: int = 1) -> None:
-        crawled[node] = True
-        for j, subnode in enumerate(node):
-            try:
-                if (isinstance(subnode, autosummary_toc) and
-                        isinstance(subnode[0], addnodes.toctree)):
-                    TocTree(env).note(env.docname, subnode[0])
-                    continue
-            except IndexError:
-                continue
-            if not isinstance(subnode, nodes.section):
-                continue
-            if subnode not in crawled:
-                crawl_toc(subnode, depth + 1)
-    crawl_toc(doctree)
 
 
 def autosummary_toc_visit_html(self: nodes.NodeVisitor, node: autosummary_toc) -> None:
@@ -178,10 +146,10 @@
 
 
 class FakeApplication:
-    def __init__(self):
+    def __init__(self) -> None:
         self.doctreedir = None
         self.events = None
-        self.extensions = {}
+        self.extensions: Dict[str, Extension] = {}
         self.srcdir = None
         self.config = Config()
         self.project = Project(None, None)
@@ -271,12 +239,12 @@
             docnames = []
             excluded = Matcher(self.config.exclude_patterns)
             filename_map = self.config.autosummary_filename_map
-            for name, sig, summary, real_name in items:
+            for _name, _sig, _summary, real_name in items:
                 real_name = filename_map.get(real_name, real_name)
                 docname = posixpath.join(tree_prefix, real_name)
                 docname = posixpath.normpath(posixpath.join(dirname, docname))
                 if docname not in self.env.found_docs:
-                    if excluded(self.env.doc2path(docname, None)):
+                    if excluded(self.env.doc2path(docname, False)):
                         msg = __('autosummary references excluded document %r. Ignored.')
                     else:
                         msg = __('autosummary: stub file not found %r. '
@@ -303,18 +271,23 @@
 
         return nodes
 
-    def import_by_name(self, name: str, prefixes: List[str]) -> Tuple[str, Any, Any, str]:
+    def import_by_name(
+        self, name: str, prefixes: List[Optional[str]]
+    ) -> Tuple[str, Any, Any, str]:
         with mock(self.config.autosummary_mock_imports):
             try:
                 return import_by_name(name, prefixes)
-            except ImportError as exc:
+            except ImportExceptionGroup as exc:
                 # check existence of instance attribute
                 try:
                     return import_ivar_by_name(name, prefixes)
-                except ImportError:
-                    pass
-
-                raise exc  # re-raise ImportError if instance attribute not found
+                except ImportError as exc2:
+                    if exc2.__cause__:
+                        errors: List[BaseException] = exc.exceptions + [exc2.__cause__]
+                    else:
+                        errors = exc.exceptions + [exc2]
+
+                    raise ImportExceptionGroup(exc.args[0], errors)
 
     def create_documenter(self, app: Sphinx, obj: Any,
                           parent: Any, full_name: str) -> "Documenter":
@@ -344,9 +317,10 @@
 
             try:
                 real_name, obj, parent, modname = self.import_by_name(name, prefixes=prefixes)
-            except ImportError:
-                logger.warning(__('autosummary: failed to import %s'), name,
-                               location=self.get_location())
+            except ImportExceptionGroup as exc:
+                errors = list({"* %s: %s" % (type(e).__name__, e) for e in exc.exceptions})
+                logger.warning(__('autosummary: failed to import %s.\nPossible hints:\n%s'),
+                               name, '\n'.join(errors), location=self.get_location())
                 continue
 
             self.bridge.result = StringList()  # initialize for each documenter
@@ -368,8 +342,6 @@
                                location=self.get_location())
                 items.append((display_name, '', '', real_name))
                 continue
-            if documenter.options.members and not documenter.check_module():
-                continue
 
             # try to also get a source code analyzer for attribute docs
             try:
@@ -415,7 +387,7 @@
         table_spec['spec'] = r'\X{1}{2}\X{1}{2}'
 
         table = autosummary_table('')
-        real_table = nodes.table('', classes=['longtable'])
+        real_table = nodes.table('', classes=['autosummary longtable'])
         table.append(real_table)
         group = nodes.tgroup('', cols=2)
         real_table.append(group)
@@ -444,9 +416,9 @@
         for name, sig, summary, real_name in items:
             qualifier = 'obj'
             if 'nosignatures' not in self.options:
-                col1 = ':%s:`%s <%s>`\\ %s' % (qualifier, name, real_name, rst.escape(sig))
+                col1 = ':py:%s:`%s <%s>`\\ %s' % (qualifier, name, real_name, rst.escape(sig))
             else:
-                col1 = ':%s:`%s <%s>`' % (qualifier, name, real_name)
+                col1 = ':py:%s:`%s <%s>`' % (qualifier, name, real_name)
             col2 = summary
             append_row(col1, col2)
 
@@ -583,7 +555,7 @@
                 node = parse(doc, document.settings)
                 if summary.endswith(WELL_KNOWN_ABBREVIATIONS):
                     pass
-                elif not node.traverse(nodes.system_message):
+                elif not any(node.findall(nodes.system_message)):
                     # considered as that splitting by period does not break inline markups
                     break
 
@@ -608,7 +580,7 @@
 
     n_chars = 0
     n_items = 0
-    for j, item in enumerate(items):
+    for item in items:
         n_chars += len(item) + len(sep)
         if n_chars < max_chars - len(overflow_marker):
             n_items += 1
@@ -620,7 +592,19 @@
 
 # -- Importing items -----------------------------------------------------------
 
-def get_import_prefixes_from_env(env: BuildEnvironment) -> List[str]:
+
+class ImportExceptionGroup(Exception):
+    """Exceptions raised during importing the target objects.
+
+    It contains an error messages and a list of exceptions as its arguments.
+    """
+
+    def __init__(self, message: Optional[str], exceptions: Sequence[BaseException]):
+        super().__init__(message)
+        self.exceptions = list(exceptions)
+
+
+def get_import_prefixes_from_env(env: BuildEnvironment) -> List[Optional[str]]:
     """
     Obtain current Python import prefixes (for `import_by_name`)
     from ``document.env``
@@ -641,26 +625,45 @@
     return prefixes
 
 
-def import_by_name(name: str, prefixes: List[str] = [None]) -> Tuple[str, Any, Any, str]:
+def import_by_name(
+    name: str, prefixes: List[Optional[str]] = [None], grouped_exception: bool = True
+) -> Tuple[str, Any, Any, str]:
     """Import a Python object that has the given *name*, under one of the
     *prefixes*.  The first name that succeeds is used.
     """
+    if grouped_exception is False:
+        warnings.warn('Using grouped_exception keyword for import_by_name() is not '
+                      'recommended. It will be removed at v7.0.  Therefore you should '
+                      'catch ImportExceptionGroup exception instead of ImportError.',
+                      RemovedInSphinx70Warning, stacklevel=2)
+
     tried = []
+    errors: List[ImportExceptionGroup] = []
     for prefix in prefixes:
         try:
             if prefix:
                 prefixed_name = '.'.join([prefix, name])
             else:
                 prefixed_name = name
-            obj, parent, modname = _import_by_name(prefixed_name)
+            obj, parent, modname = _import_by_name(prefixed_name, grouped_exception)
             return prefixed_name, obj, parent, modname
         except ImportError:
             tried.append(prefixed_name)
-    raise ImportError('no module named %s' % ' or '.join(tried))
-
-
-def _import_by_name(name: str) -> Tuple[Any, Any, str]:
+        except ImportExceptionGroup as exc:
+            tried.append(prefixed_name)
+            errors.append(exc)
+
+    if grouped_exception:
+        exceptions: List[BaseException] = sum((e.exceptions for e in errors), [])
+        raise ImportExceptionGroup('no module named %s' % ' or '.join(tried), exceptions)
+    else:
+        raise ImportError('no module named %s' % ' or '.join(tried))
+
+
+def _import_by_name(name: str, grouped_exception: bool = True) -> Tuple[Any, Any, str]:
     """Import a Python object given its full name."""
+    errors: List[BaseException] = []
+
     try:
         name_parts = name.split('.')
 
@@ -670,8 +673,8 @@
             try:
                 mod = import_module(modname)
                 return getattr(mod, name_parts[-1]), mod, modname
-            except (ImportError, IndexError, AttributeError):
-                pass
+            except (ImportError, IndexError, AttributeError) as exc:
+                errors.append(exc.__cause__ or exc)
 
         # ... then as MODNAME, MODNAME.OBJ1, MODNAME.OBJ1.OBJ2, ...
         last_j = 0
@@ -681,8 +684,8 @@
             modname = '.'.join(name_parts[:j])
             try:
                 import_module(modname)
-            except ImportError:
-                continue
+            except ImportError as exc:
+                errors.append(exc.__cause__ or exc)
 
             if modname in sys.modules:
                 break
@@ -696,25 +699,32 @@
             return obj, parent, modname
         else:
             return sys.modules[modname], None, modname
-    except (ValueError, ImportError, AttributeError, KeyError) as e:
-        raise ImportError(*e.args) from e
-
-
-def import_ivar_by_name(name: str, prefixes: List[str] = [None]) -> Tuple[str, Any, Any, str]:
+    except (ValueError, ImportError, AttributeError, KeyError) as exc:
+        errors.append(exc)
+        if grouped_exception:
+            raise ImportExceptionGroup('', errors)
+        else:
+            raise ImportError(*exc.args) from exc
+
+
+def import_ivar_by_name(name: str, prefixes: List[Optional[str]] = [None],
+                        grouped_exception: bool = True) -> Tuple[str, Any, Any, str]:
     """Import an instance variable that has the given *name*, under one of the
     *prefixes*.  The first name that succeeds is used.
     """
     try:
         name, attr = name.rsplit(".", 1)
-        real_name, obj, parent, modname = import_by_name(name, prefixes)
+        real_name, obj, parent, modname = import_by_name(name, prefixes, grouped_exception)
         qualname = real_name.replace(modname + ".", "")
         analyzer = ModuleAnalyzer.for_module(getattr(obj, '__module__', modname))
         analyzer.analyze()
         # check for presence in `annotations` to include dataclass attributes
         if (qualname, attr) in analyzer.attr_docs or (qualname, attr) in analyzer.annotations:
             return real_name + "." + attr, INSTANCEATTR, obj, modname
-    except (ImportError, ValueError, PycodeError):
-        pass
+    except (ImportError, ValueError, PycodeError) as exc:
+        raise ImportError from exc
+    except ImportExceptionGroup:
+        raise  # pass through it as is
 
     raise ImportError
 
@@ -740,7 +750,7 @@
             # try to import object by name
             prefixes = get_import_prefixes_from_env(self.env)
             import_by_name(pending_xref['reftarget'], prefixes)
-        except ImportError:
+        except ImportExceptionGroup:
             literal = cast(nodes.literal, pending_xref[0])
             objects[0] = nodes.emphasis(self.rawtext, literal.astext(),
                                         classes=literal['classes'])
@@ -748,14 +758,14 @@
         return objects, errors
 
 
-def get_rst_suffix(app: Sphinx) -> str:
+def get_rst_suffix(app: Sphinx) -> Optional[str]:
     def get_supported_format(suffix: str) -> Tuple[str, ...]:
         parser_class = app.registry.get_source_parsers().get(suffix)
         if parser_class is None:
             return ('restructuredtext',)
         return parser_class.supported
 
-    suffix: str = None
+    suffix = None
     for suffix in app.config.source_suffix:
         if 'restructuredtext' in get_supported_format(suffix):
             return suffix
@@ -768,7 +778,7 @@
 
     if genfiles is True:
         env = app.builder.env
-        genfiles = [env.doc2path(x, base=None) for x in env.found_docs
+        genfiles = [env.doc2path(x, base=False) for x in env.found_docs
                     if os.path.isfile(env.doc2path(x))]
     elif genfiles is False:
         pass
@@ -826,5 +836,6 @@
     app.add_config_value('autosummary_mock_imports',
                          lambda config: config.autodoc_mock_imports, 'env')
     app.add_config_value('autosummary_imported_members', [], False, [bool])
+    app.add_config_value('autosummary_ignore_module_all', True, 'env', bool)
 
     return {'version': sphinx.__display_version__, 'parallel_read_safe': True}
('sphinx/pycode', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,16 +1,7 @@
-"""
-    sphinx.pycode
-    ~~~~~~~~~~~~~
-
-    Utilities parsing and analyzing Python code.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Utilities parsing and analyzing Python code."""
 
 import re
 import tokenize
-import warnings
 from collections import OrderedDict
 from importlib import import_module
 from inspect import Signature
@@ -19,7 +10,6 @@
 from typing import IO, Any, Dict, List, Optional, Tuple
 from zipfile import ZipFile
 
-from sphinx.deprecation import RemovedInSphinx50Warning
 from sphinx.errors import PycodeError
 from sphinx.pycode.parser import Parser
 
@@ -143,12 +133,6 @@
 
         self._analyzed = False
 
-    def parse(self) -> None:
-        """Parse the source code."""
-        warnings.warn('ModuleAnalyzer.parse() is deprecated.',
-                      RemovedInSphinx50Warning, stacklevel=2)
-        self.analyze()
-
     def analyze(self) -> None:
         """Analyze the source code."""
         if self._analyzed:
('sphinx/pycode', 'parser.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.pycode.parser
-    ~~~~~~~~~~~~~~~~~~~~
-
-    Utilities parsing and analyzing Python code.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Utilities parsing and analyzing Python code."""
 import inspect
 import itertools
 import re
@@ -37,7 +29,7 @@
         return [node.target]  # type: ignore
 
 
-def get_lvar_names(node: ast.AST, self: ast.arg = None) -> List[str]:
+def get_lvar_names(node: ast.AST, self: Optional[ast.arg] = None) -> List[str]:
     """Convert assignment-AST to variable names.
 
     This raises `TypeError` if the assignment does not create new variable::
@@ -136,7 +128,7 @@
         """Returns specified line."""
         return self.buffers[lineno - 1]
 
-    def fetch_token(self) -> Token:
+    def fetch_token(self) -> Optional[Token]:
         """Fetch the next token from source code.
 
         Returns ``None`` if sequence finished.
@@ -312,6 +304,10 @@
         """Returns the name of the first argument if in a function."""
         if self.current_function and self.current_function.args.args:
             return self.current_function.args.args[0]
+        elif (self.current_function and
+              getattr(self.current_function.args, 'posonlyargs', None)):
+            # for py38+
+            return self.current_function.args.posonlyargs[0]  # type: ignore
         else:
             return None
 
('sphinx/pycode', 'ast.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.pycode.ast
-    ~~~~~~~~~~~~~~~~~
-
-    Helpers for AST (Abstract Syntax Tree).
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Helpers for AST (Abstract Syntax Tree)."""
 
 import sys
 from typing import Dict, List, Optional, Type, overload
@@ -149,6 +141,9 @@
         return "%s.%s" % (self.visit(node.value), node.attr)
 
     def visit_BinOp(self, node: ast.BinOp) -> str:
+        # Special case ``**`` to not have surrounding spaces.
+        if isinstance(node.op, ast.Pow):
+            return "".join(map(self.visit, (node.left, node.op, node.right)))
         return " ".join(self.visit(e) for e in [node.left, node.op, node.right])
 
     def visit_BoolOp(self, node: ast.BoolOp) -> str:
@@ -210,7 +205,11 @@
             return "%s[%s]" % (self.visit(node.value), self.visit(node.slice))
 
     def visit_UnaryOp(self, node: ast.UnaryOp) -> str:
-        return "%s %s" % (self.visit(node.op), self.visit(node.operand))
+        # UnaryOp is one of {UAdd, USub, Invert, Not}, which refer to ``+x``,
+        # ``-x``, ``~x``, and ``not x``. Only Not needs a space.
+        if isinstance(node.op, ast.Not):
+            return "%s %s" % (self.visit(node.op), self.visit(node.operand))
+        return "%s%s" % (self.visit(node.op), self.visit(node.operand))
 
     def visit_Tuple(self, node: ast.Tuple) -> str:
         if len(node.elts) == 0:
('sphinx/search', 'ja.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.search.ja
-    ~~~~~~~~~~~~~~~~
-
-    Japanese search language: includes routine to split words.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Japanese search language: includes routine to split words."""
 
 # Python Version of TinySegmenter
 # (http://chasen.org/~taku/software/TinySegmenter/)
('sphinx/search', 'pt.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.search.pt
-    ~~~~~~~~~~~~~~~~
-
-    Portuguese search language: includes the JS Portuguese stemmer.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Portuguese search language: includes the JS Portuguese stemmer."""
 
 from typing import Dict
 
('sphinx/search', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,26 +1,20 @@
-"""
-    sphinx.search
-    ~~~~~~~~~~~~~
-
-    Create a full-text search index for offline search.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Create a full-text search index for offline search."""
 import html
+import json
 import pickle
 import re
+import warnings
 from importlib import import_module
 from os import path
-from typing import IO, Any, Dict, Iterable, List, Optional, Set, Tuple, Type
+from typing import IO, Any, Dict, Iterable, List, Optional, Set, Tuple, Type, Union
 
 from docutils import nodes
-from docutils.nodes import Node
+from docutils.nodes import Element, Node
 
 from sphinx import addnodes, package_dir
+from sphinx.deprecation import RemovedInSphinx70Warning
 from sphinx.environment import BuildEnvironment
-from sphinx.search.jssplitter import splitter_code
-from sphinx.util import jsdump
+from sphinx.util import split_into
 
 
 class SearchLanguage:
@@ -53,11 +47,11 @@
        This class is used to preprocess search word which Sphinx HTML readers
        type, before searching index. Default implementation does nothing.
     """
-    lang: str = None
-    language_name: str = None
+    lang: Optional[str] = None
+    language_name: Optional[str] = None
     stopwords: Set[str] = set()
-    js_splitter_code: str = None
-    js_stemmer_rawcode: str = None
+    js_splitter_code: str = ""
+    js_stemmer_rawcode: Optional[str] = None
     js_stemmer_code = """
 /**
  * Dummy stemmer for languages without stemming rules.
@@ -132,7 +126,7 @@
 
 
 # maps language name to module.class or directly a class
-languages: Dict[str, Any] = {
+languages: Dict[str, Union[str, Type[SearchLanguage]]] = {
     'da': 'sphinx.search.da.SearchDanish',
     'de': 'sphinx.search.de.SearchGerman',
     'en': SearchEnglish,
@@ -163,14 +157,14 @@
     SUFFIX = ')'
 
     def dumps(self, data: Any) -> str:
-        return self.PREFIX + jsdump.dumps(data) + self.SUFFIX
+        return self.PREFIX + json.dumps(data) + self.SUFFIX
 
     def loads(self, s: str) -> Any:
         data = s[len(self.PREFIX):-len(self.SUFFIX)]
         if not data or not s.startswith(self.PREFIX) or not \
            s.endswith(self.SUFFIX):
             raise ValueError('invalid data')
-        return jsdump.loads(data)
+        return json.loads(data)
 
     def dump(self, data: Any, f: IO) -> None:
         f.write(self.dumps(data))
@@ -190,11 +184,13 @@
     def __init__(self, document: nodes.document, lang: SearchLanguage) -> None:
         super().__init__(document)
         self.found_words: List[str] = []
+        self.found_titles: List[Tuple[str, str]] = []
         self.found_title_words: List[str] = []
         self.lang = lang
 
-    def is_meta_keywords(self, node: addnodes.meta) -> bool:
-        if isinstance(node, addnodes.meta) and node.get('name') == 'keywords':
+    def is_meta_keywords(self, node: Element) -> bool:
+        if (isinstance(node, (addnodes.meta, addnodes.docutils_meta)) and
+                node.get('name') == 'keywords'):
             meta_lang = node.get('lang')
             if meta_lang is None:  # lang not specified
                 return True
@@ -219,8 +215,11 @@
         elif isinstance(node, nodes.Text):
             self.found_words.extend(self.lang.split(node.astext()))
         elif isinstance(node, nodes.title):
-            self.found_title_words.extend(self.lang.split(node.astext()))
-        elif isinstance(node, addnodes.meta) and self.is_meta_keywords(node):
+            title = node.astext()
+            ids = node.parent['ids']
+            self.found_titles.append((title, ids[0] if ids else None))
+            self.found_title_words.extend(self.lang.split(title))
+        elif isinstance(node, Element) and self.is_meta_keywords(node):
             keywords = node['content']
             keywords = [keyword.strip() for keyword in keywords.split(',')]
             self.found_words.extend(keywords)
@@ -232,7 +231,7 @@
     passed to the `feed` method.
     """
     formats = {
-        'jsdump':   jsdump,
+        'json':     json,
         'pickle':   pickle
     }
 
@@ -243,12 +242,14 @@
         self._mapping: Dict[str, Set[str]] = {}     # stemmed word -> set(docname)
         # stemmed words in titles -> set(docname)
         self._title_mapping: Dict[str, Set[str]] = {}
+        self._all_titles: Dict[str, List[Tuple[str, str]]] = {}  # docname -> all titles
+        self._index_entries: Dict[str, List[Tuple[str, str, str]]] = {}  # docname -> index entry
         self._stem_cache: Dict[str, str] = {}       # word -> stemmed word
         self._objtypes: Dict[Tuple[str, str], int] = {}     # objtype -> index
         # objtype index -> (domain, type, objname (localized))
         self._objnames: Dict[int, Tuple[str, str, str]] = {}
         # add language-specific SearchLanguage instance
-        lang_class: Type[SearchLanguage] = languages.get(lang)
+        lang_class = languages.get(lang)
 
         # fallback; try again with language-code
         if lang_class is None and '_' in lang:
@@ -258,8 +259,8 @@
             self.lang: SearchLanguage = SearchEnglish(options)
         elif isinstance(lang_class, str):
             module, classname = lang_class.rsplit('.', 1)
-            lang_class = getattr(import_module(module), classname)
-            self.lang = lang_class(options)
+            lang_class: Type[SearchLanguage] = getattr(import_module(module), classname)  # type: ignore[no-redef]
+            self.lang = lang_class(options)  # type: ignore[operator]
         else:
             # it's directly a class (e.g. added by app.add_search_language)
             self.lang = lang_class(options)
@@ -269,11 +270,15 @@
                 self.js_scorer_code = fp.read().decode()
         else:
             self.js_scorer_code = ''
-        self.js_splitter_code = splitter_code
+        self.js_splitter_code = ""
 
     def load(self, stream: IO, format: Any) -> None:
         """Reconstruct from frozen data."""
-        if isinstance(format, str):
+        if format == "jsdump":
+            warnings.warn("format=jsdump is deprecated, use json instead",
+                          RemovedInSphinx70Warning, stacklevel=2)
+            format = self.formats["json"]
+        elif isinstance(format, str):
             format = self.formats[format]
         frozen = format.load(stream)
         # if an old index is present, we treat it as not existing.
@@ -283,6 +288,13 @@
         index2fn = frozen['docnames']
         self._filenames = dict(zip(index2fn, frozen['filenames']))
         self._titles = dict(zip(index2fn, frozen['titles']))
+        self._all_titles = {}
+
+        for docname in self._titles.keys():
+            self._all_titles[docname] = []
+        for title, doc_tuples in frozen['alltitles'].items():
+            for doc, titleid in doc_tuples:
+                self._all_titles[index2fn[doc]].append((title, titleid))
 
         def load_terms(mapping: Dict[str, Any]) -> Dict[str, Set[str]]:
             rv = {}
@@ -299,13 +311,17 @@
 
     def dump(self, stream: IO, format: Any) -> None:
         """Dump the frozen index to a stream."""
-        if isinstance(format, str):
+        if format == "jsdump":
+            warnings.warn("format=jsdump is deprecated, use json instead",
+                          RemovedInSphinx70Warning, stacklevel=2)
+            format = self.formats["json"]
+        elif isinstance(format, str):
             format = self.formats[format]
         format.dump(self.freeze(), stream)
 
     def get_objects(self, fn2index: Dict[str, int]
-                    ) -> Dict[str, Dict[str, Tuple[int, int, int, str]]]:
-        rv: Dict[str, Dict[str, Tuple[int, int, int, str]]] = {}
+                    ) -> Dict[str, List[Tuple[int, int, int, str, str]]]:
+        rv: Dict[str, List[Tuple[int, int, int, str, str]]] = {}
         otypes = self._objtypes
         onames = self._objnames
         for domainname, domain in sorted(self.env.domains.items()):
@@ -318,7 +334,7 @@
                 fullname = html.escape(fullname)
                 dispname = html.escape(dispname)
                 prefix, _, name = dispname.rpartition('.')
-                pdict = rv.setdefault(prefix, {})
+                plist = rv.setdefault(prefix, [])
                 try:
                     typeindex = otypes[domainname, type]
                 except KeyError:
@@ -337,7 +353,7 @@
                     shortanchor = '-'
                 else:
                     shortanchor = anchor
-                pdict[name] = (fn2index[docname], typeindex, prio, shortanchor)
+                plist.append((fn2index[docname], typeindex, prio, shortanchor, name))
         return rv
 
     def get_terms(self, fn2index: Dict) -> Tuple[Dict[str, List[str]], Dict[str, List[str]]]:
@@ -362,9 +378,21 @@
         objects = self.get_objects(fn2index)  # populates _objtypes
         objtypes = {v: k[0] + ':' + k[1] for (k, v) in self._objtypes.items()}
         objnames = self._objnames
+
+        alltitles: Dict[str, List[Tuple[int, str]]] = {}
+        for docname, titlelist in self._all_titles.items():
+            for title, titleid in titlelist:
+                alltitles.setdefault(title, []).append((fn2index[docname], titleid))
+
+        index_entries: Dict[str, List[Tuple[int, str]]] = {}
+        for docname, entries in self._index_entries.items():
+            for entry, entry_id, main_entry in entries:
+                index_entries.setdefault(entry.lower(), []).append((fn2index[docname], entry_id))
+
         return dict(docnames=docnames, filenames=filenames, titles=titles, terms=terms,
                     objects=objects, objtypes=objtypes, objnames=objnames,
-                    titleterms=title_terms, envversion=self.env.version)
+                    titleterms=title_terms, envversion=self.env.version,
+                    alltitles=alltitles, indexentries=index_entries)
 
     def label(self) -> str:
         return "%s (code: %s)" % (self.lang.language_name, self.lang.lang)
@@ -372,13 +400,16 @@
     def prune(self, docnames: Iterable[str]) -> None:
         """Remove data for all docnames not in the list."""
         new_titles = {}
+        new_alltitles = {}
         new_filenames = {}
         for docname in docnames:
             if docname in self._titles:
                 new_titles[docname] = self._titles[docname]
+                new_alltitles[docname] = self._all_titles[docname]
                 new_filenames[docname] = self._filenames[docname]
         self._titles = new_titles
         self._filenames = new_filenames
+        self._all_titles = new_alltitles
         for wordnames in self._mapping.values():
             wordnames.intersection_update(docnames)
         for wordnames in self._title_mapping.values():
@@ -401,6 +432,8 @@
                 return self._stem_cache[word]
         _filter = self.lang.word_filter
 
+        self._all_titles[docname] = visitor.found_titles
+
         for word in visitor.found_title_words:
             stemmed_word = stem(word)
             if _filter(stemmed_word):
@@ -417,6 +450,38 @@
             if _filter(stemmed_word) and not already_indexed:
                 self._mapping.setdefault(stemmed_word, set()).add(docname)
 
+        # find explicit entries within index directives
+        _index_entries: Set[Tuple[str, str, str]] = set()
+        for node in doctree.findall(addnodes.index):
+            for entry_type, value, tid, main, *index_key in node['entries']:
+                tid = tid or ''
+                try:
+                    if entry_type == 'single':
+                        try:
+                            entry, subentry = split_into(2, 'single', value)
+                        except ValueError:
+                            entry, = split_into(1, 'single', value)
+                            subentry = ''
+                        _index_entries.add((entry, tid, main))
+                        if subentry:
+                            _index_entries.add((subentry, tid, main))
+                    elif entry_type == 'pair':
+                        first, second = split_into(2, 'pair', value)
+                        _index_entries.add((first, tid, main))
+                        _index_entries.add((second, tid, main))
+                    elif entry_type == 'triple':
+                        first, second, third = split_into(3, 'triple', value)
+                        _index_entries.add((first, tid, main))
+                        _index_entries.add((second, tid, main))
+                        _index_entries.add((third, tid, main))
+                    elif entry_type in {'see', 'seealso'}:
+                        first, second = split_into(2, 'see', value)
+                        _index_entries.add((first, tid, main))
+                except ValueError:
+                    pass
+
+        self._index_entries[docname] = sorted(_index_entries)
+
     def context_for_searchtool(self) -> Dict[str, Any]:
         if self.lang.js_splitter_code:
             js_splitter_code = self.lang.js_splitter_code
@@ -425,7 +490,7 @@
 
         return {
             'search_language_stemming_code': self.get_js_stemmer_code(),
-            'search_language_stop_words': jsdump.dumps(sorted(self.lang.stopwords)),
+            'search_language_stop_words': json.dumps(sorted(self.lang.stopwords)),
             'search_scorer_tool': self.js_scorer_code,
             'search_word_splitter_code': js_splitter_code,
         }
@@ -447,9 +512,9 @@
         """Returns JS code that will be inserted into language_data.js."""
         if self.lang.js_stemmer_rawcode:
             js_dir = path.join(package_dir, 'search', 'minified-js')
-            with open(path.join(js_dir, 'base-stemmer.js')) as js_file:
+            with open(path.join(js_dir, 'base-stemmer.js'), encoding='utf-8') as js_file:
                 base_js = js_file.read()
-            with open(path.join(js_dir, self.lang.js_stemmer_rawcode)) as js_file:
+            with open(path.join(js_dir, self.lang.js_stemmer_rawcode), encoding='utf-8') as js_file:
                 language_js = js_file.read()
             return ('%s\n%s\nStemmer = %sStemmer;' %
                     (base_js, language_js, self.lang.language_name))
('sphinx/search', 'no.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.search.no
-    ~~~~~~~~~~~~~~~~
-
-    Norwegian search language: includes the JS Norwegian stemmer.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Norwegian search language: includes the JS Norwegian stemmer."""
 
 from typing import Dict
 
('sphinx/search', 'ru.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.search.ru
-    ~~~~~~~~~~~~~~~~
-
-    Russian search language: includes the JS Russian stemmer.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Russian search language: includes the JS Russian stemmer."""
 
 from typing import Dict
 
('sphinx/search', 'fi.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.search.fi
-    ~~~~~~~~~~~~~~~~
-
-    Finnish search language: includes the JS Finnish stemmer.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Finnish search language: includes the JS Finnish stemmer."""
 
 from typing import Dict
 
('sphinx/search', 'hu.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.search.hu
-    ~~~~~~~~~~~~~~~~
-
-    Hungarian search language: includes the JS Hungarian stemmer.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Hungarian search language: includes the JS Hungarian stemmer."""
 
 from typing import Dict
 
('sphinx/search', 'fr.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.search.fr
-    ~~~~~~~~~~~~~~~~
-
-    French search language: includes the JS French stemmer.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""French search language: includes the JS French stemmer."""
 
 from typing import Dict
 
('sphinx/search', 'nl.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.search.nl
-    ~~~~~~~~~~~~~~~~
-
-    Dutch search language: includes the JS porter stemmer.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Dutch search language: includes the JS porter stemmer."""
 
 from typing import Dict
 
('sphinx/search', 'zh.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,19 +1,12 @@
-"""
-    sphinx.search.zh
-    ~~~~~~~~~~~~~~~~
-
-    Chinese search language: includes routine to split words.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Chinese search language: includes routine to split words."""
 
 import os
 import re
 from typing import Dict, List
 
+import snowballstemmer
+
 from sphinx.search import SearchLanguage
-from sphinx.util.stemmer import get_stemmer
 
 try:
     import jieba
@@ -238,7 +231,7 @@
             if dict_path and os.path.isfile(dict_path):
                 jieba.load_userdict(dict_path)
 
-        self.stemmer = get_stemmer()
+        self.stemmer = snowballstemmer.stemmer('english')
 
     def split(self, input: str) -> List[str]:
         chinese: List[str] = []
@@ -260,8 +253,8 @@
         should_not_be_stemmed = (
             word in self.latin_terms and
             len(word) >= 3 and
-            len(self.stemmer.stem(word.lower())) < 3
+            len(self.stemmer.stemWord(word.lower())) < 3
         )
         if should_not_be_stemmed:
             return word.lower()
-        return self.stemmer.stem(word.lower())
+        return self.stemmer.stemWord(word.lower())
('sphinx/search', 'sv.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.search.sv
-    ~~~~~~~~~~~~~~~~
-
-    Swedish search language: includes the JS Swedish stemmer.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Swedish search language: includes the JS Swedish stemmer."""
 
 from typing import Dict
 
('sphinx/search', 'en.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,17 +1,10 @@
-"""
-    sphinx.search.en
-    ~~~~~~~~~~~~~~~~
-
-    English search language: includes the JS porter stemmer.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""English search language: includes the JS porter stemmer."""
 
 from typing import Dict
 
+import snowballstemmer
+
 from sphinx.search import SearchLanguage
-from sphinx.util.stemmer import get_stemmer
 
 english_stopwords = set("""
 a  and  are  as  at
@@ -219,7 +212,7 @@
     stopwords = english_stopwords
 
     def init(self, options: Dict) -> None:
-        self.stemmer = get_stemmer()
+        self.stemmer = snowballstemmer.stemmer('porter')
 
     def stem(self, word: str) -> str:
-        return self.stemmer.stem(word.lower())
+        return self.stemmer.stemWord(word.lower())
('sphinx/search', 'tr.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.search.tr
-    ~~~~~~~~~~~~~~~~
-
-    Turkish search language: includes the JS Turkish stemmer.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Turkish search language: includes the JS Turkish stemmer."""
 
 from typing import Dict, Set
 
('sphinx/search', 'ro.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.search.ro
-    ~~~~~~~~~~~~~~~~
-
-    Romanian search language: includes the JS Romanian stemmer.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Romanian search language: includes the JS Romanian stemmer."""
 
 from typing import Dict, Set
 
('sphinx/search', 'es.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.search.es
-    ~~~~~~~~~~~~~~~~
-
-    Spanish search language: includes the JS Spanish stemmer.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Spanish search language: includes the JS Spanish stemmer."""
 
 from typing import Dict
 
('sphinx/search', 'it.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.search.it
-    ~~~~~~~~~~~~~~~~
-
-    Italian search language: includes the JS Italian stemmer.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Italian search language: includes the JS Italian stemmer."""
 
 from typing import Dict
 
('sphinx/search', 'de.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.search.de
-    ~~~~~~~~~~~~~~~~
-
-    German search language: includes the JS German stemmer.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""German search language: includes the JS German stemmer."""
 
 from typing import Dict
 
('sphinx/search', 'da.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.search.da
-    ~~~~~~~~~~~~~~~~
-
-    Danish search language: includes the JS Danish stemmer.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Danish search language: includes the JS Danish stemmer."""
 
 from typing import Dict
 
('sphinx/transforms', 'references.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.transforms.references
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    Docutils transforms used by Sphinx.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Docutils transforms used by Sphinx."""
 
 from typing import TYPE_CHECKING, Any, Dict
 
('sphinx/transforms', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,17 +1,11 @@
-"""
-    sphinx.transforms
-    ~~~~~~~~~~~~~~~~~
-
-    Docutils transforms used by Sphinx when reading documents.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Docutils transforms used by Sphinx when reading documents."""
 
 import re
+import unicodedata
 import warnings
-from typing import TYPE_CHECKING, Any, Dict, Generator, List, Optional, Tuple
-
+from typing import TYPE_CHECKING, Any, Dict, Generator, List, Optional, Tuple, cast
+
+import docutils
 from docutils import nodes
 from docutils.nodes import Element, Node, Text
 from docutils.transforms import Transform, Transformer
@@ -24,7 +18,7 @@
 from sphinx.config import Config
 from sphinx.deprecation import RemovedInSphinx60Warning
 from sphinx.locale import _, __
-from sphinx.util import docutils, logging
+from sphinx.util import logging
 from sphinx.util.docutils import new_document
 from sphinx.util.i18n import format_date
 from sphinx.util.nodes import NodeMatcher, apply_source_workaround, is_smartquotable
@@ -107,7 +101,7 @@
     def apply(self, **kwargs: Any) -> None:
         # only handle those not otherwise defined in the document
         to_handle = default_substitutions - set(self.document.substitution_defs)
-        for ref in self.document.traverse(nodes.substitution_reference):
+        for ref in self.document.findall(nodes.substitution_reference):
             refname = ref['refname']
             if refname in to_handle:
                 text = self.config[refname]
@@ -115,7 +109,7 @@
                     # special handling: can also specify a strftime format
                     text = format_date(self.config.today_fmt or _('%b %d, %Y'),
                                        language=self.config.language)
-                ref.replace_self(nodes.Text(text, text))
+                ref.replace_self(nodes.Text(text))
 
 
 class MoveModuleTargets(SphinxTransform):
@@ -128,7 +122,7 @@
     default_priority = 210
 
     def apply(self, **kwargs: Any) -> None:
-        for node in self.document.traverse(nodes.target):
+        for node in list(self.document.findall(nodes.target)):
             if not node['ids']:
                 continue
             if ('ismod' in node and
@@ -147,12 +141,12 @@
 
     def apply(self, **kwargs: Any) -> None:
         # move doctest blocks out of blockquotes
-        for node in self.document.traverse(nodes.block_quote):
+        for node in self.document.findall(nodes.block_quote):
             if all(isinstance(child, nodes.doctest_block) for child
                    in node.children):
                 node.replace_self(node.children)
         # combine successive doctest blocks
-        # for node in self.document.traverse(nodes.doctest_block):
+        # for node in self.document.findall(nodes.doctest_block):
         #    if node not in node.parent.children:
         #        continue
         #    parindex = node.parent.index(node)
@@ -172,7 +166,7 @@
     def apply(self, **kwargs: Any) -> None:
         domain: StandardDomain = self.env.get_domain('std')
 
-        for node in self.document.traverse(nodes.Element):
+        for node in self.document.findall(nodes.Element):
             if (domain.is_enumerable_node(node) and
                     domain.get_numfig_title(node) is not None and
                     node['ids'] == []):
@@ -186,7 +180,7 @@
     default_priority = 261
 
     def apply(self, **kwargs: Any) -> None:
-        for node in self.document.traverse(nodes.section):
+        for node in self.document.findall(nodes.section):
             if len(node['ids']) > 1 and node['ids'][0].startswith('id'):
                 node['ids'] = node['ids'][1:] + [node['ids'][0]]
 
@@ -207,8 +201,8 @@
     default_priority = 10
 
     def apply(self, **kwargs: Any) -> None:
-        for node in self.document.traverse():  # type: Node
-            if isinstance(node, (nodes.TextElement, nodes.image)):
+        for node in self.document.findall():  # type: Node
+            if isinstance(node, (nodes.TextElement, nodes.image, nodes.topic)):
                 apply_source_workaround(node)
 
 
@@ -219,7 +213,7 @@
     default_priority = 210
 
     def apply(self, **kwargs: Any) -> None:
-        for node in self.document.traverse(addnodes.index):
+        for node in self.document.findall(addnodes.index):
             if 'entries' in node and any(len(entry) == 4 for entry in node['entries']):
                 msg = __('4 column based index found. '
                          'It might be a bug of extensions you use: %r') % node['entries']
@@ -244,7 +238,7 @@
         def is_translatable_node(node: Node) -> bool:
             return isinstance(node, tuple(target_nodes))
 
-        for node in self.document.traverse(is_translatable_node):  # type: Element
+        for node in self.document.findall(is_translatable_node):  # type: Element
             node['translatable'] = True
 
 
@@ -276,7 +270,7 @@
     default_priority = 500
 
     def apply(self, **kwargs: Any) -> None:
-        for node in self.document.traverse(nodes.doctest_block):
+        for node in self.document.findall(nodes.doctest_block):
             node['classes'].append('doctest')
 
 
@@ -293,7 +287,7 @@
 
     def apply(self, **kwargs: Any) -> None:
         matcher = NodeMatcher(nodes.table, nodes.figure)
-        for node in self.document.traverse(matcher):  # type: Element
+        for node in self.document.findall(matcher):  # type: Element
             node.setdefault('align', 'default')
 
 
@@ -303,7 +297,7 @@
 
     def apply(self, **kwargs: Any) -> None:
         filterlevel = 2 if self.config.keep_warnings else 5
-        for node in self.document.traverse(nodes.system_message):
+        for node in list(self.document.findall(nodes.system_message)):
             if node['level'] < filterlevel:
                 logger.debug('%s [filtered system message]', node.astext())
                 node.parent.remove(node)
@@ -392,10 +386,10 @@
     default_priority = 999
 
     def apply(self, **kwargs: Any) -> None:
-        for node in self.document.traverse(addnodes.manpage):
+        for node in self.document.findall(addnodes.manpage):
             manpage = ' '.join([str(x) for x in node.children
                                 if isinstance(x, nodes.Text)])
-            pattern = r'^(?P<path>(?P<page>.+)[\(\.](?P<section>[1-9]\w*)?\)?)$'  # noqa
+            pattern = r'^(?P<path>(?P<page>.+)[\(\.](?P<section>[1-9]\w*)?\)?)$'
             info = {'path': manpage,
                     'page': manpage,
                     'section': ''}
@@ -403,6 +397,24 @@
             if r:
                 info = r.groupdict()
             node.attributes.update(info)
+
+
+class GlossarySorter(SphinxTransform):
+    """Sort glossaries that have the ``sorted`` flag."""
+    # This must be done after i18n, therefore not right
+    # away in the glossary directive.
+    default_priority = 500
+
+    def apply(self, **kwargs: Any) -> None:
+        for glossary in self.document.findall(addnodes.glossary):
+            if glossary["sorted"]:
+                definition_list = cast(nodes.definition_list, glossary[0])
+                definition_list[:] = sorted(
+                    definition_list,
+                    key=lambda item: unicodedata.normalize(
+                        'NFD',
+                        cast(nodes.term, item)[0].astext().lower())
+                )
 
 
 def setup(app: "Sphinx") -> Dict[str, Any]:
@@ -420,6 +432,7 @@
     app.add_transform(SphinxSmartQuotes)
     app.add_transform(DoctreeReadEvent)
     app.add_transform(ManpageLink)
+    app.add_transform(GlossarySorter)
 
     return {
         'version': 'builtin',
('sphinx/transforms', 'compact_bullet_list.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.transforms.compact_bullet_list
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    Docutils transforms used by Sphinx when reading documents.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Docutils transforms used by Sphinx when reading documents."""
 
 from typing import Any, Dict, List, cast
 
@@ -74,9 +66,9 @@
             else:
                 return True
 
-        for node in self.document.traverse(nodes.bullet_list):
+        for node in self.document.findall(nodes.bullet_list):
             if check_refonly_list(node):
-                for item in node.traverse(nodes.list_item):
+                for item in node.findall(nodes.list_item):
                     para = cast(nodes.paragraph, item[0])
                     ref = cast(nodes.reference, para[0])
                     compact_para = addnodes.compact_paragraph()
('sphinx/transforms', 'i18n.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,14 +1,7 @@
-"""
-    sphinx.transforms.i18n
-    ~~~~~~~~~~~~~~~~~~~~~~
-
-    Docutils transforms used by Sphinx when reading documents.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Docutils transforms used by Sphinx when reading documents."""
 
 from os import path
+from re import DOTALL, match
 from textwrap import indent
 from typing import TYPE_CHECKING, Any, Dict, List, Optional, Tuple, Type, TypeVar
 
@@ -82,6 +75,14 @@
         config.rst_prolog = rst_prolog  # type: ignore
 
 
+def parse_noqa(source: str) -> Tuple[str, bool]:
+    m = match(r"(.*)(?<!\\)#\s*noqa\s*$", source, DOTALL)
+    if m:
+        return m.group(1), True
+    else:
+        return source, False
+
+
 class PreserveTranslatableMessages(SphinxTransform):
     """
     Preserve original translatable messages before translation
@@ -89,7 +90,7 @@
     default_priority = 10  # this MUST be invoked before Locale transform
 
     def apply(self, **kwargs: Any) -> None:
-        for node in self.document.traverse(addnodes.translatable):
+        for node in self.document.findall(addnodes.translatable):
             node.preserve_original_messages()
 
 
@@ -119,6 +120,14 @@
         # phase1: replace reference ids with translated names
         for node, msg in extract_messages(self.document):
             msgstr = catalog.gettext(msg)
+
+            # There is no point in having #noqa on literal blocks because
+            # they cannot contain references.  Recognizing it would just
+            # completely prevent escaping the #noqa.  Outside of literal
+            # blocks, one can always write \#noqa.
+            if not isinstance(node, LITERAL_TYPE_NODES):
+                msgstr, _ = parse_noqa(msgstr)
+
             # XXX add marker to untranslated parts
             if not msgstr or msgstr == msg or not msgstr.strip():
                 # as-of-yet untranslated
@@ -139,6 +148,7 @@
 
             patch = publish_msgstr(self.app, msgstr, source,
                                    node.line, self.config, settings)
+            # FIXME: no warnings about inconsistent references in this part
             # XXX doctest and other block markup
             if not isinstance(patch, nodes.paragraph):
                 continue  # skip for now
@@ -199,7 +209,7 @@
 
                     # replace target's refname to new target name
                     matcher = NodeMatcher(nodes.target, refname=old_name)
-                    for old_target in self.document.traverse(matcher):  # type: nodes.target
+                    for old_target in self.document.findall(matcher):  # type: nodes.target
                         old_target['refname'] = new_name
 
                     processed = True
@@ -228,18 +238,29 @@
                 continue  # skip if the node is already translated by phase1
 
             msgstr = catalog.gettext(msg)
+            noqa = False
+
+            # See above.
+            if not isinstance(node, LITERAL_TYPE_NODES):
+                msgstr, noqa = parse_noqa(msgstr)
+
             # XXX add marker to untranslated parts
             if not msgstr or msgstr == msg:  # as-of-yet untranslated
                 continue
 
             # update translatable nodes
             if isinstance(node, addnodes.translatable):
-                node.apply_translated_message(msg, msgstr)
+                node.apply_translated_message(msg, msgstr)  # type: ignore
                 continue
 
             # update meta nodes
             if isinstance(node, nodes.pending) and is_pending_meta(node):
+                # docutils-0.17 or older
                 node.details['nodes'][0]['content'] = msgstr
+                continue
+            elif isinstance(node, addnodes.docutils_meta):
+                # docutils-0.18+
+                node['content'] = msgstr
                 continue
 
             if isinstance(node, nodes.image) and node.get('alt') == msg:
@@ -268,7 +289,6 @@
 
             patch = publish_msgstr(self.app, msgstr, source,
                                    node.line, self.config, settings)
-
             # Structural Subelements phase2
             if isinstance(node, nodes.title):
                 # get <title> node that placed as a first child
@@ -296,15 +316,15 @@
                     lst.append(new)
 
             is_autofootnote_ref = NodeMatcher(nodes.footnote_reference, auto=Any)
-            old_foot_refs: List[nodes.footnote_reference] = node.traverse(is_autofootnote_ref)
-            new_foot_refs: List[nodes.footnote_reference] = patch.traverse(is_autofootnote_ref)
-            if len(old_foot_refs) != len(new_foot_refs):
+            old_foot_refs: List[nodes.footnote_reference] = list(node.findall(is_autofootnote_ref))  # NOQA
+            new_foot_refs: List[nodes.footnote_reference] = list(patch.findall(is_autofootnote_ref))  # NOQA
+            if not noqa and len(old_foot_refs) != len(new_foot_refs):
                 old_foot_ref_rawsources = [ref.rawsource for ref in old_foot_refs]
                 new_foot_ref_rawsources = [ref.rawsource for ref in new_foot_refs]
                 logger.warning(__('inconsistent footnote references in translated message.' +
                                   ' original: {0}, translated: {1}')
                                .format(old_foot_ref_rawsources, new_foot_ref_rawsources),
-                               location=node)
+                               location=node, type='i18n', subtype='inconsistent_references')
             old_foot_namerefs: Dict[str, List[nodes.footnote_reference]] = {}
             for r in old_foot_refs:
                 old_foot_namerefs.setdefault(r.get('refname'), []).append(r)
@@ -339,15 +359,15 @@
             # * use translated refname for section refname.
             # * inline reference "`Python <...>`_" has no 'refname'.
             is_refnamed_ref = NodeMatcher(nodes.reference, refname=Any)
-            old_refs: List[nodes.reference] = node.traverse(is_refnamed_ref)
-            new_refs: List[nodes.reference] = patch.traverse(is_refnamed_ref)
-            if len(old_refs) != len(new_refs):
+            old_refs: List[nodes.reference] = list(node.findall(is_refnamed_ref))
+            new_refs: List[nodes.reference] = list(patch.findall(is_refnamed_ref))
+            if not noqa and len(old_refs) != len(new_refs):
                 old_ref_rawsources = [ref.rawsource for ref in old_refs]
                 new_ref_rawsources = [ref.rawsource for ref in new_refs]
                 logger.warning(__('inconsistent references in translated message.' +
                                   ' original: {0}, translated: {1}')
                                .format(old_ref_rawsources, new_ref_rawsources),
-                               location=node)
+                               location=node, type='i18n', subtype='inconsistent_references')
             old_ref_names = [r['refname'] for r in old_refs]
             new_ref_names = [r['refname'] for r in new_refs]
             orphans = list(set(old_ref_names) - set(new_ref_names))
@@ -366,16 +386,16 @@
 
             # refnamed footnote should use original 'ids'.
             is_refnamed_footnote_ref = NodeMatcher(nodes.footnote_reference, refname=Any)
-            old_foot_refs = node.traverse(is_refnamed_footnote_ref)
-            new_foot_refs = patch.traverse(is_refnamed_footnote_ref)
+            old_foot_refs = list(node.findall(is_refnamed_footnote_ref))
+            new_foot_refs = list(patch.findall(is_refnamed_footnote_ref))
             refname_ids_map: Dict[str, List[str]] = {}
-            if len(old_foot_refs) != len(new_foot_refs):
+            if not noqa and len(old_foot_refs) != len(new_foot_refs):
                 old_foot_ref_rawsources = [ref.rawsource for ref in old_foot_refs]
                 new_foot_ref_rawsources = [ref.rawsource for ref in new_foot_refs]
                 logger.warning(__('inconsistent footnote references in translated message.' +
                                   ' original: {0}, translated: {1}')
                                .format(old_foot_ref_rawsources, new_foot_ref_rawsources),
-                               location=node)
+                               location=node, type='i18n', subtype='inconsistent_references')
             for oldf in old_foot_refs:
                 refname_ids_map.setdefault(oldf["refname"], []).append(oldf["ids"])
             for newf in new_foot_refs:
@@ -385,16 +405,16 @@
 
             # citation should use original 'ids'.
             is_citation_ref = NodeMatcher(nodes.citation_reference, refname=Any)
-            old_cite_refs: List[nodes.citation_reference] = node.traverse(is_citation_ref)
-            new_cite_refs: List[nodes.citation_reference] = patch.traverse(is_citation_ref)
+            old_cite_refs: List[nodes.citation_reference] = list(node.findall(is_citation_ref))
+            new_cite_refs: List[nodes.citation_reference] = list(patch.findall(is_citation_ref))  # NOQA
             refname_ids_map = {}
-            if len(old_cite_refs) != len(new_cite_refs):
+            if not noqa and len(old_cite_refs) != len(new_cite_refs):
                 old_cite_ref_rawsources = [ref.rawsource for ref in old_cite_refs]
                 new_cite_ref_rawsources = [ref.rawsource for ref in new_cite_refs]
                 logger.warning(__('inconsistent citation references in translated message.' +
                                   ' original: {0}, translated: {1}')
                                .format(old_cite_ref_rawsources, new_cite_ref_rawsources),
-                               location=node)
+                               location=node, type='i18n', subtype='inconsistent_references')
             for oldc in old_cite_refs:
                 refname_ids_map.setdefault(oldc["refname"], []).append(oldc["ids"])
             for newc in new_cite_refs:
@@ -405,16 +425,16 @@
             # Original pending_xref['reftarget'] contain not-translated
             # target name, new pending_xref must use original one.
             # This code restricts to change ref-targets in the translation.
-            old_xrefs = node.traverse(addnodes.pending_xref)
-            new_xrefs = patch.traverse(addnodes.pending_xref)
+            old_xrefs = list(node.findall(addnodes.pending_xref))
+            new_xrefs = list(patch.findall(addnodes.pending_xref))
             xref_reftarget_map = {}
-            if len(old_xrefs) != len(new_xrefs):
+            if not noqa and len(old_xrefs) != len(new_xrefs):
                 old_xref_rawsources = [xref.rawsource for xref in old_xrefs]
                 new_xref_rawsources = [xref.rawsource for xref in new_xrefs]
                 logger.warning(__('inconsistent term references in translated message.' +
                                   ' original: {0}, translated: {1}')
                                .format(old_xref_rawsources, new_xref_rawsources),
-                               location=node)
+                               location=node, type='i18n', subtype='inconsistent_references')
 
             def get_ref_key(node: addnodes.pending_xref) -> Optional[Tuple[str, str, str]]:
                 case = node["refdomain"], node["reftype"]
@@ -457,7 +477,7 @@
             # Extract and translate messages for index entries.
             for node, entries in traverse_translatable_index(self.document):
                 new_entries: List[Tuple[str, str, str, str, str]] = []
-                for type, msg, tid, main, key_ in entries:
+                for type, msg, tid, main, _key in entries:
                     msg_parts = split_index_msg(type, msg)
                     msgstr_parts = []
                     for part in msg_parts:
@@ -472,7 +492,7 @@
                 node['entries'] = new_entries
 
         # remove translated attribute that is used for avoiding double translation.
-        for translated in self.document.traverse(NodeMatcher(translated=Any)):  # type: Element  # NOQA
+        for translated in self.document.findall(NodeMatcher(translated=Any)):  # type: Element  # NOQA
             translated.delattr('translated')
 
 
@@ -488,7 +508,7 @@
             return
 
         matcher = NodeMatcher(nodes.inline, translatable=Any)
-        for inline in self.document.traverse(matcher):  # type: nodes.inline
+        for inline in list(self.document.findall(matcher)):  # type: nodes.inline
             inline.parent.remove(inline)
             inline.parent += inline.children
 
('sphinx/transforms/post_transforms', 'code.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.transforms.post_transforms.code
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    transforms for code-blocks.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""transforms for code-blocks."""
 
 import sys
 from typing import Any, Dict, List, NamedTuple
@@ -42,7 +34,7 @@
                                            self.config.highlight_language)
         self.document.walkabout(visitor)
 
-        for node in self.document.traverse(addnodes.highlightlang):
+        for node in list(self.document.findall(addnodes.highlightlang)):
             node.parent.remove(node)
 
 
@@ -94,11 +86,11 @@
     default_priority = HighlightLanguageTransform.default_priority + 1
 
     def apply(self, **kwargs: Any) -> None:
-        for lbnode in self.document.traverse(nodes.literal_block):  # type: nodes.literal_block
+        for lbnode in self.document.findall(nodes.literal_block):
             if self.is_pyconsole(lbnode):
                 self.strip_doctest_flags(lbnode)
 
-        for dbnode in self.document.traverse(nodes.doctest_block):  # type: nodes.doctest_block
+        for dbnode in self.document.findall(nodes.doctest_block):
             self.strip_doctest_flags(dbnode)
 
     def strip_doctest_flags(self, node: TextElement) -> None:
('sphinx/transforms/post_transforms', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.transforms.post_transforms
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    Docutils transforms used by Sphinx.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Docutils transforms used by Sphinx."""
 
 import re
 from typing import Any, Dict, List, Optional, Sequence, Tuple, Type, cast
@@ -67,7 +59,7 @@
     default_priority = 10
 
     def run(self, **kwargs: Any) -> None:
-        for node in self.document.traverse(addnodes.pending_xref):
+        for node in self.document.findall(addnodes.pending_xref):
             content = self.find_pending_xref_condition(node, ("resolved", "*"))
             if content:
                 contnode = cast(Element, content[0].deepcopy())
@@ -78,7 +70,8 @@
 
             typ = node['reftype']
             target = node['reftarget']
-            refdoc = node.get('refdoc', self.env.docname)
+            node.setdefault('refdoc', self.env.docname)
+            refdoc = node.get('refdoc')
             domain = None
 
             try:
@@ -119,7 +112,9 @@
 
             node.replace_self(newnodes)
 
-    def resolve_anyref(self, refdoc: str, node: pending_xref, contnode: Element) -> Element:
+    def resolve_anyref(
+        self, refdoc: str, node: pending_xref, contnode: Element
+    ) -> Optional[Element]:
         """Resolve reference generated by the "any" role."""
         stddomain = self.env.get_domain('std')
         target = node['reftarget']
@@ -250,7 +245,7 @@
             self.fallback(addnodes.desc_inline)
 
     def fallback(self, nodeType: Any) -> None:
-        for node in self.document.traverse(nodeType):
+        for node in self.document.findall(nodeType):
             newnode = nodes.inline()
             newnode.update_all_atts(node)
             newnode.extend(node)
@@ -262,7 +257,7 @@
     default_priority = 200
 
     def run(self, **kwargs: Any) -> None:
-        for node in self.document.traverse(addnodes.desc_signature):
+        for node in self.document.findall(addnodes.desc_signature):
             if node.parent.get('domain'):
                 node['classes'].append(node.parent['domain'])
 
('sphinx/transforms/post_transforms', 'images.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.transforms.post_transforms.images
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    Docutils transforms used by Sphinx.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Docutils transforms used by Sphinx."""
 
 import os
 import re
@@ -30,7 +22,7 @@
 
 class BaseImageConverter(SphinxTransform):
     def apply(self, **kwargs: Any) -> None:
-        for node in self.document.traverse(nodes.image):
+        for node in self.document.findall(nodes.image):
             if self.match(node):
                 self.handle(node)
 
@@ -197,6 +189,8 @@
     def match(self, node: nodes.image) -> bool:
         if not self.app.builder.supported_image_types:
             return False
+        elif '?' in node['candidates']:
+            return False
         elif set(self.guess_mimetypes(node)) & set(self.app.builder.supported_image_types):
             # builder supports the image; no need to convert
             return False
('sphinx/environment', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.environment
-    ~~~~~~~~~~~~~~~~~~
-
-    Global creation environment.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Global creation environment."""
 
 import os
 import pickle
@@ -18,6 +10,7 @@
 from typing import (TYPE_CHECKING, Any, Callable, Dict, Generator, Iterator, List, Optional,
                     Set, Tuple, Union)
 
+import docutils
 from docutils import nodes
 from docutils.nodes import Node
 
@@ -45,23 +38,28 @@
 logger = logging.getLogger(__name__)
 
 default_settings: Dict[str, Any] = {
+    'auto_id_prefix': 'id',
+    'image_loading': 'link',
     'embed_stylesheet': False,
     'cloak_email_addresses': True,
-    'pep_base_url': 'https://www.python.org/dev/peps/',
+    'pep_base_url': 'https://peps.python.org/',
     'pep_references': None,
-    'rfc_base_url': 'https://tools.ietf.org/html/',
+    'rfc_base_url': 'https://datatracker.ietf.org/doc/html/',
     'rfc_references': None,
     'input_encoding': 'utf-8-sig',
     'doctitle_xform': False,
     'sectsubtitle_xform': False,
+    'section_self_link': False,
     'halt_level': 5,
     'file_insertion_enabled': True,
     'smartquotes_locales': [],
 }
+if docutils.__version_info__[:2] <= (0, 17):
+    default_settings['embed_images'] = False
 
 # This is increased every time an environment attribute is added
 # or changed to properly invalidate pickle files.
-ENV_VERSION = 56
+ENV_VERSION = 57
 
 # config status
 CONFIG_OK = 1
@@ -80,6 +78,60 @@
     'none': False,
     'text': is_translatable,
 }
+
+if TYPE_CHECKING:
+    from collections.abc import MutableMapping
+
+    from typing_extensions import Literal, overload
+
+    from sphinx.domains.c import CDomain
+    from sphinx.domains.changeset import ChangeSetDomain
+    from sphinx.domains.citation import CitationDomain
+    from sphinx.domains.cpp import CPPDomain
+    from sphinx.domains.index import IndexDomain
+    from sphinx.domains.javascript import JavaScriptDomain
+    from sphinx.domains.math import MathDomain
+    from sphinx.domains.python import PythonDomain
+    from sphinx.domains.rst import ReSTDomain
+    from sphinx.domains.std import StandardDomain
+    from sphinx.ext.duration import DurationDomain
+    from sphinx.ext.todo import TodoDomain
+
+    class _DomainsType(MutableMapping[str, Domain]):
+        @overload
+        def __getitem__(self, key: Literal["c"]) -> CDomain: ...  # NoQA: E704
+        @overload
+        def __getitem__(self, key: Literal["cpp"]) -> CPPDomain: ...  # NoQA: E704
+        @overload
+        def __getitem__(self, key: Literal["changeset"]) -> ChangeSetDomain: ...  # NoQA: E704
+        @overload
+        def __getitem__(self, key: Literal["citation"]) -> CitationDomain: ...  # NoQA: E704
+        @overload
+        def __getitem__(self, key: Literal["index"]) -> IndexDomain: ...  # NoQA: E704
+        @overload
+        def __getitem__(self, key: Literal["js"]) -> JavaScriptDomain: ...  # NoQA: E704
+        @overload
+        def __getitem__(self, key: Literal["math"]) -> MathDomain: ...  # NoQA: E704
+        @overload
+        def __getitem__(self, key: Literal["py"]) -> PythonDomain: ...  # NoQA: E704
+        @overload
+        def __getitem__(self, key: Literal["rst"]) -> ReSTDomain: ...  # NoQA: E704
+        @overload
+        def __getitem__(self, key: Literal["std"]) -> StandardDomain: ...  # NoQA: E704
+        @overload
+        def __getitem__(self, key: Literal["duration"]) -> DurationDomain: ...  # NoQA: E704
+        @overload
+        def __getitem__(self, key: Literal["todo"]) -> TodoDomain: ...  # NoQA: E704
+        @overload
+        def __getitem__(self, key: str) -> Domain: ...  # NoQA: E704
+        def __getitem__(self, key): raise NotImplementedError  # NoQA: E704
+        def __setitem__(self, key, value): raise NotImplementedError  # NoQA: E704
+        def __delitem__(self, key): raise NotImplementedError  # NoQA: E704
+        def __iter__(self): raise NotImplementedError  # NoQA: E704
+        def __len__(self): raise NotImplementedError  # NoQA: E704
+
+else:
+    _DomainsType = dict
 
 
 class BuildEnvironment:
@@ -89,11 +141,11 @@
     transformations to resolve links to them.
     """
 
-    domains: Dict[str, Domain]
+    domains: _DomainsType
 
     # --------- ENVIRONMENT INITIALIZATION -------------------------------------
 
-    def __init__(self, app: "Sphinx" = None):
+    def __init__(self, app: Optional["Sphinx"] = None):
         self.app: Sphinx = None
         self.doctreedir: str = None
         self.srcdir: str = None
@@ -109,7 +161,7 @@
         self.versioning_compare: bool = None
 
         # all the registered domains, set by the application
-        self.domains = {}
+        self.domains = _DomainsType()
 
         # the docutils settings for building
         self.settings = default_settings.copy()
@@ -214,7 +266,7 @@
         self.version = app.registry.get_envversion(app)
 
         # initialize domains
-        self.domains = {}
+        self.domains = _DomainsType()
         for domain in app.registry.create_domains(self):
             self.domains[domain.name] = domain
 
@@ -258,7 +310,7 @@
         """Update settings by new config."""
         self.settings['input_encoding'] = config.source_encoding
         self.settings['trim_footnote_reference_space'] = config.trim_footnote_reference_space
-        self.settings['language_code'] = config.language or 'en'
+        self.settings['language_code'] = config.language
 
         # Allow to disable by 3rd party extension (workaround)
         self.settings.setdefault('smart_quotes', True)
@@ -329,7 +381,7 @@
         """
         return self.project.doc2path(docname, base)
 
-    def relfn2path(self, filename: str, docname: str = None) -> Tuple[str, str]:
+    def relfn2path(self, filename: str, docname: Optional[str] = None) -> Tuple[str, str]:
         """Return paths to a file referenced from a document, relative to
         documentation root and absolute.
 
@@ -342,7 +394,7 @@
             rel_fn = filename[1:]
         else:
             docdir = path.dirname(self.doc2path(docname or self.docname,
-                                                base=None))
+                                                base=False))
             rel_fn = path.join(docdir, filename)
 
         return (canon_path(path.normpath(rel_fn)),
@@ -361,7 +413,7 @@
             exclude_paths = (self.config.exclude_patterns +
                              self.config.templates_path +
                              builder.get_asset_paths())
-            self.project.discover(exclude_paths)
+            self.project.discover(exclude_paths, self.config.include_patterns)
 
             # Current implementation is applying translated messages in the reading
             # phase.Therefore, in order to apply the updated message catalog, it is
@@ -490,7 +542,9 @@
 
         *filename* should be absolute or relative to the source directory.
         """
-        self.included[self.docname].add(self.path2doc(filename))
+        doc = self.path2doc(filename)
+        if doc:
+            self.included[self.docname].add(doc)
 
     def note_reread(self) -> None:
         """Add the current document to the list of documents that will
@@ -519,9 +573,14 @@
         doctree.reporter = LoggingReporter(self.doc2path(docname))
         return doctree
 
-    def get_and_resolve_doctree(self, docname: str, builder: "Builder",
-                                doctree: nodes.document = None, prune_toctrees: bool = True,
-                                includehidden: bool = False) -> nodes.document:
+    def get_and_resolve_doctree(
+        self,
+        docname: str,
+        builder: "Builder",
+        doctree: Optional[nodes.document] = None,
+        prune_toctrees: bool = True,
+        includehidden: bool = False
+    ) -> nodes.document:
         """Read the doctree from the pickle, resolve cross-references and
         toctrees and return it.
         """
@@ -532,7 +591,7 @@
         self.apply_post_transforms(doctree, docname)
 
         # now, resolve all toctree nodes
-        for toctreenode in doctree.traverse(addnodes.toctree):
+        for toctreenode in doctree.findall(addnodes.toctree):
             result = TocTree(self).resolve(docname, builder, toctreenode,
                                            prune=prune_toctrees,
                                            includehidden=includehidden)
@@ -545,7 +604,7 @@
 
     def resolve_toctree(self, docname: str, builder: "Builder", toctree: addnodes.toctree,
                         prune: bool = True, maxdepth: int = 0, titles_only: bool = False,
-                        collapse: bool = False, includehidden: bool = False) -> Node:
+                        collapse: bool = False, includehidden: bool = False) -> Optional[Node]:
         """Resolve a *toctree* node into individual bullet lists with titles
         as items, returning None (if no containing titles are found) or
         a new node.
@@ -585,7 +644,9 @@
     def collect_relations(self) -> Dict[str, List[Optional[str]]]:
         traversed = set()
 
-        def traverse_toctree(parent: str, docname: str) -> Iterator[Tuple[str, str]]:
+        def traverse_toctree(
+            parent: Optional[str], docname: str
+        ) -> Iterator[Tuple[Optional[str], str]]:
             if parent == docname:
                 logger.warning(__('self referenced toctree found. Ignored.'),
                                location=docname, type='toc',
@@ -618,7 +679,7 @@
 
     def check_consistency(self) -> None:
         """Do consistency checks."""
-        included = set().union(*self.included.values())  # type: ignore
+        included = set().union(*self.included.values())
         for docname in sorted(self.all_docs):
             if docname not in self.files_to_rebuild:
                 if docname == self.config.root_doc:
('sphinx/environment/collectors', 'toctree.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,14 +1,6 @@
-"""
-    sphinx.environment.collectors.toctree
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    Toctree collector for sphinx.environment.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
-
-from typing import Any, Dict, List, Set, Tuple, Type, TypeVar, cast
+"""Toctree collector for sphinx.environment."""
+
+from typing import Any, Dict, List, Optional, Sequence, Set, Tuple, TypeVar, Union, cast
 
 from docutils import nodes
 from docutils.nodes import Element, Node
@@ -62,20 +54,14 @@
         docname = app.env.docname
         numentries = [0]  # nonlocal again...
 
-        def traverse_in_section(node: Element, cls: Type[N]) -> List[N]:
-            """Like traverse(), but stay within the same section."""
-            result: List[N] = []
-            if isinstance(node, cls):
-                result.append(node)
-            for child in node.children:
-                if isinstance(child, nodes.section):
-                    continue
-                elif isinstance(child, nodes.Element):
-                    result.extend(traverse_in_section(child, cls))
-            return result
-
-        def build_toc(node: Element, depth: int = 1) -> nodes.bullet_list:
+        def build_toc(
+            node: Union[Element, Sequence[Element]],
+            depth: int = 1
+        ) -> Optional[nodes.bullet_list]:
+            # list of table of contents entries
             entries: List[Element] = []
+            # cache of parents -> list item
+            memo_parents: Dict[Tuple[str, ...], nodes.list_item] = {}
             for sectionnode in node:
                 # find all toctree nodes in this section and add them
                 # to the toc (just copying the toctree node which is then
@@ -87,13 +73,7 @@
                     visitor = SphinxContentsFilter(doctree)
                     title.walkabout(visitor)
                     nodetext = visitor.get_entry_text()
-                    if not numentries[0]:
-                        # for the very first toc entry, don't add an anchor
-                        # as it is the file's title anyway
-                        anchorname = ''
-                    else:
-                        anchorname = '#' + sectionnode['ids'][0]
-                    numentries[0] += 1
+                    anchorname = _make_anchor_name(sectionnode['ids'], numentries)
                     # make these nodes:
                     # list_item -> compact_paragraph -> reference
                     reference = nodes.reference(
@@ -105,22 +85,67 @@
                     if sub_item:
                         item += sub_item
                     entries.append(item)
+                # Wrap items under an ``.. only::`` directive in a node for
+                # post-processing
                 elif isinstance(sectionnode, addnodes.only):
                     onlynode = addnodes.only(expr=sectionnode['expr'])
                     blist = build_toc(sectionnode, depth)
                     if blist:
                         onlynode += blist.children
                         entries.append(onlynode)
+                # check within the section for other node types
                 elif isinstance(sectionnode, nodes.Element):
-                    for toctreenode in traverse_in_section(sectionnode,
-                                                           addnodes.toctree):
-                        item = toctreenode.copy()
-                        entries.append(item)
-                        # important: do the inventory stuff
-                        TocTree(app.env).note(docname, toctreenode)
+                    toctreenode: nodes.Node
+                    for toctreenode in sectionnode.findall():
+                        if isinstance(toctreenode, nodes.section):
+                            continue
+                        if isinstance(toctreenode, addnodes.toctree):
+                            item = toctreenode.copy()
+                            entries.append(item)
+                            # important: do the inventory stuff
+                            TocTree(app.env).note(docname, toctreenode)
+                        # add object signatures within a section to the ToC
+                        elif isinstance(toctreenode, addnodes.desc):
+                            for sig_node in toctreenode:
+                                if not isinstance(sig_node, addnodes.desc_signature):
+                                    continue
+                                # Skip if no name set
+                                if not sig_node.get('_toc_name', ''):
+                                    continue
+                                # Skip entries with no ID (e.g. with :noindex: set)
+                                ids = sig_node['ids']
+                                if not ids or sig_node.parent.get('noindexentry'):
+                                    continue
+
+                                anchorname = _make_anchor_name(ids, numentries)
+
+                                reference = nodes.reference(
+                                    '', '', nodes.literal('', sig_node['_toc_name']),
+                                    internal=True, refuri=docname, anchorname=anchorname)
+                                para = addnodes.compact_paragraph('', '', reference,
+                                                                  skip_section_number=True)
+                                entry = nodes.list_item('', para)
+                                *parents, _ = sig_node['_toc_parts']
+                                parents = tuple(parents)
+
+                                # Cache parents tuple
+                                memo_parents[sig_node['_toc_parts']] = entry
+
+                                # Nest children within parents
+                                if parents and parents in memo_parents:
+                                    root_entry = memo_parents[parents]
+                                    if isinstance(root_entry[-1], nodes.bullet_list):
+                                        root_entry[-1].append(entry)
+                                    else:
+                                        root_entry.append(nodes.bullet_list('', entry))
+                                    continue
+
+                                entries.append(entry)
+
             if entries:
                 return nodes.bullet_list('', *entries)
             return None
+
         toc = build_toc(doctree)
         if toc:
             app.env.tocs[docname] = toc
@@ -140,7 +165,9 @@
         old_secnumbers = env.toc_secnumbers
         env.toc_secnumbers = {}
 
-        def _walk_toc(node: Element, secnums: Dict, depth: int, titlenode: nodes.title = None) -> None:  # NOQA
+        def _walk_toc(
+            node: Element, secnums: Dict, depth: int, titlenode: Optional[nodes.title] = None
+        ) -> None:
             # titlenode is the title of the document, it will get assigned a
             # secnumber too, so that it shows up in next/prev/parent rellinks
             for subnode in node.children:
@@ -159,6 +186,8 @@
                     _walk_toc(subnode, secnums, depth, titlenode)
                     titlenode = None
                 elif isinstance(subnode, addnodes.compact_paragraph):
+                    if 'skip_section_number' in subnode:
+                        continue
                     numstack[-1] += 1
                     reference = cast(nodes.reference, subnode[0])
                     if depth > 0:
@@ -177,7 +206,7 @@
         def _walk_toctree(toctreenode: addnodes.toctree, depth: int) -> None:
             if depth == 0:
                 return
-            for (title, ref) in toctreenode['entries']:
+            for (_title, ref) in toctreenode['entries']:
                 if url_re.match(ref) or ref == 'self':
                     # don't mess with those
                     continue
@@ -196,7 +225,7 @@
         for docname in env.numbered_toctrees:
             assigned.add(docname)
             doctree = env.get_doctree(docname)
-            for toctreenode in doctree.traverse(addnodes.toctree):
+            for toctreenode in doctree.findall(addnodes.toctree):
                 depth = toctreenode.get('numbered', 0)
                 if depth:
                     # every numbered toctree gets new numbering
@@ -207,6 +236,7 @@
 
     def assign_figure_numbers(self, env: BuildEnvironment) -> List[str]:
         """Assign a figure number to each figure under a numbered toctree."""
+        generated_docnames = frozenset(env.domains['std'].initial_data['labels'].keys())
 
         rewrite_needed = []
 
@@ -215,10 +245,11 @@
         env.toc_fignumbers = {}
         fignum_counter: Dict[str, Dict[Tuple[int, ...], int]] = {}
 
-        def get_figtype(node: Node) -> str:
+        def get_figtype(node: Node) -> Optional[str]:
             for domain in env.domains.values():
                 figtype = domain.get_enumerable_node_type(node)
-                if domain.name == 'std' and not domain.get_numfig_title(node):  # type: ignore
+                if (domain.name == 'std'
+                        and not domain.get_numfig_title(node)):  # type: ignore[attr-defined]  # NoQA: E501,W503
                     # Skip if uncaptioned node
                     continue
 
@@ -235,7 +266,7 @@
             else:
                 secnum = secnumbers.get('')
 
-            return secnum or tuple()
+            return secnum or ()
 
         def get_next_fignumber(figtype: str, secnum: Tuple[int, ...]) -> Tuple[int, ...]:
             counter = fignum_counter.setdefault(figtype, {})
@@ -253,6 +284,7 @@
             fignumbers[figure_id] = get_next_fignumber(figtype, secnum)
 
         def _walk_doctree(docname: str, doctree: Element, secnum: Tuple[int, ...]) -> None:
+            nonlocal generated_docnames
             for subnode in doctree.children:
                 if isinstance(subnode, nodes.section):
                     next_secnum = get_section_number(docname, subnode)
@@ -261,9 +293,12 @@
                     else:
                         _walk_doctree(docname, subnode, secnum)
                 elif isinstance(subnode, addnodes.toctree):
-                    for title, subdocname in subnode['entries']:
+                    for _title, subdocname in subnode['entries']:
                         if url_re.match(subdocname) or subdocname == 'self':
                             # don't mess with those
+                            continue
+                        if subdocname in generated_docnames:
+                            # or these
                             continue
 
                         _walk_doc(subdocname, secnum)
@@ -281,12 +316,23 @@
                 _walk_doctree(docname, doctree, secnum)
 
         if env.config.numfig:
-            _walk_doc(env.config.root_doc, tuple())
+            _walk_doc(env.config.root_doc, ())
             for docname, fignums in env.toc_fignumbers.items():
                 if fignums != old_fignumbers.get(docname):
                     rewrite_needed.append(docname)
 
         return rewrite_needed
+
+
+def _make_anchor_name(ids: List[str], num_entries: List[int]) -> str:
+    if not num_entries[0]:
+        # for the very first toc entry, don't add an anchor
+        # as it is the file's title anyway
+        anchorname = ''
+    else:
+        anchorname = '#' + ids[0]
+    num_entries[0] += 1
+    return anchorname
 
 
 def setup(app: Sphinx) -> Dict[str, Any]:
('sphinx/environment/collectors', 'metadata.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.environment.collectors.metadata
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    The metadata collector components for sphinx.environment.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""The metadata collector components for sphinx.environment."""
 
 from typing import Any, Dict, List, Set, cast
 
@@ -33,9 +25,12 @@
 
         Keep processing minimal -- just return what docutils says.
         """
-        if len(doctree) > 0 and isinstance(doctree[0], nodes.docinfo):
+        index = doctree.first_child_not_matching_class(nodes.PreBibliographic)
+        if index is None:
+            return
+        elif isinstance(doctree[index], nodes.docinfo):
             md = app.env.metadata[app.env.docname]
-            for node in doctree[0]:
+            for node in doctree[index]:  # type: ignore
                 # nodes are multiply inherited...
                 if isinstance(node, nodes.authors):
                     authors = cast(List[nodes.author], node)
@@ -58,7 +53,7 @@
                         value = 0
                     md[name] = value
 
-            doctree.pop(0)
+            doctree.pop(index)
 
 
 def setup(app: Sphinx) -> Dict[str, Any]:
('sphinx/environment/collectors', 'asset.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.environment.collectors.asset
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    The image collector for sphinx.environment.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""The image collector for sphinx.environment."""
 
 import os
 from glob import glob
@@ -43,7 +35,7 @@
         """Process and rewrite image URIs."""
         docname = app.env.docname
 
-        for node in doctree.traverse(nodes.image):
+        for node in doctree.findall(nodes.image):
             # Map the mimetype to the corresponding image.  The writer may
             # choose the best image from these candidates.  The special key * is
             # set if there is only single candidate to be used by a writer.
@@ -64,18 +56,16 @@
                 rel_imgpath, full_imgpath = app.env.relfn2path(imguri, docname)
                 node['uri'] = rel_imgpath
 
-                if app.config.language:
-                    # Search language-specific figures at first
-                    i18n_imguri = get_image_filename_for_language(imguri, app.env)
-                    _, full_i18n_imgpath = app.env.relfn2path(i18n_imguri, docname)
-                    self.collect_candidates(app.env, full_i18n_imgpath, candidates, node)
+                # Search language-specific figures at first
+                i18n_imguri = get_image_filename_for_language(imguri, app.env)
+                _, full_i18n_imgpath = app.env.relfn2path(i18n_imguri, docname)
+                self.collect_candidates(app.env, full_i18n_imgpath, candidates, node)
 
                 self.collect_candidates(app.env, full_imgpath, candidates, node)
             else:
-                if app.config.language:
-                    # substitute imguri by figure_language_filename
-                    # (ex. foo.png -> foo.en.png)
-                    imguri = search_image_for_language(imguri, app.env)
+                # substitute imguri by figure_language_filename
+                # (ex. foo.png -> foo.en.png)
+                imguri = search_image_for_language(imguri, app.env)
 
                 # Update `node['uri']` to a relative path from srcdir
                 # from a relative path from current document.
@@ -124,7 +114,7 @@
 
     def process_doc(self, app: Sphinx, doctree: nodes.document) -> None:
         """Process downloadable file paths. """
-        for node in doctree.traverse(addnodes.download_reference):
+        for node in doctree.findall(addnodes.download_reference):
             targetname = node['reftarget']
             if '://' in targetname:
                 node['refuri'] = targetname
('sphinx/environment/collectors', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.environment.collectors
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    The data collector components for sphinx.environment.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""The data collector components for sphinx.environment."""
 
 from typing import TYPE_CHECKING, Dict, List, Optional, Set
 
('sphinx/environment/collectors', 'dependencies.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.environment.collectors.dependencies
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    The dependencies collector components for sphinx.environment.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""The dependencies collector components for sphinx.environment."""
 
 import os
 from os import path
('sphinx/environment/collectors', 'title.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.environment.collectors.title
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    The title collector components for sphinx.environment.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""The title collector components for sphinx.environment."""
 
 from typing import Any, Dict, Set
 
@@ -43,7 +35,7 @@
             longtitlenode = nodes.title()
             longtitlenode += nodes.Text(doctree['title'])
         # look for first section title and use that as the title
-        for node in doctree.traverse(nodes.section):
+        for node in doctree.findall(nodes.section):
             visitor = SphinxContentsFilter(doctree)
             node[0].walkabout(visitor)
             titlenode += visitor.get_entry_text()
('sphinx/environment/adapters', 'toctree.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,14 +1,6 @@
-"""
-    sphinx.environment.adapters.toctree
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    Toctree adapter for sphinx.environment.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
-
-from typing import TYPE_CHECKING, Any, Iterable, List, Optional, cast
+"""Toctree adapter for sphinx.environment."""
+
+from typing import TYPE_CHECKING, Any, Dict, Iterable, List, Optional, Tuple, cast
 
 from docutils import nodes
 from docutils.nodes import Element, Node
@@ -62,6 +54,7 @@
         """
         if toctree.get('hidden', False) and not includehidden:
             return None
+        generated_docnames: Dict[str, Tuple[str, str, str]] = self.env.domains['std'].initial_data['labels'].copy()  # NoQA: E501
 
         # For reading the following two helper function, it is useful to keep
         # in mind the node structure of a toctree (using HTML-like node names
@@ -82,6 +75,7 @@
         # interactions between marking and pruning the tree (see bug #1046).
 
         toctree_ancestors = self.get_toctree_ancestors(docname)
+        included = Matcher(self.env.config.include_patterns)
         excluded = Matcher(self.env.config.exclude_patterns)
 
         def _toctree_add_classes(node: Element, depth: int) -> None:
@@ -146,6 +140,16 @@
                         item = nodes.list_item('', para)
                         # don't show subitems
                         toc = nodes.bullet_list('', item)
+                    elif ref in generated_docnames:
+                        docname, _, sectionname = generated_docnames[ref]
+                        if not title:
+                            title = sectionname
+                        reference = nodes.reference('', title, internal=True,
+                                                    refuri=docname, anchorname='')
+                        para = addnodes.compact_paragraph('', '', reference)
+                        item = nodes.list_item('', para)
+                        # don't show subitems
+                        toc = nodes.bullet_list('', item)
                     else:
                         if ref in parents:
                             logger.warning(__('circular toctree references '
@@ -161,7 +165,7 @@
                         process_only_nodes(toc, builder.tags)
                         if title and toc.children and len(toc.children) == 1:
                             child = toc.children[0]
-                            for refnode in child.traverse(nodes.reference):
+                            for refnode in child.findall(nodes.reference):
                                 if refnode['refuri'] == ref and \
                                    not refnode['anchorname']:
                                     refnode.children = [nodes.Text(title)]
@@ -172,8 +176,10 @@
                                        ref, location=toctreenode)
                 except KeyError:
                     # this is raised if the included file does not exist
-                    if excluded(self.env.doc2path(ref, None)):
+                    if excluded(self.env.doc2path(ref, False)):
                         message = __('toctree contains reference to excluded document %r')
+                    elif not included(self.env.doc2path(ref, False)):
+                        message = __('toctree contains reference to non-included document %r')
                     else:
                         message = __('toctree contains reference to nonexisting document %r')
 
@@ -193,13 +199,13 @@
                         for toplevel in children:
                             # nodes with length 1 don't have any children anyway
                             if len(toplevel) > 1:
-                                subtrees = toplevel.traverse(addnodes.toctree)
+                                subtrees = list(toplevel.findall(addnodes.toctree))
                                 if subtrees:
                                     toplevel[1][:] = subtrees  # type: ignore
                                 else:
                                     toplevel.pop(1)
                     # resolve all sub-toctrees
-                    for subtocnode in toc.traverse(addnodes.toctree):
+                    for subtocnode in list(toc.findall(addnodes.toctree)):
                         if not (subtocnode.get('hidden', False) and
                                 not includehidden):
                             i = subtocnode.parent.index(subtocnode) + 1
@@ -257,7 +263,7 @@
 
         # set the target paths in the toctrees (they are not known at TOC
         # generation time)
-        for refnode in newnode.traverse(nodes.reference):
+        for refnode in newnode.findall(nodes.reference):
             if not url_re.match(refnode['refuri']):
                 refnode['refuri'] = builder.get_relative_uri(
                     docname, refnode['refuri']) + refnode['anchorname']
@@ -308,7 +314,7 @@
             # renders to nothing
             return nodes.paragraph()
         process_only_nodes(toc, builder.tags)
-        for node in toc.traverse(nodes.reference):
+        for node in toc.findall(nodes.reference):
             node['refuri'] = node['anchorname'] or '#'
         return toc
 
@@ -324,7 +330,7 @@
         else:
             kwargs['maxdepth'] = int(kwargs['maxdepth'])
         kwargs['collapse'] = collapse
-        for toctreenode in doctree.traverse(addnodes.toctree):
+        for toctreenode in doctree.findall(addnodes.toctree):
             toctree = self.resolve(docname, builder, toctreenode, prune=True, **kwargs)
             if toctree:
                 toctrees.append(toctree)
('sphinx/environment/adapters', 'asset.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,12 +1,4 @@
-"""
-    sphinx.environment.adapters.asset
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    Assets adapter for sphinx.environment.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Assets adapter for sphinx.environment."""
 
 from sphinx.environment import BuildEnvironment
 
('sphinx/environment/adapters', '__init__.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,9 +1 @@
-"""
-    sphinx.environment.adapters
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    Sphinx environment adapters
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Sphinx environment adapters"""
('sphinx/environment/adapters', 'indexentries.py')
--- /Users/tshi/researchProjs/sphinx/sphinx-4.2.0/
+++ /Users/tshi/researchProjs/sphinx/sphinx-5.2.0/
@@ -1,17 +1,9 @@
-"""
-    sphinx.environment.adapters.indexentries
-    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-    Index entries adapters for sphinx.environment.
-
-    :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+"""Index entries adapters for sphinx.environment."""
 
 import re
 import unicodedata
 from itertools import groupby
-from typing import Any, Dict, List, Pattern, Tuple, cast
+from typing import Any, Dict, List, Optional, Pattern, Tuple, cast
 
 from sphinx.builders import Builder
 from sphinx.domains.index import IndexDomain
@@ -33,8 +25,8 @@
         """Create the real index from the collected index entries."""
         new: Dict[str, List] = {}
 
-        def add_entry(word: str, subword: str, main: str, link: bool = True,
-                      dic: Dict = new, key: str = None) -> None:
+        def add_entry(word: str, subword: str, main: Optional[str], link: bool = True,
+                      dic: Dict[str, List] = new, key: Optional[str] = None) -> None:
             # Force the word to be unicode if it's a ASCII bytestring.
             # This will solve problems with unicode normalization later.
             # For instance the RFC role will add bytestrings at the moment
@@ -55,7 +47,7 @@
         domain = cast(IndexDomain, self.env.get_domain('index'))
         for fn, entries in domain.entries.items():
             # new entry types must be listed in directives/other.py!
-            for type, value, tid, main, index_key in entries:
+            for type, value, tid, main, index_key in entries:  # noqa: B007
                 try:
                     if type == 'single':
                         try:
@@ -126,7 +118,7 @@
             #     (in module foo)
             #     (in module bar)
             oldkey = ''
-            oldsubitems: Dict[str, List] = None
+            oldsubitems: Optional[Dict[str, List]] = None
             i = 0
             while i < len(newlist):
                 key, (targets, subitems, _key) = newlist[i]
